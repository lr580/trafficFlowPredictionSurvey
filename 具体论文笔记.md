è¯´æ˜ï¼š

- æ‰€æœ‰è®ºæ–‡æŒ‰è‡ªå®šä¹‰ç¼–å· **T-XXX**ï¼Œç¼–å·å¯¹åº”è¡¨å­˜å‚¨åœ¨ Zotero é‡Œï¼Œè‡ªè¡ŒæŸ¥é˜…ã€‚æ”¶å½•å…·ä½“å®ç°è®ºæ–‡ï¼Œä¸åŒ…æ‹¬ç»¼è¿°ã€‚ç»¼è¿°åœ¨ `å†…å®¹æ•´ç†.md` ä¸»è¦è®°å½•ã€‚

- å¼•ç”¨é‡æˆªæ­¢æŸ¥è¯¢æ—¶é—´(æŒ‰ 2024 æš‘å‡ç®—)ï¼Œå‚è€ƒè°·æ­Œå­¦æœ¯ï¼ŒæŒ‰ **CI-xxx** è¡¨ç¤ºå¼•ç”¨é‡ã€‚(CI: cite)

- CCF è¯„çº§æŒ‰ç…§ **CCF-xxx** æ¥ã€‚

- å¹´ä»½/æ—¥æœŸæŒ‰ç…§ **DT-yyyy** æ¥ï¼Œæˆ– DT-yyyy-mmã€‚(DT: datetime)

- è®ºæ–‡ç®€ç§°å†™åœ¨æ ‡é¢˜

- æŒ‰ç…§ **C-XXX** ç»™è®ºæ–‡æ‰“æ ‡ç­¾ã€‚(C: category)

  > å…·ä½“æ ‡ç­¾æœ‰ï¼š-T (target) é¢„æµ‹ç›®æ ‡(é€Ÿåº¦ï¼Œæµé‡ç­‰)

# å…·ä½“è®ºæ–‡

ç«çˆ†/ç»å…¸çš„æ ‡å‡†ï¼šå¼•ç”¨é‡ç‰¹åˆ«å¤šæˆ–è¡ç”Ÿæ¨¡å‹ç‰¹åˆ«å¤šï¼Œå…¶ä»–æ˜¯æ‚é±¼

## ç»å…¸

### T-28 STGCN

CCF-A CI-3886 DT-2017 C-T-SPEED

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

ä¸¤ç§ CNN åˆ†åˆ«å¤„ç†æ—¶é—´å’Œç©ºé—´ç‰¹å¾

ç»„æˆï¼šä¸¤ä¸ªæ—¶ç©ºå·ç§¯å—å’Œå…¨è¿æ¥å±‚è¾“å‡ºï¼Œæ¯ä¸ªå—ç”±ä¸¤ä¸ªæ—¶é—´å·ç§¯å¤¹ç€ä¸€ä¸ªç©ºé—´å·ç§¯ï¼Œä½¿ç”¨äº†æ®‹å·®è¿æ¥å’Œç“¶é¢ˆç­–ç•¥

> (GPT) ç“¶é¢ˆç­–ç•¥çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å¼•å…¥æŸç§å½¢å¼çš„é™åˆ¶ï¼ˆå¦‚ç»´åº¦å‹ç¼©ã€è®¡ç®—èµ„æºé™åˆ¶ç­‰ï¼‰ï¼Œå¼ºåˆ¶æ¨¡å‹åšå‡ºé€‰æ‹©ï¼Œèšç„¦äºæœ€é‡è¦çš„ä¿¡æ¯ã€‚è¿™åœ¨æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€ç¨³å®šæ€§ä»¥åŠå‡å°‘è®¡ç®—èµ„æºçš„ä½¿ç”¨ç­‰æ–¹é¢ï¼Œéƒ½å…·æœ‰é‡è¦ä½œç”¨ã€‚

![image-20240815222203379](img/image-20240815222203379.png)

å›¾2è¯´æ˜ï¼š

Architecture of spatio-temporal graph convolutional networks. The framework STGCN consists of two spatio-temporal convolutional blocks (ST-Conv blocks) and a fully-connected output layer in the end. Each ST-Conv block contains two temporal gated convolution layers and one spatial graph convolution layer in the middle. The residual connection and bottleneck strategy are applied inside each block.

è¶…å‚æ•°é€‰æ‹©çš„æ–¹æ³•ï¼šTree-structured Parzen Estimator (TPE) (æœ‰è®ºæ–‡)

##### æ•°æ®

ç ”ç©¶äº¤é€šé€Ÿåº¦

æ•°æ®é›†æ˜¯

è‡ªå»ºï¼šBJER4

- gathered from the major areas of east ring No.4 routes in Beijing City by double-loop detectors. There are 12 roads selected for our experiment. The traffic data are aggregated every 5 minutes. The time period used is from 1st July to 31st August, 2014 except the weekends. We select the first month of historical speed records as training set, and the rest serves as validation and test set respectively

æ ‡å‡†ï¼šPeMSD7

- ä½¿ç”¨åŠ æƒçŸ©é˜µï¼Œè·ç¦»çš„åˆ†ç±»è®¨è®ºå‡½æ•°æ˜¯è¾¹æƒ

- æ•°æ®æè¿°ï¼š(å‚è€ƒå®˜æ–¹ä»£ç ä»“åº“ README.md)

  æ¯å¤©çš„è®°å½•æ¬¡æ•°ä¹˜ä»¥å¤©æ•°æ˜¯è¡Œï¼Œé“è·¯æ•°æ˜¯åˆ—ï¼Œå†…å®¹æ˜¯é€Ÿåº¦è®°å½•ï¼ŒèŠ‚ç‚¹æ•°æ˜¯ 228 å’Œ 1026ï¼Œè¡Œæ•°æ˜¯ 12672(æˆ‘ç®—å‡ºæ¥44å¤©)ï¼Œå€¼æ˜¯ 60 å¤šå’Œ 70 å¤šçš„å å¤§å¤´ï¼Œæœ‰æå°‘å…¶ä»–å€¼ï¼Œé¢„æµ‹å–äº† 15/30/45minï¼Œé¢„æµ‹è§†é‡è¶Šå¤§è¯¯å·®è¶Šå¤§

  - PeMSD7_V_{`$num_route`}.csv : Historical Speed Records with shape of `[len_seq * num_road] (len_seq = day_slot * num_dates)`.
  - PeMSD7_W_{`$num_route`}.csv : Weighted Adjacency Matrix with shape of `[num_road * num_road]`.

è®ºæ–‡é‡Œæœ‰å›¾è¡¨å±•ç¤ºäº†æœ‰ä¸€ä¸ªUå½¢å’ŒåŒUå½¢æ•°æ®(è“è‰²æ˜¯çœŸå®)

é™„å½•æœ‰å¾ˆå¤šå¼ å›¾è¡¨ç¤ºå®éªŒç»“æœ

æŸ¥é˜…å¾—çŸ¥ï¼Œå…¶ä¸­çš„ FC-LSTM è®ºæ–‡å‡ºå¤„æ ¹æœ¬å°±ä¸æ˜¯è¿™ä¸ªé¢†åŸŸçš„ï¼Œè€Œæ˜¯è¯¥æŠ€æœ¯çš„ç»å…¸è®ºæ–‡æˆ–è¿ç§»åº”ç”¨ï¼Œæ€€ç–‘æ˜¯è‡ªå»ºæ¨¡å‹

##### ä»£ç 

[src](https://github.com/VeritasYin/STGCN_IJCAI-18/tree/master)

#### ç›¸å…³è¯„ä»·

T-ZS2 æ€»ç»“ï¼š

- å †å å¤šä¸ªæ—¶ç©ºå·ç§¯å—ï¼Œæ¯ä¸ªå—è¿æ¥ä¸¤ä¸ªæ—¶é—´å·ç§¯å±‚å’Œä¸€ä¸ªå›¾å·ç§¯å±‚

  > stacks multiple spatio-temporal convolution blocks and each block concatenate two temporal convolution and one graph convolution layer.  

- ä½¿ç”¨ ChebNet ä½œä¸ºå›¾å·ç§¯æ“ä½œï¼Œç”¨ä¸€é˜¶è¿‘ä¼¼æ¯”è¾ƒ

  > ChebNet is chosen as the graph convolution operator in STGCN, after a comparison with its first-order approximation  

- CNN ä»£æ›¿ RNN è·å–æ—¶é—´åŠ å¿«äº†è®­ç»ƒæ—¶é—´

  > The usage of temporal convolution layers instead of RNNs for temporal modeling accelerates the training phase of STGCN  

#### ç›¸å…³æ”¹ç‰ˆ

- T-128

- å˜ç§ ASTGCN å¼•å…¥ä¸¤ä¸ªæ³¨æ„åŠ›å±‚åˆ†åˆ«è·å–æ—¶ç©ºåŠ¨æ€è”ç³» T-81

  > Attention based Spatio-temporal graph convolutional network (ASTGCN) further introduces two attention layers in STGCN to capture the dynamic correlations in spatial dimension and temporal dimension, respectively  

### T-40 DCRNN

CCF-NONE CI-3654 DT-2018 C-T-SPEED

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

ç©ºé—´ï¼šå›¾åŒå‘éšæœºæ¸¸èµ°

æ—¶é—´ï¼šencoder-decoder

DCRNN captures the spatial dependency using bidirectional random walks on the graph, and the temporal dependency using the encoder-decoder architecture with scheduled sampling

- ç©ºé—´

  We model the spatial dependency by relating traffic flow to a diffusion process, which explicitly captures the stochastic nature of traffic dynamics. This diffusion process is characterized by a random walk on G with restart probability, and a state transition matrix

- æ—¶é—´

  We replace the matrix multiplications in GRU with the diffusion convolution

  In multiple step ahead forecasting, Both the encoder and the decoder are recurrent neural networks with Diffusion Convolutional Gated Recurrent Unit (DCGRU)

##### æ•°æ®

ç‰¹å¾æè¿°

![image-20240817003909585](img/image-20240817003909585.png)

Figure 1: Spatial correlation is dominated by road network structure. (1) Traffic speed in road 1 are similar to road 2 as they locate in the same highway. (2) Road 1 and road 3 locate in the opposite directions of the highway. Though close to each other in the Euclidean space, their road network distance is large, and their traffic speeds differ significantly.

æ•°æ®é›†ï¼šäº¤é€šé€Ÿåº¦é¢„æµ‹

- METR-LA æ„Ÿè§‰æ˜¯å®Œå…¨æ•°æ®é›†
- PEMS-BAY è¯¥æ•°æ®é›†çš„å¼€å±±

#### ç›¸å…³è¯„ä»·

(T-ZS1)

encoder-decoder å›¾æ‰©æ•£æ¯” FNN, LSTM å¥½ï¼Œæ¶ˆèè¯æ˜æ‰©æ•£å·ç§¯æ›´å¥½

have demonstrated that their encoder-decoder model with graph diffusion managed to outperform simple FNN and LSTM. Not only that, they also performed an ablation test to demonstrate that their novel diffusion convolution module manages to outperform simpler variations 

GRU: çŸ©é˜µä¹˜æ³•æ”¹ä¸ºæ‰©æ•£å·ç§¯æ“ä½œ

replaced the matrix multiplication inside Gated Recurrent Unit with the diffusion convolution operation 



(T-ZS2)

æœ€å‡ºåçš„ä¸€ä¸ªæ˜¯ DCRNN

> (T-ZS2) The most famous one is diffusion convolutional recurrent neural network (DCRNN)  

- å›¾å·ç§¯ç½‘ç»œå’Œ RNN å­¦ä¹ æ—¶ç©º

  > which uses diffusion graph convolutional networks and RNN to learn the representations of spatial dependencies and temporal relations  

- æœ€åˆç”¨äºäº¤é€šé€Ÿåº¦é¢„æµ‹ï¼Œç°åœ¨æˆä¸ºäº†åŸºå‡†æ¨¡å‹

  > DCRNN was originally proposed for traffic speed forecasting and is now widely used as a baseline.  

- å»ºå›¾æ–¹å¼ï¼šè·ç¦»çŸ©é˜µ

  > To create the traffic graph, the adjacency matrix is defined as the thresholded pairwise road network distances.  

- æ”¯æŒæœ‰å‘å›¾ï¼Œå¼•å…¥æ‰©æ•£å·ç§¯(DC)

  > Compared with other graph convolutional models that can only operate on undirected graphs, e.g., ChebNet, DCRNN introduces the diffusion convolution (DC) operation for directed graph and is more suitable for transportation scenarios, which is defined as follows:   

  $$
  \mathbf X_{*DC}=\sum_{k=0}^{K-1}(\theta_{k,1}(D_O^{-1}A)^k+\theta_{k,2}(D_I^{-1}A^T))\mathbf X
  $$

  å…¶ä¸­ $\mathbf X\in R^{N\times d}$ æ˜¯èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µï¼Œ$A$ æ˜¯é‚»æ¥çŸ©é˜µï¼Œ$D_O,D_I$ æ˜¯å¯¹è§’çŸ©é˜µï¼šå‡ºåº¦å’Œå…¥åº¦ï¼Œ$\theta$ æ˜¯ä¸¤ä¸ªæ¨¡å‹å‚æ•°ï¼Œ$K$ æ˜¯æ‰©æ•£æ­¥æ•°ã€‚

  åŒºåˆ†å…¥åº¦å’Œå‡ºåº¦å®ç°äº†æœ‰å‘å›¾ 

  > where X 2 RNÃ—d is the node feature matrix, A is the adjacency matrix, DO and DI are diagonal out-degree and in-degree matrices, Î¸k;1 and Î¸k;2 are model parameters, K is the number of diffusion steps. By defining and using out-degree and in-degree matrices, DCRNN models the bidirectional diffusion process to capture the influence of both upstream and downstream traffic  

- å¯¹æ— å‘å›¾ä¸æ˜¯å¾ˆå®ç”¨

  > While DCRNN is a strong baseline, it is not suitable or desirable for the undirected graph cases  

- æ‰©å±•ç‰ˆæœ¬ T-88ï¼šç»Ÿä¸€æ„å»º RNNï¼ŒåŸºäºä»»æ„å›¾å·ç§¯

  Then DCRNN is extended with a stronger learning ability in graph GRU a unified method for constructing an RNN based on an arbitrary graph convolution operator is proposed, instead of the single RNN model used in DCRNN

è§‚å¯Ÿå›¾æ‰©æ•£è¿‡ç¨‹å’Œé‚»èŠ‚ç‚¹å…³è”

observed the traffic diffusion along the road network and the correlation between several adjacent traffic sensors

### T-64 Graph WaveNet

CCF-A CI-1984 DT-2019 C-T-SPEED

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

ç©ºé—´ï¼šè‡ªé€‚åº”ä¾èµ–çŸ©é˜µï¼Œç‚¹åµŒå…¥å­¦ä¹ ï¼Œå›¾å·ç§¯

æ—¶é—´ï¼šå †å æ‰©å¼ (å¦‚å›¾2ï¼Œå€å¢) 1D CNN ä»»æ„å·ç§¯

By developing a novel adaptive dependency matrix and learn it through node embedding, our model can precisely capture the hidden spatial dependency in the data. 

With a stacked dilated 1D convolution component whose receptive field grows exponentially as the number of layers increases, Graph WaveNet is able to handle very long sequences

- We propose a graph convolution layer in which a self-adaptive adjacency matrix can be learned from the data through an end-to-end supervised training
- we adopt stacked dilated casual convolutions to capture temporal dependencies. The receptive field size of stacked dilated casual convolution networks grows exponentially with an increase in the number of hidden layers

> (GPT) â€œend-to-endâ€ï¼ˆç«¯åˆ°ç«¯ï¼‰æŒ‡çš„æ˜¯ä¸€ç§æ¨¡å‹è®­ç»ƒæ–¹å¼ï¼Œåœ¨è¿™ç§æ–¹å¼ä¸­ï¼Œæ¨¡å‹ä»è¾“å…¥çš„åŸå§‹æ•°æ®å¼€å§‹ï¼Œç›´æ¥å­¦ä¹ åˆ°æœ€ç»ˆè¾“å‡ºçš„ç›®æ ‡ç»“æœï¼Œä¸­é—´çš„æ‰€æœ‰æ­¥éª¤éƒ½æ˜¯åœ¨åŒä¸€ä¸ªæ¨¡å‹ä¸­å®Œæˆçš„

å›¾3ï¼š

![image-20240817224043300](img/image-20240817224043300.png)

##### æ•°æ®

METR-LA PEMS-BAY

åšäº†æ—¶é—´æ•ˆç‡å¯¹æ¯”ï¼Œçœ‹æ ·å­åšäº†æ¶ˆèå®éªŒ

é™æ€å›¾å¯èƒ½ä¸èƒ½ååº”çœŸå®ä¾èµ–

However, the explicit graph structure (relation) does not necessarily reflect the true dependency and genuine relation may be missing due to the incomplete connections in the data.

é™æ€çš„å±€é™æ€§çš„ä¾‹å­

To give each circumstance an example, let us consider a recommendation system. In the first case, two users are connected, but they may have distinct preferences over products. In the second case, two users may share a similar preference

ç©ºé—´å½±å“çš„ç›´è§‚å›¾ç¤º

<img src="img/image-20240817220918943.png" alt="image-20240817220918943" style="zoom:67%;" />



#### ç›¸å…³è¯„ä»·

- è‡ªé€‚åº”çŸ©é˜µè‡ªåŠ¨å‘ç°éšè—å›¾ç»“æ„ï¼Œä»»æ„å·ç§¯å­¦ä¹ æ—¶é—´å…³è”

  > constructs a self-adaptive matrix to uncover unseen graph structures automatically from the data and WaveNet, which is based on causal convolutions, is used to learn temporal relations.  

- è®­ç»ƒåçŸ©é˜µå›ºå®šï¼Œä¸èƒ½é€‚åº”åŠ¨æ€çš„æ•°æ®

  > However, the self-adaptive matrix in Graph WaveNet is fixed after training, which is unable to be adjusted dynamically with the data characteristics  

#### ç›¸å…³æ”¹ç‰ˆ

- T-136 STEP
- T-135 STD-MAE
- T-131 STAWnet
- T-130 å¾®è°ƒ

## ç«çˆ†

### T-110 AGCRN

CCF-A CI-1060 DT-2020 C-T-FLOW

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

ç©ºé—´ï¼šGCN æ”¹è¿›

æ—¶é—´ï¼šGRU

we propose two adaptive modules for enhancing Graph Convolutional Network (GCN) with new capabilities: 1) a Node Adaptive Parameter Learning (NAPL) module to capture node-specific patterns; 2) a Data Adaptive Graph Generation (DAGG) module to infer the inter-dependencies among different traffic series automatically. We further propose an Adaptive Graph Convolutional Recurrent Network (AGCRN) to capture fine-grained spatial and temporal correlations in traffic series automatically based on the two modules and recurrent networks.

- a Node Adaptive Parameter Learning (NAPL) module to learn node-specific patterns for each traffic seriesâ€”NAPL factorizes the parameters in traditional GCN and generates node-specific parameters from a weights pool and bias pool shared by all nodes according to the node embedding
- a Data Adaptive Graph Generation (DAGG) module to infer the node embedding (attributes) from data and to generate the graph during training. NAPL and DAGG are independent and can be adapted to existing GCN-based traffic forecasting models both separately and jointly
- we combine NAPL and DAGG with recurrent networks and propose a unified traffic forecasting model - Adaptive Graph Convolutional Recurrent Network (AGCRN). AGCRN can capture fine-grained node-specific spatial and temporal correlations in the traffic series and unify the nodes embeddings in the revised GCNs with the embedding in DAGG

##### æ•°æ®

PEMSD4, PEMSD8

![image-20240819010446183](img/image-20240819010446183.png)

### T-142 MTGNN

CCF-A CI-1294 DT-2020 C-T-SPEED

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

ç©ºé—´ï¼šå›¾å·ç§¯

æ—¶é—´ï¼š1D CNN

Our approach automatically extracts the uni-directed relations among variables through a graph learning module, into which external knowledge like variable attributes can be easily integrated. A novel mix-hop propagation layer and a dilated inception layer are further proposed to capture the spatial and temporal dependencies within the time series. The graph learning, graph convolution, and temporal convolution modules are jointly learned in an end-to-end framework.

- we propose a novel graph learning layer, which extracts a sparse graph adjacency matrix adaptively based on data. Furthermore, we develop a graph convolution module to address the spatial dependencies among variables, given the adjacency matrix computed by the graph learning layer. This is designed specifically for directed graphs and avoids the over-smoothing problem that frequently occurs in graph convolutional networks
- Finally, we propose a temporal convolution module to capture temporal patterns by modified 1D convolutions. It can both discover temporal patterns with multiple frequencies and process very long sequences.

![image-20240819012120958](img/image-20240819012120958.png)

##### æ•°æ®

METR-LA PEMS-BAY å’Œå…¶ä»–äº¤é€šå¤–çš„æ•°æ®ï¼Œæœ‰è¾“å…¥é•¿åº¦è¡¨ç¤ºä¸º 12

### T-36 T-GCN

CCF-B CI-2248 DT-2019 C-T-SPEED

#### é˜…è¯»ç¬”è®°

##### æ•°æ®

SZ-taxi and Los-loop datasets.

> (1) SZ-taxi. This dataset was the taxi trajectory of Shenzhen from Jan. 1 to Jan. 31, 2015. We selected 156 major roads of Luohu District as the study area. The experimental data mainly includes two parts. One is an 156*156 adjacency matrix, which describes the spatial relationship between roads. Each row represents one road and the values in the matrix represent the connectivity between the roads. Another one is a feature matrix, which describes the speed changes over time on each road. Each row represents one road; each column is the traffic speed on the roads in different time periods. We aggregate the traffic speed on each road every 15 minutes. 
>
> (2) Los-loop. This dataset was collected in the highway of Los Angeles County in real time by loop detectors. We selected 207 sensors and its traffic speed from Mar.1 to Mar.7, 2012. We aggregated the traffic speed every 5 minutes. Similarity, the data concludes an adjacency matrix and a feature matrix. The adjacency matrix is calculated by the distance between sensors in the traffic networks. Since the Los-loop dataset contained some missing data, we used the linear interpolation method to fill missing values. 
>
> In the experiments,the input data was normalized to the interval [0,1]. In addition, 80% of the data was used as the training set and the remaining 20% was used as the testing set. We predicted the traffic speed of the next 15 minutes, 30 minutes, 45 minutes and 60 minutes.

#### ç›¸å…³è¯„ä»·

GCN(ç©ºé—´) + GRU(æ—¶é—´)

used a Gated Recurrent Unit which takes input from a Graph Convolution Network and outputs the predicted traffic

### T-143 GMAN

CCF-A CI-1262 DT-2019

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

encoder-decoder æ—¶ç©ºéƒ½ç”¨æ³¨æ„åŠ›

In this paper, we focus on the spatio-temporal factors, and propose a graph multi-attention network (GMAN) to predict traffic conditions for time steps ahead at different locations on a road network graph. GMAN adapts an encoder-decoder architecture, where both the encoder and the decoder consist of multiple spatio-temporal attention blocks to model the impact of the spatio-temporal factors on traffic conditions. The encoder encodes the input traffic features and the decoder predicts the output sequence. Between the encoder and the decoder, a transform attention layer is applied to convert the encoded traffic features to generate the sequence representations of future time steps as the input of the decoder. The transform attention mechanism models the direct relationships between historical and future time steps that helps to alleviate the error propagation problem among prediction time steps

![image-20240819013039961](img/image-20240819013039961.png)

##### æ•°æ®

traffic volume prediction on the Xiamen dataset

which contains 5 months of data recorded by 95 traffic sensors ranging from August 1st, 2015 to December 31st, 2015 in Xiamen, China

ä»¥åŠ PEMS-BAY

![image-20240819013254073](img/image-20240819013254073.png)

## æ‚é±¼

### T-129 DCGCN

CCF-NONE CI-24 DT-2023 C-T-SPEED

#### é˜…è¯»ç¬”è®°

æˆ‘è§‰å¾—ä½œç”¨ä¸å¤§ï¼Œæ”¾è¡¨æ ¼é‡Œåº”è¯¥å°±è¡Œ

##### æ¨¡å‹

åŠ¨æ€è´å¶æ–¯ç½‘ç»œï¼Œå›¾å·ç§¯ç½‘ç»œï¼ŒåŠ¨æ€ä»»æ„å›¾ (GCN+RNN)

In this work, we propose a novel approach for traffic prediction that embeds time-varying dynamic Bayesian network to capture the fine spatiotemporal topology of traffic data. 

We then use graph convolutional networks to generate traffic forecasts. 

To enable our method to efficiently model nonlinear traffic propagation patterns, we develop a deep learning-based module as a hyper-network to generate stepwise dynamic causal graphs

- we propose a novel causal-embedded approach for traffic prediction. It represents the spatiotemporal traffic network topology using a time-varying DBN (TVDBN), which is designed to adapt to the time-varying traffic propagation patterns by learning DBNs step by step
- The learned TVDBN is able to summarize the dynamic spatiotemporal dependencies between nodes. Built upon it, graph convolution is applied to capture spatial dependencies for traffic prediction.
- We propose a complete deep learning based causal structure learning module that serves as a pretrained hyper-network to generate the graphs of the TVDBN.
- The predefined distance graph is further incorporated into graph generator and traffic prediction module as additional prior information to improve the performance.
- We propose an approach based on GCN and RNN to learn a TVDBN that describes the time-varying causal relationships between different locations in traffic network. The augmented Lagrange method is applied for model training to ensure the acyclicity of the TVDBN



> poe assistant æ¦‚æ‹¬ï¼š
>
> **æ—¶ç©ºç‰¹å¾å¤„ç†ï¼š**
>
> - **åŠ¨æ€è´å¶æ–¯ç½‘ç»œ (DBN)ï¼š** åŸæ–‡ä¸­æåˆ° "We propose an approach based on GCN and RNN to learn a TVDBN that describes the time-varying causal relationships between different locations in traffic network." ä»¥åŠ "The learned TVDBN is able to summarize the dynamic spatiotemporal dependencies between nodes."
> - **é€’å½’ç¥ç»ç½‘ç»œ (RNN)ï¼š** åŸæ–‡æåˆ° "We propose to capture the time-varying causal structure in traffic series by RNN, which generates the dynamic causal graphs stepwise from its hidden state." ä»¥åŠ "The challenge is to construct suitable input features for RNN that contain information about the dynamics of the causal structure."
> - **å›¾å·ç§¯ç½‘ç»œ (GCN)ï¼š** åŸæ–‡æåˆ° "We extend the linear SEM (6) to a nonlinear version by spatial-based graph convolution [39], i.e., Xt = âˆ‘Kk=0GCONV2L(Xtâˆ’k, Bkt) + Zt, where GCONV2L is a L layers spatial-based graph convolution operation with skip connections defined as:" ä»¥åŠ "The proposed model is evaluated on a real-world traffic dataset to demonstrate the effectiveness of the proposed approach."
>
> **ç©ºé—´ç‰¹å¾å¤„ç†ï¼š**
>
> - **å›¾å·ç§¯ç½‘ç»œ (GCN)ï¼š** åŸæ–‡æåˆ° "We use an attention mechanism with multi-head scaled dot-product [38], to describe the spatiotemporal correlations between nodes, i.e., sdot(Q, K) = (QWQ)(KWK)âŠ¤âˆšd âˆˆ RNÃ—N, msdot(Q, K) = [sdot1(Q, K), ...,sdoth(Q, K)] âˆˆ RNÃ—NÃ—h, CÌƒ0t = msdot(Xt, Xt), CÌƒkt = msdot(Xt, Xtâˆ’k), k = 1, ..., K, where WQ and WK are learnable parameters of linear transformation, h is the number of heads and the learnable parameters of each head are different." ä»¥åŠ "We further flatten the tensors {CÌƒkt}Kk=0 to matrices in RN2Ã—h, denoted by {Ckt}Kk=0, such that each row of Ckt captures the dynamics of an element in Bkt."
> - **å…ˆéªŒå›¾ç»“æ„ï¼š** åŸæ–‡æåˆ° "The predefined distance graph is further incorporated into graph generator and traffic prediction module as additional prior information to improve the performance." ä»¥åŠ "We conduct experiments on a widely used traffic benchmark dataset METR-LA to evaluate the traffic prediction performance of the proposed model."
>
> æ‚¨æ˜¯å¯¹çš„ï¼Œæ–‡ç« ä¸­æ²¡æœ‰æ˜ç¡®çš„â€œæ—¶é—´ç‰¹å¾â€å¤„ç†éƒ¨åˆ†



> Casual discovery ç›¸å…³ï¼š
>
> Casual discovery aims to analyze causal relationships behind statistical correlations of different variables and facilitate better machine learning.
>
> - Typical approaches to incorporate causal discovery include encoding features from domain-specific causal models as input to downstream tasks
> - and learning the structure of causal relationships between features for graph-based models
> - As a powerful graph-based tool for modeling directed causal relationships between variables, Bayesian network (BN) is being applied in traffic prediction
>
> æ–‡å¿ƒä¸€è¨€ï¼šCasual Discoveryï¼ˆå› æœå‘ç°ï¼‰æ˜¯å› æœæ¨ç†é¢†åŸŸä¸­çš„ä¸€ä¸ªé‡è¦ç ”ç©¶æ–¹å‘ï¼Œæ—¨åœ¨ä»è§‚æµ‹æ•°æ®ä¸­è¯†åˆ«å’Œç†è§£å˜é‡ä¹‹é—´çš„æ½œåœ¨å› æœç»“æ„æˆ–å…³ç³»ã€‚

#### æ•°æ®

METR-LA

A limitation of current casual-embedded traffic prediction models is the assumption of stationary temporal dependencies. However, in reality, the dependencies of traffic data in different places do change over time

### T-131 STAWnet

CCF-NONE CI-93 DT-2021 C-T-SPEED

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

æ—¶é—´ï¼šCNN (Gated TCN) gated temporal convolution network

ç©ºé—´ï¼šè‡ªæ³¨æ„åŠ›ç½‘ç»œ (DAN) dynamic attention network

a multi-step prediction model named Spatial-Temporal Attention Wavenet (STAWnet) is proposed. Temporal convolution is applied to handle long time sequences, and the dynamic spatial dependencies between different nodes can be captured using the self-attention network. Different from existing models, STAWnet does not need prior knowledge of the graph by developing a self-learned node embedding. These components are integrated into an end-to-end framework. 

- self-adaptive node embedding : capture the hidden spatial relationship in the data without knowing the graph structure information

##### æ•°æ®

The experimental results on three public traffic prediction datasets (METR-LA, PEMS-BAY, and PEMS07) demonstrate effectiveness.

å®éªŒå¯¹æ¯”æåˆ° T-GCN, FC-LSTMï¼Œæ³¨æ„åˆ°è¿™ä¿©ç»å¸¸å‡ºç°ç‰¹åˆ«æ˜¯ FC-LSTM

### T-132 ADN

CCF-NONE CI-6 DT-2022

#### é˜…è¯»ç¬”è®°

æ³¨æ„åŠ›æ—¶é—´ï¼Œæ³¨æ„åŠ›ç©ºé—´

we propose the simplest possible model, called ADN for Attention Diffusion Network, which does not rely on any structural prior whatsoever. We choose an attention based encoder-decoder architecture, where attention is adapted to the bi-dimensionality of events as location-instant pairs

> poe æ‰¾çš„ï¼š
>
> - ä½¿ç”¨ å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ (MHA)
>
>   The model alternates attention in the temporal dimension (MHA(T)), and in the spatial dimension (MHA(N)).
>
> - è®ºæ–‡ä¸­æåˆ°æ¨¡å‹ä½¿ç”¨ å¯åˆ†ç¦»æ³¨æ„åŠ›æœºåˆ¶ (separable attention)ï¼Œè¯¥æœºåˆ¶é€šè¿‡åˆ†åˆ«å¤„ç†æ—¶é—´ç»´åº¦å’Œç©ºé—´ç»´åº¦ï¼Œæ¥é™ä½æ³¨æ„åŠ›çŸ©é˜µçš„è®¡ç®—é‡
>
>   Since attention is a generalised form of convolution [1], separability works all the same with attention, where it is also known as axial attention [7]. Separable attention processes event-indexed objects along each dimension of the events (temporal and spatial) separately and alternately, just as spatially separable convolutions alternate processing images along their width and height dimensions.

æ•°æ®ï¼š

Experiments are conducted on three public traffic datasets PEMS-BAY, METR-LA and PEMS07 released by [12] and [20]. The first two are the most commonly used for measuring model performances, and consist of 207 and 325 locations, respectively. We also tested our model on PEMS07 (883 locations), to check its scalability to larger road traffic networks.

### T-133 RGDAN

CCF-B CI-3 DT-2024 C-T-SPEED

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹ 

ç©ºé—´ï¼šGAT(Graph Attention Network, å›¾æ³¨æ„åŠ›ç½‘ç»œ)

æ—¶é—´ï¼šæ³¨æ„åŠ›

çœ‹è®ºæ–‡å›¾è¿˜æœ‰ encoder-decoder

we propose a Random Graph Diffusion Attention Network (RGDAN) for traffic prediction. RGDAN comprises a graph diffusion attention module and a temporal attention module. The graph diffusion attention module can adjust its weights by learning from data like a CNN to capture more realistic spatial dependencies. The temporal attention module captures the temporal correlations

- Random GATs discard traditional attention interaction (e.g., dot product) and instead, use a learnable matrix to discover the correlations between neighbors. This method omits the process of dot-product interaction in ordinary attention, reduces the time complexity, improves the computational speed of the model, and reduces the memory overhead
- Random Graph Diffusion Attention Network (RGDAN), consists of an attention mechanism with a graph diffusion attention module that extracts the spatial correlations. Temporal attention captures the temporal dependencies. The temporal and spatial features are fused by a gated fusion layer. The transformed attention module is used to alleviate the propagation error caused by the difference between the predicted and historical time steps

![image-20240818142743477](img/image-20240818142743477.png)

- A spatio-temporal embedding (STE) generator, which provides preliminary spatio-temporal information to the encoder and decoder by generating spatio-temporal embeddings

##### æ•°æ®

METR-LA PEMS-BAY NE-BJ

- NE-BJ (T-134 æ˜¯é¼»ç¥–)

  This dataset is a collection of public transport speed data taken from the navigation data of Tencent Map. It contains 500 segments, with each road segment data contains 6509 5-min time steps.

##### å…¶ä»–

æä¾›äº†ä¸€ä¸ªè¡¨æ ¼æ€»ç»“äº†ç”¨åˆ°çš„å¯¹æ¯”å®éªŒçš„ç›¸å…³è®ºæ–‡

### T-134 DGCRN

CCF-B CI-298 DT-2021

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

encoder-decoder

ç©ºé—´ï¼šGNN å›¾å·ç§¯

æ—¶é—´ï¼šRNN

we propose a novel traffic prediction framework, named Dynamic Graph Convolutional Recurrent Network (DGCRN)

- In DGCRN, hyper-networks are designed to leverage and extract dynamic characteristics from node attributes, while the parameters of dynamic filters are generated at each time step. We filter the node embeddings and then use them to generate dynamic graph, which is integrated with pre-defined static graph
- We propose a GNN and RNN based model, where the dynamic adjacency matrix is designed to be generated from a hyper-network step by step synchronize with the iteration of RNN. The dynamic graph is incorporated with the pre-defined graph and skip connection to describe the dynamic characteristics of road networks more effectively, enhancing the performance of prediction.

![image-20240819020113960](img/image-20240819020113960.png)

Dynamic Graph Convolutional Recurrent Module (DGCRM)

![image-20240819020343932](img/image-20240819020343932.png)

##### æ•°æ®

METR-LA PEMS-BAY

NE-BJ



### T-135 STD-MAE

CCF-NONE CI-3 DT-2023 C-T-SPEED

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

æ—¶ç©ºéƒ½æ˜¯ AE + è‡ªæ³¨æ„åŠ›

self-supervised pre-training framework SpatialTemporal-Decoupled Masked Pre-training (STDMAE) that employs two decoupled masked autoencoders to reconstruct spatiotemporal series along the spatial and temporal dimensions

mask çš„æ€æƒ³ï¼šå­¦ä¹ å¡«å……ç¼ºå¤±ã€‚åŸºäºè¿™ä¸ªè¿›è¡Œé¢„è®­ç»ƒï¼Œæœ‰è¯¦ç»†ä»‹ç»

- The core idea is to mask parts of the input sequence during pre-training, requiring the model to reconstruct the missing contents
- spatial-temporal-decoupled masking, Such decoupled masking mechanism allows the model to learn representation that can capture clearer heterogeneity
- It consists of a temporal autoencoder (T-MAE) and a spatial autoencoder (S-MAE), both having a similar architecture
- S-MAE applies self-attention along spatial dimension, while T-MAE performs self-attention along temporal dimension

æ‚é¡¹ï¼š

- patch embedding technique: The long input is divided into non-overlapping patches
- Moreover, to simultaneously encode spatial and temporal positional information, we implement a two-dimensional positional encoding

æ¨¡å‹ç»“æ„ï¼š

- The spatial and temporal decoders each consists of a padding layer, a standard transformer layer, and a regression layer.

![image-20240818161239792](img/image-20240818161239792.png)

- å…·ä½“æ¨¡å‹ï¼šGWNet (Graph WaveNet)

##### æ•°æ®

PEMSD3/4/7/8/BAY, METR-LA

### T-136 MegaCRN

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

ç©ºé—´ GCN( Graph Convolutional Networks (GCNs) )

æ—¶é—´ Gated Recurrent Unit (GRU)

we implement this idea into Meta-Graph Convolutional Recurrent Network (MegaCRN) by plugging the Meta-Graph Learner powered by a MetaNode Bank into GCRN encoder-decoder.

> Graph Structure Learning (GSL)
>
> spatio-temporal graph (STG)

The term meta-graph is coined to describe the generation of node embeddings (similar in adaptive and momentary) for GSL.

our STG learning consists of two steps: (1) querying node-level prototypes from a Meta-Node Bank; (2) reconstructing node embeddings with Hyper-Network

injecting graph convolution operation into recurrent cell (e.g. LSTM). The derived Graph Convolutional Recurrent Unit (GCRU) can thereby simultaneously capture

- spatial dependency, represented by an input graph topology, and
- temporal dependency in a sequential manner.

##### å…¶ä»–

ç»éªŒå‡†åˆ™ Toblerâ€™s first law of geography

> æ‰˜å¸ƒå‹’ç¬¬ä¸€åœ°ç†å­¦å®šå¾‹æŒ‡å‡ºï¼šâ€œäº‹ç‰©å½¼æ­¤é è¿‘â€ã€‚æ¢å¥è¯è¯´ï¼Œåœ°ç†ä¸Šç›¸è¿‘çš„äº‹ç‰©æ¯”ç›¸è·è¾ƒè¿œçš„äº‹ç‰©æ›´ç›¸ä¼¼ã€‚
>
> è¿™ä¸ªå®šå¾‹åœ¨è®¸å¤šé¢†åŸŸéƒ½æœ‰åº”ç”¨ï¼ŒåŒ…æ‹¬ï¼š
>
> - åœ°ç†å­¦ï¼š ç†è§£ç©ºé—´æ¨¡å¼å’Œåœ°ç†ç°è±¡ä¹‹é—´çš„å…³ç³»ã€‚
> - åŸå¸‚è§„åˆ’ï¼š è§„åˆ’åŸå¸‚åŸºç¡€è®¾æ–½å’ŒæœåŠ¡ï¼Œä»¥æ»¡è¶³å±…æ°‘çš„éœ€æ±‚ã€‚
> - ç¯å¢ƒç§‘å­¦ï¼š ç ”ç©¶æ±¡æŸ“ç‰©å’Œç”Ÿæ€ç³»ç»Ÿä¹‹é—´çš„å…³ç³»ã€‚
> - ç¤¾ä¼šå­¦ï¼š åˆ†æç¤¾ä¼šç°è±¡çš„ç©ºé—´åˆ†å¸ƒã€‚
>
> æ‰˜å¸ƒå‹’ç¬¬ä¸€åœ°ç†å­¦å®šå¾‹æ˜¯ä¸€ä¸ªé‡è¦çš„æ¦‚å¿µï¼Œå®ƒæé†’æˆ‘ä»¬åœ°ç†ä½ç½®åœ¨å¡‘é€ ä¸–ç•Œä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚

### T-137 STEP

CCF-A CI-146 DT-2022 C-T-SPEED C-T-FLOW

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

æ—¶é—´ï¼šTransformer

ç©ºé—´ï¼šå›¾

ä»¥åŠ encoder-decoderï¼Œä½†æ˜¯åŸºäº Grah WaveNet æ”¹ç¼–

we propose a novel framework, in which <u>ST</u>GNN is <u>E</u>nhanced by a scalable time series <u>P</u>re-training model (STEP). 

Specifically, we design a pre-training model to efficiently learn temporal patterns from very long-term history time series (e.g., the past two weeks) and generate segment-level representations. 

These representations provide contextual information for short-term time series input to STGNNs and facilitate modeling dependencies between time series

- Specifically, we design an efficient unsupervised pre-training model for <u>T</u>ime <u>S</u>eries based on Trans<u>Former</u> blocks (TSFormer)
- which is trained through the masked autoencoding strategy
- design a graph structure learner based on the representation of TSFormer, which learns discrete dependency graph and utilizes the ğ‘˜NN graph computed based on the representation of TSFormer as a regularization to guide the joint training of graph structure and STGNN

![image-20240818173141567](img/image-20240818173141567.png)

STEP framework can extend to almost any STGNN, and we choose a representative method as our backend, the Graph WaveNet

##### æ•°æ®

METR-LA PEMS-BAY PEMS04(flow)

### T-138 D2STGNN

CCF-NONE CI-140 DT-2022 C-T-SPEED C-T-FLOW

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

ç©ºé—´ï¼šGNN + è‡ªæ³¨æ„åŠ›

æ—¶é—´ï¼šRNN + è‡ªæ³¨æ„åŠ›

to improve modeling performance, we propose a novel Decoupled Spatial-Temporal F ramework (DSTF) that separates the diffusion and inherent traffic information in a data-driven manner, which encompasses a unique estimation gate and a residual decomposition mechanism

- The former (residual) removes the parts of signals that the diffusion and inherent models can approximate well. Thus, the parts of signals that are not learned well is retained. 
- The latter (gate) estimates roughly the proportion of the two kinds of signals to relieve the burden of the first model in each layer, which takes the original signal as input and needs to learn specific parts in it

we propose an instantiation of DSTF, Decoupled Dynamic Spatial-Temporal Graph Neural Network (D2STGNN), that captures spatial-temporal correlations and also features a dynamic graph learning module that targets the learning of the dynamic characteristics of traffic networks

- spatial dependency by learning latent correlations between time series based on the self-attention mechanism.
- A spatial-temporal localized convolution is designed to model the hidden diffusion time series. A recurrent neural network and self-attention mechanism are used jointly to model the hidden inherent time series.

##### æ•°æ®

METR-LA PEMS-BAY é€Ÿåº¦

PEMS04 PEMS08 æµé‡

### T-139 STAEformer

CCF-B CI-57 DT-2023 C-T-SPEED C-T-FLOW

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

æ—¶ç©ºè‡ªé€‚åº”åµŒå…¥ + æœ´ç´  transformer

æ—¶ç©ºéƒ½æ˜¯è‡ªæ³¨æ„åŠ›å±‚ï¼Œå¦‚å›¾æ‰€ç¤ºï¼ŒåµŒå…¥å¯ä»¥é¢å¤–èå…¥æ—¥æœŸç­‰ä¿¡æ¯

In this study, we present a novel component called spatio-temporal adaptive embedding that can yield outstanding results with vanilla transformers. 

Our proposed Spatio-Temporal Adaptive Embedding transformer (STAEformer)

- Specifically, it adds an embedding layer on the input, providing multiple types of embeddings for the model backbone

![image-20240818223717438](img/image-20240818223717438.png)

##### æ•°æ®

METR-LA, PEMS-BAY, PEMS03/4/7/8

### T-140 SLCNN

CCF-A CI-234 DT-2020 T-C-SPEED

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

ç©ºé—´ï¼šCNN + GNN

æ—¶é—´ï¼šCNN

we propose a novel framework named Structure Learning Convolution (SLC) that enables to extend the traditional convolutional neural network (CNN) to graph domains and learn the graph structure for traffic forecasting

- We propose a generic graph convolutional formulation, which defines convolution operation as a combination of structure module and kernel module
- Two data-driven and time-vary SLC modules are proposed to capture the global and local structures, respectively
- P3D ConvNet is incorporated in SLCNN to capture the temporal dependencies in traffic data

##### æ•°æ®

PeMS-S (æ‰¾ä¸åˆ°æ¥æº)

The time range of PeMS-S is the weekdays of May and Jun of 2012, the interval is 5 minute and 228 sensors (nodes) are selected

PEMS-BAY, METR-LA 

BJF, BRF, BRF-L è‡ªå»º

- are generated from a real-world GPS trajectory data, in which about 80 million GPS points of 30,000 taxis are recoded per day
- BJF. Each node in BJF indicates a junction and 190 important junctions in Beijing are selected. The traffic data of each node is recorded in every 15 minutes and the time range is from November 2015 to October 2016. 
- BRF. BRF has totally 300 nodes and each node indicates a road. The time interval is set to 20 minutes and the time period used of BRF is from November 2015 to May 2016. 
- BRF-L. Similar to BRF, the traffic flow of each road is recoded in the dataset. BRF-L contains 1586 roads and the time interval is set to 10 minutes. The time period used of BRF-L is from November 2015 to December 2015.

#### ç›¸å…³è¯„ä»·

T-ZS2 æœ‰æ•°æ®ï¼Œä½†æ²¡è®ºè¿°

### T-74 Traffic Transformer

CCF-NONE CI-277 DT-2020 C-T-SPEED

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

we propose to design different strategies for encoding temporal information so thatboth the continuity and periodicity of traffic data can be preserved, and extend Transformer to modeling temporaland spatial dependencies jointly with the help of graph convolutional networks (GCNs)

- We design four novel position encoding strategies to encode the continuity and periodicity of time seriesto facilitate the modeling of temporal dependencies in traffic data
- We introduce a hybrid encoderâ€“decoder architecture, called Traffic Transformer, to coherently model spatial and temporal dependencies of traffic data in an end-to-end training manner, where Transformer is leveraged to model temporal dependencies and GCNs contribute to the modeling of spatial dependencies

![image-20240818235942477](img/image-20240818235942477.png)

![image-20240818235952372](img/image-20240818235952372.png)

##### æ•°æ®

METR-LA PEMS-BAY



### T-141 STGM

CCF-C CI-24 DT-2023 C-T-SPEED

#### é˜…è¯»ç¬”è®°

##### æ¨¡å‹

æ—¶ç©ºä¾èµ–ï¼šæ³¨æ„åŠ›

ç©ºé—´ï¼šGNN

æ—¶é—´ï¼šCNN

we propose a Spatio-Temporal Graph Mixformer (STGM) network, a highly optimized model with low memory footprint. We address the aforementioned limits by utilizing a novel attention mechanism to capture the correlation between temporal and spatial dependencies. Specifically, we use convolution layers with a variable fields of view for each head to capture longâ€“short term temporal dependency. Additionally, we train an estimator model that express the contribution of a node over the desired prediction. The estimation is fed alongside a distance matrix to the attention mechanism. Meanwhile, we use a gated mechanism and a mixer layer to further select and incorporate the different perspectives.

- We suggest a similarity estimator model that given a set of nodes with a segment of historical traffic, approximates the expected implication of each node over the future traffic signal. 
- Furthermore, we designed a couple of improvements for the original transformer architecture named STGA that fully utilizes the multi-head attention and seamlessly capture both temporal and spatial dependencies. 
- We propose the CT-Mixer module that works in coordination with STGA to further capture the temporal locality and internode channels information

æœ‰ä¸€æ®µæè¿° CNN ä»£æ›¿ RNN çš„æè¿°ï¼Œè¯´ä¸å®šå¯ä»¥å‚è€ƒ

![image-20240819004354922](img/image-20240819004354922.png)

##### æ•°æ®

PEMS-BAY METR-LA PEMSD7M(å‚è€ƒT-28)