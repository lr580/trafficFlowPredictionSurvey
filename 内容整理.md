> 诸如 T-ZS1 的标号参见 Zotero 目录(如无请联系我获取)

## 背景介绍

### 背景

#### 交通系统

意义：

- (T-ZS2) Transportation systems are among the most important infrastructure in modern cities, supporting the daily commuting and traveling of millions of people.  

组成：

- (T-ZS2)  With rapid urbanization and population growth, transportation systems have become more complex. Modern transportation systems encompass road vehicles, rail transport, and various shared travel modes that have emerged in recent years, including online ride-hailing, bike-sharing, and e-scooter sharing.  

#### 交通拥堵

- 面临的主要问题

  (T-ZS1) Traffic congestion is a major problem faced by metropolitan cities -> Most congestion mitigation measures are costly, difficult to implement, or both.   
  
  > (T-ZS2) Expanding cities face many transportation-related problems, including air pollution and traffic congestion
  
- 指示：交通速度
  
  (T-ZS2) Traffic speed is another important indicator of traffic state with potential applications in ITS systems, The speed value on the urban road can reflect the crowdedness level of road traffic.  
  
- 其解决：交通预测
  
  (T-ZS1) Educated traffic decision made through accurate prediction is a far cheaper and easier to implement alternative for reducing road congestion  
  
  > (T-ZS1) Traffic flow prediction is one of the easiest and cheapest measures to address traffic congestion  
  
  > (T-ZS2) Traffic forecasting is important for the success of intelligent transportation systems  
  >
  > (T-ZS2) Early intervention based on traffic forecasting is seen as the key to improving the efficiency of a transportation system and to alleviate transportation-related problems  

#### 应用前景

##### 交通流量

交通流量应用面：拥挤控制、信号灯控制等

(T-ZS2 描述 T-ZS10 说的) An accurate traffic flow prediction is beneficial for a variety of applications, e.g., traffic congestion control, traffic light control, vehicular cloud

> 如，交通灯可以减少车辆停留时间，优化交通流，减少交通拥挤和排放
>
> (T-ZS2) For example, traffic light control can reduce vehicle staying time at the road intersections, optimizing the traffic flow, and reducing traffic congestion and vehicle emission.  

(T-ZS3 图2) 更快出行，道路容量增加，交通管理，智慧城市，减少污染，增加交通效率，道路安全 (虽然我觉得有几点是乱扯)

reduce congestion, faster travel times, increase roads capacity, urban traffic management, planning of smart cities, reduced pollution, enhance traffic efficiency, more safe roads

(T-ZS32 图2) 红绿灯优化、导航、智慧交通、安全应急、城市规划

<img src="img/image-20240809114536522.png" alt="image-20240809114536522" style="zoom:67%;" />

##### 交通速度

交通速度：预测拥堵(Google 为例)，路径规划，到达时间评估

(T-ZS2) For example, Google Maps visualizes this crowdedness level from crowd-sourcing data collected from individual mobile devices and in-vehicle sensors. A better traffic speed prediction is also useful for route navigation and estimation of-arrival applications  

> (T-ZS2) **Travel time prediction** is useful for passengers to plan their commuting time and for drivers to select fast routes, respectively. **Traffic congestion** is one of the most important and urgent transportation problems in cities, which brings significant time loss, air pollution and energy waste. The congestion prediction results can be used to control the road conditions and optimize vehicle flow, e.g., with traffic signal control  

##### 交通需求

(T-ZS2) 服务商资源分配，用户合理选择

Traffic demand prediction is a key component for taxi and ride-hailing services to be successful, which benefits these service providers to allocate limited available transportation resources to those urban areas with a higher demand.

For passengers, traffic demand prediction encourages the consideration of various transportation forms, e.g., taking the public transit service when taxi or ride-hailing services are in short supply

(T-ZS2) 现状例子及其重要性

For example, on an online ride-hailing platform, the ride requests sent by passengers represent the demand, whereas only a subset of these requests may be served depending on the supply of drivers and vehicles, especially during rush hours. Accurate prediction of travel demand is a key element of vehicle scheduling systems (e.g. online ride-hailing or taxi dispatch platforms)

##### 交通异常

交通延迟的主要原因，可以助于决策制定

(T-ZS2) the target is to predict the traffic accident number reported to the police system. Traffic anomaly is the major cause of traffic delay and a timely detection and prediction would help the administrators to identify the situation and turn the traffic situation back to normal as quickly as possible    

##### 交通排放

拥堵会增加排放

(T-ZS2) Urban vehicle emission is a major source of air pollutants and its amount is affected by different traffic states, e.g., the excess emission would be created in traffic congestion situations.  

#### 真实数据

- 交通拥挤的代价

  (T-ZS1) In 2015, it is estimated that the avoidable cost of traffic congestion for Australian capital cities is approximately \$16.5 billion, up from the 2010 estimate of \$12.8 billion. Furthermore, this value is estimated to increase to about $30 billion by 2030

  > [参考 Cosgove D. Traffic and congestion cost trends for Australian capital cities[J]. Canberra: Department of Infrastructure and Regional Development, Bureau of Infrastructure, Transport and Regional Economics, 2015.](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Cosgove%2C+Traffic+and+congestion+cost+trends+for+Australian+capital+cities&btnG=#d=gs_cit&t=1721488944765&u=%2Fscholar%3Fq%3Dinfo%3ACPeX2qr_RW8J%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Dzh-CN)

- 交通监管政策

  (T-ZS1) Singapore implemented regulations on the number of vehicles on roads -> which is infeasible for countries with poor public transportation systems

  > [参考 “Singapore to freeze car numbers,” https://www.bbc.
  > com/news/business-41730778, accessed: 20 November
  > 2018](https://www.bbc.
  > com/news/business-41730778)

- 修路成本

  (T-ZS1) the estimated per mile cost of a standard one lane road in New Jersey, USA is $220,490 -> Constructing new roads to ease congestion is also difficult due to the extremely high cost  
  
  > [参考 J. Carnegie and A. M. Voorhees, “The cost of roadway
  > construction, operations and maintenance in new jersey,” pp. 557–566, 2016.  ](https://trid.trb.org/View/1408290)
  
- 城市人口预测

  (T-ZS32) the majority of people resides in urban areas and a percentage that is predicted to rise by 13% by 2050.
  
- 拥堵率

  (T-ZS35) 60% 中国主要城市高峰时段拥堵增加

#### 前置条件

##### 数据获取

- 传感器的普及 -> 大数据获取

  (T-ZS1) With the advancements and widespread adoption of traffic sensors, access to large traffic databases is now available.  -> This has led to the development of traffic prediction as a research field. 
  
  > With the widespread installation of traffic loop detectors, traffic data will continuously grow 
  
  数据源
  
  (T-ZS2) In the development and operation of smart cities and intelligent transportation systems (ITSs), traffic states are detected by sensors (e.g. loop detectors) installed on roads, subway and bus system transaction records, traffic surveillance videos, and even smartphone GPS (Global Positioning System) data collected in a crowd-sourced fashion.  
  
  大数据的介绍：(说引用自另外的文献)
  
  (T-ZS30) the five characteristics of big data, referred to as 5 V features, including large volume, large velocity, large variety, veracity, and value. The 5 V features highlight the notable increase in data volume. Specifically, traffic data is a sort of big data  

##### 库

- 库 

  (T-ZS1) Due to the availability of deep neural network libraries such as Keras, PyTorch , and TensorFlow, development of complex neural network models has become much easier  

  > The introduction of deep neural network libraries such as Keras, PyTorch and TensorFlow has simplified the implementation of complex hybrid deep neural network models. As we have observed, this has resulted in numerous unique hybrid structures, each focusing on specific ideas to improve prediction performance  

  (T-ZS2) Several open source frameworks for implementing general deep learning models, most of which are built with the Python programming language, can be accessed online, e.g. TensorFlow, Keras, PyTorch, MXNet, Additional Python libraries designed for implementing GNNs are available. These include DGL, pytorch\_geometric, and Graph Nets.

  分别是：

  > 17 https://www.tensorflow.org/
  > 18 https://keras.io/
  > 19 https://pytorch.org/
  > 20 https://mxnet.apache.org/
  > 21 https://www.dgl.ai/
  > 22 https://pytorch-geometric.readthedocs.io/
  > 23 https://github.com/deepmind/graph_nets  

  最常用：TensorFlow 和 PyTorch

  (T-ZS2) TensorFlow and PyTorch are the two frameworks that are used most frequently  

### 问题定义

> #### 交通预测

#### 概念

##### 描述

描述：

(T-ZS1)  Future traffic prediction involves creating a prediction model from historical traffic data to predict the short-term future traffic state ranging from 5 to 60 minutes into the future

> (T-ZS2) 相关数据类型：Traffic forecasting is typically based on consideration of historical traffic state data, together with the external factors which affect traffic states, e.g. weather and holidays  

##### 特点

特点：

> 交通预测与其他时序分析的不同在于：
>
> - 一个地点可能影响另一个地点
> - 空间依赖
> - 存在全局外部因素如天气、节假日、交通事故等
> - 数据高维

(T-ZS1)  Traffic prediction is different from conventional time-series analysis in that traffic prediction is subject to **spatial** as well as many **other** external factors.  the prediction of traffic at one site depends on the traffic at other sites and all of the sites are affected by external factors such as weather and holidays.  

> (T-ZS2) The traffic forecasting problem is more challenging than other time series forecasting problems because it involves **large  data** volumes with high dimensionality, as well as **multiple** dynamics including emergency situations, e.g. traffic accidents 
>
> (T-ZS2) The traffic state in a specific location has both **spatial** dependency, which may not be affected only by nearby areas, and **temporal** dependency, which may be seasonal.  
>
> (T-ZS2) Generally speaking, traffic forecasting problems are challenging, not only for the complex **temporal** dependency, but only for the complex **spatial** dependency.  

(T-40 图1)

![image-20240817003909585](img/image-20240817003909585.png)

Figure 1: Spatial correlation is dominated by road network structure. (1) Traffic speed in road 1 are similar to road 2 as they locate in the same highway. (2) Road 1 and road 3 locate in the opposite directions of the highway. Though close to each other in the Euclidean space, their road network distance is large, and their traffic speeds differ significantly.

##### 时空特点

相互影响

(T-ZS2 说 [T-81](https://ojs.aaai.org/index.php/AAAI/article/view/3881) 说的) As for the traffic problems, the spatial and temporal dependencies are closely intertwined in reality. For example, it is argued that the historical observations in different locations at different times have varying impacts on central region in the future  

(T-64 图1) 空间影响的直观图示

<img src="img/image-20240817220918943.png" alt="image-20240817220918943" style="zoom:67%;" />

##### 动态性

也可以参考 GNN 里的动态图静态图

> T-129 说的时间动态：
>
> A limitation of current casual-embedded traffic prediction models is the assumption of stationary temporal dependencies. However, in reality, the dependencies of traffic data in different places do change over time

##### 严格定义

定义：使用可学习的函数，使用历史交通数据输入，预测未来交通

(T-ZS1) Traffic prediction concerns the usage of a learnable function that takes as input the historical traffic data from several previous time-steps in order to predict the traffic in the future.  

> 近义句 Traffic prediction is a task of training an arbitrary function to predict future traffic given past traffic data  

> 还有其他，参考下文

$$
\hat y_{t+T'}=f([X_{t-T+1},X_{t-T},\cdots,X_t])
$$

目标：找到模型参数，最小化误差：

The objective is to find the model parameters which minimize the error between the predicted traffic and the observed traffic:  
$$
\theta^*=\arg\min_{\theta^*}L(y_{t+T'},\hat y_{t+T'};\theta^*)
$$

> 其中 $y_t$ 是时间 $t$ 的观察值，$\hat y_t$ 是预测值，$T$ 是输入序列长度，$T'$ 是预测范围，$L$ 是损失函数，$f$ 是任意函数，$\theta^*$ 是最优参数。
>
> - The observed traffic at time $t$
> - The predicted traffic at time $t$
> - Input sequence length, i.e., how many time steps of past traffic data are used as the input 
> - Prediction horizon, i.e., how many time steps in the future the prediction is for 
> - An arbitrary function that calculates the traffic prediction based on the input data  
> - Loss function, which is the function that calculates the quality of the prediction
> - The optimal set of parameters for the function $f$

(T-ZS30, T-ZS38) 有单步和多步的定义

(T-40, T-136) 有多步定义 (T-136 我觉得不错)

(T-28) 有基于条件概率的多步定义

#### 目标类型

##### 综述

(T-ZS1)

- 交通流量 某地某段时间车辆总数

  (T-ZS1) Traffic flow is denoted as the total number of vehicles detected in a target detection site during a certain time period. 

  (T-ZS2) Traffic flow is defined as the number of vehicles passing through a spatial unit, such as a road segment or traffic sensor point, in a given time period  

- 交通速度 某地某段时间各车辆平均速度

  (T-ZS1) Traffic speed is denoted as the average traveling speed of vehicles detected in a target detection site during a certain time period
  
  (T-ZS2) is defined as the average speed of vehicles passing through a spatial unit in a given time period  

其他类别：

- 交通状况 
  
  (T-ZS1) T-4 traffic condition, which consists of four categories: fluency, slow, congestion and extreme congestion  
  
- 人流量 
  - (T-ZS1) T-51 [T-30](https://www.researchgate.net/profile/Leye-Wang/publication/322886199_Crowd_Flow_Prediction_by_Deep_Spatio-Temporal_Transfer_Learning/links/5aa9bd6b0f7e9b88266f6529/Crowd-Flow-Prediction-by-Deep-Spatio-Temporal-Transfer-Learning.pdf) crowd flow instead of traffic flow: Crowd flow measurements are the same as traffic flow, but they are designed for general human mobility instead of automobile mobility  
  - (T-ZS1) [T-31](https://dl.acm.org/doi/abs/10.1145/3292500.3330646) 细粒度而不是历史数据的  a fine-grained prediction is performed using a coarser data (e.g., predicting crowd flow of different school buildings given crowd flow of the entire university area) instead of using historical data
  
- 红绿灯：影响时空依赖

  (T-ZS2) The traffic light is another source of challenges for various traffic prediction tasks.  

  Short-term traffic flow fluctuation and the spatial relation change between two road segments can be caused by the traffic light. The way of controlling the traffic light may be different in different time periods, causing an inconsistent traffic flow pattern.  
  
- (T-ZS2) 交通需求：如打车服务需求量 (前景应用见上文)

- (T-ZS2) 交通事故，交通异常 Traffic accident and Traffic anomaly  

  定义：A traffic accident is usually an accident in road traffic involving different vehicles, which may cause significant loss of life and property.  

  The traffic anomaly has a broader definition that deviates from the normal traffic state, e.g., the traffic jam caused by a traffic accident or a public procession  

- (T-ZS2) 车位空余

  Parking availability: the target is to predict the availability of vacant parking space for cars in the streets or in a car parking lot

- (T-ZS2 描述 [T-65](https://ieeexplore.ieee.org/abstract/document/9151256)) 车辆排放

  Urban vehicle emission refers to the emission produced by motor vehicles, e.g., those use internal combustion engines.   

- (T-ZS2 描述 [T-66](https://ieeexplore.ieee.org/abstract/document/9294742)) 交通延迟

  Railway delay: the delay time of specific routes in the railway system

- (T-ZS2 描述 [T-67](https://ieeexplore.ieee.org/abstract/document/8917174)) 车道占用

  Lane occupancy: With simulated traffic data, lane occupancy has been measured and predicted  

##### 交通流量

可以分为无向流、双向流、入流、出流。

(T-ZS2) Road-level traffic flow problems are further divided into cases of unidirectional and bidirectional traffic flow, whereas region-level and station-level traffic flow problems are further divided into the cases of inflow and outflow, based on different problem formulations.  

(T-110 图)

![image-20240819010513289](img/image-20240819010513289.png)

##### 交通需求

定义：

(T-ZS2) Traffic demand refers to the potential demand for travel, which may or may not be fulfilled completely. 

数据：使用用户数据推断，可能低估真实数据

(T-ZS2) However, in some cases, it is difficult to collect the potential travel demand from passengers and a compromise method using transaction records as an indication of the traffic demand is used. In such cases the real demand may be underestimated.  

分类：

(T-ZS2) Based on transport mode, the traffic demand problems considered include ride-hailing demand, taxi demand, shared vehicle demand, and bike demand.  

#### 道路类型

##### 综述

(T-ZS2) 分类原因：表征空间依赖的模型要求不一样

Different problem types have different modelling requirements for representing spatial dependency

(T-ZS2) 分类为：道路、区域、站点等级

These include road-level, region-level, and station-level categories.  

- 道路：探测器 -> 路段 / GPS 轨迹(映射为路网)，路网连接+空间近似性

  For the road-level problems, the traffic data are usually collected from sensors, which are associated with specific road segments, or GPS trajectory data, which are also mapped into the road network with map
  matching techniques. In this case, the road network topology can be seen as the graph to use, which may contain hundreds or thousands of road segments potentially. The spatial dependency may be described by the road network connectivity or spatial proximity  

- 站点：地铁/车站拓扑图，数十数百个点，地铁公交线路图为空间依赖

  For the station-level problems, the metro or bus station topology can be taken as the graph to use, which may contain tens or hundreds of stations potentially. The spatial dependency may be described by the metro lines or bus routes  

- 区域：规则或不规则区域为节点，依赖：土地使用目的，POI 等获取

  For the region-level problem, the regular or irregular regions are used as the nodes in a graph. The spatial dependency between different regions can be extracted from the land use purposes, e.g., from the points-of-interest data  

##### 细分

(T-ZS2) 交通流按道路类型细分：

- 道路级：交通流、OD 流、路口吞吐量

  Road-level flow problems are concerned with traffic volumes on a road and include road traffic flow, road origin-destination (OD) Flow, and intersection traffic throughput.

  - 某个传感器位置

    In road traffic flow problems, the prediction target is the traffic volume that passes a road sensor or a specific location along the road within a certain time period (e.g. five minutes)

  - 某个起止点

    In the road OD flow problem, the target is the volume between one location (the origin) and another (the destination) at a single point in time. 

  - 某个交叉路

    The intersection traffic throughput problem considers the volume of traffic moving through an intersection

- 区域级：规则或不规则区域

  Region-level flow problems consider traffic volume in a region. A city may be
  divided into regular regions (where the partitioning is grid-based) or irregular regions (e.g. road-based or zip-code-based partitions). 

  These problems are classified by transport mode into regional taxi flow, regional bike flow, regional ride-hailing flow, regional dockless e-scooter flow, regional OD taxi flow, regional OD bike flow, and regional OD ride-hailing flow problems  

- 站点级：

  Station-level flow problems relate to the traffic volume measured at a physical station, for example, a subway or bus station. These problems are divided by station type into station-level subway passenger flow, station-level bus passenger flow, station-level shared vehicle flow, station-level bike flow, and station-level railway passenger flow problems  

(T-ZS2) 交通速度划分：道路速度、区域级速度、旅行时间、拥堵预测

- 交通拥挤和道路交通速度细分

  (T-ZS2) In several studies, traffic congestion is judged by a threshold-based speed inference. 

  The specific road-level speed problem categories considered are road traffic speed, road travel time, traffic congestion, and time of arrival problems; 

  while the region-level speed problem considered is regional OD taxi speed  

- 高速公路的速度预测相对简单：没有红绿灯、上下坡

  Freeways have a few traffic signals or on/off-ramps, making the prediction easier than the urban case.  

  挑战来自于时间依赖

  And the challenge mainly comes from the complex temporal dependency  

- 城市区域：突发变化、复杂连接、限速、空间依赖

  More complex traffic networks exist in urban roads with more complicated connection patterns and abrupt changes. For example, different road segments may have different speed limit values and the allowed vehicle types. Besides the complex temporal dependency, modeling the spatial dependency becomes a bigger challenge for urban traffic speed forecasting.  

(T-ZS2) 感觉分的太细了：

> - Road Traffic Flow
> - Road OD Flow [Origin-Destination] 仅 2 篇
> - Intersection Traffic Throughput (吞吐量) 仅 1 篇
> - Regional Taxi Flow 几篇
> - Regional Bike Flow 3 篇
> - Regional Ride-hailing Flow (打车) 仅 1 篇
> - Regional Dockless E-Scooter Flow (无桩电摩) 仅 1 篇
> - Regional OD Taxi Flow 仅 2 篇
> - Regional OD Bike Flow 仅 1 篇
> - Regional OD Ride hailing Flow 3 篇
> - Station-level Subway Passenger Flow  近 10 篇
> - Station-level Bus Passenger Flow  3 篇
> - Station-level Shared Vehicle Flow 仅 1 篇
> - Station-level Bike Flow 仅 2 篇
> - Station-level Railway Passenger Flow  仅 1 篇
> - Road Traffic Speed 最多
> - Road Travel Time 几篇
> - Traffic Congestion 几篇
> - Time of Arrival 仅 1 篇
> - Regional OD Taxi Speed 仅 1 篇
> - Ride-hailing Demand 几篇
> - Taxi Demand 十几篇
> - Shared Vehicle Demand 仅 1 篇
> - Bike Demand 十几篇
> - Traffic Accident 3 篇
> - Traffic Anomaly 仅 1 篇
> - Parking Availability 3 篇
> - Transportation Resilience (弹性) 仅 1 篇
> - Urban Vehicle Emission 仅 1 篇
> - Railway Delay 仅 1 篇
> - Lane Occupancy 仅 1 篇

#### 评价指标

##### 准确率

> (T-ZS2) Some commonly used evaluation metrics, namely, RMSE, MAE and MAPE, are defined as follows:  (下文公式符号与论文有所差异)
>
> (T-ZS2) root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE)  
>
> (T-ZS28) 中文分别为平均绝对误差、根均方误差、平均绝对百分比误差

设 $y$ 是实际值，$\hat y$ 是预测值，$n$ 是样本数
$$
\begin{cases}
RMSE=\sqrt{\dfrac1n\sum_{i=1}^n(y_i-\hat y_i)^2}\\
MAE=\dfrac1n\sum_{i=1}^n|y_i-\hat y_i|\\
MAPE=\dfrac{1}n\sum_{i=1}^n\left|\dfrac{y_i-\hat y_i}{y_i}\right|
\end{cases}
$$

> where y denotes the true values, ^y denotes the predicted values, and n is the number of values to predict.   

(T-ZS2) 含义：RMSE/MAE 越低，表现越好

> A lower RMSE or MAE value indicates a better prediction performance  

> (T-ZS35) 还有 MSE，就是没有根号
>

> ##### 评价
>
> (T-ZS2 说 T-ZS1 说的) 因为用不同的数据集，所以难以衡量 SOTA
>
> It is known that different works use different datasets and it is very hard to assess the relative performance of different state-of-the-art models  
>
> 同一数据也可能不同子集

##### 性能

训练时间，预测时间衡量模型是否足够轻量化之类的

根据阅读具体论文，许多论文虽然准确率只提升一些，但是速度可以快一倍这样，这也是一种提升，如 T-135

可以用参数量如 T-110

## 现有综述

### 列表

##### 完整读过的

- T-ZS1

  CNN, RNN, FNN 2014-2019

- T-ZS2

  GNN 综述，2018-2020 (212论文)

##### 粗略读过 / 浏览的

- T-ZS3

  ML 综述，2023 发的，质量不行，主要总结 2019-2020 的引用低的论文

- [T-ZS25](https://kns.cnki.net/kcms2/article/abstract?v=zLXkCTFmbAE0kiBiuRwo43mnAPv-R_ASfI6CgqtMR3zj_43SjyOTlvGD1iOASGiFU80MD6K4pd5Ormzx1MgcxP_9iprx62eGFql9DNVEPGfAf7_gd8TfHMvnla9tV6KS1Cfa87s8HL7ZAV7uj2RS7_c5zffroQJ59bwB5YRmZMPZgZs5yGzo_XerdqFM7tbGGNbogxDcESA=&uniplatform=NZKPT&language=CHS)

  国内综述，2023 发的，但引用的都是 2020 或以前为主，其相关技术介绍部分可以读

- [T-ZS26](https://kns.cnki.net/kcms2/article/abstract?v=zLXkCTFmbAHQsgkv3Z5hR3gzXma6lYxfCt6KHiMGCj6XF9KOgBA5h7Ba9G_a-N49FAW1pI0ZF9Jbau4sJDZZklmHyMEvb0Bno58PXXshhRTHYFPplpjPh5Gjw0eanMFbjgHUi7ubbN1uQW_YHvDKvaHkKpkZWdlbxTAChnY0-ZERhM_Updl-ny5s550R9g-0Qaadz6lq_1k=&uniplatform=NZKPT&language=CHS)

  给出了公开数据集的下载链接列表和部分介绍

  虽然引用了一些近几年(2019-2022,也有一部分2023)的论文，但是没有做系统的介绍和对比

- [T-ZS27](https://kns.cnki.net/kcms2/article/abstract?v=zLXkCTFmbAEVIf30YEPWb5SUyGnQEDWOxW148qzMF8BbjFczUk4xY6mmbLBOPFd4_--SluXrQNbMqJ5ooZiKn_ec2fVsDu1sN4OfqFbD7tWBcynHZughZYhAZCbfJ1fN7CsNTOm-5mcA5HBMNG1ibHA4-cO4YxkGe-y3KrgUftfnl67WiNW2HvMaexqIVfqs3yTF07-xlcySi-x1wx5GuA==&uniplatform=NZKPT&language=CHS)

  给了一个按技术场景和数据库主题分类的列表文章汇总，年份大约到 2022 年，不新，但是不知道对比结果

- [T-ZS28](https://kns.cnki.net/kcms2/article/abstract?v=zLXkCTFmbAGbEBcbq4eDAo3k2DEo3Fsplf6RYMh_a0JPj_N2Uk7TSuSi33CoCnLOGUfG4jFGPG63P0GDtIJEZciu9OaN8MEA2a3F-2U8pLMT2v-M-Eva6MBbAE0TtTEcK1H2o4CrNkOCv8zDb-UVkl9YUUqE9OM_uRwSq7Em7Kgj4PX_AS0Gewc3JxQJlHnecBWt1q2x5vY=&uniplatform=NZKPT&language=CHS)

  讲 GNN 的，有一个 GNN 的模型论文的分类归纳总结表格，实验结果，数据表(没给出处) ，2021 年左右多

- T-ZS24

  GNN 综述，2023 发的，但是叫 urban computing，对 GNN 技术介绍比较多，对交通的应用只给了一小部分例子论文之类的，感觉作用不大
  
- [T-ZS29](https://www.mdpi.com/2220-9964/12/3/100)

  T-ZS2 的正统续作，研究了 2022 的其他论文，列举了到 2023-2 为止的论文

- [T-ZS30](https://link.springer.com/article/10.1007/s41019-024-00246-x)

  2024 写的，描述的论文不多，但比较新，也有可参考之处
  
- [T-ZS32](https://ieeexplore.ieee.org/abstract/document/10522180)

  2023 的论文收录较多，感觉有参考价值
  
- [T-ZS33](https://ieeexplore.ieee.org/abstract/document/10401928)

  可以参考这里对交通速度和流量关系的描述，其他讲智能交通和多任务学习的感觉关系不大

- [T-ZS34](https://ieeexplore.ieee.org/abstract/document/10411651)

  GNN 的，年份大约主要是 2022 的，但是感觉描述不详细，分别对时空要点进行了总结

- [T-ZS35](https://ieeexplore.ieee.org/abstract/document/10562041)

  LSTM 的，年份有到 2023 的近年较多 LSTM+XXX 论文，挑战部分也可以参考一下
  
- [T-ZS37](https://kns.cnki.net/kcms2/article/abstract?v=yQB21MkjwM8r7VSCFl4R_R0TQjr59IRayu-seXUC7-xY2JRr5EWzAgVQOAbaWuS4KDJp9FwiDgOuCWhNuntH2Ek0XZX987H1yEUwOYOmRb96IYGbqCdgbkUTsoYxZXLQDWXqAbWfaS8qae-4ibLsizj3lfNvicEQviou9qr3GwSewc2n5J5NKi1Z-6Tl2J3ANIYBQktwP8f8CMEfX0IdMldKD_CAcsOHWtO2unjtcaUj3vYCulDsStnMgDQCBe7NKbW88x7R17IbSKndD4ROwePZAFcPEElFKplxgobsDwo9Ys92bM1as7MgfxCxpAF7n89dKdlr5CJn-H0w4DeKKf5b2by0A2tp6AJrDQiESjaQJx526QkViV9a3YumQQc8usgc3dgyg3rBSnzg49melcAlA8LzDIYmzVju2tUBvc0w9Cq6yxeoAFAASPmxD1aiNyl4WE90M03S8hlu3q5mmICURHwNJ7uO6SwJtaq7jMDXcbws5A11mXslGJioesrzariMosF4O_Y7YZjwZwf2ysqPofK4rZ9-HcY7INTOz0IIYs_xi1k1w2PKec5sN6nPq5Ztrk0HddQ=&uniplatform=NZKPT&language=CHS)

  中文，论文和对比结果不多，有新的，有 GNN + 各种东西的详细介绍

- [T-ZS38](https://ieeexplore.ieee.org/abstract/document/10535113)

  论文不是很新，时空分类和技术细分可以看一下

##### 没读过的

- [T-ZS23](https://www.sciencedirect.com/science/article/pii/S0968090X14000096)

  statistical, neural network, hybrid model 2006-2013

  time series, function approximation 浏览了一下，深度学习较少

  提出了十个挑战，为 T-ZS1 所继承

- [T-ZS4](https://www.sciencedirect.com/science/article/pii/S1574119217306521)

  浏览了一下，对深度学习介绍很少，传统方法介绍篇幅很多

- [T-ZS5](https://ieeexplore.ieee.org/abstract/document/8344848/)

  浏览了一下，主要讲大数据技术，感觉相关性不大

- [T-ZS6](https://www.sciencedirect.com/science/article/pii/S0968090X10001610)

  读摘要，对比统计方法和 NN

- [T-ZS7](https://dl.acm.org/doi/abs/10.1145/3231541.3231544)

  没搞到 pdf，只读了摘要，NN 相关 2018

- T-ZS8

  年份太久远了 2004

- [T-ZS9](https://www.sciencedirect.com/science/article/pii/S1389128620311567)

  浏览摘要，分成统计和摘要方法，2020

- [T-ZS10](https://www.sciencedirect.com/science/article/pii/S1389128620311877)

  浏览摘要都在说 ML，2020

- [T-ZS11](https://link.springer.com/article/10.1007/s11277-020-07612-8)

  浏览摘要有 ML/DL，2020

- [T-ZS12](https://link.springer.com/article/10.1007/s42421-020-00020-1)

  浏览摘要有 DL，2020

- [T-ZS13](https://ieeexplore.ieee.org/abstract/document/9395529)

  浏览摘要有 DL，2021

- [T-ZS14](https://iris.cnr.it/bitstream/20.500.14243/380062/1/prod_438502-doc_157210.pdf)

  浏览摘要有数据源、DL、挑战，2020

- [T-ZS15](https://ieeexplore.ieee.org/abstract/document/9447807)

  浏览摘要有 DL 和实验，2021

- [T-ZS16](https://link.springer.com/article/10.1186/s12544-019-0345-9)

  摘要说特征选择和提取方法，1984-2018.3

- [T-ZS17](https://arxiv.org/abs/1808.06865)

  摘要说是时空序列预测，2018

- [T-ZS18](https://link.springer.com/article/10.1007/s42421-020-00030-z)

  摘要说研究影响 DL 精度的因素，评价指标等，2020

- [T-ZS19](https://www.sciencedirect.com/science/article/pii/S1566253519303094)

  摘要说影响因素，数据预处理，分类为统计、ML、DL、迁移、强化，2020

- [T-ZS20](https://ieeexplore.ieee.org/abstract/document/9310691/)

  摘要说 GNN 综述，2020

- [T-ZS21](https://ieeexplore.ieee.org/abstract/document/9352246)

  摘要说有数据集，比较实验，挑战，2020

- [T-ZS22](https://link.springer.com/article/10.1007/s42486-020-00039-x)

  摘要说是 ITS, DL，2020
  
- [T-ZS31](https://dl.acm.org/doi/abs/10.1145/3459637.3482000)

  (T-ZS30) 说是三种分类：网格、图、多变量时序
  
- [T-ZS36](https://shodhganga.inflibnet.ac.in/handle/10603/522607?mode=full)

  只看了参考文献，看年份大部分很旧，感觉没必要读
  
- [T-ZS39](https://www.sciencedirect.com/science/article/pii/S2667305323000935)

  浏览了表格，感觉引用的论文比较旧

- [T-ZS40](https://arxiv.org/abs/2403.07444)

  讲联邦学习，论文还是比较新的

- [T-ZS41](https://ieeexplore.ieee.org/abstract/document/10444919)

  讲智能交通的，相关论文太少了，感觉没必要读

##### 无关综述

自己搜的：

- Forecasting Network Traffic: A Survey and Tutorial With Open-Source Comparative Evaluation

  研究网络的(如 wifi, TCP, 5g)

- Graph-based Time-series Forecasting in Deep Learning

  浏览了目录，感觉关系不大，不必要读

### 评价

#### 论文互评

评价/内容概述

- T-ZS1 只关心 DL，encoder-decoder LSTM+GNN SOTA；介绍了数据类型、DL 结构、挑战

  (T-ZS2 评价) only focus on the progress of deep learning-based methods

  The authors conclude that encoder-decoder long short term-memory (LSTM) combined with graph-based methods is the state-of-the-art prediction technique

  A detailed explanation of various data types and popular deep neural network architectures is also provided, along with challenges and future directions for traffic prediction  

- T-ZS23

  (T-ZS1 评价) 分类老旧、深度学习少

  do not include the now ubiquitous deep neural network models

  their work categorized the models based on several criteria such as the type of model (e.g. statistical, neural network, hybrid model) and the problem (e.g. time series, function approximation). This taxonomy is outdated because modern traffic prediction models are mainly based on deep neural network, which under their taxonomy will all fall under the neural network category of model and function approximation category of problem  

- T-ZS4

  (T-ZS1 评价) 分类比较少、没讨论挑战

  their model taxonomy only has a few points of comparison, which are: whether or not the model integrates environmental data, contains spatial property, handles nonlinearity and handles nonstationarity  

  Additionally, their work does not have a future challenges section that discusses how the field can be advanced  

- T-ZS5

  (T-ZS1 评价) 与机器学习关联不大

  their work focuses on big data analytics without much focus on the actual models  
  
- T-ZS10

  (T-ZS2 评价) 分类了 ML：回归、基于例子的(kNN)、基于核的(SVM, RBF)、NN、混合模型

  Machine learning models for traffic prediction are further categorized, which include the regression model, examplebased models (e.g., k-nearest neighbors), kernel-based models (e.g. support vector machine and radial basis function), neural network models, and hybrid models  
  
- T-ZS11, T-ZS19

  (T-ZS2 评价) 分类了五种预测方法：统计、ML、DL、强化、迁移

  Roughly speaking, five different types of traffic prediction methods are identified and categorized in previous surveys, namely, statistics-based methods, traditional machine learning methods, deep learning-based methods, reinforcement learning-based methods, and transfer learning based methods.  
  
- T-ZS12

  (T-ZS2 评价) GNN 只在交通特征预测任务提及

  GNNs are only mentioned in the task of traffic characteristics prediction 
  
- T-ZS13

  (T-ZS2 评价) 把 DL 分成了五类；GNN 仍然是 SOTA

  Deep learning models are further categorized into five different generations, in which GCNs are classified as the fourth generation and other advanced techniques that have been considered but are not yet widely applied are merged into the fifth generation. These include transfer learning, meta learning, reinforcement learning, and the attention mechanism.  
  
  Before these advanced techniques become mature in traffic prediction tasks, GNNs remain the state-of-the-art technique  
  
- T-ZS15, T-ZS21

  (T-ZS2 评价) 比较了 DL 和基于统计的方法/ML

  compare them with the statistics-based and machine learning methods
  
- T-ZS15

  (T-ZS2 评价) DL 不总是最优的，线性模型/ML 可能更好

  Conversely, it is found that deep learning is not always the best modeling technique in practical applications, where linear models and machine learning techniques with less computational complexity can sometimes be preferable
  
- T-ZS16

  (T-ZS2 评价) 特征选择和预处理方法的综述

  spatiotemporal feature selection and extraction pre-processing methods, which may also be embedded as internal model processes, are reviewed
  
- T-ZS18

  (T-ZS2 评价) 准确率的元分析，不同 DL 方法，样本大小，预测视野

  A meta-analysis of prediction accuracy when applying deep learning methods to transport studies  
  
  In this study, apart from the models themselves, additional factors including sample size and prediction time horizon are shown to have a significant influence on prediction accuracy  
  
- T-ZS20

  (T-ZS2 评价) 对交通堵塞、旅行需求、交通安全等的 GNN 综述；讨论了 GNN 和 DL 的优缺点

  Graph-based deep learning architectures are reviewed for a series of traffic applications, namely, traffic congestion, travel demand, transportation safety, traffic surveillance, and autonomous driving.  
  
  Specific and practical guidance for constructing graphs in these applications is provided  
  
  The advantages and disadvantages of both GNNs and other deep learning models ,e.g. recurrent neural network (RNN), temporal convolutional network (TCN), Seq2Seq, and generative adversarial network (GAN), are examined  
  
  While the focus is not limited to traffic prediction problems, the graph construction process is universal in the traffic domain when GNNs are involved  
  
- T-ZS22

  (T-ZS2 评价) 2019 后 SOTA 都是基于 GNN 的

  Among the major milestones of deep-learning driven traffic prediction (summarized in Figure 2), the state-of-the-art models after 2019 are all based on GNNs, indicating that GNNs are indeed the frontier of deep learning-based traffic prediction research  

#### 关系

T-ZS1 介绍了 T-ZS23, T-ZS4，好像也有 T-ZS5, T-ZS6, T-ZS7

T-ZS2 提到了 T-ZS8，列举了综述 T-ZS1，T-ZS9 到 T-ZS21

#### 个人总结

##### T-ZS3

该论文提及，传统技术还包括：Random Forest (RF) Algorithm, Bayesian Algorithm (BA) approach, K-Nearest Neighbor (KNN), Principal Component Analysis (PCA), and Support Vector Algorithms

神经网络：BackPropagation Neural Network (BPNN)、CNN、RNN、LSTM、Restricted Boltzmann Machines (RBM), Deep Belief Networks (DBN) , and Stacked Auto-Encoder (SAE)  

> 提供了 AI, ML, DL 的概念， ML 领域的分类图，感觉还是可以参考有用的
>
> 以及十页这样描述了 ML 的常用算法，如 KNN 等
>
> 介绍了强化学习的概念和常用方法

> 给了 DL 和 ML 的技术发展时间线

技术介绍部分，感觉没提到 GNN，综述的内容年份也不是很新，整体来说除非要学习 ML/DL 的基本概念不然感觉意义不大

其前 20 页介绍具体技术的时候，没有和交通流量结合起来，只是单纯介绍技术本身

具体论文部分，每一个论文单独写了一句话表述这个论文，并给了表格，表 3 是 DL，包含引用里的 134-159 论文，但表格只是简单描述论文方法，数据集，结论，不加任何统计和对比分类 (~~写的这么烂难怪 CCF NONE)~~

其大部分论文在 2019-2020 年份，最新有一点 2021/2022 的，随便抽查了五六篇，都是引用的具体论文的参考量才几十，感觉都是犄角旮旯的水文总结的水综述，而且感觉都是 CCF NONE，~~鉴定为：水论文，没有参考价值~~

> 挑战章节部分一笔带过

##### T-ZS25

有 CNN, GNN 的详细介绍，GNN 的发展历史图

提供了点数据和轨迹数据的常用公开数据集列表，但没给出处下载链接，引用的工作没有做按年份和表格的整理，而且感觉也不是很新

> 说可以分为 5-15min 为短时预测，15-45 为中时，45+ 长时
>
> 提到的传统 ML 有 kNN, SVM, 贝叶斯网络等

按照时间特征技术和空间特征技术分类，值得参考

- 时间：ML、RNN、混合(+ARIMA)
- 空间：CNN、GNN、融合

> 其相关技术论述可以阅读，应该能查漏补缺地学习

相关论文：(有时间轴线) (引用量都挺多的)

RNN

- 2015 T-25 [论文笔记](https://blog.csdn.net/qq_39805362/article/details/105509203) LSTM 在交通的开山
- 2016 [T-117](https://ieeexplore.ieee.org/abstract/document/7804912) (使用了 LSTM, GRU 两种 RNN)
- 2017 T-46 (二维 LSTM 变体)
- 2017 [T-118](https://ieeexplore.ieee.org/abstract/document/8215650) Prediction for Time Series at Uber (2层编码器预训练等的 LSTM 变体)
- 2018 [T-119](https://www.sciencedirect.com/science/article/pii/S0925231218310294) (考虑缺失数据的 LSTM-M)
- 2019 T-43 (Meta-RNN)
- 2019 [T-120](Traffic flow prediction using LSTM with feature enhancement) (注意力+LSTM)
- 2020 [T-121](https://ieeexplore.ieee.org/abstract/document/9315723/) (SAE+LSTM)

CNN

- 2017 T-72 (将交通视为图像，横轴为时间、纵轴为空间)
- 2017 [T-122](https://ieeexplore.ieee.org/abstract/document/8240913/) (CNN+GRU)
- 2019 [T-123](https://ieeexplore.ieee.org/abstract/document/8684259) (三维 CNN 结合经纬+时间信息)
- 2019 [T-124](https://ojs.aaai.org/index.php/AAAI/article/view/4511) (局部CNN+LSTM处理动态时空依赖 STDN)
- 2016 T-3 (一维CNN+2层LSTM)
- 还有若干 CNN 网络框架(十几篇，没具体介绍)

> GNN 略

> 还做了实验，对陕西数据跑了 10 个不同领域经典模型
>
> 提出了一种收费流转交通流的路子 [T-125](https://ieeexplore.ieee.org/abstract/document/8600736)

##### T-ZS30

列表总结了一些综述，有单步和多步预测的定义 (T-ZS38 也有定义)

对预测的结构：数据分析（收集、格式、特征）、建模、应用总结

有几种建模图的分类及其严格定义

空间建模：CNN、GNN、注意力、多图融合，有按时间的总结图(到2023)

时间建模：RNN、TCN (一种卷积)、自注意力

时空建模：元学习、ODE 网络、自监督、持续学习

> GPT：自监督学习是一种机器学习方法，它介于监督学习和无监督学习之间。在监督学习中，模型依赖于大量标注的数据进行训练，而无监督学习则完全依赖未标注的数据，自监督学习试图通过构造内部监督信号来解决缺乏标注数据的问题。

有对交通流量预测等的列表描述，表示了时间空间分别怎么处理，新倒是有挺新的，表格里论文数量不多，文字描述篇幅倒是还比较详细

有数据集的列表和描述，按问题领域分类

##### T-ZS32

收录的论文基本都是 2023 的，有引用量，感觉比较新，列表有一定数量论文，可以参考。

##### T-ZS33

摘要说交通速度和交通流量高度关联

讲多任务学习，其中一个应用领域是交通流量预测，还有需求预测等

多任务学习一种模式为硬参数：共享一部分层，参见论文图 2 所示，最常用；另一种是软参数硬更减少过拟合，降低开销

看了一眼第三章相关部分论文的年份，感觉不新。第四页有二者关系的简单论述，提供了表 1 表示相关的几篇论文的内容

##### T-ZS35

有近几年到 2023(不是很多)的 LSTM + X 的论文的表格汇总，包含其数据集，主要技术等

有数据集的表格汇总，分类：速度/流/轨迹，时间，地点，更新时间，链接等，但没有找到详细的介绍

在 PeMS 04/08 上对比了 10 个经典模型的结果

未来挑战部分的观点也可以参考一下

##### T-ZS38

有单步、多步的定义

列表总结了 RNN, LSTM, GRU, CNN, TCN 的梯度消失、长距离信息、时间开销内容、参数异同，分别介绍了它们，还介绍了 Seq2seq 和 Transformer，按时空也分类了一个表格和描述，论文不是很新，没有对论文的列表总结

## 具体技术

### 概述

#### 描述

(T-ZS1) The earliest class of models used is the classical statistical models. Afterwards, machine learning models improve upon the performance of classical statistical models. Then, the deep neural network class of models dominates the field due to its capability in capturing the complex and nonlinear patterns in traffic data.  

#### 分类

(T-ZS28 的树形分类图 1)

![image-20240808152704281](img/image-20240808152704281.png)



### 统计模型

##### ARIMA

(T-ZS1) classical statistical models, of which the Autoregressive Integrated Moving Average (ARIMA) family of models is the most popular. 

局限：(T-ZS1) 线性模型，假设数据规律不变；只能预测小时间段，参数手调

- T-3 T-5 [T-ZS6](https://www.sciencedirect.com/science/article/pii/S0968090X10001610) simple linear models which assume that the traffic is stationary  ->  frequently fail when handling the complex, nonlinear traffic data 
- [T-12](https://arxiv.org/abs/1801.02143) were proposed at a time where traffic data were simpler and much smaller in size  -> a condition that no longer holds true in the present day where the ubiquity of traffic sensors has caused an explosion in traffic flow data   
- [O-1](https://www.tandfonline.com/doi/abs/10.1080/00031305.1996.10473554) the function parameters are manually defined a priori  

评价：(T-ZS2) Traditional linear time series models, e.g. auto-regressive and integrated moving average (ARIMA) models, cannot handle such spatiotemporal forecasting problems  

(stated by T-ZS1)

- [T-6](https://trid.trb.org/View/148123) [1979] first researchers to apply ARIMA to traffic prediction 
- [T-7](https://trid.trb.org/View/167550) [1980] found that the ARIMA(0,1,1) model is the most statistically significant
- [T-8](https://journals.sagepub.com/doi/abs/10.3141/1678-22) [1999] applied subset ARIMA and found that it provides stable and accurate results
- [T-9](https://journals.sagepub.com/doi/abs/10.3141/1776-25) [2001] discovered the impact of upstream traffic sensors to downstream ones and applied ARIMAX model for traffic flow prediction
- [T-10](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-947X(2003)129:6(664)) [2003] applied Seasonal ARIMA to the United States and the United Kingdom traffic data 
- [T-11](https://journals.sagepub.com/doi/abs/10.3141/1857-09) [2003] discussed and compared the Vector Autoregressive Moving Average and Single space-time ARIMA model

优点是解释性比 ML 好

(T-ZS2 论述说 T-ZS9 指出)：statistics-based models have better model interpretability, whereas ML-based models are more flexible 

##### 多元时间序列模型

> ARIMA 是一元的 (GPT4o)

介绍：如向量自回归模型(VAR, vector autoregression)

(T-ZS2) Before the usage of graph theories and GNNs, the spatial information is usually extracted by multivariate time series models or CNNs. Within a multivariate time series model, e.g., vector autoregression, the traffic states collected in different locations or regions are combined together as multivariate time series.  

缺点：线性

(T-ZS2) However, the multivariate time series models can only extract the linear relationship among different states, which is not enough for modeling the complex and nonlinear spatial dependency  

##### 其他

(T-ZS2) autoregression 

- 如 T-78

(T-ZS2) Markov process (马尔科夫链)

- 如 T-79

### 机器学习

#### 历史

(T-ZS1) machine learning models during the 2000s utilize shallow and simple structures, limiting their prediction power  

(stated by T-ZS1)

- [T-13](https://research.aber.ac.uk/en/publications/the-use-of-neural-networks-to-recognise-and-predict-traffic-conge) [1993] One of the first neural network applications in traffic flow prediction  
- [T-14](https://www.sciencedirect.com/science/article/pii/S0968090X05000276) [2005] proposed a genetic algorithm approach to optimally tune the network
- [T-15](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-947X(2006)132:2(114)) [2006] used multiple neural network predictors which are combined using the theory of conditional probability and the Bayes rule  
- [T-16](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0887-3801(2005)19:1(94)) [2005] neural network model was applied to traffic prediction  
- [T-17](https://ieeexplore.ieee.org/abstract/document/6088012) [2012] imbued a neural network model with the hybrid exponential smoothing method to preprocess training data and the Levenberg-Marquardt algorithm to train the network weights

非 NN：

(stated by T-ZS1)

- k-Nearest Neighbor [T-18](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-947X(1991)117:2(178)) [T-19](https://www.sciencedirect.com/science/article/pii/S1877042813022027) [T-20](https://www.sciencedirect.com/science/article/pii/S0968090X15003812)
- support vector regression (SVR) [T-21](https://www.sciencedirect.com/science/article/abs/pii/S0957417408004740) [T-22](https://ieeexplore.ieee.org/abstract/document/4344269) [T-23](https://link.springer.com/chapter/10.1007/978-3-540-72393-6_121)

(T-ZS2) 其他模型，如 Kalman filters (滤波器) 如 T-80

(T-ZS3 给出的，说引用自另一篇综述 [O-29](https://ui.adsabs.harvard.edu/abs/2021arXiv211215538M/abstract))

![image-20240806225417369](img/image-20240806225417369.png)

#### 概述

##### 分类

(T-ZS3 给出的，说引用自另一篇综述 O-29)

![image-20240806224808082](img/image-20240806224808082.png)

##### 优缺点

- 局限性：数据密集

  (T-ZS1) The main weakness is that machine learning models are data intensive 

- 局限性：

  (T-ZS1) powerful but very hard to train efficiently  

- 局限性：手动提取特征

  (T-ZS1) many other machine learning models’ feature extraction phase, which helps extract useful patterns and information from the data to help the prediction, is done manually (i.e., using manually tuned kernels)  

- 优点：

  (T-ZS1) Machine learning models are flexible as they can learn from the data. That is, the parameters of the prediction function are adjusted automatically as the model traverses through the dataset  

#### 混合模型

##### 概念

集各家之长

(T-ZS1) As complex deep neural networks are becoming viable to train, most authors have utilized the hybrid neural network setting, which combines different neural network structures into a larger entity, to maximize the prediction performance  

The popularity of hybrid neural network structure is contributed by its power and flexibility of utilizing the different strengths of its individual components.   

> While complex models are expensive to train, their performance improvements have proven that the investment is worthwhile  

现状：占主要

(T-ZS1) we can see that the simpler “deep neural network” category consists of papers from the earlier years of traffic prediction research while “hybrid deep neural network” and “hybrid deep neural network and graph theory” mostly contain more recent papers. Hybrid deep neural networks combine different types of simple deep neural network structures in order to combine the strengths of each  

##### 对比简单的例子

(T-ZS1) 对比简单模型的例子：

- T-40 encoder-decoder 图扩散比 FNN, LSTM 好，消融证明扩散卷积更好

  have demonstrated that their encoder-decoder model with graph diffusion managed to outperform simple FNN and LSTM. Not only that, they also performed an ablation test to demonstrate that their novel diffusion convolution module manages to outperform simpler variations  

- T-44 与 FNN, LSTM, GRU 对比

  have compared their method against simple FNN, LSTM and GRU, showing similar trends  

结论：复杂的比简单的好，新的技术更好

While we provide only two examples due to space constraints, we can attest that many complex hybrid deep neural network models have managed to outperform simpler deep neural network models and that many novel modules designed to capture spatial and temporal correlations (e.g., spatial and temporal attention) have resulted in further performance improvement  

#### SAE / DBN

##### 概念

(T-ZS1) 评价：不能明确获取时空信息

The main contributing factor of this rarity is that SAEs and DBNs do not explicitly capture the spatial or the temporal aspect of the data and thus tend to perform worse than the neural networks that capture such aspects. 

(T-ZS1) 早期出现的原因：计算快，现在已被淘汰

- 不显示获取时空信息，表现不优，在早期可能多见
- 逐层贪心训练方法预训练权重，加速训练

> SAE 基于多层神经网络的无监督学习算法。它由多个自动编码器（Autoencoder）堆叠而成
>
> Deep Belief Network (深度信念网络) 是一种由多层 Restricted Boltzmann Machines (RBMs) 组成的概率生成模型，通常用于特征学习和无监督预训练
>
> RBM 是一种受限玻尔兹曼机，用于学习数据的概率分布

In fact, SAEs and DBNs receive attention mostly at the earlier years of deep neural network for traffic flow prediction. We speculate that this is because early researchers are concerned with the computation time optimization of the training methodology. SAEs and DBNs use the greedy layer-wise training method ([O-4](https://proceedings.neurips.cc/paper/2006/hash/5da713a690c067105aeb2fae32403405-Abstract.html)) to pre-train their network weights, which accelerates the training in the long run. However, as more and more complex techniques were introduced and as hardware and software optimization reduce the computational time of these methods, the middling performance of SAEs and DBNs resulted in the two being phased out  

##### 具体论文

This has been demonstrated through several experiments:

- T-1 T-4 [T-56](https://arxiv.org/abs/1802.02147)

Stacked Autoencoder (SAE)  

(T-ZS1)

- [T-54](https://ieeexplore.ieee.org/abstract/document/6894591) 

- [T-55](https://ieeexplore.ieee.org/abstract/document/7727607) 使用 Dempster-Shafer theory 结合交通流数据

  > Dempster-Shafer理论是一种用于处理不确定性和推理的数学理论。它由Peter Dempster和Arthur Shafer在20世纪70年代提出，是一种用于描述和处理不确定性信息的方法，特别适用于决策支持系统和人工智能领域。
  >
  > 这个理论的核心是使用概率分布函数（称为Belief函数），来描述每一个可能事件发生的可能性。这种方法与传统的贝叶斯概率理论不同，因为它允许对不同假设之间的关联性进行建模，而不是简单地单独考虑每个假设的概率。
  >
  > Dempster-Shafer理论的应用包括数据融合、模式识别、专家系统、风险评估等领域，它在处理非完整和不确定信息时显示出了一定的优势

Deep Belief Network (DBN)

(T-ZS1)

- T2 T-26 T-27 

#### 贝叶斯网络

Bayesian Network  

(T-ZS2) 

贝叶斯网络：一种概率图模型，使用贝叶斯推断

To tackle this gap, the Bayesian network, which is a type of probabilistic graphical model using Bayesian inference for probability computations, is a promising solution  

- 多数论文是确定性模型和平均预测

  Most of the existing studies aim for deterministic models that make mean predictions 

  > 一些交通应用需要不确定性，特别是极端交通状况
  >
  > However, some traffic applications rely on uncertainty estimates for the future situations  
  >
  > The combination of GNNs with Bayesian networks is proposed for the challenge of GNN model interpretation. With probabilistic predictions, uncertainty estimates are generated for the future situations, especially the chance of extreme traffic states.  

- 应用例子：分位数回归 Quantile Regression

  A similar alternative is Quantile Regression, which estimates the quantile function of a distribution at chosen points, combined with Graph WaveNet for uncertainty estimates [T-116](https://arxiv.org/abs/2012.05207)

#### 其他

- (T-ZS30) [T-127](https://ieeexplore.ieee.org/abstract/document/8963628) SVR
- (T-145) ODE 常微分方程

### 神经网络

#### 概念

深度神经网络

(T-ZS1) Amongst all the available traffic prediction methods, deep neural network is the most prominent.  

- 概念：

  (T-ZS1) Deep neural networks consist of complex neural network models with a large number of layers. 

- 条件：

  (T-ZS1) increasing computational power, as well as theoretical and software improvements in recent times had made increasingly complex neural network models feasible to train. Thus, in the middle of the 2010s, researchers started to apply deep neural network models for traffic prediction  

  > As technology advanced on both the hardware and the software front, complex deep neural network models are becoming easier to train. This has prompted researchers to combine the capabilities of multiple deep neural networks, and even add some novel components of their own creation  

- 理由：

  (T-ZS1) This is due to its sheer predictive power that can model the complex and nonlinear traffic patterns

  > 参考几个具体应用论文：[T-1](https://www.mdpi.com/1424-8220/17/7/1501)、[T-2](https://www.mdpi.com/1424-8220/17/7/1501)、[T-3](https://arxiv.org/abs/1612.01022)、[T-4](https://ieeexplore.ieee.org/abstract/document/8489600)、[T-5](https://arxiv.org/abs/1707.03213)，引用都不错

#### 优缺

- 适用理由：CNN/RNN抓时空+层数

  (T-ZS1) Some of the deep neural network models can explicitly capture different aspects of traffic data, which made them even more attractive. For instance, CNN can explicitly capture the spatial aspect of traffic data while RNN can explicitly capture the temporal aspect of traffic data. Additionally, the increased number of layers improves the models’ prediction capability. This factor allows them to model traffic fluctuations more accurately  

- 优点：自动学习特征

  (T-ZS1) (The reason behind its prominence is that) neural networks perform automatic feature extraction as well as the actual prediction in one model 

  > 相较于传统机器学习而言 (T-ZS1: O-1)
  >
  > Neural network’s prominence in traffic flow prediction can be attributed to the model’s flexibility. This is because the functional form of neural network models is approximated via learning, as opposed to classical statistical models which assume the functional form a priori  

- 局限性：当前状态和未来方向不明

  (T-ZS1) The increasing popularity of deep neural network models for traffic prediction has led to numerous publications, but issues such as the wide variety of hybrid deep neural network structures have made it difficult to assess the current state and future directions of this research field. This problem is compounded by the fact that survey works focusing specifically on deep neural network models are rare

- 缺点：

  (T-ZS1) 需要大数据，训练代价高，难以理解(如参数含义)

  - Deep neural network models require a large amount of data that covers all traffic conditions. 

    If the amount of data is too small or if the data is not diverse enough, the model’s generalization capability is compromised.

  - Deep neural network models still take a long time to train. 

    As deep neural network models are complex and have a large number of layers, the training time can be very long. This problem is compounded on hybrid deep neural network models. As classical statistical and older machine learning models are not as complex, their training time is much shorter.

  - Deep neural network models are difficult to interpret. 

    This is because of two reasons: the number of internal parameters is very large, and the parameters are learned from training, not set manually. Thus, while they can predict well, it is hard to understand their parameters. Understanding the parameters may reveal important information such as the spatiotemporal dynamics in the road network 
    
    > Consequently, neural network models’ internal parameters are rarely explored because they are hard to interpret as their focus is mostly on raw prediction performance rather than interpretability.  
    
    该缺点可以 更多参见下文未来趋势一节

#### 分类

类别：

(T-ZS1) The three most common deep neural network models used for traffic prediction are Convolutional Neural Networks, Recurrent Neural Networks, and Feedforward Neural Networks

> (T-ZS2) Deep learning models, including convolution neural networks and recurrent neural networks, have been extensively applied in traffic forecasting problems to model spatial and temporal dependencies  

(T-ZS1) RNN, CNN, FNN

- RNN is commonly used to capture the temporal trends of traffic data–the dynamics of how past traffic can influence future traffic. CNN is commonly used to capture the spatial trends of the data–how traffic propagates through the road network. FNN can aggregate the output from different subnetworks and also can process external data such as weather information  

#### 发展

(T-ZS30 图 6)

![image-20240808225705488](img/image-20240808225705488.png)



### FNN

#### 概念

概念：

- (T-ZS1) 名称 A Feedforward Neural Network (FNN), which is also commonly referred to as Fully Connected Neural Network (FC or FCNN), is one of the earliest and simplest neural network models  

  组成 It consists of several layers of fully connected computational nodes organized in many layers  

  计算方式 The value of every node in the hidden or output layers is computed by taking the weighted sum of all of the previous layer’s nodes and then passing the value to a nonlinear function such as sigmoid, tanh and relu  

缺点：

- 参数多、训练久

  (T-ZS1) The FNN’s fully connected structure enables each of its layers to process the combination of all the previous layer’s features. However, this also serves as a weakness because its full connection results in a large amount of parameters  

  Consequently, the training process of FNNs can be quite time consuming. In addition  

- 没有明确获取时空信息

  (T-ZS1) do not have the capability of explicitly capturing spatial or temporal data. Because of this, FNNs are rarely used as the main predictor in deep neural network literatures.  

作用：工具组件：聚合输出、维度转换、引入数据

- (T-ZS1) For traffic flow prediction, FNNs usually serve a utility role in a hybrid deep network, whose main purpose is to perform tasks such as aggregating outputs from different components within the network, dimensionality transformation and incorporating external data such as weather.  

  - 维度转换：This is because the size of input layer or output layer can be set manually, which gives FNN the capability to transform inputs of an arbitrary dimensionality to an output of an arbitrary dimensionality  
  
  - 聚合输出：When used to integrate external data, the input depends on the type of external data. Numerical values can be provided as it is while categorical values need to be transformed first (e.g., using one-hot encoding)  
  
    > FNNs are commonly used to aggregate the output of one or more subnetwork components in a deep neural network 
    >
    > a natural component for CNNs and RNNs, since FNNs can take the output from these networks and output a smaller representation
  
  - 引入数据：For aggregating outputs and dimensionality transformation, the inputs depend entirely on the model  
  
    > FNNs are also commonly used to incorporate external data to the network, because it can take inputs of an arbitrary dimensionality and perform a transformation to ensure that the dimensionality of the external data and that of the other components within the network match  
  
  - 子模块：as a submodule component. FNNs are often used as a component in a model’s submodule, such as attention network modules  

#### 具体论文

(T-ZS1)

1. FNN as Output Aggregator

   - T-3 合并 CNN+2LSTM 的输出

     combine the outputs from one CNN component and two LSTM components  

   - T-1 T-33 T-48 T-50 T-37 合并 CNN 的输出

   - T-41 T-53(结合天气+消融) T-36 合并 RNN 的输出

2. FNNs for Incorporating External data

   - T-51 T-37 T-3

3. FNNs as a submodule component

   - T-43 学习哪条路网重要

     used an FNN to learn features from a road network, which enables the network to learn which nodes in a road network are important  

   - T-42 与上面一样，但没用图结构

     used an FNN for the same purpose, although they do not use the graph structure  

### CNN

#### 基本

##### 概念

组成：卷积层、池化层

(T-ZS1) 

A CNN consists of several “convolution” and “pooling” layers. 

- Convolution’s purpose is to extract features from the input, 

  > Mathematically, convolution layers extract features by computing the dot product between a matrix of some preset values (referred to as filter) and a subset of cells from the original grid, which produces a matrix that is called feature map  

  > The example in Figure 1 shows, (i) the top-left 3 × 3 subset of cells produces the value 470, and (ii) the bottom-right 3 × 3 subset of cells produces the value 170 in the feature map. This can be interpreted as the top-left subset having a much higher number of vehicles in that region than the bottom-right subset  

  <img src="img/image-20240722103753648.png" alt="image-20240722103753648" style="zoom: 67%;" />

- whereas pooling’s purpose is to reduce the dimensionality of each feature map but preserve the most important information.  

功能概述：

(T-ZS1) A Convolutional Neural Network (CNN) has the capability to learn inherent features progressively, starting from low level features and then building up to more abstract concepts through a series of convolutional layers. 

> 功能：建模局部空间信息，划分为规则二维网格图像格式
>
> (T-ZS2) CNNs take a step further by modeling the local spatial information, e.g., the whole spatial range is divided into regular grids as the two-dimensional image format and the convolution operation is performed in the neighbor grids.  

##### 应用

能用的理由：交通流读入可以建模为图像，每个像素点对应一个交通密集的地区，因此可以用图像识别技术，即把区域网格化，像素值是如车辆数目，不同时间即像素值不一样

> (T-ZS1) A CNN is the optimal choice for capturing the spatial aspect of the data. CNN is able to capture the correlation between different regions in the road network. By utilizing this strength, a CNN can learn the spatial dynamics of traffic in order to improve the prediction accuracy.  

(T-ZS1) 

- Although this strength contributes to its popularity in image recognition, CNNs have been regularly applied to traffic flow prediction. The intuition is, traffic flow readings can be modeled as an image, where each pixel corresponds to the traffic intensity at a certain block of area. Thus, similar techniques developed for image recognition can be easily applied 
- Given a road network, the input of a CNN is preprocessed by partitioning the network as a grid, which is essentially a set of cells with each cell representing an area in the data space and the value associated with the cell representing the number of vehicles detected in that cell at a certain point in a time period (e.g., 5×5 cells in Figure 1). The traffic flow reading for each time period will be represented with the same grid but different number of vehicles. Thus, the entire traffic data modeled this way can be seen as several images with the same size but different pixel values   

具体应用：混合网络、空间特征 (如晚高峰商业区和居住区间流量强关联)

- (T-ZS1)  In the application of traffic prediction, CNN is often used as a component in a hybrid deep neural network, whose task is to capture the spatial aspect of traffic data.
  This is because different roads in different locations may be correlated and these correlated roads share similar traffic trend. Therefore, the traffic of the correlated roads may rise or fall, depending on their historical data 

  For instance, during the evening, there is a strong correlation between the road traffic of commercial and residential districts because employees are heading off from work  

##### 优缺

优点：不全连接，参数少

- (T-ZS1) Unlike most neural networks, CNN’s layers are not fully connected. Consequently, the number of parameters and training time are significantly reduced 

  不全连接的另一个优点在于可以学习空间的局部相关性

  (T-ZS1) Since CNN’s layers are not fully connected, one layer of CNN does not learn from all of the previous layer’s features. However, this actually proves to be an advantage in many applications as CNN can learn how the different aspects of the input relate to each other spatially  

优点：权重共享

- (T-ZS1) Additionally, CNN uses a weight sharing mechanism, which further reduces the number of required parameters  

优点：结构简单、并行计算、稳定的梯度

- (T-ZS2) CNNs demonstrate their superiority in terms of simple structure, parallel computing and stable gradients.  

缺点：路网数据不行 (非欧拓扑不行)

- (T-ZS2) the CNN-based approach is not optimal for traffic foresting problems that have a graph-based form, e.g. road networks

  (T-ZS2) However, the CNN-based approach is bounded to the case of Euclidean structure data, which cannot model the topological structure of the subway network or the road network  

#### 具体论文

(T-ZS1) 根据数据分类，理由：

Deep neural network models, hybrid or otherwise, that are applicable for one data type are incompatible for the other without major modifications. Consequently, we categorize works related to CNN based on the type of the main datasets  

##### point data

(T-ZS1) CNN 获取空间信息的能力取决于数据类型，一般用点数据。

可以：

- 使用 1D CNN(一维)

  use a 1D CNN as it is compatible with point data which are commonly organized in a line

  如 T-3 T-35

- 在 2D CNN 矩阵同时使用时空数据(一维时间、一维空间)

  capture both the spatial and the temporal aspects of the data in a 2D matrix to be fed into a CNN. That is, one axis of the matrix captures the different traffic detection sites and the other is used to capture the different time step  

  如：T-33 [T-48](https://ieeexplore.ieee.org/abstract/document/8547068) [T-49](https://ieeexplore.ieee.org/abstract/document/7837874) [T-50](https://dl.acm.org/doi/abs/10.1145/3282834.3282836)

  两者都用，如：T-38

(T-ZS2)

- [T-63](https://ieeexplore.ieee.org/abstract/document/8526506) CNN NYCtaxi 数据

##### trajectory data

(T-ZS1)  可以获取时间数据(如维度：空间、时间点、天)，或对时间做一维卷积。

(T-ZS1) 例子：

- T-1 映射为2D网格

  mapped a road link to a 2D grid and assigned to each grid the average traffic speed of the associated road link.  

- [T-51](https://ojs.aaai.org/index.php/AAAI/article/view/10735) T-31 2D矩形空间，再划分为多个网格

  defined a 2D rectangular space that encompasses all the trajectory points. This space is then divided into grids. Finally, for each grid, the traffic flow for a certain period of time is calculated as the number of trajectory points that are recorded within the grid during that period. Using this modeling, the entire space can be seen as a city and the grids represent small regions within the city. 

  结合天气 

- T-37 在上述方法基础上，增加了起点终点数据

  used a similar method as the previous, but they also modeled the traffic volume using CNN by using data of a trajectory’s start and end  
  
- T-2

- T-30

##### other

(T-ZS1) 时间信息捕获

Some authors have also attempted to use CNNs to capture the temporal aspect of the data  

(T-ZS1) 例子：

- [T-52](https://www.mdpi.com/1424-8220/17/4/818) 行：空间、列：时间、深：天数 -> 比 RNN 更短的输入序列

  included both the spatial and the temporal dimensions by modeling the traffic data as a tensor, where the rows represent the spatial aspect, the columns represent the temporal aspect and the depth represents the different days  

  They argued that using RNNs requires long input sequences which can impact training time greatly and instead applied CNN to capture both the spatial and the temporal aspects of the data  

  车祸考虑 + 模拟实验

- T-51 多个 CNN 分别获取小时、天、周粒度数据

  captured the temporal aspect using CNNs which are fed data from different time granularities (e.g. weekly, daily, hourly)   

-  1D CNN 获取时间

  used a one dimensional convolution on the time axis in order to capture the temporal aspect  

### RNN

#### 基本

##### 概念

定义：

- (T-ZS1) An RNN consists of a single node with a recurrent connection, but is often visualized as a chain of nodes, with each node representing the network state at a particular recurrence/time step  

  <img src="img/image-20240722110704917.png" alt="image-20240722110704917" style="zoom:67%;" />

  节点状态 $s_t$ 处理 $t$ 时刻的输入数据 $x_t$，和截止 $t-1$ 为止的全部信息($s_{t-1}$)一起传入到该节点

  The node state $s_t$ processes the input data $x_t$ at time $t$, as well as a ‘summary’ of all the information obtained up to time $t - 1$. This summary is stored in $s_{t-1}$, and it memorizes which parts of the sequence are important. Node $s_t$ then has the summary up to time $t$ and this information is passed to the next node state
  $s_{t+1}$. Thus, the node state $s_t$ stores the state of nodes for all the previous time steps until the beginning of the input (i.e., $s_{t-1}$, $s_{t-2}$, . . . ). The output $o_t$ is then compared with the ground truth $y_t$ in order to calculate the loss, which is used to fine-tune the model parameters.  

##### 建模

具体输入：

- (T-ZS1) In traffic prediction applications, the input to an RNN consists of past traffic readings. A continuous time period is divided into discrete time blocks and the traffic flow reading from each block is fed into the RNN.  

  > In the field of traffic prediction, LSTM as well as other RNN-based methods are commonly used as a component in hybrid deep neural network models. Its task is to capture the temporal patterns of traffic data; learning how traffic evolves over time  

> 应用：命名实体识别、声音识别、音乐识别、图像字幕生成等
>
> (T-ZS1) RNN-based methods in general possess the major advantage in the form of its memorization capability. The ability of learning important parts of the sequence and knowing when to memorize or forget them had led RNN to be the prime choice for sequence data. Due to this, RNN based models have been applied in many fields such as named entity recognition [40](https://link.springer.com/chapter/10.1007/978-3-319-55699-4_33), voice recognition [41](https://dl.acm.org/doi/abs/10.1145/3132847.3132893), music composition [42](https://people.idsia.ch/~juergen/blues/IDSIA-07-02.pdf), and image caption generation [43](https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Vinyals_Show_and_Tell_2015_CVPR_paper.html)
>
> 这些论文大部分引用不多或比较古老，除了 43 感觉都很一般

##### 发展

(T-ZS25 图5)

![image-20240806234935217](img/image-20240806234935217.png)

##### 优缺

优点：长短的时间依赖都可以记忆，而且比其他记得更长

- (T-ZS1) Recurrent Neural Networks (RNN) are commonly applied to sequence data because of their memorization capability, which can learn both long and short term dependencies between parts of the sequence. Additionally, RNN is able to scale to longer sequences compared to other network architectures. Its unique capability makes it one of the most popular deep neural networks.  

> 适用：(T-ZS2) many solutions have been proposed for dealing with the time dependency, e.g., recurrent neural networks and temporal convolutional networks  

缺点：梯度消失

- (T-ZS1) By its nature of being able to take in possibly very long sequences, RNN suffers from the vanishing gradient problem, which hinders the network’s ability to memorize information for a long time  

缺点：训练时间长

- (T-ZS1) RNN’s recurrent structure leads to significantly longer training time compared to other deep neural network models  

> (T-ZS2) Among different approaches for temporal modeling, RNNs suffer from timeconsuming iterations and gradient vanishing or explosion problem with long sequences  

#### LSTM

开山(1997) [O-2](https://ieeexplore.ieee.org/abstract/document/6795963) ；改进(2000) [O-3](https://ieeexplore.ieee.org/abstract/document/6789445)

概念：

- (T-ZS1) maintains the RNN’s recurrent structure, but introduces the three gates to control the cell value.  

  > also contains multiple layers, each possessing a cell with the memorization capability. In addition, it contains three gates, which control how information propagates throughout the network.  

  These gates are: 种门控制信息的传播($i,o$，分别控制遗忘多少之前信息、当前与下一层的相关性)

  - the input gate $i$, which controls the importance of the inputs $x_t$ and $h_{t-1}$,

  - forget gate $f$ which controls how much of the previous information $C_{t-1}$ is to be forgotten, 

  - and the output gate $o$, which controls how relevant is the current information $C_t$ for the next step.  


<img src="img/image-20240722113840626.png" alt="image-20240722113840626" style="zoom: 67%;" />

适用的原因：交通数据是时序的

(T-ZS1) We speculate that this is because traffic data constitutes a temporal sequence, which fits LSTM’s purpose. Additionally, most available traffic flow data is compatible with LSTM, as these traffic flow data can easily be modeled as a sequence of traffic flow readings  

> For instance, the traffic flow between 11:00 and 12:00 can be captured as the aggregated traffic reading for four periods, including 11:00-11:15, 11:15-11:30, 11:30-11:45, and 11:45-12:00. This data can be fed into an RNN, resulting in an RNN with four recurrences  

#### 具体论文

##### basic

(T-ZS1)

- 首次应用 T-25 [T-32](https://ieeexplore.ieee.org/abstract/document/7463717) the first few applications of basic LSTM  
- 建模为矩阵以融合空间信息 [T-33](https://ieeexplore.ieee.org/abstract/document/7966128) [T-34](https://ieeexplore.ieee.org/abstract/document/8317872) use an LSTM that takes in readings from multiple time slots as well as multiple detectors. The data is modeled in a matrix, which captures both the spatial and temporal aspects of the data  

##### hybrid

(T-ZS1) 三种思路：

> 1. RNN 输出特征融入到融合层(fusion layer)(如 FNN) (最简单)
>
> 2. 输出作为下个组成部分的输入(流水线)(先时再空或反过来或多次时间都行)
>
> 3. 作为主预测器，修改模型内部结构 (最复杂) 
>
>    (如反向传播->RTBL, 融入图卷积等)

(T-ZS1) 即：

1. Outputting features to be fed into a fusion layer.

   the simplest because models that fall into this category usually consist of several simpler subnetworks that only interact at the final fusion layer  

2. Outputting features to be fed into subsequent components within the model.

   treats LSTM as a pipeline that transforms one feature representation to another

   > As observed, in this category of method, some preprocessing steps such as the masking of missing values can be a part of the architecture.  

3. Used as the main predictor, but with modifications
   to the internal structure  

  the most complex one, as it requires modifying the internal LSTM structure

(T-ZS1) 分别：

1. 融合层

   - T-3 CNN+2LSTM (空间，短时间特征，周期时间特征)

     a combination of a CNN and two LSTMs to capture spatial features, the short-term temporal feature, and the periodic temporal feature respectively. The outputs from these three networks are then fed into a FNN to fuse the features  

   - [T-35](https://ieeexplore.ieee.org/abstract/document/8258813) CNN+LSTM

     used a combination of a CNN component and an LSTM component to capture spatial features and temporal features respectively. The outputs from these networks are combined to form the prediction  

   - T-29 SAE + LSTM

     a combination of a Stacked Autoencoder to encode traffic accidents data and an LSTM to capture the temporal aspect of the data  

2. 流水线

   - T-1 CNN -> LSTM

   - first used a CNN to encode the spatial aspect of the data and then fed this processed information to an LSTM to learn the temporal aspect  

   - T-4 CNN -> LSTM

     used an LSTM to process the outputs from a CNN before passing them to a max-pooling layer  

   - T-12 缺失值处理 -> 双向LSTM(特征转换) -> LSTM

     performed masking to fill in missing values in the data before passing it to a bidirectional LSTM for feature transformation and then a regular LSTM for the prediction  

   - [T-36](https://arxiv.org/abs/1811.05320) GCN(空间) + GRU(时间)

     used a Gated Recurrent Unit which takes input from a Graph Convolution Network and outputs the predicted traffic

   - [T-37](https://www.researchgate.net/profile/Huaxiu-Yao/publication/323570926_Modeling_Spatial-Temporal_Dynamics_for_Traffic_Prediction/links/5b1e23ea45851587f29f6a61/Modeling-Spatial-Temporal-Dynamics-for-Traffic-Prediction.pdf) 多个 LSTM

     used multiple LSTMs that represent the daily traffic features

   - [T-38](https://www.sciencedirect.com/science/article/pii/S0968090X18302651) 注意力+GRU+CNN

     used a Gated Recurrent Unit to learn feature representation from an attention model which are then fused with the CNN spatial component  

3. 修改结构

   - [T-39](https://ieeexplore.ieee.org/abstract/document/8917706) LSTM: 图卷积+卷积改为RTBL(查不到，疑似自创)

     modified the LSTM calculation to include a graph convolution process as well as using a novel Real-Time Branching Learning (RTBL) which modifies the backpropagation process  

   - [T-40](https://arxiv.org/abs/1707.01926) GRU: 矩阵乘法改为扩散卷积操作

     replaced the matrix multiplication inside Gated Recurrent Unit with the diffusion convolution operation 

##### encoder-decoder

见下文

##### other

(T-ZS1) 可以同时获取时空信息

Some authors have used RNNs to capture both the temporal and the spatial aspects of the data  

- T-34 多检测器一次输入 LSTM

  captured the temporal aspect by feeding data from multiple traffic loop detectors at once into an LSTM  

- [T-46](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-its.2016.0208)  每个检测器一个 LSTM + ODC矩阵表示之间相关

  used one LSTM for each traffic loop detector and incorporates an Origin Destination Correlation (ODC) matrix, which weighs how much the traffic of one loop detector’s location affects another  

- T-30 LSTM 密度核改成卷积来同时捕获时空

  replaced the dense kernels in LSTM with convolutional ones to successfully use an LSTM to capture both the spatial and the temporal aspects of traffic data  

  拼接天气和交通流数据

(T-ZS2) +图卷积

- T-82, T-83, T-84, T-85, T-86

##### 多粒度

(T-ZS1) RNN 输入可能过长，因此只选取多个粒度的代表性数据，分别训练多个粒度的 RNN 组合，如要预测某个时刻的流量，与其输入很长的小时单位，不如输入短的小时，短的天，短的周结合起来，代替可能长达周的小时输入。

In addition, RNN has been used to capture the temporal aspect of the data using different granularities. As discussed in Section 3.2, RNN-based methods are commonly used to learn the temporal patterns of traffic data. However, we also mentioned that RNN-based methods are time-consuming. Consequently, RNN-based methods are not usually fed very long input sequences. Several data modeling-based approaches have been explored to mitigate this problem. The most common method is to use multiple LSTMs with each taking shorter sequences from a specific granularity. 

As an example, if we want to predict the traffic at 09:00 AM at December 25, one RNN can be used to capture the data from 06:00, 07:00, and 08:00 AM at December 25 (hourly granularity), one RNN can be used to capture the data from 09:00 AM at 22, 23 and 24 December (daily granularity) and one RNN can be used to capture the data from 09:00 AM at 4, 11 and 18 December (weekly granularity)  

- 例子如 T-3 T-37 T-38

### GNN

> (T-ZS2) GNN 本身的综述：O-7, [O-8](https://ieeexplore.ieee.org/abstract/document/9039675), [O-9](https://www.sciencedirect.com/science/article/pii/S2666651021000012) (都是 2020 的)

#### 概念

##### 兴起

(T-ZS1) 近年新技术：

One of the most significant breakthroughs of recent work in deep neural network for traffic flow prediction is the graph-based methods  ->  in particular, the graph convolution operation  

> 现状：SOTA：图结构和上下文信息(contextual)
>
> (T-ZS2) [O-6](https://ieeexplore.ieee.org/abstract/document/9046288)(GNN 综述) In recent years, to model the graph structures in transportation systems as well as contextual information, graph neural networks have been introduced and have achieved state-of the-art performance in a series of traffic forecasting problems  

##### 适用理由

适用的理由：

- 路网动态获取

  (T-ZS1)  Due to this ability of capturing the dynamics of road network, graph-based method is a promising future research direction.  

  (T-ZS2) For the dynamic spatial dependency, dynamic graphs can be learned from the data automatically.  

  (T-ZS1) they naturally conform to traffic dynamics

- 非欧结构数据信息

  (T-ZS2) Graph neural networks bring new opportunities for solving traffic forecasting problems, because of their strong learning ability to capture the spatial information hidden in the non-Euclidean structure data, which are frequently seen in the traffic domain
  
  远的空间依赖
  
  (T-ZS2) The spatial dependency, which refers to the complex and nonlinear relationship between the traffic state in one particular location with other locations. This location could be a road intersection, a subway station, or a city region. The spatial dependency may not be local, e.g., the traffic state may not only be affected by nearby areas, but also those which are far away in the spatial range but connected by a fast transportation tool. The graphs are necessary to capture such kind of spatial information  
  
- 层次结构，超图子图

  (T-ZS2) For the case of hierarchical traffic problems, the concepts of super-graphs and sub-graphs can be defined and further used  

##### 建模方式

非欧图结构的空间依赖：建图方式，点是路交点，边是路连接

(T-ZS2) GNNs are ideally suited to traffic forecasting problems because of their ability to capture spatial dependency, which is represented using non -Euclidean graph structures. For example, a road network is naturally a graph, with road intersections as the nodes and road connections as the edges. With graphs as the input, several GNN-based models have demonstrated superior performance to previous approaches on tasks including road traffic flow and speed forecasting problems  

> (T-ZS2) Based on graph theories, both nodes and edges have their own attributes, which can be used further in the convolution or aggregation operations. These attributes describe different traffic states, e.g., volume, speed, lane numbers, road level, etc.  

##### 应用领域

应用面：(T-ZS2) The GNN-based approach has also been extended to other transportation modes, utilizing various graph formulations and models.  

##### 发展

(T-ZS25)

![image-20240806235625831](img/image-20240806235625831.png)

##### 对比

(T-ZS2) 欧氏数据：图像、视频、文本

Previous neural networks, e.g. fully-connected neural networks (FNNs), CNNs, and RNNs, could only be applied to Euclidean data (i.e. images, text, and videos)  

(T-ZS1) 图论领域GNN vs 欧氏几何CNN：

(T-ZS27) 网格化数据 vs 拓扑化数据

(T-ZS28) 欧氏空间 vs 非欧空间

When applied to road networks, graph convolution works on the graph domain while regular convolution works on the Euclidean domain

> road networks do not conform to the Euclidean space as roads and highways that are close to each other may connect different parts of the city and thus have very different traffic characteristics  

讨论二者的优缺：

(T-ZS1) Graph-based methods are more appropriate for traffic data compared to the more conventional methods of dividing an area into spatial grids. The reason is that roads close to each other may connect entirely different parts of a city. It is more accurate to capture spatial correlations in terms of the connectivity of different parts of the area, which graph-based methods provide  

(T-140 图示对比)

![image-20240818224842670](img/image-20240818224842670.png)

##### 优缺

优点：图表示的复杂物体联系的获取能力

(T-ZS2 说 [O-10](https://www.sciencedirect.com/science/article/pii/S0140366421004874) 说的) GNNs have the ability to capture complex relationships between objects and make inferences based on data described by graphs. GNNs have been proven effective in various node-level, edge-level, and graph-level prediction tasks  

缺点：

(T-ZS1) 实现复杂，可能需要手动预处理

> Graph-based models can be complex to implement as it requires additional data as well as data preprocessing  
>
> The road topology data, which captures how different traffic detection sites are connected by roads, is often not readily available and has to be manually curated. 
>
> > While this challenge is significant, it is important to measure and understand how well graph-based methods improve the traffic prediction performance  

数据获取难度

(T-ZS1)  the difficulty lies in the data requirement and the additional preprocessing step  

#### 建模

##### 图定义

图的定义：

(T-ZS2) It is defined as $G=(V,E,A)$ where

- $V$ is the set of vertices or nodes

- $E$ is the set of edges between the nodes  

- $A$ is the adjacency matrix  

  Element $a_{ij}$ of $A$​ epresents the "edge weight" between nodes $i$ and $j$

  > For a binary connection matrix $A$, $a_{ij}=1$ if there is an edge between nodes $i$ and $j$ in $E$, and $a_{ij} = 0$ otherwise. 
  >
  > If $A$ is symmetric, the corresponding graph $G$ is defined as undirected. Otherwise, $G$ is directed, when the edge only exists in one direction between a node pair  

点和边都有含义(权/信息)

(T-ZS2) Both nodes and edges can be associated with different attributes in different GNN problems  

> 交通状态建模到点上：
>
> (T-ZS2) For simplicity, we assume that the traffic state is associated with the nodes. The other case with edges can be derived similarly. In practice, the traffic state is collected or aggregated in discrete time steps, e.g. five minutes or one hour, depending on the specific scenario  

> 时间步 $t$，点的特征矩阵为 $\chi_t\in R^{N\times d}$，$N$ 是点数，$d$ 是特征数。
>
> (T-ZS2) For a single time step t, we denote the node feature matrix as $\chi_t\in R^{N\times d}$, where N is the number of nodes and d is the dimension of the node features, i.e., the number of traffic state variables. Now we are ready to give a formal definition of traffic graph

交通图定义：(Traffic Graph)

(T-ZS2) A traffic graph (with node features) is defined as a specific type of graph G = (V; E; A), where V is the node set, E is the edge set, and A is the adjacency matrix. For a single time step t, the node feature matrix $\chi_t\in R^{N\times d}$  for G contains specific traffic states, where N is the number of nodes and d is the number of traffic state variables

##### 问题定义

基于图的交通预测问题：Graph-based Traffic Forecasting)  

(T-ZS2) A graph-based traffic forecasting (without external factors) is defined as follows: find a function $f$ which generates $y=f(\chi;G)$, where $y$ is the traffic state to be predicted, $\chi=\{\chi_1,\chi_2,\cdots,\chi_T\}$ is the historical traffic state defined on graph $G$, and $T$ is the number of time steps in the historical window size.

带外部状态：$\epsilon$ 为外部因素。  

The forecasting problem formulation, extended to incorporate these external factors, takes the form $y=f(\chi,\epsilon, G)$, where $\epsilon$ represents the external factors.  

分为单步预测和多步预测 

> (T-ZS30, T-ZS38 有定义, T-28 有基于条件概率的定义)

(T-ZS2) In single step forecasting, the traffic state in the next time step only is predicted, whereas in multiple step forecasting the traffic state several time steps later is the prediction target  

> T-ZS2 有图示(figure1) (图源 T-ZS20，进行了修改)
>
> ![image-20240801205059347](img/image-20240801205059347.png)

##### 图的分类

(T-ZS2) 静态动态的角度分类：

- 静态图 pre-defined static graphs  

  - 自然图：真实世界路网

    Natural graphs are based on a real-world transportation system, e.g. the road network or subway system  

  - 相似图：点之间相似性

    whereas similarity graphs are based solely on the similarity between different node attributes where nodes may be virtual stations or regions  

- 动态图：从数据学习 dynamic graphs continuously learned from the data  

(T-ZS2) 道路类型的角度分类：(其 P20 提供了一个表展示了各论文的建图类型，点边类型)

- 道路级：探测器图、基于路网的图(路段图、路口图、车道图) (论文图2表示例子)

  Road-level graphs. These include sensor graphs, road segment graphs, road intersection graphs, and road lane graphs.  

  - Sensor graphs are based on traffic sensor data (e.g. the PeMS dataset) where each sensor is a node, and the edges are road connections
  - The other three graphs are based on road networks with the nodes formed by road segments, road intersections, and road lanes, respectively.   

  适用：当应用车辆只在建图范围内移动时

  In some cases, road-level graphs are the most suitable format, e.g., when vehicles can move only through pre-defined roads  

  其中探测器和路段是全部数据里最常用的：现成数据集多

  Sensor graphs and road segment graphs are most frequently used because they are compatible with the available public datasets  

  (图源 T-ZS20，进行了重绘)

  ![image-20240801212136966](img/image-20240801212136966.png)

- 区域级：不规则、规则、OD

  Region-level graphs. These include irregular region graphs, regular region graphs, and OD graphs  

  - 规则：适合 CNN

    Regular region graphs, which have grid-based partitioning, are listed separately because of their natural connection to previous widely used grid-based forecasting using CNNs, in which the grids may be seen as image pixels.  

  - 不规则 (具体 zip code 地图图片实例：[here](https://maps-manhattan.com/manhattan-zip-code-map))

    irregular region graphs include all other partitioning approaches, e.g. road based, or zip code based (如 [T-68](https://www.sciencedirect.com/science/article/pii/S0968090X20307580))

  - OD：节点是起点终点对

    In the OD graph, thenodes are origin region - destination region pairs

  边是邻居或其他相似性(如 PoI 数据的功能相似)

  In these graphs, the edges are usually defined with a spatial neighborhood or other similarities, e.g., functional similarity derived from point-of-interests (PoI) data  

- 站点级：地铁、车站、单车站、铁路、共享汽车站、停车场、停车块

  Station-level graphs. These include subway station graphs, bus station graphs, bike station graphs, railway station graphs, car-sharing station graphs, parking lot graphs, and parking block graphs. Usually, there are natural links between stations that are used to define the edges, e.g. subway or railway lines, or the road network  

  例子如 [北京地铁线路图](https://www.travelchinaguide.com/cityguides/beijing/transportation/subway.htm)

- 可以混合使用，如：[T-69](https://ieeexplore.ieee.org/abstract/document/9098104)、[T-70](https://www.worldscientific.com/doi/abs/10.1142/S0218194019400187)

##### 邻接矩阵构造

Adjacency Matrix Construction

> 重要性：(T-ZS2 说 T-ZS20 说的) Adjacency matrices are seen as the key to capturing spatial dependency in traffic forecasting

灵活性较大：

(T-ZS2) While nodes may be fixed by physical constraints, the user typically has control over the design of the adjacency matrix, which can even be dynamically trained from continuously evolving data

分类：

(T-ZS2 基于 T-ZS20 改进) 基于：道路、距离、相似性、动态矩阵 (论文有表 3)

divide them into four types, namely, road-based, distance-based, similarity-based, and dynamic matrices  

连接和距离最常用：定义简单 

The connection and distance matrices are the most frequently used types, because of their simple definition and representation of spatial dependency.  

- 道路 Road-based Matrix：连接矩阵、交通连接性矩阵、方向矩阵

  This type of adjacency matrix relates to the road network and includes connection matrices, transportation connectivity matrices, and direction matrice  

  - 连接矩阵：最常用，01 矩阵

    A connection matrix is a common way of representing the connectivity between nodes. It has a binary format, with an element value of 1 if connected and 0 otherwise  

  - 交通连接性：很远但可达也连接；可以用几分钟内可达都连一条边

    The transportation connectivity matrix is used where two regions are geographically distant but conveniently reachable by motorway, highway, or subway (T-ZS2 说 T-ZS20 说的)

    It also includes cases where the connection is measured by travel time between different nodes, e.g. if a vehicle can travel between two intersections in less than 5 minutes then there is an edge between the two intersections (用时间内可达做例子的，T-ZS2 说 [T-71](https://ieeexplore.ieee.org/abstract/document/8612556))

- 距离矩阵：邻居和距离

  This widely used matrix-type represents the spatial closeness between nodes. It contains two sub-types, namely, neighbor and distance matrices

  - 邻居：有相邻边界就连边

    In neighbor matrices, the element values are determined by whether the two regions share a common boundary (if connected the value is set to 1, generally, or 1/4 for grids, and 0 otherwise)  

  - 距离：驾驶距离、最短路或近似方位(RWR求出)

    In distance-based matrices, the element values are a function of geometrical distance between nodes. This distance may be calculated in various ways, e.g. the driving distance between two sensors, the shortest path length along the road (最短路如 [T-72](https://ieeexplore.ieee.org/abstract/document/8917213)、[T-73](https://www.sciencedirect.com/science/article/pii/S0968090X21004538)) or the proximity between locations calculated by the random walk
    with restart (RWR) algorithm (如 T-62)

    常见缺陷：不考虑长距离相似性，静态

    One flaw of distance-based matrices is that the fail to take into account the similarity of traffic states between long-distance nodes, and the constructed adjacency matrix is static in most cases  

- 相似性：交通模式、功能相似

  This type of matrix is divided into two sub-types, namely, traffic pattern and functional similarity matrices

  - 交通模式：状态联系，如流量模式、互依赖、交通需求关联

    Traffic pattern similarity matrices represent the correlations between traffic states, e.g. similarities of flow patterns, mutual dependencies between different locations, and traffic demand correlation in different regions  

  - 功能：不同类型 PoI 的分布

    Functional similarity matrices represent, for example, the distribution of different types of PoIs in different regions  

- 动态矩阵：不预定义静态的，有优势

  This type of matrix is used when no pre-defined static matrices are used. Many studies have demonstrated the advantages of using dynamic matrices, instead of a pre-defined adjacency matrix, for various traffic forecasting problems 

##### 动态静态对比

(T-64) 静态图可能不能反应真实依赖

However, the explicit graph structure (relation) does not necessarily reflect the true dependency and genuine relation may be missing due to the incomplete connections in the data.

> (T-64) 静态的局限性的例子
>
> To give each circumstance an example, let us consider a recommendation system. In the first case, two users are connected, but they may have distinct preferences over products. In the second case, two users may share a similar preference

#### 基础

##### 分类

> 分类：基于 RNN, CNN, FNN, 注意力
>

> (T-ZS2 说 O-7 说的) 循环 GNN，卷积 GNN，GAE(图自编码器)，时空 GNN
>
> GNNs can be roughly divided into four types, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatiotemporal GNNs  
>
> (T-ZS2) 按照这个定义，全都是时空 GNN，但可以根据时间用啥再分：RNN 和 CNN 可以处理时间信息 （RNN 论文数比 CNN 多一倍左右）
>
> Spatiotemporal GNNs can be further categorized based on the approach used to capture the temporal dependency in particular. Most of the relevant studies in the literature can be split into two types, namely, RNN-based and CNN-based spatiotemporal GNNs  
>
> (T-ZS2) 此外还有基于注意力的，基于 FNN 的，一共四种分类。
>
> With the recent expansion of relevant studies, we add two sub-types of spatiotemporal GNNs in this survey, namely, attention-based and FNN-based
>
> (T-ZS2) 其中 Transformer 有 T-74, T-75, T-76, T-77，注意力机制和 FNN 的论文数量差不多，感觉都没 CNN 和 RNN 多
>
> 其他技术：
>
> - autoregression [T-78](https://arxiv.org/abs/1905.10709)
> - Markov processes [T-79](https://www.sciencedirect.com/science/article/pii/S0968090X20305866)
> - Kalman filters [T-80](https://journals.sagepub.com/doi/abs/10.1177/0361198120919399) T-99

> 同时处理时空：图卷积融入 RNN
>
> (T-ZS2) Some efforts are put to jointly modeling the potential interaction between spatial and temporal features and one promising direction is the incorporate of the graph convolution operations into RNNs to capture spatial-temporal correlations  
>
> - 如 [T-82](Gated residual recurrent graph neural networks for traffic prediction), [T-83](Optimized graph convolution recurrent neural network for traffic prediction), [T-84](https://ieeexplore.ieee.org/abstract/document/9269513), [T-85](https://arxiv.org/abs/1903.05631). [T-86](https://arxiv.org/abs/1906.00560)
>
> (T-ZS2) 例如邻接矩阵+局部时空图的 GCN [T-87](https://ojs.aaai.org/index.php/AAAI/article/view/5438)
>
> For example, the localized spatio-temporal correlation information is extracted simultaneously with the adjacency matrix of localized spatio-temporal graph, in which a localized spatio-temporal graph that includes both temporal and spatial attributes is constructed first and a spatial-based GCN method is applied then  

> 卷积 GNN 最常用，循环 GNN ([O-19](https://ieeexplore.ieee.org/abstract/document/4700287)) 和 GAE ([O-20](https://arxiv.org/abs/1611.07308)) 更少用
>
> (T-ZS2) Of the additional GNN components adopted in the surveyed studies, convolutional GNNs are the most popular, while recurrent GNN and Graph Auto-Encoder (GAE) are used less frequently  

##### 卷积GNN概述

> GCN(图卷积网络,Graph Convolutional Network)

给定图 $G=(V,E,A)$，点 $v_i$ 的邻居 $\mathcal N(v_i)$，$\mathbf D$ 是度矩阵，即 $\mathbf D_{ii}=||\mathcal N(v_i)||$，$\mathbf L=\mathbf D-\mathbf A$ 是无向图拉普拉斯矩阵，且 $\tilde{\mathbf L}=\mathbf I_N-\mathbf D^{-\frac12}\mathbf A\mathbf D^{-\frac12}$ 是标准化的该矩阵，其中 $\mathbf I_N$ 是 $N$ 阶单位矩阵；不考虑时间步，则节点信息矩阵是 $\mathbf X\in R^{N\times d}$，$d$ 是信息的维度，$N$ 是节点数

> (T-ZS2) Give a graph G = (V; E; A), N (vi) is defined as the neighbor node set of a single node vi. D is defined as the degree matrix, of which each element is $\mathbf D_{ii}=||\mathcal N(v_i)||$，$\mathbf L=\mathbf D-\mathbf A$ is defined as the Laplacian matrix of an undirected graph and $\tilde{\mathbf L}=\mathbf I_N-\mathbf D^{-\frac12}\mathbf A\mathbf D^{-\frac12}$ is defined as the normalized Laplacian matrix, where  $\mathbf I_N$ is the identity matrix with size N. Without considering the time step index, the node feature matrix of a graph is simplified as $\mathbf X\in R^{N\times d}$ , where N is the node number and d is the dimension of the node feature vector as before.  

欧氏数据卷积扩展到非欧时，将学习一个关于节点及其邻居的数据映射

> (T-ZS2) When extending the convolution operation from Euclidean data to nonEuclidean data, the basic idea of GNNs is to learn a function mapping for a node to aggregate its own features and the features of its neighbors to generate a new representation  

GCN 是基于频谱的卷积 CNN，图卷积：先傅里叶，做操作，再逆傅里叶回去

(T-ZS2) GCNs are spectral-based convolutional GNNs, in which the graph convolutions are defined by introducing filters from graph signal processing in the spectral domain, e.g., the Fourier domain. The graph Fourier transform is firstly used to transform the graph signal to the spectral domain and the inverse graph Fourier transform is further used to transform the result after the convolution operation back

> (T-ZS2) 背景：
>
> - 核是可学习参数，多通道
>
>   [O-11](https://arxiv.org/abs/1312.6203) Spectral convoluted neural networking assumes that the filter is a set of learnable parameters and considers graph signals with multiple channels 
>
> - 平滑，空间局部性
>
>   [O-12](https://arxiv.org/abs/1506.05163) GNN introduces a parameterization with smooth coefficients and makes the spectral filters spatially localized
>
> - 切比雪夫多项式扩展来近似对角矩阵
>
>   [O-13](https://proceedings.neurips.cc/paper_files/paper/2016/hash/04df4d434d481c5bb723be1b6df1ee65-Abstract.html) Chebyshev’s spectral CNN (ChebNet)  leverages a truncated expansion in terms of Chebyshev polynomials up to Kth order to approximate the diagonal matrix  

GCN ([O-14](https://arxiv.org/abs/1609.02907)) 是 ChebNet 的近似，且 $K=1$ 避免过拟合，使用对角矩阵特征值的切比雪夫多项式来近似卷积核，定义卷积操作如下：

(T-ZS2) is a first-order approximation of ChebNet, which approximates the filter using the Chebyshev polynomials of the diagonal matrix of eigenvalues. To avoid overfitting, K = 1 is used in GCN. Formally, the graph convolution operation ∗G in GCN is defined as follows:
$$
\mathbf X_{*G}=\mathbf W(\mathbf I_N+\mathbf D^{-\frac12}\mathbf A\mathbf D^{-\frac12})\mathbf X
$$
$\mathbf W$ 是模型参数，为了降低梯度爆炸，修改为：

> (T-ZS2) where W is a learnable weight matrix, i.e., the model parameters. While in practice, the graph convolution operation is further developed in order to alleviate the potential gradient explosion problem as follows  

$$
\mathbf X_{*G}=\mathbf W(\mathbf{\tilde D}^{-\frac12}\mathbf{\tilde A}\mathbf{\tilde D}^{-\frac12})\mathbf X
$$

其中 $\mathbf{\tilde A}=\mathbf A+\mathbf I_N$ 且 $\mathbf{\tilde D}_{ii}=\sum_j \mathbf{\tilde A}_{ij}$ 

替代方法：基于空间的卷积 GNN：图卷积定义为信息传播。如 DCG, MPNN, GraphSAGE, GAT。

(T-ZS2) The alternative approach is spatial-based convolutional GNNs, in which the graph convolutions are defined by information propagation.  

- DGC [O-15](https://proceedings.neurips.cc/paper_files/paper/2016/hash/390e982518a50e280d8e2b535462ec1f-Abstract.html) Diffusion graph convolution  

  图卷积建模为扩散过程，从一个节点到相邻节点的转移概率被考虑在内，最终达到平衡

  The graph convolution is modeled as a diffusion process with a transition probability from one node to a neighboring node in DGC. An equilibrium is expected to be obtained after several rounds of information transition  

- MPNN [O-16](https://proceedings.mlr.press/v70/gilmer17a) message passing neural network  

  图卷积为从一个点到其他连通点直接传递信息的过程

  The general framework followed is a message passing network, which models the graph convolutions as an information-passing process from one node to another connected node directly  

  用信息传播函数来统一不同空间变量，操作两阶段：信息传递、读出。

  > MPNN uses message passing functions to unify different spatial-based variants. MPNN operates in two stages, namely, a message passing phase and a readout phase. The message passing phase is defined as follows:  

  信息传递阶段：
  $$
  \mathbf m^{(t)}_{v_i}=\sum_{v_j\in\mathcal N(v_i)}\mathcal M^{(t)}(\mathbf X_i^{(t-1)},\mathbf X_j^{(t-1)},\mathbf e_{ij})
  $$
  $\mathbf m^{(t)}_{v_i}$ 是从 $v_i$ 的邻居聚合而来的信息，$\mathcal M^{(t)}(\cdot)$ 是第 $t$ 次迭代的聚合函数，$\mathbf X_i^{(t)}$ 是该次迭代 $v_i$ 节点的隐藏状态，$\mathbf e_{ij}$ 是 $v_i,v_j$ 之间的边特征向量

  > where m( vti) is the message aggregated from the neighbors of node vi, M(t)(·) is the aggregation function in the t-th iteration, X(it) is the hidden state of node vi in the t-th iteration, and eij is the edge feature vector between node vi and node vj.  

  读出阶段：
  $$
  \mathbf X_i^{(t)}=\mathcal U^{(t)}(\mathbf X_i^{(t-1)},\mathbf m^{(t)}_{v_i})
  $$
  其中 $\mathcal U^{(t)}(\cdot)$ 是读出函数。

  > The readout phase is defined as follows, where U(t)(·) is the readout function in the t-th iteration  

- GraphSAGE [O-17](https://proceedings.neurips.cc/paper/2017/hash/5dd9db5e033da9c6fb5ba83c7a7ebea9-Abstract.html)

  只采样固定数量的邻居避免计算问题

  To alleviate the computation problems caused by a large number of neighbors, sampling is used to obtain a fixed number of neighbors  

- GAT [O-18](https://arxiv.org/abs/1710.10903) graph attention network  

  用注意力机制(O-5 开山)学习两个连通点之间的相对权重

  without using a predetermined adjacency matrix, the attention mechanism is used to learn the relative weights between two connected nodes  

  使用了多头注意力机制：稳定学习过程

  the attention mechanism is incorporated into the propagation step and the multi-head attention mechanism is further utilized with the aim of stabilizing the learning process 

  > The specific operation is defined as follows:

  $$
  \mathbf X_i^{(t)}=||_k\sigma(\sum_{j\in\mathcal N(v_i)}\alpha^k(\mathbf X_i^{(t-1)},\mathbf X_j^{(t-1)})\mathbf W^{(t-1)}\mathbf X_j^{(t-1)})
  $$

  其中 $\sigma$ 是激活函数，$\alpha^k(\cdot)$ 是第 $k$ 次的注意力机制，$||$ 是连接操作

  > where k is the concatenation operation, σ is the activation method, αk(·) is the k-th attention mechanism  

> 如图，分别是：两层 GCN 和时空 GNN 典型结构 (1D CNN + GCN 为例)，论文图 5
>
> 上图只有空间依赖被捕获了，下图中：
>
> - GCN 捕获空间依赖，CNN 捕获时间依赖，可以替换
>
>   GCN is used to capture the spatial dependency and 1D-CNN is used to capture the temporal dependency. Both GCN and 1D-CNN components can be replaced with other structures for other spatiotemporal GNNs  
>
> - MLP 转换输出
>
>   A multilayer perceptron (MLP) component is used to generate the desired output  
>
> ![image-20240802212217655](img/image-20240802212217655.png)
>
> ![image-20240802212207043](img/image-20240802212207043.png)

(T-ZS2) 把卷积 GNN 分为：

> We further categorize convolutional GNNs into the following five types:  

1. GCN O-14
2. DGC O-15
3. MPNN O-16
4. GraphSAGE O-17
5. GAT O-18

发展过程如论文图 6 所示：

> These relevant graph neural networks are listed chronologically in Figure 6 

![image-20240803113331085](img/image-20240803113331085.png)

T-ZS2 表格5 给出了使用上述不同模块的论文的列表

##### 设计过程

(T-ZS2 说 O-9 说的) 建议的设计流水线：

> a general design pipeline is proposed and suggested for future studies as follows:

1. 找图结构

   > Find graph structure. As discussed in Section IV, different traffic graphs
   > are available  

2. 找图的类型和规模：如是否有向?同质?静态? 一般规模不大

   > Specify graph type and scale. The graphs can be further classified into different types if needed, e.g., directed/undirected graphs, homogeneous/heterogeneous graphs, static/dynamic graphs. For most cases in traffic forecasting, the graphs of the same type are used in a single study. As for the graph scale, the graphs in the traffic domain are not as large as those for the social networks or academic networks with millions of nodes and edges  

3. 设计损失函数：通常有监督学习，预测任务一般是节点的回归问题，可以用 RMSE, MAE, MAPE

   > Design loss function. The training setting usually follows the supervised approach, which means the GNN-based models are firstly trained on a training set with labels and then evaluated on a test set. The forecasting task is usually designed as the node-level regression problem. Based on these considerations, the proper loss function and evaluation metrics can be chosen, e.g., root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE)  
   >
   > 设 $y$ 是实际值，$\hat y$ 是预测值，$n$ 是样本数，查阅资料：
   > $$
   > \begin{cases}
   > RMSE=\sqrt{\dfrac1n\sum_{i=1}^n(y_i-\hat y_i)^2}\\
   > MAE=\dfrac1n\sum_{i=1}^n|y_i-\hat y_i|\\
   > MAPE=\dfrac{100\%}n\sum_{i=1}^n\left|\dfrac{y_i-\hat y_i}{y_i}\right|
   > \end{cases}
   > $$

4. 用模块构建模型，这些模块如 GCN(最常用), GAT(越来越多) 等

   > The GNNs discussed in this section are exactly those which have already been used as computational modules to build forecasting models in the surveyed studies  
   >
   > Currently, the most widely used GNN is the GCN. However, we also notice a growing trend in the use of GAT in traffic forecasting.  

##### 经典GNN

> (T-ZS2) During the process of customizing GNNs for traffic forecasting,  someclassical models stand out in the literature  

###### DCRNN

最出名的一个是 DCRNN (T-40)

> (T-ZS2) The most famous one is diffusion convolutional recurrent neural network (DCRNN)  

- 图卷积网络和 RNN 学习时空

  > which uses diffusion graph convolutional networks and RNN to learn the representations of spatial dependencies and temporal relations  

- 最初用于交通速度预测，现在成为了基准模型

  > DCRNN was originally proposed for traffic speed forecasting and is now widely used as a baseline.  

- 建图方式：距离矩阵

  > To create the traffic graph, the adjacency matrix is defined as the thresholded pairwise road network distances.  

- 支持有向图，引入扩散卷积(DC)

  > Compared with other graph convolutional models that can only operate on undirected graphs, e.g., ChebNet, DCRNN introduces the diffusion convolution (DC) operation for directed graph and is more suitable for transportation scenarios, which is defined as follows:   

  $$
  \mathbf X_{*DC}=\sum_{k=0}^{K-1}(\theta_{k,1}(D_O^{-1}A)^k+\theta_{k,2}(D_I^{-1}A^T))\mathbf X
  $$

  其中 $\mathbf X\in R^{N\times d}$ 是节点特征矩阵，$A$ 是邻接矩阵，$D_O,D_I$ 是对角矩阵：出度和入度，$\theta$ 是两个模型参数，$K$ 是扩散步数。

  区分入度和出度实现了有向图 

  > where X 2 RN×d is the node feature matrix, A is the adjacency matrix, DO and DI are diagonal out-degree and in-degree matrices, θk;1 and θk;2 are model parameters, K is the number of diffusion steps. By defining and using out-degree and in-degree matrices, DCRNN models the bidirectional diffusion process to capture the influence of both upstream and downstream traffic  

- 对无向图不是很实用

  > While DCRNN is a strong baseline, it is not suitable or desirable for the undirected graph cases  

- 扩展版本 [T-88]()：统一构建 RNN，基于任意图卷积

  Then DCRNN is extended with a stronger learning ability in graph GRU a unified method for constructing an RNN based on an arbitrary graph convolution operator is proposed, instead of the single RNN model used in DCRNN  

###### STGNN

(T-ZS2) Spatio-temporal graph convolutional network (STGCN)  T-28

- 堆叠多个时空卷积块，每个块连接两个时间卷积层和一个图卷积层

  > stacks multiple spatio-temporal convolution blocks and each block concatenate two temporal convolution and one graph convolution layer.  

- 使用 ChebNet 作为图卷积操作，用一阶近似比较

  > ChebNet is chosen as the graph convolution operator in STGCN, after a comparison with its first-order approximation  

- CNN 代替 RNN 获取时间加快了训练时间

  > The usage of temporal convolution layers instead of RNNs for temporal modeling accelerates the training phase of STGCN  

- 变种 ASTGCN 引入两个注意力层分别获取时空动态联系 T-81

  > Attention based Spatio-temporal graph convolutional network (ASTGCN) further introduces two attention layers in STGCN to capture the dynamic correlations in spatial dimension and temporal dimension, respectively  

###### Graph WaveNet

(T-ZS2) T-64 

- 自适应矩阵自动发现隐藏图结构，任意卷积学习时间关联

  > constructs a self-adaptive matrix to uncover unseen graph structures automatically from the data and WaveNet, which is based on causal convolutions, is used to learn temporal relations.  

- 训练后矩阵固定，不能适应动态的数据

  > However, the self-adaptive matrix in Graph WaveNet is fixed after training, which is unable to be adjusted dynamically with the data characteristics  

#### 其他

##### 知识图

包含概念、实体、关系、属性的知识图，未来可以是发展方向。难点是获取这样的信息。

(T-ZS2) While various graphs have been constructed in the surveyed studies as discussed in Section 4.1 and have been proven successful to some extent, most of them are natural graphs based on a real-world transportation system, e.g. the road network or subway system, as the current development status. And most of the graphs used are static, instead of dynamic ones. One specific direction that is not fully considered before is the design of transportation knowledge graph. As an important tool for knowledge integration, knowledge graph is a complex relational network that consists of concepts, entities, entity relations and attributes T-ZS21

The transportation knowledge graph helps to leverage the traffic semantic information to improve the forecasting performance. And the challenge is to extract the hidden transportation domain knowledge from multi-source and heterogeneous traffic data  

#### 具体论文

(T-ZS1) 基于图的方法，图卷积操作(图论领域)。常规卷积是欧氏领域

如：

- 图扩散处理，基于双向图随机游走，结果用于卷积和 RNN

  T-38 (T-ZS1)  performed a graph diffusion process based on a bidirectional graph random walk. Then, the resulting graph diffusion was used in a convolution process which is then incorporated into a Gated Recurrent Unit RNN  

- 图卷积，计算图(几步内)可达

  T-39 (T-ZS1) used a similar idea of graph convolution, but instead of using the diffusion process, they proposed a method which involves calculating whether or not it is possible to reach one node from another under a certain number of time-step when the traffic is on free-flow condition  

- 有向图找上游下游方向融入到卷积层

  T-4 (T-ZS1) used a directed graph which represents how traffic flows between locations. Through this directed graph, it is possible to find the upstream and the downstream locations. This information is incorporated in a convolution layer  

- 空间图卷积层

  T-28 (T-ZS1) modeled the traffic network as a graph and proposed a spatial graph convolutional layer  

- 图注意力网络

  T-43 (T-ZS1) modeled road network as a graph and used a graph attention network to model spatial correlations in the network  

- GN块输出同拓扑不同特征的图

  T-45 (T-ZS1) used a novel component called GN block that takes a road network graph as input and outputs another graph with the same topology but different graph features  

- 用 Deepwalk 把图转向量

  [T-58](https://pubs.aip.org/aip/cha/article-abstract/29/10/103125/282714/Road-traffic-state-prediction-based-on-a-graph?redirectedFrom=fulltext) (T-ZS1) used Deepwalk to transform a graph into a vector representation, which makes it easier to be incorporated into the deep neural network model  

- 扩散卷积 RNN (DCRNN) 

  T-40 (T-ZS1); (T-ZS2) diffusion convolutional recurrent neural network (详见 GNN 经典一节)
  
- Graph WaveNet  

  [T-64](https://arxiv.org/abs/1906.00121) (T-ZS2)

### 注意力

#### 概念

(T-ZS1) 动机：替代基于图的方法，比它更容易实现

An alternative to this method is some sort of an attention module that can model the spatial and temporal correlations in the data  

> #### 基础

开山 O-5



#### 具体论文

(T-ZS1)

- T-42
- T-44

### encoder-decoder

#### 传统

##### 概念

(T-ZS1) 概念介绍：

In addition to these methods, the encoder-decoder RNNs are also used in many recent studies. Encoder-decoder RNNs are partly inspired by autoencoders. 

Autoencoders are deep neural network structures that consist of two parts: 

- the encoder that takes an input and produces a vector representation of it (usually with a smaller dimension), 
- and the decoder that takes the vector representation and produces an approximation of the original input. 

(T-ZS41) Autoencoders 又名 AES

In encoder-decoder RNNs, both input and output are sequences, and instead of approximating the original input, the target output is a ground-truth sequence (e.g., prediction for 5, 10, 15, 20, 25, and 30 minutes into the future)  

> 效果最好，而且可以输出序列而不是答案，所以可以在任意环节输入向量，或提前拿出答案

(T-ZS1) 特点：输出为序列，可以继续做输入等

can output sequences instead of a single result. This means that Encoder-Decoder RNNs can take input data from multiple steps and also output predictions multiple steps ahead  

encoder-decoder RNN (编码器-解码器模型)

- Autoencoder 是深层神经网络，两部分组成：

  编码器把输入转成向量表示(通常更低维度)

  解码器把向量还原为近似成输入

- 对 encoder-decoder RNN

  解码器从近似输入改成近似真实答案 目前的 SOTA

(T-ZS1) 主要使用基于图的方法

To imbue Encoder-Decoder RNN with the capability to capture spatial data, most of these works also utilize graph-based methods  

> (T-ZS1) 评价：与 GNN 一同 SOTA
>
> Despite the complexity of Encoder-Decoder RNNs and graph-based methods, we have observed that this combination has shown to be very proficient at predicting future traffic and is one of the more important recent developments of traffic prediction

(T-ZS38) 是 Seq2seq

> Seq2Seq is a typical architecture under the Encoder-Decoder structure

##### 评价

(T-ZS1) While state-of-the-art models that commonly use encoder-decoder LSTM combined with graph-based methods, have achieved excellent performance, these promising new techniques may be able to further improve the performance of traffic flow prediction  

##### 具体论文

(T-ZS1) 论文例子：

- T-40
- [T-41](https://dl.acm.org/doi/abs/10.1145/3219819.3219895) 200+引用 2018
- [T-42](https://ieeexplore.ieee.org/abstract/document/8580534) STANN (+注意力+RNN) 60引用 2019
- [T-43](https://dl.acm.org/doi/abs/10.1145/3292500.3330884) 500+引用 2019
- [T-44](https://www.sciencedirect.com/science/article/pii/S0968090X19301330) 250引用 2019
- [T-45](https://ieeexplore.ieee.org/abstract/document/8708297/) (STANN+注意力) 60+引用 2019

#### Transformer

##### 概述

(T-ZS1) Transformer $\approx$ encoder-decoder RNN + 注意力 (可并行)

> Transformers are similar to encoder-decoder RNNs in that
> they take sequences as inputs and outputs sequences. The difference is that Transformers are designed with attention mechanisms in mind and can be parallelized  

开山鼻祖 (机器翻译) [O-5](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)

##### 具体论文

(T-ZS1) 第一个应用 [T-59](https://arxiv.org/abs/2001.02908)

(T-ZS2)

- [T-74]() Transformer
- [T-75](https://arxiv.org/abs/2007.15189) 看标题是交通需求分析的 +GNN
- [T-76](https://ebooks.iospress.nl/volumearticle/55026) 看摘要是打车需求的 +GNN
- [T-77](https://link.springer.com/chapter/10.1007/978-3-030-59410-7_49) +GNN

### GAN

#### 概念

##### 定义

(T-ZS2) Generative Adversarial Network (GAN)   

需要达到纳什均衡

(T-ZS1) Generative Adversarial Networks consist of two neural networks that are trained to compete with each other. The two networks are generative networks, designed to capture the data distribution, and discriminative network, which judges whether a given sample came from the true data or from the distribution generated by the generative network  [开山 O-6](https://proceedings.neurips.cc/paper_files/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html)

> (T-ZS2) GAN is a machine learning framework that has two components, namely, a generator, which learns to generate plausible data, and a discriminator, which learns to distinguish the generator’s fake data from real data 
> After training to a state of Nash equilibrium, the generator may generate undistinguished data, which helps to expand the training data size for many problems, including GNN-based traffic forecasting.  

##### 作用

(T-ZS2) 可以生成数据来模拟真实数据

GAN is proposed for the challenges caused by the small data amount used in previous studies or the changes in the transportation networks and infrastructure when not enough historical traffic data are available  



##### 评价

> SOTA 可能是这个
>
> (T-ZS1) While state-of-the-art models that commonly use encoder-decoder LSTM combined with graph-based methods, have achieved excellent performance, these promising new techniques may be able to further improve the performance of traffic flow prediction  

优点是可把序列任意部分访问，无视距离

(T-ZS2) As a special case, Transformer is built entirely upon attention mechanisms, which makes it possible to access any part of a sequence regardless of its distance to the target  

#### 具体应用

(T-ZS1)

- [T-60](https://journals.sagepub.com/doi/abs/10.1177/0361198118798737) LSTM 生成和对抗

  use LSTMs for both the generative and discriminative network  

- [T-61](https://ieeexplore.ieee.org/abstract/document/8438991) 增强边界健壮性

  where a GAN is used to enable traffic flow prediction that is more robust to outliers  

- [T-62]() +图CNN 使用句子到句子的 autoencoder

  combine GAN with graph CNN, and use sequence-to-sequence autoencoder for the generative network  

(T-ZS2)

- [T-74](https://onlinelibrary.wiley.com/doi/abs/10.1111/tgis.12644)

- [T-114](https://www.sciencedirect.com/science/article/pii/S0968090X19312409) 

  the road network is used directly as the graph, in which the nodes are road state detectors and the edges are built based on their adjacent links. DeepWalk is used to embed the graph and the road traffic state sensor information is transferred into a low-dimensional space  

- [O-28](https://arxiv.org/abs/1701.07875) WassersteinGAN (WGAN)   

  used to train the traffic state data distribution and generate predicted results. Both public traffic flow (i.e., Caltrans PeMSD7) and traffic speed (i.e., METR-LA) datasets are used for evaluation, and the results demonstrate the effectiveness of the GAN-based solution when used in graph-based modeling.  



### 其他技术

#### 数据增强

广泛应用于图像分类、时序预测任务。为解决小数据量的预测偏差。

GNN 图结构复杂，增强困难。数据增强有效性未知。

(T-ZS2) Data Augmentation. Data augmentation has been proven effective for boosting the performance of deep learning models, e.g. in image classification tasks and time series prediction tasks. Data augmentation is proposed for the challenge of the possible forecasting bias introduced by the small amount of available data. However, due to the complex structure of graphs, it is more challenging to apply data augmentation techniques to GNNs. Recently, data augmentation for GNNs has proven helpful in semi-supervised node classification tasks [O-25](https://ojs.aaai.org/index.php/AAAI/article/view/17315). However, it remains a question whether data augmentation may be effective in traffic forecasting GNN applications.  

#### 迁移学习

> 如在图像分类，预训练通常源自 ImageNet, MS COCO
>
> (T-ZS2) Transfer learning utilizes knowledge or models trained for one task to solve related tasks, especially those with limited data. In the image classification field, pre-trained deep learning models from the ImageNet or MS COCO datasets are widely used in other problems.  

该领域数据缺失频繁，所以具有应用价值，把一个地点迁移到另个地点

(T-ZS2) In traffic prediction problems, where a lack of historical data is a frequent problem, transfer learning is a possible solution. For GNNs, transfer learning can be used from a graph with more historical traffic data for the model training process to another graph with less available data. Transfer learning can also be used for the challenge caused by the changes in the transportation networks and infrastructure, when new stations or regions have not accumulated enough historical traffic data to train a GNN model
A novel transfer learning approach for DCRNN is proposed in [T-112](https://ieeexplore.ieee.org/abstract/document/9413270), so that a model trained on data-rich regions of highway network can be used to predict traffic on unseen regions of the highway network. The authors demonstrated the efficacy of model transferability between the San Francisco and Los Angeles regions using different parts of the California road network from the PeMS  

#### 元学习

(T-ZS2) Meta-learning. Meta-learning, or learning how to learn, has recently become a potential learning paradigm that can absorb information from a task and effectively generalize it to an unseen task. Meta-learning is proposed for the challenge of GNN-based multi-task prediction, especially those involving mutiple graphs. There are different types of meta learning methods and some of them are combined with graph structures for describing relationships between tasks or data samples [O-26](https://ieeexplore.ieee.org/abstract/document/9413270), [O-27](https://arxiv.org/abs/1711.04043). Based on a deep meta learning method called network weight generation, ST-MetaNet+ is proposed in [T-113](https://ieeexplore.ieee.org/abstract/document/9096591), which leverages the meta knowledge extracted from geo-graph attributes and dynamic traffic context learned from traffic states to generate the parameter weights in graph attention networks and RNNs, so that the inherent relationships between diverse types of spatiotemporal correlations and geo-graph attributes can be captured

#### 联邦学习

(T-ZS40 是联邦学习在该问题的综述)

(GPT) 联邦学习（Federated Learning）是一种分布式机器学习的方法，它允许多个参与方在本地训练模型，并仅共享模型的更新而不是原始数据。这样可以保护数据隐私并减少数据传输的需求。

在联邦学习中，每个参与方（比如个人设备或组织）都有自己的数据和模型。每个参与方在本地训练模型，并将模型参数（如权重和梯度）发送到一个中央服务器。中央服务器将这些更新汇总并生成一个全局模型，然后将更新后的全局模型返回给参与方，参与方继续在本地进行训练。这种过程重复进行，直到模型收敛。

联邦学习的主要优点包括：

1. 数据隐私保护：数据不会离开本地设备，只共享模型更新，因此用户的敏感信息更好地被保护。
2. 减少数据传输：只需要传输模型参数而不是原始数据，减少了带宽消耗。
3. 适应分布式环境：适用于数据分布广泛且分散的情况，如移动设备或多个机构的数据。

这种方法特别适用于需要保护隐私和数据安全的场景，如移动设备上的个性化推荐系统或医疗健康数据分析。

#### AutoML

自动化机器学习 Automated Machine Learning (AutoML).  

ML 里特征获取、模型选择、参数调整都是手动的，AutoML 学习这些步骤，对特征、模型、优化、评估自动化，有助于提高模型

(T-ZS2) The application of machine learning requires considerable manual intervention in various aspects of the process, including feature extraction, model selection, and parameter adjustment. AutoML automatically learns the important steps related to features, models, optimization, and evaluation, so that machine learning models can be applied without manual intervention. AutoML would help to improve the implementation of machine learning models, including GNNs. 

对超参数的选择可能更好

(T-ZS2) AutoML is proposed for the challenge for computational requirements in graph-based modeling, in which case the hyper parameter tuning for GNNs can be more efficient with state-ofthe-art AutoML techniques. 
An early attempt to combine AutoML with GNNs for traffic prediction problems is an Auto-STGCN algorithm, proposed in [T-115](https://arxiv.org/abs/2010.07474). This algorithm searches the parameter space for STGCN models quickly based on reinforcement learning and generates optimal models automatically for specific scenarios.  

## 相关数据

### 概述

#### 分类

##### 主数据

参考 T-ZS1 的分类标准，主要数据集可以分为两类：

- 固定式采集数据集(point data)：安装在固定地方的探测器所采集的数据

  > (T-ZS1) 标准数据集为 PeMS

- 移动式交通数据(trajectory data)：GPS 等收集的车辆轨迹信息

  > (T-ZS1) 无标准 do not have a standard dataset  
  >
  > Different works use different datasets with different properties, including the origin country (mostly America or China), method of transportation (cars, taxis or bicycles) and time range
  >
  > trajectory data from Beijing is relatively more popular    

> (T-ZS1) road link data 是特殊的 point data 的理由：
>
> As we can derive the traffic speed from road link data by averaging the speed of vehicles on each road link, we also regard road link data as a special type of point data.  
>
> (T-ZS1) 非主流——使用了 point + 道路连接的论文： 
>
> - use road link data in addition to point data as the main datasets  
>
>   T-12 T-39

##### 辅助数据

(T-ZS1) 此外，可能还需要一些辅助数据信息：

- 交通网络数据：探测器的分布图(欧氏空间网格或无向加权图等)
- 气候数据、日期(节假日)数据、事件(如车祸)数据等

(T-ZS1) In traffic prediction, commonly used external information include weather, accidents, events, day of the week, time of the day and social media data  

(T-ZS2) 天气：温度、湿度、降水、气压、风力

Weather Data. Traffic states are highly affected by the meteorological factors including temperature, humidity, precipitation, barometer pressure, and wind strength  

(T-ZS2) 日期：工作日/节假日。

Calendar Data. This includes the information on weekends and holidays. Because traffic patterns vary significantly between weekdays and weekends/holidays, some studies consider these two cases separately. 

> Both weather and calendar data have been proven useful for traffic forecasting in the literature and should not be neglected in graph-based modeling as external factors  



##### 图网数据

(T-ZS2)

参考 T-ZS2 的分类方法：三类数据是图相关、历史交通和外部

> We categorize the data used in the surveyed studies into three major types, namely, graph-related data, historical traffic data, and external data  

- 图相关：交通的图结构

  > graph-related data refer to those data which exhibit a graph structure in the traffic domain, i.e., transportation network data  

  路网数据，从政府部门或在线地图服务获取，可以直接建图，缺点为静态图

  > Transportation Network Data. These data represent the underlying transportation infrastructure, e.g., road, subway, and bus networks. They can be obtained from government transportation departments or extracted from online map services, e.g., OpenStreetMap. Based on their topology structure, these data can be used to build the graphs directly, e.g., the road segments or the stations are nodes and the road intersections or subway links are the edges. While this modeling approach is straightforward, the disadvantage is that only static graphs can be built from transportation network data.  

- > 历史交通：过去的交通状态，在不同的时空
  >
  > Historical traffic data refer to those data which record the historical traffic states, usually in different locations and time points.  

- > 外部数据：影响交通的其他因素如天气、日历，可能需要预处理
  >
  > External data refer to the factors that would affect the traffic states, i.e., weather data and calendar data. Some of these data can be used in the graph-based modeling directly, while the others may require some pre-processing steps before being Incorporated into GNN-based models  

#### point data

可用性，兼容性好，无序数据转换

(T-ZS1) Point data consists of traffic readings from road-installed sensors. This data is popular due to its availability and compatibility with deep neural network models; usually, point data does not require major data transformation step and can be used as is  

使用/表征方式：向量、矩阵、张量

(T-ZS1) For point data, spatial aspect is typically captured by collating data from multiple detection points into vectors. Sometimes, matrices can be used when capturing both the spatial and the temporal aspects. In addition, tensors can also be used when there are multiple matrices to be used all at once, such as when we are inputting the spatiotemporal traffic data from multiple days at once. These vectors/matrices/tensors are then fed as input into the network where a CNN resides  

优点为：

- 公开数据集可用
- 简单的数据转换
- 可以与图论方法一起用

The advantages of using point data are:

- (T-ZS1) Common public data are available. 

  For instance, the Caltrans data is very commonly used in the literature. Although each work uses different subsets, the availability of one unified data source makes it easier to establish a benchmark data.

  来源权威，覆盖面广

  Point data generally comes from traffic detectors installed by the transportation bureau. Consequently, the system is well-established, resulting in better temporal coverage  

- (T-ZS1) Data transformation is simpler.

  To obtain an input data that contains both the temporal and the spatial trends, the common procedure is just collating the data into vectors/matrices/tensors.

- (T-ZS1) Works better for methods that are based on the graph space. 

  Point data often constitutes traffic detectors installed on roads, which can be easily converted to graphs; each detector site can be treated as a vertex and every two adjacent detectors define an edge.   

限制：

- 成本高昂，几乎没有 arterial/highways 数据

- 与欧氏空间方法不兼容(如 2D CNN 即普通的 CNN)

  因为很多真实空间连成线

- 数据缺失和数据噪音问题

- 获取困难：隐私、存储空间有限

(T-ZS1) Although point data has multiple advantages as detailed above, it also has some limitations as listed below:

- (T-ZS1) Almost exclusive highways data.

  Since traffic loop detectors are difficult and expensive to install, they are not commonly available for arterial roads.

  > However, as traffic detectors are costly to install, they are mostly limited to highways  

  (T-ZS2) While traffic sensors have been successfully used, data collection for traffic flow information is still a challenge when considering the high costs in deployment and maintenance of traffic sensors.  

- (T-ZS1) Not compatible with methods that conform to the Euclidean space (e.g. 2D CNN). 

  This is because most point-based data are highways data where the traffic detectors are spatially organized in a line.  

> (T-ZS2) 探测器数据，广泛使用，优点是节点属性可直接用原始数据，但可能存在数据出错(缺失/噪音)，且区域范围小
>
> Traffic Sensor Data. Traffic sensors, e.g. loop detectors, are installed on roads to collect traffic information, e.g., traffic volume or speed. This type of data is widely used for traffic prediction, especially road traffic flow and speed prediction problems. For graph-based modeling, each sensor can be used as a node, with road connections as the edges. One advantage of using traffic sensor data for graph-based modeling is that the captured traffic information can be **used directly** as the node attributes, with little pre-processing overhead. One exception is that the sensors are prone to hardware **faults**, which causes the missing data or data noise problems and requires corresponding pre-processing techniques, e.g., data imputation and denoising methods. Another disadvantage of using traffic sensor data for graph-based modeling is that the traffic sensors can only be installed in a **limited** number of **locations** for a series of reasons, e.g., installation cost. With this constraint, only the part of the road networks with traffic sensors can be incorporated into a graph, while the uncovered areas are neglected
>
> (T-ZS2) While present road network and weather data can be easily found on the Internet, it is much more difficult to source historical traffic data, both due to data **privacy** concerns and the transmission and **storage** requirements of large data volumes  

#### trajectory data

如果使用轨迹数据，每条轨迹映射到 2D 平面网格，优点：

- GPS 数据，覆盖了 arterial roads(干道) 和 highways(公路)
- 对欧氏空间方法更好
- 结果可视化/可解释简单

The advantages of trajectory data are:

- (T-ZS1) Not exclusive to highways data. 

  Trajectory data are usually GPS data, which cover both arterial roads and highways.

  > has a more general spatial coverage as drivers pass through arterial, urban and highway roads alike  

- (T-ZS1) Works better for methods that are based on the euclidean space.

  After the data processing, the spatial correlation is inherently captured within the resulting 2D plane. Additionally, the resulting data transformation output is a matrix, which naturally fits 2D CNN. Finally, trajectory data usually cover city regions, which usually conform to the 2D shape.

- (T-ZS1) Results are easily interpretable. 

  By visualizing the values assigned to each grid in the 2D map, the region’s traffic flow prediction can be observed directly. 

缺点：

- 数据转换到 2D 平面复杂 (故文献少)
- 不能建图用图论方法
- 时间覆盖没这么广
- 数据质量
- 预处理难度大

(T-ZS1) For trajectory data, utilizing the Euclidean space is common. Each trajectory needs to be mapped onto a 2D plane which represents the region (e.g. city, country) where the data resides. This region is divided into grids where each grid represents a subregion. Processing the data this way yields a matrix that represents the traffic state of a region, which can be fed into a CNN to capture the spatial aspect.

The disadvantages of trajectory data are:

- (T-ZS1) Complex data transformation. 

  The process of mapping each trajectory point to the 2D plane is complex and time consuming.

- (T-ZS1) Not compatible with methods that model their data using graph-based methods. 

  Points in the road network can be transformed into vertices and the connections between them can be mapped to edges. This is not possible for trajectory data.  

- (T-ZS1) the temporal coverage is limited, ranging from a month (T-36 T-37) to several months (T-1 T-37 T-51) and up to one year (T-49 T-30), compared to the Caltrans data, for instance, which contains more than five years’ worth of data for its detectors  

(T-ZS2) Another potential approach is using the pervasive mobile and IoT devices, which have a lower cost generally, e.g., GPS sensors. However, challenges still exist when considering the data quality problems frequently seen in GPS data, e.g., missing data caused by unstable communication links  

(T-ZS2) 2-60 区间间隔记录，匹配到路网里，计算出交通速度/流，低成本高覆盖，数据质量可能存在问题，预处理难

> GPS Trajectory Data. Different types of vehicles (e.g. taxis, buses, online ride-hailing vehicles, and shared bikes) can be equipped with GPS receivers, which record GPS coordinates in 2-60 second intervals. The trajectory data calculated from these GPS coordinate samples can be matched to road networks and further used to derive traffic flow or speed. The advantage of using GPS trajectory data for graph-based modeling is both the **low expense** to collect GPS data with smartphones and the **wider coverage** with the massive number of vehicles, compared with traffic sensor data. However, GPS trajectory data contain no direct traffic information, which can be derived with corresponding definitions though. The data **quality** problems also remain with GPS trajectory data and more **pre-processing** steps are required, e.g., map matching  

(T-ZS2) 有来源更广的数据，但质量更差。

> Location-based Service Data. GPS function is also embedded in smartphones, which can be used to collect various types of location-related data, e.g., check-in data, point-of-interest data, and route navigation application data. The pros and cons of using location-based service data are similar with GPS trajectory data. And the difference is that location-based service data are often collected in a crowd-sourced approach, with more data providers but potentially a lower data quality  

(T-ZS1) 更推荐轨迹数据

The installation of traffic detectors is expensive, and point data’s spatial limitation is difficult to address. Therefore, we recommend focusing on trajectory data. Floating car data collected from GPS is the most widespread and efficient source of trajectory data. However, researchers must take into account the required preprocessing to use trajectory data for traffic prediction

#### 其他来源数据

旅行记录、交通报告、多媒体数据、模拟数据

(T-ZS2) 旅行记录，推导出速度和需求；建模方便，容易收集

Trip Record Data. These include departure and arrival dates/times, departure and arrival locations, and other trip information. Traffic speed and demand can derived from trip record data from various sources, e.g., taxis, ride-hailing services, buses, bikes, or even dock-less e-scooters ([T-89](https://dl.acm.org/doi/abs/10.1145/3366423.3380101))
These data can be collected in public transportation systems with mature methods, for example, by AFC (Automatic Fare Collection) in the subway and bus systems. Trip record data have the advantage of being capable of constructing multiple graph-based problems, e.g., station-level traffic flow and demand problems. They are also easier to collect in existing public transportation systems  

(T-ZS2) 交通报告：异常案例，但时空跨度上都很少见故很少用

Traffic Report Data. This type of data is often used for abnormal cases, e.g., anomaly report data used in [T-90](https://ebooks.iospress.nl/volumearticle/55105?ref=https://githubhelp.com), and traffic accident report data used in [T-91](https://ieeexplore.ieee.org/abstract/document/9158447), [T-92](https://ojs.aaai.org/index.php/AAAI/article/view/5480), [T-93](https://ieeexplore.ieee.org/abstract/document/9242313). Traffic report data are less used in graph-based modeling because of their sparsity in both spatial and temporal dimensions, compared with trip record data.  

(T-ZS2) 多媒体数据：街景图预测拥挤、卫星图等。数据收集、存储高要求，信息获取困难

Multimedia Data. This type of data can be used as an additional input to deep learning models or for verifying the traffic status indicated by other data sources. Multimedia data used in the surveyed studies include the Baidu street-view images used in [T-94](https://onlinelibrary.wiley.com/doi/abs/10.1111/tgis.12641), for traffic congestion, as well as satellite imagery data T-91, and video surveillance data. Multimedia data are also less seen in graph-based modeling because of their higher requirement for data collection, transmission and storage, compared with traffic sensor data with similar functionalities. It is also more difficult to extract precise traffic information, e.g., vehicle counts, from images or videos through image processing and object detection techniques  

(T-ZS2) 模拟交通数据，真实数据很多所以少用，但可以模拟罕见情景

Simulated Traffic Data. In addition to observed real-world datasets, microscopic traffic simulators are also used to build virtual training and testing datasets for deep learning models. Examples in the surveyed studies include the MATES Simulator used in [T-95](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-its.2019.0778), and INTEGRATION software used in [T-96](https://ieeexplore.ieee.org/abstract/document/9149233). With many real-world datasets available, simulated traffic data are rarely used in GNN-based and more broader ML-based traffic forecasting studies. Traffic simulations have the potential of modeling unseen graphs though, e.g., evaluating a planned road topology.  

### 评价

#### 日期

> 日期容易结合：
>
> (T-ZS1) Conversely, time-of-day and day-of-week data are much easier to incorporate
>
> 日期少于一年的缺点：
>
> (T-ZS1) 26 out of 37 literatures use less than one year’s worth of data. This deficiency will have an adverse impact on sub-tropical regions, as seasonal changes may affect temperature and weather, which in turn can affect traffic. By using data from only one or several months, the model cannot generalize to different seasons. This can be mitigated by incorporating weather data, but as mentioned before, this is a difficult and time-consuming task.  
>
> 时间不完整一天/周的缺点：
>
> (T-ZS1) e-consuming task. Some authors also use data from only a certain range of hours or use data from weekdays only. This will also cause problems as the model cannot generalize well to situations outside the boundaries of the provided data. For instance, using traffic data from 07.00 AM to 11.00 PM only may reduce the model’s performance on the excluded hours, and using only weekdays data may adversely impact the model’s performance when predicting weekend traffic  



#### 真实性

> 数据要趋于真实的理由：
>
> (T-ZS1) using vastly different datasets may result in an entirely different model. Thereby, for a model to be applicable to real application scenarios, it is important to use a dataset that closely resembles those scenarios.  



#### 时间粒度

> 时间粒度：大部分 5min (默认)，推荐 15min
>
> (T-ZS1) using vastly different datasets may result in an entirely different model. Thereby, for a model to be applicable to real application scenarios, it is important to use a dataset that closely resembles those scenarios.  
>
> (T-ZS1) 指出[文献](https://onlinepubs.trb.org/Onlinepubs/trnews/rpo/rpo.trn129.pdf)推荐 15min 粒度
>
> 数据粒度的辩证讨论：对结果和训练/输入的影响
>
> Depending on the dataset, the data granularity is a potentially important hyperparameter. Using a data granularity that is too small may cause a lot of zero values, especially during conditions where traffic is very sparse. For example, it is highly likely for a traffic loop detector to not detect any cars in 2 or 5 minute periods during off-peak hours (e.g. 02:00 04:00 AM) while this becomes less likely if the granularity is increased to 15 minutes or more. On the other hand, using a granularity that is too high might result in the smoothness of the traffic flow reading where important trends are lost. For instance, if the traffic experiences periodic shifts during 12:30PM, this trend might not be detected if the data granularity is one hour.
>
> Data granularity also impacts the number of possible data points as well as the size of the input sequence. Using a smaller granularity will increase the length of the required data sequence. For instance, one hour’s worth of data can be captured with only a sequence of length 4 when the granularity is 15 minutes, but when the granularity is 5 minutes, the sequence length is 12. This can impact training time, especially for RNN-based models.  
>
> Due to the aforementioned reasons, choosing the correct data granularity becomes a decision based on trade-offs and should be considered carefully depending on the data, the model, as well as the application scenarios  

#### 输入输出长度

> (T-ZS1) 多个长度都试一下，一般输入输出正相关，未得到充分研究：超参搜索耗时。多数是人为设置的，因为搜索超参太慢。可以用小数据集做超参搜索来缓解该问题。
>
> many authors perform experiments with different prediction horizons and use different input sequence lengths for each of the selected prediction horizons  
>
> Intuitively, as we increase the prediction horizon, the input sequence length also needs to be increased. This is because the increase in prediction horizon means predicting the traffic of further time frame in the future and thus, increasing the task complexity. Increasing the size of the data points by extending the input sequence may help in tackling the complex problem.  
>
> Unfortunately, the relationship between the input sequence length and the prediction horizon is rarely explored by the literature. Most of the input sequence lengths were chosen arbitrarily without iterating through different possible values. This is because hybrid deep neural network structures take a long time to train, which makes iterating through different settings unwieldy. Despite this issue, hyperparameter search remains an important facet of deep neural network development that cannot be omitted. One possible remedy of this problem is to first use a smaller data, chosen randomly from the main dataset, to find the optimal parameter setting.  

### 数据集列表

> #### 数据集
>

列出部分常用的数据集：

##### PeMS

[PeMS](http://pems.dot.ca.gov/) (Caltrans Performance Measurement System)

> T-87 说数据集论文是 [O-31](https://journals.sagepub.com/doi/abs/10.3141/1748-12)

研究最广泛的数据集，由加利福尼亚州主要公路的上万探测器收集，2001-2009，每半分钟采集一次，包含容量、速度、交通流量等多种数据

> 优点 (T-ZS1) public availability, ease of download, simple structure and long historical data  
>
> 提供的数据、粒度 (T-ZS1) provides information regarding date, time stamp, traffic flow per lane, and aggregated traffic flow. Traffic flow is the most commonly used field, but occupancy and speed information is also available. The data granularity can be set to 5 minutes, hourly, daily, weekly and monthly depending on user requirements  
>
> (T-ZS2) This dataset contains raw detector data from over 18,000 vehicle detector stations on the freeway system spanning all major metropolitan areas of California from 2001 to 2019, collected with various sensors including inductive loops, side-fire radar, and magnetometers. The samples are captured every 30 seconds and aggregated in 5-minute intervals. Each data sample contains a timestamp, station ID, district, freeway ID, direction of travel, total flow, and average speed  
>
> (T-ZS26) 说 4w 多个单独检测器

官网有图片提供(直接打开官网即可看到)

有多个子集广泛用于论文中，包括 PeMS-BAY、PeMSD3、PeMSD4、PeMSD7、PeMSD8 等，可以参考(有的论文会说 D 是 0，但是根据我论文阅读观察其实是同一个数据集)

> (T-ZS2) Different subsets of PeMS data have been used in previous studies, for example:  

- [PeMS-BAY](https://github.com/liyaguang/DCRNN)

  This subset contains data from 325 sensors in the Bay Area from January 1st to June 30th, 2017 (2017/1/1 - 2017/5/31)

  (T-64) 2369条边，52116个时间步 (T-133) 2691 条边，5min 粒度

  (T-40) 16937179个数据点

- PeMSD3

  This subset uses 358 sensors in the North Central Area. The frequently referenced time period for this dataset is September 1st to November 30th, 2018  

  (T-135) 26208 个时间区间

- PeMSD4

  This subset uses 307 sensors in the San Francisco Bay Area. The frequently referenced time period for this dataset is January 1st to February 28th, 2018  

  (T-135) 16992 个时间区间  (T-137, T-138) 说是 flow，680条边

- PeMSD7

  This subset uses 883 sensors in the Los Angeles Area. The frequently referenced time period for this dataset is May to June, 2012.  

  (T-28 图4) 有一个U形和双U形数据 ，具体数据看 T-28 具体论文笔记描述

  每天的记录次数乘以天数是行，道路数是列，内容是速度记录，节点数是 228 和 1026，行数是 12672(我算出来44天)，值是 60 多和 70 多的占大头

  (T-145) 228 和 1026 分别是 M 和 L 子数据集，边数分别是 1132, 10150，点数是 12672；但是不含 M/L 的是 883 个点，866 条边，28224

  (T-135) 28224 个时间区间 

- PeMSD8

  This subset uses 170 sensors in the San Bernardino Area. The frequently referenced time period for this dataset is July to August, 2016
  
  (T-135) 17856 个时间区间 (T-138) 说是 flow，548条

(T-135) 都是 5min 时间步

(T-138) 速度单位 Traffic speed data records the average vehicles speed (miles per hour)

流量单位：The flow data should be an integer, up to hundreds

其他：

- PeMSD7M (T-28提出)

  (T-141) 228点 5分钟 12672个时间

  (T-128) 12612 个数据点

  (T-153) 说是 speed PEMSD7(M) 228 12672 05/2012 - 06/2012 5min

- PEMSD7L

  (T-153) speed PEMSD7(L) 1026 12672 05/2012 - 06/2012 5min

- PeMS-S (找不到来源)

  (T-140) The time range of PeMS-S is the weekdays of May and Jun of 2012, the interval is 5 minute and 228 sensors (nodes) are selected
  
- BayArea

  (T-151 自建) flow data
  
  is also collected from PeMS of CalTrans. It is collected from 4096 sensors installed in the Bay Area with observations of 12 months of data ranging from January 1 to December 30, 2019. Then we discard the data of nodes with a missing rate greater than 0.1%, leaving only 699 nodes

> (T-143) 对 PEMS-BAY 的图：
>
> ![image-20240819013320675](img/image-20240819013320675.png)

##### METR-LA

[METR-LA](https://github.com/liyaguang/DCRNN) (Metro Traffic Los Angeles)

洛杉矶公路网，207 个探测器，5 分钟间隔收集数据，一般用 2021 3.1 - 6-30

(T-ZS2) This dataset contains traffic speed and volume collected from the highway of the Los Angeles County road network, with 207 loop detectors. The samples are aggregated in 5-minute intervals. The most frequently referenced time period for this dataset is from March 1st to June 30th, 2012.  

(T-64) 1515 条边，34272 个时间步  (T-138) 说1722条边

(T-40) 说 6519002 个数据点 (T-128) 说 每个点35000个数据

##### Seattle Loop

[Seattle Loop](https://github.com/zhiyongc/Seattle-Loop-Data)

西雅图 4 条路数据，323 个探测器，5 分钟间隔收集数据，2015 年 1 月数据

(T-ZS2) This dataset was collected by inductive loop detectors deployed on four connected freeways (I-5, I-405, I-90, and SR-520) in the Seattle area, from January 1st to 31st, 2015. It contains the traffic speed data from 323 detectors. The samples are aggregated in 5-minute intervals  

(T-ZS26) I-5、I405、I-90和 SR-520这 4条高速公路的环路数据，T-12 用了

##### 出租车数据

Taxi Data  

- T-drive [T-97](https://dl.acm.org/doi/abs/10.1145/1869790.1869807) 轨迹数据 3w出租车 北京 2015/2/1 到 6/2

  (T-ZS2) This dataset contains a large number of taxicab trajectories collected by 30,000 taxis in Beijing from February 1st to June 2nd, 2015.

  (T-151) 32x32网格 60min 数据 02/01/2015-06/30/2015

  is a dataset based on taxi GPS trajectories on Beijing, jointly released by Microsoft Asia Research Institute and Peking University. The data used in our paper spans from February 1 to June 30, 2015

  contain inflow and outflow data

- [SHSpeed](https://github.com/xxArbiter/grnn) (Shanghai Traffic Speed) [T-98](https://arxiv.org/abs/1811.00740) 轨迹 上海

  (T-ZS2) This dataset contains 10-minute traffic speed data, derived from raw taxi trajectory data, collected from 1 to 30 April 2015, for 156 urban road segments in the central area of Shanghai, China.  

- TaxiBJ T-51 GPS轨迹 3w数据 背景 32x32 网格

  (T-ZS2) This dataset contains inflow and outflow data derived from GPS data in more than 34,000 taxicabs in Beijing from four time intervals: (1) July 1st to October 30th, 2013; (2) March 1st to June 30th, 2014; (3) March 1st to June 30th, 2015; and (4) November 1st, 2015 to April 10th, 2016. The Beijing city map is divided into 32 × 32 grids and the time interval of the flow data is 30 minutes

- [SZ-Taxi](https://github.com/lehaifeng/T-GCN) T-36 深圳罗湖区 156 条路轨迹数据，15 分钟粒度，2015 年 1 月数据

  (T-ZS2) This dataset is derived from taxi trajectories in Shenzhen from January 1st to 31st, 2015. It contains the traffic speed on 156 major roads of the Luohu District every 15 minutes.  

- [TaxiCD](https://js.dclab.run/v2/cmptDetail.html?id=175) 14亿 GPS轨迹数据 1w5 出租车 2014 8月 成都

  (T-ZS2) This dataset contains 1.4 billion GPS records from 14,864 taxis collected from August 3rd to 30th, 2014 in Chengdu, China. Each GPS record consists of a taxi ID, latitude, longitude, an indicator of whether the taxi is occupied, and a timestamp  

- [TaxiNYC](https://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml) 2009 纽约

  (T-ZS2) The taxi trip records in New York starting from 2009, in both yellow and green taxis. Each trip record contains pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts.
  
  (T-ZS38 给了另一个下载地址) ＮＹＣＴａｘｉ数据集包括了２００９—２０２０年纽约黄色和绿色出租车行程记录数据，主要记录了接送日期／时间、接送地点、行程距离、分项票价、费率类型、付款类型和司机报告的乘客数量等信息．该数据集是一个学术界常用的出租车数据集
  
  NYCTaxi
  
  (T-148 说 [T-149](https://ieeexplore.ieee.org/abstract/document/9127874/)) 75(15x5) 30min 01/01/2014-12/31/2014 
  
  (T-151) is a dataset of taxi trips made in New York City. It is provided by the New York City Taxi and Limousine Commission (TLC) The data used in our paper spans from January 1 to December 31, 2014.
  
  网格数据 75个点(15x5) 30分钟区间 contain inflow and outflow data
  
  (T-153 不同的，需求分析) 
  
  NYC-Taxi15 200 2880 01/2015 - 03/2015 30 min (2880是时间步)
  
  NYC-Taxi16 266 4368 04/2016 - 06/2016 30 min
  
  the traffic demand datasets have two dimensions: ’Pick-up’ and ’Drop-off
  
- CHI-Taxi

  (T-ZS35) 对 Illinois, USA 的数据集，有链接，轨迹数据

##### 打车数据

Ride-hailing Data

(T-ZS2)

- [UberNYC](https://github.com/fivethirtyeight/uber-tlc-foil-response) 百万计的数据 Uber

  This dataset comes from Uber, which is one of the largest online ride-hailing companies in the USA, and is provided by the NYC Taxi & Limousine Commission (TLC). It contains data from over 4.5 million Uber pickups in New York City from April to September 2014, and 14.3 million more Uber pickups from January to June 2015  

- [Digi GAIA Open Data](https://outreach.didichuxing.com/research/opendata/) 滴滴出行

  > (T-ZS37 译为滴滴盖亚开发数据集)：统计了网约车在成都、西安、海口等城市行驶中的所有传感器数据．该数据集包括的数据有：车辆平均速度 OD 信息、轨迹信息、驾驶场景、POI 检索数据等  

  This open data plan is supported by Didi Chuxing, which is one of the largest online ride-hailing companies in China  
  
  - DiDiChengdu: This dataset contains the trajectories of DiDi Express and DiDi Premier drivers within Chengdu, China. The data contains trips from October to November 2016  
  - DiDiTTIChengdu: This dataset represents the DiDi Travel Time Index Data in Chengdu, China in the year of 2018, which contains the average speed of major roads every 10 minutes  
  - DiDiXi’an: This dataset contains the trajectories of DiDi Express and DiDi Premier drivers within Xi’an, China. The data contains trips from October to November 2016  
  - DiDiHaikou: The dataset contains DiDi Express and DiDi Premier orders from May 1st to October 31st, 2017 in the city of Haikou, China, including the coordinates of origins and destinations, pickup and drop-off timestamps, as well as other information  

##### 单车数据

(T-ZS2) The open bike data used in the surveyed studies are listed as follows. 

- [BikeNYC](https://www.citibikenyc.com/system-data)

  This dataset is from the NYC Bike System, which contains 416 stations. The frequently referenced time period for this dataset is from 1st July, 2013 to 31th December, 2016  

  (T-153) 需求数据 (点数，时间步数)

  NYC-Bike14 128 4392 04/2014 - 09/2014 1 hour

  NYC-Bike15 200 2880 01/2015 - 03/2015 30 min

  NYC-Bike16 250 4368 04/2016 - 06/2016 30 min

  the traffic demand datasets have two dimensions: ’Pick-up’ and ’Drop-off

- [BikeDC](https://www.capitalbikeshare.com/system-data) 

  This dataset is from the Washington D.C. Bike System, which contains 472 stations. Each record contains trip duration, start and end station IDs, and start and end times.

- [BikeChicago](https://www.divvybikes.com/system-data)

  This dataset is from the Divvy System Data in Chicago, from 2015 to 2020.  
  
- CHI-Bike

  (T-ZS35) Illinois, USA 的轨迹数据
  
- CHBike

  (T-148 说 [O-32](https://dl.acm.org/doi/abs/10.1145/3474717.3483923))CHBike 270(15x18) 30min 07/01/2020-09/30/2020 

##### 地铁数据

(T-ZS2) The subway data referenced in the surveyed studies are listed as follows.  

- [SHMetro](https://github.com/ivechan/PVCGN) T-84 上海 8kw 数据 2016 近300个站千条边

  This dataset is derived from 811.8 million transaction records of the Shanghai metro system collected from July 1st to September 30th, 2016. It contains 288 metro stations and 958 physical edges. The inflow and outflow of each station are provided in 15 minute intervals.  

- [HZMetro](https://github.com/ivechan/PVCGN) T-84 杭州 2019 80个站 [src2](https://tianchi.aliyun.com/competition/entrance/231708/information)

  This dataset is similar to SHMetro, from the metro system in Hangzhou, China, in January 2019. It contains 80 metro stations and 248 physical edges, and the aggregation time length is also 15 minutes.  
  
  > (T-SZ26 也提及 [T-126](https://www.mdpi.com/1424-8220/20/16/4574)) 为阿里天池数据大赛的公开数据集，记录了杭州市 2019 年 1 月 1 日—2019 年 1 月 15 日约 7 000 万条地 铁刷卡数据，采样时间间隔为 10 min
  >
  > (T-151) The datasets of the metro crowd flow type are collected from the Hangzhou metro system
  >
  > including inflow and outflow datasets. The HZME datasets contain 80 nodes and 168 edges (undirected network) with a sparse spatial structural relationship
  
- NYC Subway

  (T-ZS35) 纽约地铁数据有链接，乘客流

##### 北京其他

- [Beijing Traffic](https://github.com/deepkashiwa20/Urban_Concept_Drift)

  北京市 3126 个路段在 2022 年 5-7 月的 5 分钟粒度的数据

- [Q-Traffic](https://github.com/JingqingZ/BaiduTraffic)

  (T-ZS26 说 T-41)北京 2017 年 4-5 月一万多个路段每 15 分钟采样一次的百度地图数据；速度数据
  
- NE-BJ (T-133 说 [T-134](https://dl.acm.org/doi/full/10.1145/3532611))

  2023 论文提的新数据
  This dataset is a collection of public transport speed data taken from the navigation data of Tencent Map. It contains 500 segments, with each road segment data contains 6509 5-min time steps.

  (T-134) in weekdays of July 2020. The unit of speed is km/h. The dataset contains 500 road segments selected on the main roads in the northeast area of Beijing where a lot more traffic congestion always happens. The NE-BJ dataset is composed of traffic speed data of corresponding road segments seen as nodes in the graph

> (T-140 自建) BJF, BRF, BRF-L
>
> - are generated from a real-world GPS trajectory data, in which about 80 million GPS points of 30,000 taxis are recoded per day
> - BJF. Each node in BJF indicates a junction and 190 important junctions in Beijing are selected. The traffic data of each node is recorded in every 15 minutes and the time range is from November 2015 to October 2016. 
> - BRF. BRF has totally 300 nodes and each node indicates a road. The time interval is set to 20 minutes and the time period used of BRF is from November 2015 to May 2016. 
> - BRF-L. Similar to BRF, the traffic flow of each road is recoded in the dataset. BRF-L contains 1586 roads and the time interval is set to 10 minutes. The time period used of BRF-L is from November 2015 to December 2015.

北京：

(T-ZS1) it is unclear as to whether or not all of the Beijing-based datasets come from one unified dataset source  

(T-ZS1 stated:) usually cover the Ring Road area

- 用到的 (2015, 2k引用) [T-25](https://www.sciencedirect.com/science/article/pii/S0968090X15000935)、(2017, 100引用) [T-26](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-its.2016.0257)、(2016, 180引用) [T-27](https://ieeexplore.ieee.org/abstract/document/7795712)、(2018，近4k引用) [T-28 STGCN](https://arxiv.org/abs/1709.04875)
- T-25 contains the traffic volume, occupancy and speed data (2017, 近500引用) [T-29](https://epubs.siam.org/doi/abs/10.1137/1.9781611974973.87) 

> (T-134) NE-BJ 图示
>
> 

##### 其他

- [深圳市政府数据开放平台数据集](https://opendata.sz.gov.cn/)

  (T-ZS26) 深圳市部分地区的各种交通相关数据。例如，停车场数、卡口数据、车流量数据、营运车辆GPS数据、街道实时数据和路段属性数据等

- [上海出租车数据集](http://www.cse.ust.hk/scrg/) (好像挂了)

  (T-ZS26) 速度；由香港科技大学智慧城市研究组提出，包含 2007年 2月 20日在中国上海的 4 000辆出租车全天的 GPS 报告。其中，车辆行驶数据采样时间间隔为 1 min，数据包 含ID、时间、经纬度、速度等信息

- [UVDS](https://link.springer.com/chapter/10.1007/978-3-030-73280-6_6) 4 引用 useless 感觉

  (T-ZS26) 韩国城市地区数据集 UVDS 包含 104 个 VDS 传感 器收集的城市主要道路数据，具有交通流量、车辆类型、交 通速度和占用率等交通特征

- [Highways England](http://tris.highwaysengland.co.uk/detail/trafficflowdata)

  (T-ZS26) 英国高速公路数据集包含英国M、A级高速公路的 数据，采样时间间隔为 15 min，具有时间、流量、速度、占用 率等交通特征

  (T-ZS35) 有表格提及该数据集等

- [LargeST](https://proceedings.neurips.cc/paper_files/paper/2023/hash/ee57cd73a76bd927ffca3dda1dc3b9d4-Abstract-Datasets_and_Benchmarks.html) [src](https://github.com/liuxu77/LargeST  )

  (T-ZS30) This is a large-scale traffic forecasting dataset with 8,600 sensors, which consist of sensor ID, latitude, longitude, district, country, highway location, lane, type, direction. It’s divided into three subsets, including Greater Los Angeles (GLA), Greater Bay Area (GBA), and San Diego (SD). This dataset provides a vital foundation for large-scale traffic prediction research 交通速度；2024的刊才提出的 CCFA
  
- [韩国 Urban](http://topis.seoul.go.kr/)

  (T-ZS38) 记录了韩国首尔江南区（Ｕｒｂａｎ１）和麻浦区（Ｕｒｂａｎ２）两个区域的真实车流数据．Ｕｒｂａｎ１和Ｕｒｂａｎ２是首尔交通流量最大的两个地区，且均具有高度复杂的城市交通网络．数据集的采样周期为２０１８年４月１日至２０１８年４月３０日．数据集主要是基于ＧＰＳ采集的７万多辆出租车的轨迹数据，采样时间间隔为５ｍｉｎ．采集的交通流数据经过数据预处理得到的是各链路的平均速度
  
- EXPY-TKY

  (T-136 建立) 2021/10/1 - 12/31, 10min 时间区间，13248 时间步，1843 条道路连接，速度

  contains the traffic speed information and the corresponding traffic incident information in 10-minute interval for 1843 expressway road links in Tokyo over three months (2021/10∼2021/12).

- 厦门 [O-30](https://ieeexplore.ieee.org/abstract/document/8029849)

  (T-143 描述) traffic volume prediction on the Xiamen dataset

  which contains 5 months of data recorded by 95 traffic sensors ranging from August 1st, 2015 to December 31st, 2015 in Xiamen, China
  
- Traffic Flow Prediction T-152

  感觉是自建 The Traffic Flow Prediction dataset is collected every 15 min at 36 sensor locations along two major highways in the Northern Virginia/Washington, D.C., capital region

其他数据集：参见 [paperwithcode 网站：Traffic Prediction Task](https://paperswithcode.com/task/traffic-prediction)、[这篇综述](https://arxiv.org/pdf/2101.11174?trk=public_post_comment-text)、[TKDE2020综述](https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=6998&context=sis_research)、[这篇综述](https://kns.cnki.net/kcms2/article/abstract?v=7sQefmFxFK3uEKBquRla5qDHveK9oCCRpBWf04Zyi-hciTPIaXDHO5AckFT2OGZGmxYUV8QI8BcEApyz73mJ280tQxDTOIZYSnF6llnWzinghcTnd6z1lC2pEY218-lrd9AoSHndDepAUNkp_yiHGfr7Tsk5vANL&uniplatform=NZKPT&language=CHS)。



### 论文统计

#### paperwithcode

##### METR-LA

[src](https://paperswithcode.com/sota/traffic-prediction-on-metr-la)

按榜单顺序：

1.  [T-141](https://www.sciencedirect.com/science/article/pii/S0957417423007832)
2.  T-74
3.  [T-140](https://aaai.org/ojs/index.php/AAAI/article/view/5470)
4.  [T-139](https://dl.acm.org/doi/abs/10.1145/3583780.3615160)
5.  [T-138](https://arxiv.org/abs/2206.09112)
6.  [T-137](https://dl.acm.org/doi/abs/10.1145/3534678.3539396)
7.  [T-136](https://ojs.aaai.org/index.php/AAAI/article/view/25976)
8.  [T-135](https://arxiv.org/abs/2312.00516)
9.  [T-133](https://www.sciencedirect.com/science/article/pii/S0893608023007542) 
10.  [T-132](https://arxiv.org/abs/2202.03539)
11.  [T-131](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/itr2.12044)
12.  [T-130](https://arxiv.org/abs/1912.07390) 引用少，名不见，CCF NONE，2019，读着感觉很水，就是对 Graph Wave Net 的一些微调
13.  [T-129](https://ieeexplore.ieee.org/abstract/document/10260564)
14.  [T-128](https://proceedings.mlr.press/v139/yoo21b.html)
15.  T-64
16.  T-85 引用少且 T-ZS2 没有具体提及，认为不重要
17.  T-40
18.  T-28

##### NE-BJ

1.  T-133
2.  T-134
3.  [T-143](https://ojs.aaai.org/index.php/AAAI/article/view/5477)
4.  [T-142](https://dl.acm.org/doi/abs/10.1145/3394486.3403118)
5.  T-64
6.  T-110

##### PEMS-BAY

1. T-135
2. T-137
3. T-138
4. T-141
5. T-133
6. T-136
7. T-131
8. T-128
9. T-139
10. T-143
11. T-64
12. T-140
13. T-40
14. [T-144](https://ieeexplore.ieee.org/abstract/document/9565380) 几乎名不见经传，交通信号预测，时间：动态线性模型、空间：图热扩散，2021

##### PEMS07

1. T-135
2. T-139
3. [T-154](https://arxiv.org/abs/2408.07100)
4. T-154
5. [T-153](https://arxiv.org/abs/2401.15894)
6. [T-152](https://link.springer.com/article/10.1007/s00521-023-08831-3)
7. [T-151](https://arxiv.org/abs/2401.04148)
8. [T-150](https://www.sciencedirect.com/science/article/pii/S0031320323003710)
9. [T-148](https://ojs.aaai.org/index.php/AAAI/article/view/25556)
10. [T-147](https://ieeexplore.ieee.org/abstract/document/10184591)
11. T-132
12. [T-146](https://ojs.aaai.org/index.php/AAAI/article/view/16542) 
13. [T-145](https://dl.acm.org/doi/abs/10.1145/3447548.3467430)
14. T-87
15. T-28
16. T-81

#### 综述统计

(T-ZS2) 表11 对常用的数据集就三种指标 RMSE, MAE, MAPE 下最好的几篇论文 (60min 为预测周期)

(T-ZS2) 经典基线模型 DCRNN T-40, STGCN T-28, Graph WaveNet T-64

> (T-ZS1)  表格的评价尺度：
>
> - 参考([xx])、作者、年份、主要数据类型、主数据集、时间范围、粒度、次要数据集、输入序列长度、预测视野
>
> - 模型分类、预测值、时/空、模型子分类
>
>   > 时空分类的具体定义参见论文，指模型专门用来处理哪一部分，or both
>

> 数据集
>
> - PeMS 14/37
> - 北京点数据和轨迹数据，各 6/37
>
> 辅助数据
>
> - 天气 6/37 ；时间(time of day / day of week) 3/37  ；路网(road network) 3/37
>
> 数据跨度
>
> - 一个月 5/37；数个月 22/37；一年 6/37；超过一年 4/37
>
> 模型：
>
> - LSTM 18/37； 混合模型 21/37； 其他DNN(SAE, DBN) 6/37
>

(T-ZS2) 统计了一整页不同的数据集，和用这些数据集的论文 (表6)，这些数据通常数据清洗/预处理过。

该综述的表7, 8, 9, 10 分别统计了交通流量、交通速度、交通需求和其他问题的，开源代码及其年份、所用的代码框架(如 PyTorch)和开源链接

> #### 旧论文排行
>
> 列举部分 [paperwithcode](https://paperswithcode.com/task/traffic-prediction) 上的 SOTA 论文，概述如下：
>
> - METR-LA 数据集：
>
>   - [STGM](https://www.sciencedirect.com/science/article/pii/S0957417423007832) 注意力捕获时空依赖+GNN(空间处理)+改进CNN(时间处理) 2023 (SOTA)
>
>   - [Traffic Transformer](https://onlinelibrary.wiley.com/doi/abs/10.1111/tgis.12644) (Transformer) 2020
>
>   - [SLCNN](https://aaai.org/ojs/index.php/AAAI/article/view/5470/5326) (CNN+图) 2020
>
>   - [STAEformer](https://arxiv.org/pdf/2308.10425v5) (Transformer) 2023 (也是 PeMSD7 的 SOTA)
>
>   - [D2STGNN](https://arxiv.org/pdf/2206.09112v4)、[STEP](https://arxiv.org/pdf/2206.09113v2)、[MegaCRN](https://arxiv.org/pdf/2211.14701v4) (GNN) 2022
>
>     [DCGCN](https://arxiv.org/pdf/2306.07019v2) (GNN) 2023； [DCRNN](https://arxiv.org/pdf/1707.01926v3) (有向图扩散+CRNN) 2018
>
> - PeMSD8 数据集：
>
>   - [STWave](https://ieeexplore.ieee.org/abstract/document/10184591/) (图+注意力) 2023 (SOTA)
>
>   - [STD-MAE](https://arxiv.org/pdf/2312.00516v3) (两个 autoencoder 分别处理时空) 2023
>
>     PeMS-BAY、PeMS07、PeMSD04、PeMS04 四个数据集的 SOTA
>
>   - [PDFormrer](https://paperswithcode.com/paper/pdformer-propagation-delay-aware-dynamic-long) (Transformer) 2023
>
>   - [DDGCRN](https://paperswithcode.com/paper/a-decomposition-dynamic-graph-convolutional) GNN 2023
>
> - 其他数据集：
>
>   - SOTA PeMS08 [HTVGNN](https://arxiv.org/pdf/2401.10155v4) (注意力(时间)+改进GNN(空间)) 2024
>   - SOTA NE-BJ [RGDAN](https://www.sciencedirect.com/science/article/pii/S0893608023007542) (图扩散+注意力) 2024
>   - ……

## 未来挑战

> (T-ZS2) 一种开头表述方法 While GNNs achieve a better forecasting performance, they are not the panacea. Some existing challenges from the border topic of traffic forecasting remain unsolved in current graph-based studies. Based on these challenges, we discuss possible future directions as well as early attempts in these directions.  

> ### 现存挑战

#### 应用问题

##### 落地

(T-ZS2) Applications in Real-World ITS Systems  

如，红绿灯控制、地图导航、打车服务

> Last but not the least, most of the surveyed GNN-based studies are only based on the simulations with historical traffic data, without being validated or deployed in real-world ITS systems. However, there are a number of potential applications, especially for GNN-based models with the better forecasting performance  
>
> - To name a few potential cases, the GNN-based forecasting model can be used for traffic light control in signalized intersections, when each intersection is modeled as a node in the graph and the corresponding traffic flow forecasting result can be used to design the traffic light control strategy  
> - Another example is the application in map service and navigation applications, in which each road segment is modeled as a node in the graph and the corresponding traffic speed and travel time forecasting result can be used to calculate the estimated time of arrival  
> - A third example is the application in online ride-hailing service providers, e.g., Uber and Lyft, in which each region is modeled as a node and the corresponding ride-hailing demand forecasting can be used to design a more profitable vehicle dispatching and scheduling system  
>
> Inspired by these potential application scenarios, there are a lot of potential research opportunities for researchers from both the academia and the industry.  

##### 响应式方案

(类似：数据结合问题)

(T-ZS1) 响应式方案：如交通事故，天气变化融入到模型

Developing responsive algorithms and prediction schemes. 

Several of the recent works have attempted to address the problem of algorithm responsiveness in the face of unexpected traffic incidents such as accidents and weather changes. This is mainly done by using weather and accidents data as additional inputs to the traffic flow prediction models

- 如 T-55 使用 Dempster-Shafer theory 结合天气与交通流数据(参见上文)

  combined weather and traffic flow data using the Dempster-Shafer theory  

- 如 T-30 单纯结合天气 

  simply concatenated weather and traffic flow data  

- 如 T-51 简单相加

  performed simple addition  

评价：缺乏消融实验

lack ablation tests which can reveal the effectiveness of utilizing weather data  

有实验的：

- T-53 嵌入天气 + 消融实验

  incorporated weather data by embedding them into the traffic flow data in their test and performed a simple ablation test, which proved that the inclusion of weather data does improve prediction performance  

- T-52 事故+模拟实验

  performed a network stimulation test to understand the
  effect of sudden traffic accidents  

评价：探索不足，融合数据困难

As we can see, several authors have tested the impacts of weather and accidents in traffic flow prediction. Although several experiments have proven that the addition of these data can increase the prediction power of the models and increase their responsiveness to unexpected changes in traffic, this facet of traffic prediction has not been explored in great depth. This is due to the difficulty of incorporating these external data. Overcoming the challenge of data incorporation is the first step in utilizing weather and non-recurring incidents data in general to improve model responsiveness.  

#### 模型解释能力

(T-ZS1) Explanatory power, associations and causality  解释力、关联、因果关系

(T-ZS2) Model Interpretation

模型参数难以理解，NN 是黑盒模型

> (T-ZS2) The challenge of model interpretation is a point of criticism for all blackbox" machine learning or deep learning models, and traffic forecasting tasks are no exception [T-111](https://ieeexplore.ieee.org/abstract/document/8916985), T-38

参考上文具体技术，神经网络节的优缺点

如：

- T-40 观察图扩散过程和邻节点关联

  observed the traffic diffusion along the road network and the correlation between several adjacent traffic sensors

- T-39 可视化网络权重以预训练不同探测器找到关键路段

  visualized the network weights pertaining to different detector sites to find key road segments in the traffic network

- T-4 可视化注意力权重上下流，观察交通流的移动

  visualized the attention weights of upstream and downstream stations to observe how traffic flow moves across several traffic stations

(T-ZS1) 解读参数的意义

Performing explanatory analyses on neural networks may uncover useful traffic patterns 

黑盒模型，只解释了空间方面的一部分内容

(T-ZS1) While neural networks have proven to be a very effective prediction model, they are infamously known as black-box models; models that are difficult to dissect and explain. Although the aforementioned authors managed to explain the traffic phenomena to some degree, their observations are mostly limited to the spatial aspect; observing how the traffic at one site affects another and how traffic propagates across the road network. To the best of our knowledge, there  is no work that observes other aspects of the prediction, such as the dynamics of abrupt weather changes and accidents.  

对 CNN 的解读可视化有进展，但 GNN 尚未有

(T-ZS2) While there have been remarkable progresses for visualizing and explaining other deep neural network structures, e.g., CNNs, the development of post-processing techniques to explain the predictions made by GNNs is still in an early phase [O-21](https://arxiv.org/abs/1905.13686), [O-22](https://openaccess.thecvf.com/content_CVPR_2019/html/Pope_Explainability_Methods_for_Graph_Convolutional_Neural_Networks_CVPR_2019_paper.html), [O-23](https://proceedings.neurips.cc/paper_files/paper/2019/hash/d80b7040b773199015de6d3b4293c8ff-Abstract.html), and the application of these techniques to the traffic forecasting domain has not yet been addressed  

> 跟其他领域相比，该领域对可解释性的要求更高
>
> (T-ZS2) Compared with other similar forecasting problems in other domains, lack of model interpretation may be a more severe problem in the transportation domain, when complex data types and representations of heterogeneous traffic data make it more challenging to design an interpretable deep learning model, compared with other data formats, e.g., images and text. While some efforts have been made to incorporate the state space model to increase the model interpretation for traffic forecasting [O-24](https://arxiv.org/abs/2102.00397), , this problem has not fully solved, especially for GNN-based models  

> ### 未来挑战

#### 数据问题

##### 缺乏基准数据集

Lack of a benchmark dataset / Centralized Data Repository  

(T-ZS1) 难以对比，且同一数据集也有多个子集/不同与处理方式

(T-ZS1) The availability of a wide range of traffic data supports traffic prediction. However, this availability also poses a challenge to comparative work. Due to the fact that different works use different datasets, it is very hard to assess the relative performance of different state-of-the-art models. The Caltrans data is the closest to a benchmark dataset, as it is used by 14 out of 37 literatures we have covered. However, different works use different subsets of the Caltrans from different periods of time and from different traffic detector sites  

> (T-ZS2 再表述) It is known that different works use different datasets and it is very hard to assess the relative performance of different state-of-the-art models. Even for those studies using the same dataset, different subsets may be used. Different preprocessing techniques, e.g., the missing data imputation method, and different evaluation settings, e.g., the training/validation/test subset split ratio, also cause incomparable results  
>
> (T-ZS2) With more and more GNN-based models being proposed, it becomes even more difficult to compare different models and validate the effectiveness of new traffic forecasting methods without a considerable effort, when a standardized benchmark dataset and consistent experimental settings have not been established yet  

但选择大的子集存在训练代价困难，依赖复杂；选择小的子集难以拟合真实数据，在时空上分别讨论

(T-ZS1) Choosing a subset of data within a larger dataset also poses a challenge. As temporal and spatial correlation affects traffic greatly, the period of the data and the traffic detector locations become important considerations. For instance, when using data that covers a period of less than a year, there is a risk of not capturing the seasonal effects on traffic, and when using only weekdays data, the models cannot learn weekend traffic well. For the spatial aspect, the choice of roads or highways can greatly affect the traffic flow as metropolitan roads have significantly busier traffic compared to rural areas, and long interstate highways tend to cover both rural and metropolitan areas. Models that are trained on a certain traffic condition may not perform well when used to predict traffic on significantly different traffic

> 统一数据集的意义：
>
> (T-ZS2) A centralized data repository for GNN-based traffic forecasting resources would facilitate objective comparison of the performance of different models and be an invaluable contribution to the field  

理想的基准数据集：城乡结合、工作日周末结合、一天各时段、至少一年

(T-ZS1) For deep neural network models to perform well on real applications, the dataset needs to mimic real data. Therefore, it is important for benchmark datasets to cover enough time frame and locations so that the models can generalize well to any traffic situations. To overcome this challenge, the following criteria are important:

- The data covers both urban and rural areas.
- The data covers both weekdays and weekends.
- The data covers all hours of the day.
- The temporal range is at least one year

> 理想数据：时空覆盖广、增加时间、增加天气和事故
>
> (T-ZS1) A benchmark data that covers a specific area within a specific period, complete with relevant secondary data will greatly benefit the traffic flow field. We recommend the following sequence of actions:
>
> 1) Establish a benchmark dataset that has sufficient spatial and temporal coverage based on the requirements mentioned in the previous challenge.
> 2) Add day of the week and time of day data by concatenating them with the traffic reading data.
> 3) Add geographical-related data, such as weather and accidents data to every traffic data reading. For instance, one reading at a particular time stamp and location will have both the traffic flow, current weather and accident type, if any accident occurs at the location.  
>
> 解决数据质量问题，增加图数据：
>
> (T-ZS2) This future direction is proposed for the challenge of heterogeneous data as well as the data quality problem. Another unique feature of this repository could be the inclusion of graph-related data, which have not be provided directly in previous traffic forecasting studies.  
>
> 一些要求：统一数据格式、版本管理、开源代码、排名结果、长于一年。
>
> (T-ZS2) Some criteria for building such data repositories, e.g. a unified data format, tracking of dataset versions, public code and ranked results, and sufficient record lengths (longer than a year ideally) T-ZS15
>
> 在 GNN 里，因为图被编码的格式多样化，所以具有难度
>
> (T-ZS2) Compiling a centralized and standardized data repository is particularly challenging for GNN-based models where natural graphs are collected and stored in a variety of data formats (e.g. Esri Shapefile and OSM XML used by Openstreetmap are used for digital maps in the GIS community) and various different similarity graphs can be constructed from the same traffic data in different models  

在 paperwithcode 有基准对多个任务，有竞赛系列(打不开了)

> (T-ZS2) Some previous attempts in this direction have been made in the machine learning community, e.g. setting benchmarks for several traffic prediction tasks in [Papers With Code](https://paperswithcode.com/task/traffic-prediction), and in data science competitions, e.g., the Traffic4cast [competition series](https://www.iarai.ac.at/traffic4cast/). However, the realization of a centralized data repository remains an open challenge.  

目前最接近的是 PeMS，但只包含道路级数据

> (T-ZS2) The most close one is the PeMS dataset, but it covers the road-level case only and more efforts are still needed, especially for the remaining cases  

##### 数据结合难

(类似：响应方案)

(T-ZS1) Difficulty of incorporating external information with traffic data

(T-ZS2) / Heterogeneous Data

> 结合数据的困难：难以包含外部信息：天气、车祸、事件、星期、时刻、媒体信息
>
> (T-ZS1) one model that uses the Caltrans data covering a long highway will need to match the time stamp, the latitude, and the longitude of each reading in order to find the appropriate weather and accidents data  
>
> (T-ZS2) Traffic prediction problems involve both spatiotemporal data and external factors, e.g., weather and calendar information.  
>
> - 时间容易其他难：理由是需要和具体时空对应
>
>   (T-ZS1) While the inclusion of day of the week and time of the day is relatively simple, data that are bound to a specific geographical coordinate or a geographical area is difficult to incorporate with traffic data. This is because the process requires the coordinates of detection points (in the case of point data) or trajectory points (in the case of trajectory data) to be mapped to the secondary data
>
> 成本变大：
>
> (T-ZS1) added time complexity of aggregating the different data together , which is undesirable, especially in an already time-consuming hybrid deep neural network structure  



##### 不同路段的预测

(T-ZS1) Freeway, arterial and network traffic predictions. 

The authors mentioned several related sub-challenges: the complexity of urban arterial traffic prediction, network-level traffic prediction and the incorporation of network dynamics on traffic prediction  

数据的缺乏，采集数据成本过大，只在 highways 有

轨迹数据可以代替网络预测(network-wide prediction)，覆盖 arterial 和 highways

While the prediction of traffic in urban arterial roads and network-level traffic prediction are dissimilar challenges, the cause is the same: the lack of traffic detectors on urban arterial roads. This is because installing traffic detectors is costly and thus, is often done only on highways. However, the increasing amount of trajectory data has resulted in an alternative solution for network-wide prediction, as car trajectories cover both arterial and highways alike.  

使用了轨迹数据的论文：T-29, T-1, T-51, T-30, T-37，具体参见上文

动态网络的预测(路网数据)使用图论方法：

The third challenge, incorporation of network dynamics on traffic prediction, is caused by traffic flow readings not inherently containing road network data. Therefore, this operation has to be done manually through data modeling. The most popular method to capture network data is to use graph-based methods  

使用了图论的论文：T-4 T-28 T-40 T-39

忽略了 T-ZS1 对 CNN, RNN 获取时空依赖这一段的描述，忽略了对 GNN 一段的描述

##### 数据过少

时空跨度，样本量少，导致跟真实有偏差：但增加数据成本大，难以采集

(T-ZS2) First, there is significant bias introduced by the small amount of data considered in the existing GNN-based studies which, in most cases, spans less than one year. The proposed solutions are therefore not necessarily applicable to different time periods or different places. If longer traffic data are to be used in GNNs, the corresponding change of the underlying traffic infrastructures should be recorded and updated, which increases both the expense and difficulty of the associated data collection process in practice.  

GNN 计算规模小，难以处理真实世界量级

(T-ZS2) A second challenge is the computation scalability of GNNs. To avoid the huge computation requirements of the large-scale real-world traffic network graphs, only a subset of the nodes and edges are typically considered. For example, most studies only use a subset of the PeMS dataset when considering the road traffic flow or speed problems. Their results can therefore only be applied to the selected subsets  

解决办法：图分块，并行计算，但提升很有限

(T-ZS2) Graph partitioning and parallel computing infrastructures have been proposed for solving this problem. The traffic speed and flow of the entire PeMS dataset with 11,160 traffic sensor locations are predicted simultaneously in [T-108](https://journals.sagepub.com/doi/abs/10.1177/0361198120930010), using a graph-partitioning method that decomposes a large highway network into smaller networks and trains a single DCRNN model on a cluster with graphics processing units (GPUs). However, increased modeling power can only improve the state-of-the-art results with narrow performance margins, compared to statistical and machine learning models with less complex structures and computational requirements  

##### 数据质量

数据缺失、数据稀疏、数据噪音

(T-ZS2) Data quality concerns present an additional challenge with problems such as missing data, sparse data and noise potentially compromising forecasting results.   

相邻的点不一定是最有影响的

(T-ZS2) geographically close nodes may not be the most influential, both for CNN-based and GNN-based approaches.  

数据可能是过时的或不准确的：真实情况的动态性，故静态图不足够解决

(T-ZS2) the underlying graph information may not be correct or up to date. For example, the road topology data of OpenStreetMap, an online map services, are collected in a crowd-sourced approach, which may be inaccurate or lagged behind the real road network. The spatial dependency relationship extracted by GNNs with these inaccurate data may decrease the forecasting accuracy  

(T-ZS2) A challenge is presented by changes in the transportation networks and infrastructure, which are essential to build the graphs in GNNs. The realworld network graphs change when road segments or bus lines are added or removed. Points-of-interest in a city also change when new facilities are built. Static graph formulations are not enough for handling these situations. 
Some efforts have been made to solve this problem with promising results  

- 动态拉普拉斯矩阵评估器 [T-109](https://ojs.aaai.org/index.php/AAAI/article/view/3877)

  a dynamic Laplacian matrix estimator is proposed to find the change of Laplacian matrix, according to changes in spatial dependencies hidden in the traffic data  

- 数据自适应图生成器 DAGG [T-110](https://proceedings.neurips.cc/paper/2020/hash/ce1aad92b939420fc17005e5461e6f48-Abstract.html?ref=https://githubhelp.com)

  a Data Adaptive Graph Generation (DAGG) module is proposed to infer the inter-dependencies between different traffic series automatically, without using pre-defined graphs based on spatial connections 

> 多数模型只考虑处理过的高质量数据集
>
> (T-ZS2) Most of the surveyed models are only evaluated with processed highquality datasets  
>
> 一些模型考虑了数据质量问题：
>
> (T-ZS2) A few studies do, however, take data quality related problems into consideration, e.g.,   
>
> - [T-99](https://dl.acm.org/doi/abs/10.1145/3397536.3422257) using the Kalman filter to deal with the sensor data bias and noise 
> - [T-100](https://ieeexplore.ieee.org/abstract/document/9005965) infilling missing data with moving average filters  
> - T-99 [T-101](https://ieeexplore.ieee.org/abstract/document/9201971) linear interpolation 
>
> 且 GNN 中可能缺失数据更明显：GCN 可以填充缺失数据间隙，OD 问题
>
> (T-ZS2) Missing data problem could be more common in GNNs, with the potential missing phenomena happening with historical traffic data or underlying graph information, e.g., GCNs are proposed to fill data gaps in missing OD flow problems [T-102](https://ieeexplore.ieee.org/abstract/document/9130943)

交通异常(如拥堵)，影响显著，社会事件和节假日也是，但数据太少难以训练

> (T-ZS2) Traffic anomalies (e.g., congestion) are an important external factor that may affect prediction accuracy and it has been proven that under congested traffic conditions a deep neural network may not perform as well as under normal traffic conditions [T-103](https://ieeexplore.ieee.org/abstract/document/9092975)
> However, it remains a challenge to collect enough anomaly data to train deep learning models (including GNNs) in both normal and anomalous situations. The same concern applies for social events, public holidays, etc  
>
> 还有数据的隐私权利应该得到保证，参见论文
>
> However, it remains a challenge to collect enough anomaly data to train deep learning models (including GNNs) in both normal and anomalous situations. The same concern applies for social events, public holidays, etc  



#### 在线学习

(T-ZS1) Online learning.

在线学习。持续更新应对 concept drift 的存在。现状：没有研究探索在线学习：但训练开销大，模型复杂难以更新。需要考虑更新频率和数据数目、更新所用时间。

> Concept Drift（概念漂移）指的是数据分布或数据生成过程发生变化的现象。训练与真实不一致就会概念漂移

In this setting where new data is incrementally added, traffic trends will shift over time. This is applicable even for the same traffic detector site. This idea is called concept drift and it causes the relationship between the input and output data to change over time, rendering models that are trained on past data to degrade in performance on present and future data  

> One way to mitigate this problem is to incrementally update the prediction model with new data in real-time, in a process often called online learning. However, to the best of our knowledge, there is no work that explores online learning in the traffic prediction domain. This can be attributed to the time complexity of training hybrid deep neural network model and the lack of attention to the concept drift problem. Online learning is a promising subtopic to explore in the field of traffic prediction as this will ensure that complex deep neural network models are always up-to-date. Experiments that seek to identify the viability of online training will need to take into account the following factors:
>
> - The frequency of which the deep neural network models need to be retrained. Practitioners need to ask the question “How often do we need to update our prediction model to ensure that it is always upto-date?”
>
> - The number of data points required for the update, which is affected by the frequency and has to reflect real life scenario. Practitioners need to ask the questions “How much data can we acquire during a certain period?” and “How long will it take to collect and preprocess the data to fit it into the prediction models?”  
>
> - The time required for the model to be re-trained using the specified number of data points and whether or not it is suitable for real life scenario. Practitioners need to ask the question “With the available amount of data, will the training of the model be fast enough such that daily operations are not hindered?”  



#### 其他领域任务

(T-ZS1) Exploring other traffic prediction tasks

其他领域问题。子问题/其他问题可能会启发该问题。如交通拥挤分析。

Currently, the Intelligent Transportation Systems (ITS) field greatly focuses on traffic flow prediction, neglecting the other traffic prediction tasks. Exploring these subproblems may bring new insights that are able to help the main traffic prediction task. As we mentioned before, deep neural network models are black-box models. Models that are trained on the traffic flow prediction may not be able to explain the intricacies of traffic patterns. Additionally, each of the subproblems is interesting by itself as its results can be directly used by drivers and traffic management bureau alike to make educated decisions. One example of these prediction tasks is traffic congestion analysis. Knowing how traffic congestion moves throughout the network can assist in the traffic prediction task  

> #### 多任务
>
> 流量和速度可以一定程度一起用，但其他领域不太行
>
> (T-ZS2) or the public service operation of ITSs, a multi-task framework is necessary to incorporate all the traffic information and predict the demand of multiple transportation modes simultaneously. For example, knowledge adaption is proposed to adapt the relevant knowledge from an information-intensive source to information-sparse sources for demand prediction [T-104](https://dl.acm.org/doi/abs/10.1145/3340531.3411965) 
> Related challenges lie in data format incompatibilities as well as the inherent differences in spatial or temporal patterns. While some of the surveyed models can be used for multiple tasks, e.g., traffic flow and traffic speed prediction on the same road segment, most can only be trained for a single task at one time  
>
> 有几个多任务完成了的论文例子
>
> (T-ZS2) Multi-task forecasting is a bigger challenge in graph-based modeling because different tasks may use different graph structures, e.g., road-level and stationlevel problems use different graphs and thus are difficult to be solved with a single GNN model. Some efforts that have been made in GNN-based models for multi-task prediction include taxi departure flow and arrival flow [T-105](https://www.mdpi.com/1424-8220/20/13/3776), region-flow and transition-flow [T-106](https://link.springer.com/chapter/10.1007/978-3-030-59410-7_30), crowd flows, and OD of the flows [T-107](https://dl.acm.org/doi/abs/10.1145/3340531.3412054). However, most of the existing attempts are based on the same graph with multiple outputs generated by feed forward layers. Nonetheless, GNN-based multi-task prediction for different types of traffic forecasting problems is a research direction requiring significant further development, especially those requiring multiple graph structures  

#### 缺乏最新试验评估

(T-ZS1) Lack of up-to-date experimental evaluation  

> there is a lack of up-to-date and comprehensive experimental evaluation, making it difficult to assess how promising these specific ideas are  

缺乏最新试验评估 (最大的问题)。库简化了实现，每个论文实现了不同的想法，但没有综合的整理。缺乏基准数据集，代码有效性(可复现性)。

- (我个人) 就算用同一个数据集，其预测长度不一样，参数不一样，指标不一样，也会有不一样的结果

> Experimental evaluation in traffic flow prediction is complex due to two factors. The first is the lack of benchmark dataset, a problem that we have discussed above. The second is the lack of code availability. One might attempt to recreate the model from the author’s description. However, while the deep neural network aspect can be recreated relatively easy, novel components, such as graph diffusion, are difficult to build in a way that is faithful to the source material  
>
> This lack of experimental evaluation is perhaps the largest challenge that the traffic flow prediction community faces. Addressing this problem will enable practitioners to easily identify the effectiveness of new ideas in improving prediction performance, model efficiency, and the overall applicability of deep neural network models in real-time traffic prediction applications  
>
> 意义：
>
> We believe that the future of the traffic flow prediction field lies on determining a more standardized approach that ensures that the significance of every novel idea can be identified  
>
> 建议做法：开源
>
> to provide more transparency in this research field. Implementation details and publicly accessible codes will be necessary  

基准实验评估需要考虑：新想法的影响、CNN/RNN 类型的影响、应用性和重训练时间、外部数据如天气的作用(消融实验)

> A benchmark experimental evaluation needs to take into account the following insights:  
>
> - The impact of each model’s novel ideas to the prediction power, particularly for models that use a similar network structure.
> - The impact of using a certain neural network type such as CNN and RNN.
> - The viability in real life applications with respect to the retraining time. That is, online learning using a realistically sized batch of data, e.g. data from one week.
> - The impact of using external information such as weather and accidents data. This can be observed by performing an ablation test on models that utilize these external information  

#### 其他技术

T-ZS2 ; 参考具体技术，包含迁移学习、元学习、数据增强、GAN、Auto ML、贝叶斯网络。

#### 应用新技术

(T-ZS1) Applying Emerging Techniques   

## 写作技巧

### 组织结构

#### T-ZS1

1. INTRODUCTION

   一段交通拥挤现状

   一段交通预测的应用、定义、特点

   一长段技术简述和论文目的

   一无序列表表示论文要点

   一段论文行文结构

   三段比较其他综述（一段一篇综述）

   一段描述实现框架（PyTorch 等）

2. BACKGROUND  

   一段概括本章内容

   三段交通预测定义（公式隔开了段落）

   三段介绍 ARIMA（初始，变式，优缺）

   一段介绍 ML 及其与统计模型相比的优缺

   一段介绍 NN 及其与 ML 相比的优缺

   一段介绍 NN, ML 在交通的应用

   三段介绍 DNN（兴起条件，分类简述，优缺）

   一段总结

3. DEEP NEURAL NETWORK  

   一段概括本章内容

   1. Convolutional Neural Network

      一段简述

      一段组成定义，含图

      一段介绍应用建模思路

      一段介绍优点特点

      一段介绍应用方法

   2. Recurrent Neural Network and Long Short-Term Memory

      一段 RNN 简述

      一段 RNN 组成定义，含图

      一段缺点和 LSTM 引入

      一段 LSTM 组成定义，含图

      一段 RNN 优缺和其他领域应用

      一段应用

   3. Feedforward Neural Network

      一段定义

      一段优缺

      一段应用

   一段总结本章内容

4. DEEP NEURAL NETWORK FOR TRAFFIC FLOW PREDICTION

   一段研究范围和本章介绍 

   1. Traffic Flow Prediction – Data

      两个小表格分别列表表示主数据、辅助数据集的占比、典例、类型

      两个大表格按数据分类了论文，表头有：引用、作者、年份、主数据类型、主数据集、时间范围、数据粒度、辅数据集、输入序列长度、预测视野

      (表格里的论文我抽查了几篇，发现都在正文有出现过)

      一段介绍这两大表格及其举例和特例介绍

      一段介绍主数据集及其代表（表项一）

      一段介绍北京数据集（表项二）

      一段介绍轨迹数据集（表项三）和对小表格一介绍

      一段介绍辅助数据集和对小表格二介绍

      一段介绍辅助的低使用率

      一段介绍时间辅助数据

      两段介绍数据时间范围及其两个大表格例子

      一段介绍数据集多样性的意义

      四段介绍数据粒度

      四段介绍输入序列长度和预测视野

   2. Traffic Flow Prediction – Model

      三段介绍大表格及其举例

      大表格：按模型类型表头再分类，其他表头为引用、年份、问题类型、是否使用时/空、主数据类型、模型子类

      1. RNN

         两段总结 LSTM 常见性及其原因和举例

         一段介绍基础 RNN 的几篇论文，按历史顺序一篇一句话

         一段介绍混合模型的使用简介和原因

         一无序列表表示三种使用方法

         三段分别介绍三种方法的论文，每篇论文一句话，疑似时间顺序

         一段介绍 encoder-decoder RNN，定义和一句话列举所用论文及其效果(SOTA)

         一段介绍其他 RNN 用法，一句话一篇论文

         一段介绍 RNN 与多粒度方法及一句话列举多个论文

      2. CNN

         一段简述

         一段介绍 CNN 与两种数据类型及其例外论文

         两段介绍点数据如何用到 CNN，两个无序列表介绍优缺点

         一段介绍两种点数据应用方法，分别介绍和列举相关论文

         一段介绍轨迹数据应用，两个无序列表介绍优缺点

         一段介绍相关论文并总结

         一段介绍其他用法如获取空间数据及其论文例子

      3. Feedforward Neural Networks  

         一段介绍三种用法

         三段分别介绍三种用法，前两段先介绍后枚举，第三段后一句话介绍

      4. ther Deep Neural Networks  

         一段介绍 SAE, DBN 并枚举论文和占比

         一段介绍兴起时间和原因推断和衰落原因

      5. Other Techniques

         一段承上启下

         一段介绍 GNN 及其优势

         一段介绍 GNN 的各论文，一篇论文一两句话

   3. Discussion  

      一段简介

      1. Complex Versus Simple Models

         一段介绍现状

         一段比较优缺并提供论文例子

      2. Benchmark Model Structures

         一段介绍 encoder-decoder RNN 特点

         一段介绍上述+GNN 的结合，枚举论文例子

         一段介绍注意力机制和枚举论文

         一段总结

5. CHALLENGES AND FUTURE DIRECTIONS  

   一段简介和表明继承

   1. Existing Challenges

      第一个挑战一段介绍，两段论文举例介绍，一段总结

      第二个挑战一段介绍，一段举例和枚举论文

      第三个挑战一段介绍和枚举论文

      第四个挑战一段介绍并引用前文

      第五个挑战一段介绍和一段论文例子介绍再接一段介绍

   2. Future Challenges

      一段简介

      第一个挑战三段介绍，现状和论文举例，两段建议和无需列表描述

      第二个挑战一段介绍，一个有序列表建议

      第三个挑战一段介绍，一段建议，两段无序列表具体陈述

      第四个挑战引用前文和一段介绍

      第五个挑战一段介绍

      第六个挑战一段介绍，两段原因，一个无序列表建议

      第七个挑战一段总介绍，两段分陈述和论文例子，一段总结

6. CONCLUSION

   一段论文内容总结

   一段建议

   一段展望

ABSTRACT, ACKNOWLEDGMENTS, REFERNCES 略

#### T-ZS2

1. Introduction

   一段交通系统的介绍，交通预测的定义

   一段交通预测的特点和技术历史

   一段 RNN 的介绍

   一段综述枚举，本文内容介绍

   一段本文受众介绍

   一个有序列表描述文章内容

   一段话描述论文章节

2. Related Research Surveys

   一段简介

   四段综述介绍（交通大类、交通预测、DL 相关、其他）

   一段本文优势内容

3. Problems

   一段简介

   一段定义数据粒度分类的介绍

   一段话介绍所研究论文，提供表格按问题细分类别

   一段描述问题的时空特征及其对应模型

   一段描述 CNN 等思路解决空间特征的办法和缺点

   一段描述 GNN 解决空间特征的优势

   1. Traffic Flow

      一段介绍定义和意义

      一段描述按数据粒度的三种分类

      三段分别描述三种分类下的细分类和定义

      一段介绍按有向无向图的分类

      一段描述数据来源和特点

   2. Traffic Speed

      一段介绍定义和意义

      一段介绍按数据粒度的两种分类及其细分

      一段介绍两类的区别

   3. Traffic Demand

      一段意义

      一段定义和细分

   4. Other Problems

      一段引出下文

      一段介绍交通异常

      一小段介绍停车

      三段介绍车辆排放、铁路延迟、道路占用，分别指出论文

4. Graphs and Graph Neural Networks

   一段介绍本章内容和其他更广的参考论文

   1. Traffic Graphs

      1. Graph Construction

         三段介绍图的定义、点权假设、时间

         两段定义段交通图、基于图的交通预测，中间一段过渡

         一段介绍单步多步预测，提供图

         一段按数据真实性分类图

         三段按数据粒度分类图，提供图和指出相关论文

         一段介绍按图的类型、节点和边的意义分类的论文的竖表格

      2. Adjacency Matrix Construction

         一段介绍分类法的出处论文和分类

         四段介绍四种类型的矩阵，子类，两段介绍了相关论文的建模例子

         一段介绍按邻接矩阵的类型、元素定义分类的论文的竖表格

   2. Graph Neural Networks

      一段对比 CNN，分类 GNN 为四类

      一段提供 GCN 相关的数学定义，提供符号表格

      一段介绍基于频谱的 GNNs 的发展和相关论文

      两段介绍 GCN 的相关数学定义，有公式断开

      一段介绍基于空间的的 GNNs 的发展和相关论文

      五段介绍这些经典方法的数学定义和思想，提供图

      一段介绍按时间是 RNN 还是 CNN 的分类大枚举论文代替表格

      一段介绍给予注意力和 FNN 和其他的分类大枚举论文

      一段介绍 RNN, CNN 的对比优缺和时空联系解决的相关论文

      一段对卷积 GNN 进行再分类，有图介绍发展时间

      一个有序列表介绍了设计模型的步骤

      三段分别介绍了三种经典模型的数学定义、相关论文

5. Open Data and Source Codes

   一段介绍本章内容

   1. Open data

      一段介绍分类

      十段分别介绍不同类型的数据，有一些有举例论文

      总结数据的应用，提供表格列举了使用不同数据集的各论文

      1. Traffic Sensor Data

         一段启下

         三段分别介绍不同数据集，其中一段有无序列表

      2. Taxi Data

         一段启下

         六段分别介绍不同数据集

      3. Ride-hailing Data

         一段启下

         两段分别介绍不同数据集，其中一段有无序列表

      4. Bike Data

         一段启下

         三段分别介绍不同数据集

      5. Subway Data

         一段启下

         两段分别介绍不同数据集

   2. Open Source Codes

      一段介绍 python 框架

      一段提供多个表格列举使用这些框架的论文，年份，及其研究问题，按研究问题大类划分不同的表格

   3. State-of-the-art Performance

      一段陈述难以选出最优的理由

      一段给出评价指标的定义，一个表格给出不同数据集的经典和最高论文的不同指标得分

      一段总结

6. Challenges and Future Directions

   一段简介

   1. Challenges

      1. Heterogeneous Data

         四段，提供了相关论文

      2. Multi-task Performance  

         两段，提供了相关论文

      3. Practical Implementation

         四段，提供了相关论文

      4. Model Interpretation

         两段，提供了相关论文

   2. Future Directions

      1. Centralized Data Repository

         四段，提供了相关论文

      2. Traffic Graph Design

         一段，提供了相关论文

      3. Combination with Other Techniques

         一段总述

         六段讲述了六种技术，提供了相关论文

      4. Applications in Real-World ITS Systems

         一段

7. Conclusion

   一段概括了文章内容

Abstract, References 略

#### 建议

论文分类依据：

- 时间特征处理技术
- 空间特征处理技术
- 时空依赖处理技术
- 数据预处理的技术
- 其它补充信息技术
- 缩写年份基本信息
- 是否使用 encoder-decoder

论文数据依据：

- 所用数据集
- 所用额外数据集
- [训练参数 (输入长度等)]

数据表格依据：

- 问题类型 (速度/流量等)
- 时间跨度
- 开山论文
- 地理位置
- 时间间隔
- 节点数量
- 时间数量

### 通用用语

根据阅读归纳：

论文作者人名：一个人就人名(姓)，两个人就 and，三个人就 et al.

中文也名在前，且名两个字只有第一个字大写首字母

[i.e. e.g. et al. 的读法和全称](https://www.bilibili.com/video/BV14W421d74d/)

续表叫

- continued (T-ZS35)
- Contd. (T-ZS1)
- continued from previous page (T-ZS2)

w/o (消融实验里) with/without

实验数据：Bold values denote the best results

### 专用术语

#### 关键词

(T-ZS1) Deep neural network, deep learning, traffic flow prediction, traffic speed prediction, road network  

(T-ZS2) Traffic Forecasting, Graph Neural Networks, Graph Convolution Network, Graph Attention Network, Deep Learning  
