> 诸如 T-ZS1 的标号参见 Zotero 目录(如无请联系我获取)

## 背景介绍

### 交通拥堵

- 面临的主要问题

  (T-ZS1) Traffic congestion is a major problem faced by metropolitan cities -> Most congestion mitigation measures are costly, difficult to implement, or both.   
  
  其解决：交通预测
  
  Educated traffic decision made through accurate prediction is a far cheaper and easier to implement alternative for reducing road congestion  
  
  > Traffic flow prediction is one of the easiest and cheapest measures to address traffic congestion  

### 交通数据等

- 交通拥挤的代价

  (T-ZS1) In 2015, it is estimated that the avoidable cost of traffic congestion for Australian capital cities is approximately \$16.5 billion, up from the 2010 estimate of \$12.8 billion. Furthermore, this value is estimated to increase to about $30 billion by 2030

  > [参考 Cosgove D. Traffic and congestion cost trends for Australian capital cities[J]. Canberra: Department of Infrastructure and Regional Development, Bureau of Infrastructure, Transport and Regional Economics, 2015.](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Cosgove%2C+Traffic+and+congestion+cost+trends+for+Australian+capital+cities&btnG=#d=gs_cit&t=1721488944765&u=%2Fscholar%3Fq%3Dinfo%3ACPeX2qr_RW8J%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Dzh-CN)

- 交通监管政策

  (T-ZS1) Singapore implemented regulations on the number of vehicles on roads -> which is infeasible for countries with poor public transportation systems

  > [参考 “Singapore to freeze car numbers,” https://www.bbc.
  > com/news/business-41730778, accessed: 20 November
  > 2018](https://www.bbc.
  > com/news/business-41730778)

- 修路成本

  (T-ZS1) the estimated per mile cost of a standard one lane road in New Jersey, USA is $220,490 -> Constructing new roads to ease congestion is also difficult due to the extremely high cost  
  
  > [参考 J. Carnegie and A. M. Voorhees, “The cost of roadway
  > construction, operations and maintenance in new jersey,” pp. 557–566, 2016.  ](https://trid.trb.org/View/1408290)

### 前置条件

- 传感器的普及 -> 大数据获取

  (T-ZS1) With the advancements and widespread adoption of traffic sensors, access to large traffic databases is now available.  -> This has led to the development of traffic prediction as a research field. 
  
  > With the widespread installation of traffic loop detectors, traffic data will continuously grow    
  
- 库 

  (T-ZS1) Due to the availability of deep neural network libraries such as Keras, PyTorch , and TensorFlow, development of complex neural network models has become much easier  
  
  > The introduction of deep neural network libraries such as Keras, PyTorch and TensorFlow has simplified the implementation of complex hybrid deep neural network models. As we have observed, this has resulted in numerous unique hybrid structures, each focusing on specific ideas to improve prediction performance  

### 问题定义

#### 交通预测

##### 描述

- 交通预测

  (T-ZS1) 

  描述：

  Future traffic prediction involves creating a prediction model from historical traffic data to predict the short-term future traffic state ranging from 5 to 60 minutes into the future
  
  特点：
  
  > 交通预测与其他时序分析的不同在于：
  >
  > - 一个地点可能影响另一个地点
  > - 存在全局外部因素如天气、节假日
  
  Traffic prediction is different from conventional time-series analysis in that traffic prediction is subject to spatial as well as many other external factors.  ->  the prediction of traffic at one site depends on the traffic at other sites and all of the sites are affected by external factors such as weather and holidays.  
  
  定义：使用可学习的函数，使用历史交通数据输入，预测未来交通
  
  Traffic prediction concerns the usage of a learnable function that takes as input the historical traffic data from several previous time-steps in order to predict the traffic in the future.  
  
  > 近义句 Traffic prediction is a task of training an arbitrary function to predict future traffic given past traffic data  
  
  > 还有其他，参考下文
  
  $$
  \hat y_{t+T'}=f([X_{t-T+1},X_{t-T},\cdots,X_t])
  $$
  
  目标：找到模型参数，最小化误差：
  
  The objective is to find the model parameters which minimize the error between the predicted traffic and the observed traffic:  
  $$
  \theta^*=\arg\min_{\theta^*}L(y_{t+T'},\hat y_{t+T'};\theta^*)
  $$
  
  > 其中 $y_t$ 是时间 $t$ 的观察值，$\hat y_t$ 是预测值，$T$ 是输入序列长度，$T'$ 是预测范围，$L$ 是损失函数，$f$ 是任意函数，$\theta^*$ 是最优参数。
  >
  > - The observed traffic at time $t$
  > - The predicted traffic at time $t$
  > - Input sequence length, i.e., how many time steps of past traffic data are used as the input 
  > - Prediction horizon, i.e., how many time steps in the future the prediction is for 
  > - An arbitrary function that calculates the traffic prediction based on the input data  
  > - Loss function, which is the function that calculates the quality of the prediction
  > - The optimal set of parameters for the function $f$

##### 类型

(T-ZS1)

- 交通流量 某地某段时间车辆总数

  Traffic flow is denoted as the total number of vehicles detected in a target detection site during a certain time period.   

- 交通速度 某地某段时间各车辆平均速度

  Traffic speed is denoted as the average traveling speed of vehicles detected in a target detection site during a certain time period  

T-4 交通状况 traffic condition, which consists of four categories: fluency, slow, congestion and extreme congestion  

T-28 [T-30](https://www.researchgate.net/profile/Leye-Wang/publication/322886199_Crowd_Flow_Prediction_by_Deep_Spatio-Temporal_Transfer_Learning/links/5aa9bd6b0f7e9b88266f6529/Crowd-Flow-Prediction-by-Deep-Spatio-Temporal-Transfer-Learning.pdf) 人流量 crowd flow instead of traffic flow: Crowd flow measurements are the same as traffic flow, but they are designed for general human mobility instead of automobile mobility  

- [T-31](https://dl.acm.org/doi/abs/10.1145/3292500.3330646) 细粒度而不是历史数据的  a fine-grained prediction is performed using a coarser data (e.g., predicting crowd flow of different school buildings given crowd flow of the entire university area) instead of using historical data  




## 现有综述

### 列表

年份，模型分类，问题分类，数据集分类

- T-ZS1

  CNN, RNN, FNN 2014-2019

- [T-ZS3](https://www.sciencedirect.com/science/article/pii/S0968090X14000096)

  statistical, neural network, hybrid model 2006-2013

  time series, function approximation 浏览了一下，深度学习较少
  
  提出了十个挑战，为 T-ZS1 所继承
  
- [T-ZS4](https://www.sciencedirect.com/science/article/pii/S1574119217306521)

  浏览了一下，对深度学习介绍很少，传统方法介绍篇幅很多

- [T-ZS5](https://ieeexplore.ieee.org/abstract/document/8344848/)

  浏览了一下，主要讲大数据技术，感觉相关性不大

- [T-ZS6](https://www.sciencedirect.com/science/article/pii/S0968090X10001610)

  读摘要，对比统计方法和 NN

- [T-ZS7](https://dl.acm.org/doi/abs/10.1145/3231541.3231544)

  没搞到 pdf，只读了摘要，NN 相关 2018

### 评价

- T-ZS3

  (T-ZS1 评价) 分类老旧、深度学习少

  do not include the now ubiquitous deep neural network models

  their work categorized the models based on several criteria such as the type of model (e.g. statistical, neural network, hybrid model) and the problem (e.g. time series, function approximation). This taxonomy is outdated because modern traffic prediction models are mainly based on deep neural network, which under their taxonomy will all fall under the neural network category of model and function approximation category of problem  

- T-ZS4

  (T-ZS1 评价) 分类比较少、没讨论挑战

  their model taxonomy only has a few points of comparison, which are: whether or not the model integrates environmental data, contains spatial property, handles nonlinearity and handles nonstationarity  

  Additionally, their work does not have a future challenges section that discusses how the field can be advanced  

- T-ZS5

  (T-ZS1 评价) 与机器学习关联不大

  their work focuses on big data analytics without much focus on the actual models  

### 关系

T-ZS1 介绍了 T-ZS3, T-ZS4

## 具体技术

### 概述

(T-ZS1) The earliest class of models used is the classical statistical models. Afterwards, machine learning models improve upon the performance of classical statistical models. Then, the deep neural network class of models dominates the field due to its capability in capturing the complex and nonlinear patterns in traffic data.  

### 统计模型

> ##### ARIMA

(T-ZS1) classical statistical models, of which the Autoregressive Integrated Moving Average (ARIMA) family of models is the most popular. 

局限：(T-ZS1) 线性模型，假设数据规律不变；只能预测小时间段，参数手调

- T-3 T-5 [T-ZS6](https://www.sciencedirect.com/science/article/pii/S0968090X10001610) simple linear models which assume that the traffic is stationary  ->  frequently fail when handling the complex, nonlinear traffic data 
- [T-12](https://arxiv.org/abs/1801.02143) were proposed at a time where traffic data were simpler and much smaller in size  -> a condition that no longer holds true in the present day where the ubiquity of traffic sensors has caused an explosion in traffic flow data   
- [O-1](https://www.tandfonline.com/doi/abs/10.1080/00031305.1996.10473554) the function parameters are manually defined a priori  

(stated by T-ZS1)

- [T-6](https://trid.trb.org/View/148123) [1979] first researchers to apply ARIMA to traffic prediction 
- [T-7](https://trid.trb.org/View/167550) [1980] found that the ARIMA(0,1,1) model is the most statistically significant
- [T-8](https://journals.sagepub.com/doi/abs/10.3141/1678-22) [1999] applied subset ARIMA and found that it provides stable and accurate results
- [T-9](https://journals.sagepub.com/doi/abs/10.3141/1776-25) [2001] discovered the impact of upstream traffic sensors to downstream ones and applied ARIMAX model for traffic flow prediction
- [T-10](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-947X(2003)129:6(664)) [2003] applied Seasonal ARIMA to the United States and the United Kingdom traffic data 
- [T-11](https://journals.sagepub.com/doi/abs/10.3141/1857-09) [2003] discussed and compared the Vector Autoregressive Moving Average and Single space-time ARIMA model

### 机器学习

#### 历史

(T-ZS1) machine learning models during the 2000s utilize shallow and simple structures, limiting their prediction power  

(stated by T-ZS1)

- [T-13](https://research.aber.ac.uk/en/publications/the-use-of-neural-networks-to-recognise-and-predict-traffic-conge) [1993] One of the first neural network applications in traffic flow prediction  
- [T-14](https://www.sciencedirect.com/science/article/pii/S0968090X05000276) [2005] proposed a genetic algorithm approach to optimally tune the network
- [T-15](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-947X(2006)132:2(114)) [2006] used multiple neural network predictors which are combined using the theory of conditional probability and the Bayes rule  
- [T-16](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0887-3801(2005)19:1(94)) [2005] neural network model was applied to traffic prediction  
- [T-17](https://ieeexplore.ieee.org/abstract/document/6088012) [2012] imbued a neural network model with the hybrid exponential smoothing method to preprocess training data and the Levenberg-Marquardt algorithm to train the network weights

非 NN：

(stated by T-ZS1)

- k-Nearest Neighbor [T-18](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-947X(1991)117:2(178)) [T-19](https://www.sciencedirect.com/science/article/pii/S1877042813022027) [T-20](https://www.sciencedirect.com/science/article/pii/S0968090X15003812)
- support vector regression (SVR) [T-21](https://www.sciencedirect.com/science/article/abs/pii/S0957417408004740) [T-22](https://ieeexplore.ieee.org/abstract/document/4344269) [T-23](https://link.springer.com/chapter/10.1007/978-3-540-72393-6_121)



#### 概述

- 局限性：数据密集

  (T-ZS1) The main weakness is that machine learning models are data intensive 

- 局限性：

  (T-ZS1) powerful but very hard to train efficiently  

- 局限性：手动提取特征

  (T-ZS1) many other machine learning models’ feature extraction phase, which helps extract useful patterns and information from the data to help the prediction, is done manually (i.e., using manually tuned kernels)  

- 优点：

  (T-ZS1) Machine learning models are flexible as they can learn from the data. That is, the parameters of the prediction function are adjusted automatically as the model traverses through the dataset  

### SAE / DBN

#### 概念

(T-ZS1) 评价：不能明确获取时空信息

The main contributing factor of this rarity is that SAEs and DBNs do not explicitly capture the spatial or the temporal aspect of the data and thus tend to perform worse than the neural networks that capture such aspects. 

(T-ZS1) 早期出现的原因：计算快，现在已被淘汰

- 不显示获取时空信息，表现不优，在早期可能多见
- 逐层贪心训练方法预训练权重，加速训练

> SAE 基于多层神经网络的无监督学习算法。它由多个自动编码器（Autoencoder）堆叠而成
>
> Deep Belief Network 是一种由多层 Restricted Boltzmann Machines (RBMs) 组成的概率生成模型，通常用于特征学习和无监督预训练
>
> RBM 是一种受限玻尔兹曼机，用于学习数据的概率分布

In fact, SAEs and DBNs receive attention mostly at the earlier years of deep neural network for traffic flow prediction. We speculate that this is because early researchers are concerned with the computation time optimization of the training methodology. SAEs and DBNs use the greedy layer-wise training method ([O-4](https://proceedings.neurips.cc/paper/2006/hash/5da713a690c067105aeb2fae32403405-Abstract.html)) to pre-train their network weights, which accelerates the training in the long run. However, as more and more complex techniques were introduced and as hardware and software optimization reduce the computational time of these methods, the middling performance of SAEs and DBNs resulted in the two being phased out  

#### 具体论文

This has been demonstrated through several experiments:

- T-1 T-4 [T-56](https://arxiv.org/abs/1802.02147)

Stacked Autoencoder (SAE)  

(T-ZS1)

- [T-54](https://ieeexplore.ieee.org/abstract/document/6894591) 

- [T-55](https://ieeexplore.ieee.org/abstract/document/7727607) 使用 Dempster-Shafer theory 结合交通流数据

  > Dempster-Shafer理论是一种用于处理不确定性和推理的数学理论。它由Peter Dempster和Arthur Shafer在20世纪70年代提出，是一种用于描述和处理不确定性信息的方法，特别适用于决策支持系统和人工智能领域。
  >
  > 这个理论的核心是使用概率分布函数（称为Belief函数），来描述每一个可能事件发生的可能性。这种方法与传统的贝叶斯概率理论不同，因为它允许对不同假设之间的关联性进行建模，而不是简单地单独考虑每个假设的概率。
  >
  > Dempster-Shafer理论的应用包括数据融合、模式识别、专家系统、风险评估等领域，它在处理非完整和不确定信息时显示出了一定的优势

Deep Belief Network (DBN)

(T-ZS1)

- T2 T-26 T-27 

### 神经网络

#### 概念

深度神经网络

(T-ZS1) Amongst all the available traffic prediction methods, deep neural network is the most prominent.  

- 概念：

  (T-ZS1) Deep neural networks consist of complex neural network models with a large number of layers. 

- 条件：

  (T-ZS1) increasing computational power, as well as theoretical and software improvements in recent times had made increasingly complex neural network models feasible to train. Thus, in the middle of the 2010s, researchers started to apply deep neural network models for traffic prediction  

  > As technology advanced on both the hardware and the software front, complex deep neural network models are becoming easier to train. This has prompted researchers to combine the capabilities of multiple deep neural networks, and even add some novel components of their own creation  

- 理由：

  (T-ZS1) This is due to its sheer predictive power that can model the complex and nonlinear traffic patterns

  > 参考几个具体应用论文：[T-1](https://www.mdpi.com/1424-8220/17/7/1501)、[T-2](https://www.mdpi.com/1424-8220/17/7/1501)、[T-3](https://arxiv.org/abs/1612.01022)、[T-4](https://ieeexplore.ieee.org/abstract/document/8489600)、[T-5](https://arxiv.org/abs/1707.03213)，引用都不错

#### 优缺

- 适用理由：CNN/RNN抓时空+层数

  (T-ZS1) Some of the deep neural network models can explicitly capture different aspects of traffic data, which made them even more attractive. For instance, CNN can explicitly capture the spatial aspect of traffic data while RNN can explicitly capture the temporal aspect of traffic data. Additionally, the increased number of layers improves the models’ prediction capability. This factor allows them to model traffic fluctuations more accurately  

- 优点：自动学习特征

  (T-ZS1) (The reason behind its prominence is that) neural networks perform automatic feature extraction as well as the actual prediction in one model 

  > 相较于传统机器学习而言 (T-ZS1: O-1)
  >
  > Neural network’s prominence in traffic flow prediction can be attributed to the model’s flexibility. This is because the functional form of neural network models is approximated via learning, as opposed to classical statistical models which assume the functional form a priori  

- 局限性：当前状态和未来方向不明

  (T-ZS1) The increasing popularity of deep neural network models for traffic prediction has led to numerous publications, but issues such as the wide variety of hybrid deep neural network structures have made it difficult to assess the current state and future directions of this research field. This problem is compounded by the fact that survey works focusing specifically on deep neural network models are rare

- 缺点：

  (T-ZS1) 需要大数据，训练代价高，难以理解(如参数含义)

  - Deep neural network models require a large amount of data that covers all traffic conditions. 

    If the amount of data is too small or if the data is not diverse enough, the model’s generalization capability is compromised.

  - Deep neural network models still take a long time to train. 

    As deep neural network models are complex and have a large number of layers, the training time can be very long. This problem is compounded on hybrid deep neural network models. As classical statistical and older machine learning models are not as complex, their training time is much shorter.

  - Deep neural network models are difficult to interpret. 

    This is because of two reasons: the number of internal parameters is very large, and the parameters are learned from training, not set manually. Thus, while they can predict well, it is hard to understand their parameters. Understanding the parameters may reveal important information such as the spatiotemporal dynamics in the road network 
    
    > Consequently, neural network models’ internal parameters are rarely explored because they are hard to interpret as their focus is mostly on raw prediction performance rather than interpretability.  
    
    该缺点可以 更多参见下文未来趋势一节

#### 分类

分类：

类别：

(T-ZS1) The three most common deep neural network models used for traffic prediction are Convolutional Neural Networks, Recurrent Neural Networks, and Feedforward Neural Networks

(T-ZS1) RNN, CNN, FNN

- RNN is commonly used to capture the temporal trends of traffic data–the dynamics of how past traffic can influence future traffic. CNN is commonly used to capture the spatial trends of the data–how traffic propagates through the road network. FNN can aggregate the output from different subnetworks and also can process external data such as weather information  

### FNN

#### 概念

概念：

- (T-ZS1) 名称 A Feedforward Neural Network (FNN), which is also commonly referred to as Fully Connected Neural Network (FC or FCNN), is one of the earliest and simplest neural network models  

  组成 It consists of several layers of fully connected computational nodes organized in many layers  

  计算方式 The value of every node in the hidden or output layers is computed by taking the weighted sum of all of the previous layer’s nodes and then passing the value to a nonlinear function such as sigmoid, tanh and relu  

缺点：

- 参数多、训练久

  (T-ZS1) The FNN’s fully connected structure enables each of its layers to process the combination of all the previous layer’s features. However, this also serves as a weakness because its full connection results in a large amount of parameters  

  Consequently, the training process of FNNs can be quite time consuming. In addition  

- 没有明确获取时空信息

  (T-ZS1) do not have the capability of explicitly capturing spatial or temporal data. Because of this, FNNs are rarely used as the main predictor in deep neural network literatures.  

作用：工具组件：聚合输出、维度转换、引入数据

- (T-ZS1) For traffic flow prediction, FNNs usually serve a utility role in a hybrid deep network, whose main purpose is to perform tasks such as aggregating outputs from different components within the network, dimensionality transformation and incorporating external data such as weather.  

  - 维度转换：This is because the size of input layer or output layer can be set manually, which gives FNN the capability to transform inputs of an arbitrary dimensionality to an output of an arbitrary dimensionality  
  
  - 聚合输出：When used to integrate external data, the input depends on the type of external data. Numerical values can be provided as it is while categorical values need to be transformed first (e.g., using one-hot encoding)  
  
    > FNNs are commonly used to aggregate the output of one or more subnetwork components in a deep neural network 
    >
    > a natural component for CNNs and RNNs, since FNNs can take the output from these networks and output a smaller representation
  
  - 引入数据：For aggregating outputs and dimensionality transformation, the inputs depend entirely on the model  
  
    > FNNs are also commonly used to incorporate external data to the network, because it can take inputs of an arbitrary dimensionality and perform a transformation to ensure that the dimensionality of the external data and that of the other components within the network match  
  
  - 子模块：as a submodule component. FNNs are often used as a component in a model’s submodule, such as attention network modules  

#### 具体论文

(T-ZS1)

1. FNN as Output Aggregator

   - T-3 合并 CNN+2LSTM 的输出

     combine the outputs from one CNN component and two LSTM components  

   - T-1 T-33 T-48 T-50 T-37 合并 CNN 的输出

   - T-41 T-53(结合天气+消融) T-36 合并 RNN 的输出

2. FNNs for Incorporating External data

   - T-51 T-37 T-3

3. FNNs as a submodule component

   - T-43 学习哪条路网重要

     used an FNN to learn features from a road network, which enables the network to learn which nodes in a road network are important  

   - T-42 与上面一样，但没用图结构

     used an FNN for the same purpose, although they do not use the graph structure  

### CNN

#### 基本

组成：卷积层、池化层

(T-ZS1) 

A CNN consists of several “convolution” and “pooling” layers. 

- Convolution’s purpose is to extract features from the input, 

  > Mathematically, convolution layers extract features by computing the dot product between a matrix of some preset values (referred to as filter) and a subset of cells from the original grid, which produces a matrix that is called feature map  

  > The example in Figure 1 shows, (i) the top-left 3 × 3 subset of cells produces the value 470, and (ii) the bottom-right 3 × 3 subset of cells produces the value 170 in the feature map. This can be interpreted as the top-left subset having a much higher number of vehicles in that region than the bottom-right subset  

  <img src="img/image-20240722103753648.png" alt="image-20240722103753648" style="zoom: 67%;" />

- whereas pooling’s purpose is to reduce the dimensionality of each feature map but preserve the most important information.  

功能概述：

(T-ZS1) A Convolutional Neural Network (CNN) has the capability to learn inherent features progressively, starting from low level features and then building up to more abstract concepts through a series of convolutional layers.  

能用的理由：交通流读入可以建模为图像，每个像素点对应一个交通密集的地区，因此可以用图像识别技术，即把区域网格化，像素值是如车辆数目，不同时间即像素值不一样

> (T-ZS1) A CNN is the optimal choice for capturing the spatial aspect of the data. CNN is able to capture the correlation between different regions in the road network. By utilizing this strength, a CNN can learn the spatial dynamics of traffic in order to improve the prediction accuracy.  

(T-ZS1) 

- Although this strength contributes to its popularity in image recognition, CNNs have been regularly applied to traffic flow prediction. The intuition is, traffic flow readings can be modeled as an image, where each pixel corresponds to the traffic intensity at a certain block of area. Thus, similar techniques developed for image recognition can be easily applied 
- Given a road network, the input of a CNN is preprocessed by partitioning the network as a grid, which is essentially a set of cells with each cell representing an area in the data space and the value associated with the cell representing the number of vehicles detected in that cell at a certain point in a time period (e.g., 5×5 cells in Figure 1). The traffic flow reading for each time period will be represented with the same grid but different number of vehicles. Thus, the entire traffic data modeled this way can be seen as several images with the same size but different pixel values   

优点：不全连接，参数少

- (T-ZS1) Unlike most neural networks, CNN’s layers are not fully connected. Consequently, the number of parameters and training time are significantly reduced 

  不全连接的另一个优点在于可以学习空间的局部相关性

  (T-ZS1) Since CNN’s layers are not fully connected, one layer of CNN does not learn from all of the previous layer’s features. However, this actually proves to be an advantage in many applications as CNN can learn how the different aspects of the input relate to each other spatially  

优点：权重共享

- (T-ZS1) Additionally, CNN uses a weight sharing mechanism, which further reduces the number of required parameters  

具体应用：混合网络、空间特征 (如晚高峰商业区和居住区间流量强关联)

- (T-ZS1)  In the application of traffic prediction, CNN is often used as a component in a hybrid deep neural network, whose task is to capture the spatial aspect of traffic data.
  This is because different roads in different locations may be correlated and these correlated roads share similar traffic trend. Therefore, the traffic of the correlated roads may rise or fall, depending on their historical data 

  For instance, during the evening, there is a strong correlation between the road traffic of commercial and residential districts because employees are heading off from work  

#### 具体论文

(T-ZS1) 根据数据分类，理由：

Deep neural network models, hybrid or otherwise, that are applicable for one data type are incompatible for the other without major modifications. Consequently, we categorize works related to CNN based on the type of the main datasets  

##### point data

(T-ZS1) CNN 获取空间信息的能力取决于数据类型，一般用点数据。

可以：

- 使用 1D CNN(一维)

  use a 1D CNN as it is compatible with point data which are commonly organized in a line

  如 T-3 T-35

- 在 2D CNN 矩阵同时使用时空数据(一维时间、一维空间)

  capture both the spatial and the temporal aspects of the data in a 2D matrix to be fed into a CNN. That is, one axis of the matrix captures the different traffic detection sites and the other is used to capture the different time step  

  如：T-33 [T-48](https://ieeexplore.ieee.org/abstract/document/8547068) [T-49](https://ieeexplore.ieee.org/abstract/document/7837874) [T-50](https://dl.acm.org/doi/abs/10.1145/3282834.3282836)

  两者都用，如：T-38

##### trajectory data

(T-ZS1)  可以获取时间数据(如维度：空间、时间点、天)，或对时间做一维卷积。

(T-ZS1) 例子：

- T-1 映射为2D网格

  mapped a road link to a 2D grid and assigned to each grid the average traffic speed of the associated road link.  

- [T-51](https://ojs.aaai.org/index.php/AAAI/article/view/10735) T-31 2D矩形空间，再划分为多个网格

  defined a 2D rectangular space that encompasses all the trajectory points. This space is then divided into grids. Finally, for each grid, the traffic flow for a certain period of time is calculated as the number of trajectory points that are recorded within the grid during that period. Using this modeling, the entire space can be seen as a city and the grids represent small regions within the city. 

  结合天气 

- T-37 在上述方法基础上，增加了起点终点数据

  used a similar method as the previous, but they also modeled the traffic volume using CNN by using data of a trajectory’s start and end  
  
- T-2

- T-30

##### other

(T-ZS1) 时间信息捕获

Some authors have also attempted to use CNNs to capture the temporal aspect of the data  

(T-ZS1) 例子：

- [T-52](https://www.mdpi.com/1424-8220/17/4/818) 行：空间、列：时间、深：天数 -> 比 RNN 更短的输入序列

  included both the spatial and the temporal dimensions by modeling the traffic data as a tensor, where the rows represent the spatial aspect, the columns represent the temporal aspect and the depth represents the different days  

  They argued that using RNNs requires long input sequences which can impact training time greatly and instead applied CNN to capture both the spatial and the temporal aspects of the data  

  车祸考虑 + 模拟实验

- T-51 多个 CNN 分别获取小时、天、周粒度数据

  captured the temporal aspect using CNNs which are fed data from different time granularities (e.g. weekly, daily, hourly)   

-  1D CNN 获取时间

  used a one dimensional convolution on the time axis in order to capture the temporal aspect  

### RNN

#### 基本

定义：

- (T-ZS1) An RNN consists of a single node with a recurrent connection, but is often visualized as a chain of nodes, with each node representing the network state at a particular recurrence/time step  

  <img src="img/image-20240722110704917.png" alt="image-20240722110704917" style="zoom:67%;" />

  节点状态 $s_t$ 处理 $t$ 时刻的输入数据 $x_t$，和截止 $t-1$ 为止的全部信息($s_{t-1}$)一起传入到该节点

  The node state $s_t$ processes the input data $x_t$ at time $t$, as well as a ‘summary’ of all the information obtained up to time $t - 1$. This summary is stored in $s_{t-1}$, and it memorizes which parts of the sequence are important. Node $s_t$ then has the summary up to time $t$ and this information is passed to the next node state
  $s_{t+1}$. Thus, the node state $s_t$ stores the state of nodes for all the previous time steps until the beginning of the input (i.e., $s_{t-1}$, $s_{t-2}$, . . . ). The output $o_t$ is then compared with the ground truth $y_t$ in order to calculate the loss, which is used to fine-tune the model parameters.  

具体输入：

- (T-ZS1) In traffic prediction applications, the input to an RNN consists of past traffic readings. A continuous time period is divided into discrete time blocks and the traffic flow reading from each block is fed into the RNN.  

  > In the field of traffic prediction, LSTM as well as other RNN-based methods are commonly used as a component in hybrid deep neural network models. Its task is to capture the temporal patterns of traffic data; learning how traffic evolves over time  

> 应用：命名实体识别、声音识别、音乐识别、图像字幕生成等
>
> RNN-based methods in general possess the major advantage in the form of its memorization capability. The ability of learning important parts of the sequence and knowing when to memorize or forget them had led RNN to be the prime choice for sequence data. Due to this, RNN based models have been applied in many fields such as named entity recognition [40](https://link.springer.com/chapter/10.1007/978-3-319-55699-4_33), voice recognition [41](https://dl.acm.org/doi/abs/10.1145/3132847.3132893), music composition [42](https://people.idsia.ch/~juergen/blues/IDSIA-07-02.pdf), and image caption generation [43](https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Vinyals_Show_and_Tell_2015_CVPR_paper.html)
>
> 这些论文大部分引用不多或比较古老，除了 43 感觉都很一般

优点：长短的时间依赖都可以记忆，而且比其他记得更长

- (T-ZS1) Recurrent Neural Networks (RNN) are commonly applied to sequence data because of their memorization capability, which can learn both long and short term dependencies between parts of the sequence. Additionally, RNN is able to scale to longer sequences compared to other network architectures. Its unique capability makes it one of the most popular deep neural networks.  

缺点：梯度消失

- (T-ZS1) By its nature of being able to take in possibly very long sequences, RNN suffers from the vanishing gradient problem, which hinders the network’s ability to memorize information for a long time  

缺点：训练时间长

- (T-ZS1) RNN’s recurrent structure leads to significantly longer training time compared to other deep neural network models  

#### LSTM

开山(1997) [O-2](https://ieeexplore.ieee.org/abstract/document/6795963) ；改进(2000) [O-3](https://ieeexplore.ieee.org/abstract/document/6789445)

概念：

- (T-ZS1) maintains the RNN’s recurrent structure, but introduces the three gates to control the cell value.  

  > also contains multiple layers, each possessing a cell with the memorization capability. In addition, it contains three gates, which control how information propagates throughout the network.  

  These gates are: 种门控制信息的传播($i,o$，分别控制遗忘多少之前信息、当前与下一层的相关性)

  - the input gate $i$, which controls the importance of the inputs $x_t$ and $h_{t-1}$,

  - forget gate $f$ which controls how much of the previous information $C_{t-1}$ is to be forgotten, 

  - and the output gate $o$, which controls how relevant is the current information $C_t$ for the next step.  


<img src="img/image-20240722113840626.png" alt="image-20240722113840626" style="zoom: 67%;" />

适用的原因：交通数据是时序的

(T-ZS1) We speculate that this is because traffic data constitutes a temporal sequence, which fits LSTM’s purpose. Additionally, most available traffic flow data is compatible with LSTM, as these traffic flow data can easily be modeled as a sequence of traffic flow readings  

> For instance, the traffic flow between 11:00 and 12:00 can be captured as the aggregated traffic reading for four periods, including 11:00-11:15, 11:15-11:30, 11:30-11:45, and 11:45-12:00. This data can be fed into an RNN, resulting in an RNN with four recurrences  

#### 具体论文

##### basic

(T-ZS1)

- 首次应用 T-25 [T-32](https://ieeexplore.ieee.org/abstract/document/7463717) the first few applications of basic LSTM  
- 建模为矩阵以融合空间信息 [T-33](https://ieeexplore.ieee.org/abstract/document/7966128) [T-34](https://ieeexplore.ieee.org/abstract/document/8317872) use an LSTM that takes in readings from multiple time slots as well as multiple detectors. The data is modeled in a matrix, which captures both the spatial and temporal aspects of the data  

##### hybrid

(T-ZS1) 三种思路：

> 1. RNN 输出特征融入到融合层(fusion layer)(如 FNN) (最简单)
>
> 2. 输出作为下个组成部分的输入(流水线)(先时再空或反过来或多次时间都行)
>
> 3. 作为主预测器，修改模型内部结构 (最复杂) 
>
>    (如反向传播->RTBL, 融入图卷积等)

(T-ZS1) 即：

1. Outputting features to be fed into a fusion layer.

   the simplest because models that fall into this category usually consist of several simpler subnetworks that only interact at the final fusion layer  

2. Outputting features to be fed into subsequent components within the model.

   treats LSTM as a pipeline that transforms one feature representation to another

   > As observed, in this category of method, some preprocessing steps such as the masking of missing values can be a part of the architecture.  

3. Used as the main predictor, but with modifications
   to the internal structure  

  the most complex one, as it requires modifying the internal LSTM structure

(T-ZS1) 分别：

1. 融合层

   - T-3 CNN+2LSTM (空间，短时间特征，周期时间特征)

     a combination of a CNN and two LSTMs to capture spatial features, the short-term temporal feature, and the periodic temporal feature respectively. The outputs from these three networks are then fed into a FNN to fuse the features  

   - [T-35](https://ieeexplore.ieee.org/abstract/document/8258813) CNN+LSTM

     used a combination of a CNN component and an LSTM component to capture spatial features and temporal features respectively. The outputs from these networks are combined to form the prediction  

   - T-29 SAE + LSTM

     a combination of a Stacked Autoencoder to encode traffic accidents data and an LSTM to capture the temporal aspect of the data  

2. 流水线

   - T-1 CNN -> LSTM

   - first used a CNN to encode the spatial aspect of the data and then fed this processed information to an LSTM to learn the temporal aspect  

   - T-4 CNN -> LSTM

     used an LSTM to process the outputs from a CNN before passing them to a max-pooling layer  

   - T-12 缺失值处理 -> 双向LSTM(特征转换) -> LSTM

     performed masking to fill in missing values in the data before passing it to a bidirectional LSTM for feature transformation and then a regular LSTM for the prediction  

   - [T-36](https://arxiv.org/abs/1811.05320) GCN(空间) + GRU(时间)

     used a Gated Recurrent Unit which takes input from a Graph Convolution Network and outputs the predicted traffic

   - [T-37](https://www.researchgate.net/profile/Huaxiu-Yao/publication/323570926_Modeling_Spatial-Temporal_Dynamics_for_Traffic_Prediction/links/5b1e23ea45851587f29f6a61/Modeling-Spatial-Temporal-Dynamics-for-Traffic-Prediction.pdf) 多个 LSTM

     used multiple LSTMs that represent the daily traffic features

   - [T-38](https://www.sciencedirect.com/science/article/pii/S0968090X18302651) 注意力+GRU+CNN

     used a Gated Recurrent Unit to learn feature representation from an attention model which are then fused with the CNN spatial component  

3. 修改结构

   - [T-39](https://ieeexplore.ieee.org/abstract/document/8917706) LSTM: 图卷积+卷积改为RTBL(查不到，疑似自创)

     modified the LSTM calculation to include a graph convolution process as well as using a novel Real-Time Branching Learning (RTBL) which modifies the backpropagation process  

   - [T-40](https://arxiv.org/abs/1707.01926) GRU: 矩阵乘法改为扩散卷积操作

     replaced the matrix multiplication inside Gated Recurrent Unit with the diffusion convolution operation 

##### encoder-decoder

见下文

##### other

(T-ZS1) 可以同时获取时空信息

Some authors have used RNNs to capture both the temporal and the spatial aspects of the data  

- T-34 多检测器一次输入 LSTM

  captured the temporal aspect by feeding data from multiple traffic loop detectors at once into an LSTM  

- [T-46](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-its.2016.0208)  每个检测器一个 LSTM + ODC矩阵表示之间相关

  used one LSTM for each traffic loop detector and incorporates an Origin Destination Correlation (ODC) matrix, which weighs how much the traffic of one loop detector’s location affects another  

- T-30 LSTM 密度核改成卷积来同时捕获时空

  replaced the dense kernels in LSTM with convolutional ones to successfully use an LSTM to capture both the spatial and the temporal aspects of traffic data  

  拼接天气和交通流数据

##### 多粒度

(T-ZS1) RNN 输入可能过长，因此只选取多个粒度的代表性数据，分别训练多个粒度的 RNN 组合，如要预测某个时刻的流量，与其输入很长的小时单位，不如输入短的小时，短的天，短的周结合起来，代替可能长达周的小时输入。

In addition, RNN has been used to capture the temporal aspect of the data using different granularities. As discussed in Section 3.2, RNN-based methods are commonly used to learn the temporal patterns of traffic data. However, we also mentioned that RNN-based methods are time-consuming. Consequently, RNN-based methods are not usually fed very long input sequences. Several data modeling-based approaches have been explored to mitigate this problem. The most common method is to use multiple LSTMs with each taking shorter sequences from a specific granularity. 

As an example, if we want to predict the traffic at 09:00 AM at December 25, one RNN can be used to capture the data from 06:00, 07:00, and 08:00 AM at December 25 (hourly granularity), one RNN can be used to capture the data from 09:00 AM at 22, 23 and 24 December (daily granularity) and one RNN can be used to capture the data from 09:00 AM at 4, 11 and 18 December (weekly granularity)  

- 例子如 T-3 T-37 T-38

### GNN

#### 概念

(T-ZS1) 近年新技术：

One of the most significant breakthroughs of recent work in deep neural network for traffic flow prediction is the graph-based methods  ->  in particular, the graph convolution operation  

(T-ZS1) 适用的理由：路网动态获取

Due to this ability of capturing the dynamics of road network, graph-based method is a promising future research direction.  

> they naturally conform to traffic dynamics

#### 对比

(T-ZS1) 图论领域GNN vs 欧氏几何CNN：

When applied to road networks, graph convolution works on the graph domain while regular convolution works on the Euclidean domain

> road networks do not conform to the Euclidean space as roads and highways that are close to each other may connect different parts of the city and thus have very different traffic characteristics  

讨论二者的优缺：

(T-ZS1) Graph-based methods are more appropriate for traffic data compared to the more conventional methods of dividing an area into spatial grids. The reason is that roads close to each other may connect entirely different parts of a city. It is more accurate to capture spatial correlations in terms of the connectivity of different parts of the area, which graph-based methods provide  

#### 优缺

缺点：

(T-ZS1) 实现复杂，可能需要手动预处理

> Graph-based models can be complex to implement as it requires additional data as well as data preprocessing  
>
> The road topology data, which captures how different traffic detection sites are connected by roads, is often not readily available and has to be manually curated. 
>
> > While this challenge is significant, it is important to measure and understand how well graph-based methods improve the traffic prediction performance  

数据获取难度

the difficulty lies in the data requirement and the additional preprocessing step  

#### 具体论文

(T-ZS1) 基于图的方法，图卷积操作(图论领域)。常规卷积是欧氏领域

如：

- 图扩散处理，基于双向图随机游走，结果用于卷积和 RNN

  T-38 performed a graph diffusion process based on a bidirectional graph random walk. Then, the resulting graph diffusion was used in a convolution process which is then incorporated into a Gated Recurrent Unit RNN  

- 图卷积，计算图(几步内)可达

  T-39 used a similar idea of graph convolution, but instead of using the diffusion process, they proposed a method which involves calculating whether or not it is possible to reach one node from another under a certain number of time-step when the traffic is on free-flow condition  

- 有向图找上游下游方向融入到卷积层

  T-4 used a directed graph which represents how traffic flows between locations. Through this directed graph, it is possible to find the upstream and the downstream locations. This information is incorporated in a convolution layer  

- 空间图卷积层

  T-28 modeled the traffic network as a graph and proposed a spatial graph convolutional layer  

- 图注意力网络

  T-43 modeled road network as a graph and used a graph attention network to model spatial correlations in the network  

- GN块输出同拓扑不同特征的图

  T-45 used a novel component called GN block that takes a road network graph as input and outputs another graph with the same topology but different graph features  

- 用 Deepwalk 把图转向量

  [T-58](https://pubs.aip.org/aip/cha/article-abstract/29/10/103125/282714/Road-traffic-state-prediction-based-on-a-graph?redirectedFrom=fulltext) used Deepwalk to transform a graph into a vector representation, which makes it easier to be incorporated into the deep neural network model  

- 扩散卷积 RNN

  T-40

### 注意力

#### 概念

(T-ZS1)动机：替代基于图的方法，比它更容易实现

An alternative to this method is some sort of an attention module that can model the spatial and temporal correlations in the data  

#### 具体论文

(T-ZS1)

- T-42
- T-44

### encoder-decoder

#### 传统

##### 概念

(T-ZS1) 概念介绍：

In addition to these methods, the encoder-decoder RNNs are also used in many recent studies. Encoder-decoder RNNs are partly inspired by autoencoders. 

Autoencoders are deep neural network structures that consist of two parts: 

- the encoder that takes an input and produces a vector representation of it (usually with a smaller dimension), 
- and the decoder that takes the vector representation and produces an approximation of the original input. 

In encoder-decoder RNNs, both input and output are sequences, and instead of approximating the original input, the target output is a ground-truth sequence (e.g., prediction for 5, 10, 15, 20, 25, and 30 minutes into the future)  

> 效果最好，而且可以输出序列而不是答案，所以可以在任意环节输入向量，或提前拿出答案

(T-ZS1) 特点：输出为序列，可以继续做输入等

can output sequences instead of a single result. This means that Encoder-Decoder RNNs can take input data from multiple steps and also output predictions multiple steps ahead  

encoder-decoder RNN (编码器-解码器模型)

- Autoencoder 是深层神经网络，两部分组成：

  编码器把输入转成向量表示(通常更低维度)

  解码器把向量还原为近似成输入

- 对 encoder-decoder RNN

  解码器从近似输入改成近似真实答案 目前的 SOTA

(T-ZS1) 主要使用基于图的方法

To imbue Encoder-Decoder RNN with the capability to capture spatial data, most of these works also utilize graph-based methods  

> (T-ZS1) 评价：与 GNN 一同 SOTA
>
> Despite the complexity of Encoder-Decoder RNNs and graph-based methods, we have observed that this combination has shown to be very proficient at predicting future traffic and is one of the more important recent developments of traffic prediction

##### 评价

(T-ZS1) While state-of-the-art models that commonly use encoder-decoder LSTM combined with graph-based methods, have achieved excellent performance, these promising new techniques may be able to further improve the performance of traffic flow prediction  

##### 具体论文

(T-ZS1) 论文例子：

- T-40
- [T-41](https://dl.acm.org/doi/abs/10.1145/3219819.3219895) 200+引用 2018
- [T-42](https://ieeexplore.ieee.org/abstract/document/8580534) STANN (+注意力+RNN) 60引用 2019
- [T-43](https://dl.acm.org/doi/abs/10.1145/3292500.3330884) 500+引用 2019
- [T-44](https://www.sciencedirect.com/science/article/pii/S0968090X19301330) 250引用 2019
- [T-45](https://ieeexplore.ieee.org/abstract/document/8708297/) (STANN+注意力) 60+引用 2019

#### Transformer

##### 概述

(T-ZS1) Transformer $\approx$ encoder-decoder RNN + 注意力 (可并行)

> Transformers are similar to encoder-decoder RNNs in that
> they take sequences as inputs and outputs sequences. The difference is that Transformers are designed with attention mechanisms in mind and can be parallelized  

开山鼻祖 (机器翻译) [O-5](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)

##### 具体论文

(T-ZS1) 第一个应用 [T-59](https://arxiv.org/abs/2001.02908)

### GAN

#### 概念

##### 定义

(T-ZS1)  

Generative Adversarial Networks consist of two neural networks that are trained to compete with each other. The two networks are generative networks, designed to capture the data distribution, and discriminative network, which judges whether a given sample came from the true data or from the distribution generated by the generative network  [开山](https://proceedings.neurips.cc/paper_files/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html)

##### 评价

(T-ZS1) While state-of-the-art models that commonly use encoder-decoder LSTM combined with graph-based methods, have achieved excellent performance, these promising new techniques may be able to further improve the performance of traffic flow prediction  

#### 具体应用

(T-ZS1)

- [T-60](https://journals.sagepub.com/doi/abs/10.1177/0361198118798737) LSTM 生成和对抗

  use LSTMs for both the generative and discriminative network  

- [T-61](https://ieeexplore.ieee.org/abstract/document/8438991) 增强边界健壮性

  where a GAN is used to enable traffic flow prediction that is more robust to outliers  

- [T-62]() +图CNN 使用句子到句子的 autoencoder

  combine GAN with graph CNN, and use sequence-to-sequence autoencoder for the generative network  

### 混合模型

#### 概念

集各家之长

(T-ZS1) As complex deep neural networks are becoming viable to train, most authors have utilized the hybrid neural network setting, which combines different neural network structures into a larger entity, to maximize the prediction performance  

The popularity of hybrid neural network structure is contributed by its power and flexibility of utilizing the different strengths of its individual components.   

> While complex models are expensive to train, their performance improvements have proven that the investment is worthwhile  

现状：占主要

(T-ZS1) we can see that the simpler “deep neural network” category consists of papers from the earlier years of traffic prediction research while “hybrid deep neural network” and “hybrid deep neural network and graph theory” mostly contain more recent papers. Hybrid deep neural networks combine different types of simple deep neural network structures in order to combine the strengths of each  

#### 对比简单的例子

(T-ZS1) 对比简单模型的例子：

- T-40 encoder-decoder 图扩散比 FNN, LSTM 好，消融证明扩散卷积更好

  have demonstrated that their encoder-decoder model with graph diffusion managed to outperform simple FNN and LSTM. Not only that, they also performed an ablation test to demonstrate that their novel diffusion convolution module manages to outperform simpler variations  

- T-44 与 FNN, LSTM, GRU 对比

  have compared their method against simple FNN, LSTM and GRU, showing similar trends  

结论：复杂的比简单的好，新的技术更好

While we provide only two examples due to space constraints, we can attest that many complex hybrid deep neural network models have managed to outperform simpler deep neural network models and that many novel modules designed to capture spatial and temporal correlations (e.g., spatial and temporal attention) have resulted in further performance improvement  



## 相关数据

### 概述

#### 分类

##### 主数据

参考 T-ZS1 的分类标准，主要数据集可以分为两类：

- 固定式采集数据集(point data)：安装在固定地方的探测器所采集的数据

  > (T-ZS1) 标准数据集为 PeMS

- 移动式交通数据(trajectory data)：GPS 等收集的车辆轨迹信息

  > (T-ZS1) 无标准 do not have a standard dataset  
  >
  > Different works use different datasets with different properties, including the origin country (mostly America or China), method of transportation (cars, taxis or bicycles) and time range
  >
  > trajectory data from Beijing is relatively more popular    

> (T-ZS1) road link data 是特殊的 point data 的理由：
>
> As we can derive the traffic speed from road link data by averaging the speed of vehicles on each road link, we also regard road link data as a special type of point data.  
>
> (T-ZS1) 非主流——使用了 point + 道路连接的论文： 
>
> - use road link data in addition to point data as the main datasets  
>
>   T-12 T-39

##### 辅助数据

此外，可能还需要一些辅助数据信息：

- 交通网络数据：探测器的分布图(欧氏空间网格或无向加权图等)
- 气候数据、日期(节假日)数据、事件(如车祸)数据等

(T-ZS1) In traffic prediction, commonly used external information include weather, accidents, events, day of the week, time of the day and social media data  

### 评价

#### 数据集基准缺乏

参见下文

#### point data

(T-ZS1) 可用性，兼容性好，无序数据转换

Point data consists of traffic readings from road-installed sensors. This data is popular due to its availability and compatibility with deep neural network models; usually, point data does not require major data transformation step and can be used as is  

使用/表征方式：向量、矩阵、张量

For point data, spatial aspect is typically captured by collating data from multiple detection points into vectors. Sometimes, matrices can be used when capturing both the spatial and the temporal aspects. In addition, tensors can also be used when there are multiple matrices to be used all at once, such as when we are inputting the spatiotemporal traffic data from multiple days at once. These vectors/matrices/tensors are then fed as input into the network where a CNN resides  

优点为：

- 公开数据集可用
- 简单的数据转换
- 可以与图论方法一起用

The advantages of using point data are:

- Common public data are available. 

  For instance, the Caltrans data is very commonly used in the literature. Although each work uses different subsets, the availability of one unified data source makes it easier to establish a benchmark data.

  来源权威，覆盖面广

  Point data generally comes from traffic detectors installed by the transportation bureau. Consequently, the system is well-established, resulting in better temporal coverage  

- Data transformation is simpler.

  To obtain an input data that contains both the temporal and the spatial trends, the common procedure is just collating the data into vectors/matrices/tensors.

- Works better for methods that are based on the graph space. 

  Point data often constitutes traffic detectors installed on roads, which can be easily converted to graphs; each detector site can be treated as a vertex and every two adjacent detectors define an edge.   

限制：

- 成本高昂，几乎没有 arterial/highways 数据

- 与欧氏空间方法不兼容(如 2D CNN 即普通的 CNN)

  因为很多真实空间连成线

Although point data has multiple advantages as detailed above, it also has some limitations as listed below:

- Almost exclusive highways data.

  Since traffic loop detectors are difficult and expensive to install, they are not commonly available for arterial roads.

  > However, as traffic detectors are costly to install, they are mostly limited to highways  

- Not compatible with methods that conform to the Euclidean space (e.g. 2D CNN). 

  This is because most point-based data are highways data where the traffic detectors are spatially organized in a line.  

#### trajectory data

(T-ZS1) 如果使用轨迹数据，每条轨迹映射到 2D 平面网格，优点：

- GPS 数据，覆盖了 arterial roads(干道) 和 highways(公路)
- 对欧氏空间方法更好
- 结果可视化/可解释简单

The advantages of trajectory data are:

- Not exclusive to highways data. 

  Trajectory data are usually GPS data, which cover both arterial roads and highways.

  > has a more general spatial coverage as drivers pass through arterial, urban and highway roads alike  

- Works better for methods that are based on the euclidean space.

  After the data processing, the spatial correlation is inherently captured within the resulting 2D plane. Additionally, the resulting data transformation output is a matrix, which naturally fits 2D CNN. Finally, trajectory data usually cover city regions, which usually conform to the 2D shape.

- Results are easily interpretable. 

  By visualizing the values assigned to each grid in the 2D map, the region’s traffic flow prediction can be observed directly. 

缺点：

- 数据转换到 2D 平面复杂 (故文献少)
- 不能建图用图论方法
- 时间覆盖没这么广

For trajectory data, utilizing the Euclidean space is common. Each trajectory needs to be mapped onto a 2D plane which represents the region (e.g. city, country) where the data resides. This region is divided into grids where each grid represents a subregion. Processing the data this way yields a matrix that represents the traffic state of a region, which can be fed into a CNN to capture the spatial aspect.

The disadvantages of trajectory data are:

- Complex data transformation. 

  The process of mapping each trajectory point to the 2D plane is complex and time consuming.

- Not compatible with methods that model their data using graph-based methods. 

  Points in the road network can be transformed into vertices and the connections between them can be mapped to edges. This is not possible for trajectory data.  
  
- the temporal coverage is limited, ranging from a month (T-36 T-37) to several months (T-1 T-37 T-51) and up to one year (T-49 T-30), compared to the Caltrans data, for instance, which contains more than five years’ worth of data for its detectors  

（T-ZS1) 更推荐轨迹数据

The installation of traffic detectors is expensive, and point data’s spatial limitation is difficult to address. Therefore, we recommend focusing on trajectory data. Floating car data collected from GPS is the most widespread and efficient source of trajectory data. However, researchers must take into account the required preprocessing to use trajectory data for traffic prediction  

#### 日期

> 日期容易结合：
>
> (T-ZS1) Conversely, time-of-day and day-of-week data are much easier to incorporate
>
> 日期少于一年的缺点：
>
> (T-ZS1) 26 out of 37 literatures use less than one year’s worth of data. This deficiency will have an adverse impact on sub-tropical regions, as seasonal changes may affect temperature and weather, which in turn can affect traffic. By using data from only one or several months, the model cannot generalize to different seasons. This can be mitigated by incorporating weather data, but as mentioned before, this is a difficult and time-consuming task.  
>
> 时间不完整一天/周的缺点：
>
> (T-ZS1) e-consuming task. Some authors also use data from only a certain range of hours or use data from weekdays only. This will also cause problems as the model cannot generalize well to situations outside the boundaries of the provided data. For instance, using traffic data from 07.00 AM to 11.00 PM only may reduce the model’s performance on the excluded hours, and using only weekdays data may adversely impact the model’s performance when predicting weekend traffic  

#### 结合数据

参见下文未来趋势

#### 真实性

> 数据要趋于真实的理由：
>
> (T-ZS1) using vastly different datasets may result in an entirely different model. Thereby, for a model to be applicable to real application scenarios, it is important to use a dataset that closely resembles those scenarios.  

#### 时间粒度

> 时间粒度：大部分 5min (默认)，推荐 15min
>
> (T-ZS1) using vastly different datasets may result in an entirely different model. Thereby, for a model to be applicable to real application scenarios, it is important to use a dataset that closely resembles those scenarios.  
>
> (T-ZS1) 指出[文献](https://onlinepubs.trb.org/Onlinepubs/trnews/rpo/rpo.trn129.pdf)推荐 15min 粒度
>
> 数据粒度的辩证讨论：对结果和训练/输入的影响
>
> Depending on the dataset, the data granularity is a potentially important hyperparameter. Using a data granularity that is too small may cause a lot of zero values, especially during conditions where traffic is very sparse. For example, it is highly likely for a traffic loop detector to not detect any cars in 2 or 5 minute periods during off-peak hours (e.g. 02:00 04:00 AM) while this becomes less likely if the granularity is increased to 15 minutes or more. On the other hand, using a granularity that is too high might result in the smoothness of the traffic flow reading where important trends are lost. For instance, if the traffic experiences periodic shifts during 12:30PM, this trend might not be detected if the data granularity is one hour.
>
> Data granularity also impacts the number of possible data points as well as the size of the input sequence. Using a smaller granularity will increase the length of the required data sequence. For instance, one hour’s worth of data can be captured with only a sequence of length 4 when the granularity is 15 minutes, but when the granularity is 5 minutes, the sequence length is 12. This can impact training time, especially for RNN-based models.  
>
> Due to the aforementioned reasons, choosing the correct data granularity becomes a decision based on trade-offs and should be considered carefully depending on the data, the model, as well as the application scenarios  

#### 输入输出长度

> (T-ZS1) 多个长度都试一下，一般输入输出正相关，未得到充分研究：超参搜索耗时。多数是人为设置的，因为搜索超参太慢。可以用小数据集做超参搜索来缓解该问题。
>
> many authors perform experiments with different prediction horizons and use different input sequence lengths for each of the selected prediction horizons  
>
> Intuitively, as we increase the prediction horizon, the input sequence length also needs to be increased. This is because the increase in prediction horizon means predicting the traffic of further time frame in the future and thus, increasing the task complexity. Increasing the size of the data points by extending the input sequence may help in tackling the complex problem.  
>
> Unfortunately, the relationship between the input sequence length and the prediction horizon is rarely explored by the literature. Most of the input sequence lengths were chosen arbitrarily without iterating through different possible values. This is because hybrid deep neural network structures take a long time to train, which makes iterating through different settings unwieldy. Despite this issue, hyperparameter search remains an important facet of deep neural network development that cannot be omitted. One possible remedy of this problem is to first use a smaller data, chosen randomly from the main dataset, to find the optimal parameter setting.  

### 列表

列出部分常用的数据集：

- [PeMS](http://pems.dot.ca.gov/) (Caltrans Performance Measurement System)

  研究最广泛的数据集，由加利福尼亚州主要公路的上万探测器收集，每半分钟采集一次，包含容量、速度、交通流量等多种数据

  有多个子集广泛用于论文中，包括 PeMS-BAY、PeMSD3、PeMSD4、PeMSD7、PeMSD8 等，可以参考 [这篇综述](https://arxiv.org/pdf/2101.11174?trk=public_post_comment-text)

  > 优点 (T-ZS1) public availability, ease of download, simple structure and long historical data  
  >
  > 提供的数据、粒度 (T-ZS1) provides information regarding date, time stamp, traffic flow per lane, and aggregated traffic flow. Traffic flow is the most commonly used field, but occupancy and speed information is also available. The data granularity can be set to 5 minutes, hourly, daily, weekly and monthly depending on user requirements  

- [METR-LA](https://github.com/liyaguang/DCRNN) (Metro Traffic Los Angeles)

  洛杉矶公路网，207 个探测器，5 分钟间隔收集数据

- [Seattle Loop](https://github.com/zhiyongc/Seattle-Loop-Data)

  西雅图 4 条路数据，323 个探测器，5 分钟间隔收集数据，2015 年 1 月数据

- [SZ-Taxi](https://github.com/lehaifeng/T-GCN)

  深圳罗湖区 156 条路的数据，15 分钟粒度，2015 年 1 月数据

- [Beijing Traffic](https://github.com/deepkashiwa20/Urban_Concept_Drift)

  北京市 3126 个路段在 2022 年 5-7 月的 5 分钟粒度的数据

- [Q-Traffic](https://github.com/JingqingZ/BaiduTraffic)

  北京 2017 年 4-5 月一万多个路段每 15 分钟采样一次的百度地图数据

北京：

(T-ZS1) it is unclear as to whether or not all of the Beijing-based datasets come from one unified dataset source  

(T-ZS1 stated:) usually cover the Ring Road area

- 用到的 (2015, 2k引用) [T-25](https://www.sciencedirect.com/science/article/pii/S0968090X15000935)、(2017, 100引用) [T-26](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-its.2016.0257)、(2016, 180引用) [T-27](https://ieeexplore.ieee.org/abstract/document/7795712)、(2018，近4k引用) [T-28 STGCN](https://arxiv.org/abs/1709.04875)
- T-25 contains the traffic volume, occupancy and speed data (2017, 近500引用) [T-29](https://epubs.siam.org/doi/abs/10.1137/1.9781611974973.87)

其他数据集：参见 [paperwithcode 网站：Traffic Prediction Task](https://paperswithcode.com/task/traffic-prediction)、[这篇综述](https://arxiv.org/pdf/2101.11174?trk=public_post_comment-text)、[TKDE2020综述](https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=6998&context=sis_research)、[这篇综述](https://kns.cnki.net/kcms2/article/abstract?v=7sQefmFxFK3uEKBquRla5qDHveK9oCCRpBWf04Zyi-hciTPIaXDHO5AckFT2OGZGmxYUV8QI8BcEApyz73mJ280tQxDTOIZYSnF6llnWzinghcTnd6z1lC2pEY218-lrd9AoSHndDepAUNkp_yiHGfr7Tsk5vANL&uniplatform=NZKPT&language=CHS)。

### 统计

(T-ZS1) 

表格的评价尺度：

- 参考([xx])、作者、年份、主要数据类型、主数据集、时间范围、粒度、次要数据集、输入序列长度、预测视野

- 模型分类、预测值、时/空、模型子分类

  > 时空分类的具体定义参见论文，指模型专门用来处理哪一部分，or both

数据集

- PeMS 14/37
- 北京点数据和轨迹数据，各 6/37

辅助数据

- 天气 6/37 ；时间(time of day / day of week) 3/37  ；路网(road network) 3/37

数据跨度

- 一个月 5/37；数个月 22/37；一年 6/37；超过一年 4/37

模型：

- LSTM 18/37； 混合模型 21/37； 其他DNN(SAE, DBN) 6/37

## 未来挑战

> ### 现存挑战
>

#### 响应式方案

(T-ZS1) 响应式方案：如交通事故，天气变化融入到模型

Developing responsive algorithms and prediction schemes. 

Several of the recent works have attempted to address the problem of algorithm responsiveness in the face of unexpected traffic incidents such as accidents and weather changes. This is mainly done by using weather and accidents data as additional inputs to the traffic flow prediction models

- 如 T-55 使用 Dempster-Shafer theory 结合天气与交通流数据(参见上文)

  combined weather and traffic flow data using the Dempster-Shafer theory  

- 如 T-30 单纯结合天气 

  simply concatenated weather and traffic flow data  

- 如 T-51 简单相加

  performed simple addition  

评价：缺乏消融实验

lack ablation tests which can reveal the effectiveness of utilizing weather data  

有实验的：

- T-53 嵌入天气 + 消融实验

  incorporated weather data by embedding them into the traffic flow data in their test and performed a simple ablation test, which proved that the inclusion of weather data does improve prediction performance  

- T-52 事故+模拟实验

  performed a network stimulation test to understand the
  effect of sudden traffic accidents  

评价：探索不足，融合数据困难

As we can see, several authors have tested the impacts of weather and accidents in traffic flow prediction. Although several experiments have proven that the addition of these data can increase the prediction power of the models and increase their responsiveness to unexpected changes in traffic, this facet of traffic prediction has not been explored in great depth. This is due to the difficulty of incorporating these external data. Overcoming the challenge of data incorporation is the first step in utilizing weather and non-recurring incidents data in general to improve model responsiveness.  

#### 不同路段的预测

(T-ZS1) Freeway, arterial and network traffic predictions. 

The authors mentioned several related sub-challenges: the complexity of urban arterial traffic prediction, network-level traffic prediction and the incorporation of network dynamics on traffic prediction  

数据的缺乏，采集数据成本过大，只在 highways 有

轨迹数据可以代替网络预测(network-wide prediction)，覆盖 arterial 和 highways

While the prediction of traffic in urban arterial roads and network-level traffic prediction are dissimilar challenges, the cause is the same: the lack of traffic detectors on urban arterial roads. This is because installing traffic detectors is costly and thus, is often done only on highways. However, the increasing amount of trajectory data has resulted in an alternative solution for network-wide prediction, as car trajectories cover both arterial and highways alike.  

使用了轨迹数据的论文：T-29, T-1, T-51, T-30, T-37，具体参见上文

动态网络的预测(路网数据)使用图论方法：

The third challenge, incorporation of network dynamics on traffic prediction, is caused by traffic flow readings not inherently containing road network data. Therefore, this operation has to be done manually through data modeling. The most popular method to capture network data is to use graph-based methods  

使用了图论的论文：T-4 T-28 T-40 T-39

忽略了 T-ZS1 对 CNN, RNN 获取时空依赖这一段的描述，忽略了对 GNN 一段的描述

#### 模型解释能力

(T-ZS1) Explanatory power, associations and causality  解释力、关联、因果关系

模型参数难以理解，NN 是黑盒模型

参考上文具体技术，神经网络节的优缺点处

如：

- T-40 观察图扩散过程和邻节点关联

  observed the traffic diffusion along the road network and the correlation between several adjacent traffic sensors

- T-39 可视化网络权重以预训练不同探测器找到关键路段

  visualized the network weights pertaining to different detector sites to find key road segments in the traffic network

- T-4 可视化注意力权重上下流，观察交通流的移动

  visualized the attention weights of upstream and downstream stations to observe how traffic flow moves across several traffic stations

(T-ZS1) 解读参数的意义

Performing explanatory analyses on neural networks may uncover useful traffic patterns 

黑盒模型，只解释了空间方面的一部分内容

While neural networks have proven to be a very effective prediction model, they are infamously known as black-box models; models that are difficult to dissect and explain. Although the aforementioned authors managed to explain the traffic phenomena to some degree, their observations are mostly limited to the spatial aspect; observing how the traffic at one site affects another and how traffic propagates across the road network. To the best of our knowledge, there  is no work that observes other aspects of the prediction, such as the dynamics of abrupt weather changes and accidents.  

> ### 未来挑战

#### 缺乏基准数据集

Lack of a benchmark dataset

(T-ZS1) 难以对比，且同一数据集也有多个子集

The availability of a wide range of traffic data supports traffic prediction. However, this availability also poses a challenge to comparative work. Due to the fact that different works use different datasets, it is very hard to assess the relative performance of different state-of-the-art models. The Caltrans data is the closest to a benchmark dataset, as it is used by 14 out of 37 literatures we have covered. However, different works use different subsets of the Caltrans from different periods of time and from different traffic detector sites  

但选择大的子集存在训练代价困难，依赖复杂；选择小的子集难以拟合真实数据，在时空上分别讨论

Choosing a subset of data within a larger dataset also poses a challenge. As temporal and spatial correlation affects traffic greatly, the period of the data and the traffic detector locations become important considerations. For instance, when using data that covers a period of less than a year, there is a risk of not capturing the seasonal effects on traffic, and when using only weekdays data, the models cannot learn weekend traffic well. For the spatial aspect, the choice of roads or highways can greatly affect the traffic flow as metropolitan roads have significantly busier traffic compared to rural areas, and long interstate highways tend to cover both rural and metropolitan areas. Models that are trained on a certain traffic condition may not perform well when used to predict traffic on significantly different traffic

理想的基准数据集：城乡结合、工作日周末结合、一天各时段、至少一年

For deep neural network models to perform well on real applications, the dataset needs to mimic real data. Therefore, it is important for benchmark datasets to cover enough time frame and locations so that the models can generalize well to any traffic situations. To overcome this challenge, the following criteria are important:

- The data covers both urban and rural areas.
- The data covers both weekdays and weekends.
- The data covers all hours of the day.
- The temporal range is at least one year

#### 数据结合难

(T-ZS1) Difficulty of incorporating external information with traffic data

> 结合数据的困难：难以包含外部信息：天气、车祸、事件、星期、时刻、媒体信息
>
> (T-ZS1) one model that uses the Caltrans data covering a long highway will need to match the time stamp, the latitude, and the longitude of each reading in order to find the appropriate weather and accidents data  
>
> - 时间容易其他难：理由是需要和具体时空对应
>
>   While the inclusion of day of the week and time of the day is relatively simple, data that are bound to a specific geographical coordinate or a geographical area is difficult to incorporate with traffic data. This is because the process requires the coordinates of detection points (in the case of point data) or trajectory points (in the case of trajectory data) to be mapped to the secondary data
>
> 成本变大：
>
> (T-ZS1) added time complexity of aggregating the different data together , which is undesirable, especially in an already time-consuming hybrid deep neural network structure  

理想数据：时空覆盖广、增加时间、增加天气和事故

A benchmark data that covers a specific area within a specific period, complete with relevant secondary data will greatly benefit the traffic flow field. We recommend the following sequence of actions:

1) Establish a benchmark dataset that has sufficient spatial and temporal coverage based on the requirements mentioned in the previous challenge.
2) Add day of the week and time of day data by concatenating them with the traffic reading data.
3) Add geographical-related data, such as weather and accidents data to every traffic data reading. For instance, one reading at a particular time stamp and location will have both the traffic flow, current weather and accident type, if any accident occurs at the location.  

#### 在线学习

(T-ZS1) Online learning.

在线学习。持续更新应对 concept drift 的存在。现状：没有研究探索在线学习：但训练开销大，模型复杂难以更新。需要考虑更新频率和数据数目、更新所用时间。

> Concept Drift（概念漂移）指的是数据分布或数据生成过程发生变化的现象。训练与真实不一致就会概念漂移

In this setting where new data is incrementally added, traffic trends will shift over time. This is applicable even for the same traffic detector site. This idea is called concept drift and it causes the relationship between the input and output data to change over time, rendering models that are trained on past data to degrade in performance on present and future data  

> One way to mitigate this problem is to incrementally update the prediction model with new data in real-time, in a process often called online learning. However, to the best of our knowledge, there is no work that explores online learning in the traffic prediction domain. This can be attributed to the time complexity of training hybrid deep neural network model and the lack of attention to the concept drift problem. Online learning is a promising subtopic to explore in the field of traffic prediction as this will ensure that complex deep neural network models are always up-to-date. Experiments that seek to identify the viability of online training will need to take into account the following factors:
>
> - The frequency of which the deep neural network models need to be retrained. Practitioners need to ask the question “How often do we need to update our prediction model to ensure that it is always upto-date?”
>
> - The number of data points required for the update, which is affected by the frequency and has to reflect real life scenario. Practitioners need to ask the questions “How much data can we acquire during a certain period?” and “How long will it take to collect and preprocess the data to fit it into the prediction models?”  
>
> - The time required for the model to be re-trained using the specified number of data points and whether or not it is suitable for real life scenario. Practitioners need to ask the question “With the available amount of data, will the training of the model be fast enough such that daily operations are not hindered?”  

#### 其他领域任务

(T-ZS1) Exploring other traffic prediction tasks

其他领域问题。子问题/其他问题可能会启发该问题。如交通拥挤分析。

Currently, the Intelligent Transportation Systems (ITS) field greatly focuses on traffic flow prediction, neglecting the other traffic prediction tasks. Exploring these subproblems may bring new insights that are able to help the main traffic prediction task. As we mentioned before, deep neural network models are black-box models. Models that are trained on the traffic flow prediction may not be able to explain the intricacies of traffic patterns. Additionally, each of the subproblems is interesting by itself as its results can be directly used by drivers and traffic management bureau alike to make educated decisions. One example of these prediction tasks is traffic congestion analysis. Knowing how traffic congestion moves throughout the network can assist in the traffic prediction task  

#### 缺乏最新试验评估

(T-ZS1) Lack of up-to-date experimental evaluation  

> there is a lack of up-to-date and comprehensive experimental evaluation, making it difficult to assess how promising these specific ideas are  

缺乏最新试验评估 (最大的问题)。库简化了实现，每个论文实现了不同的想法，但没有综合的整理。缺乏基准数据集，代码有效性(可复现性)。

> Experimental evaluation in traffic flow prediction is complex due to two factors. The first is the lack of benchmark dataset, a problem that we have discussed above. The second is the lack of code availability. One might attempt to recreate the model from the author’s description. However, while the deep neural network aspect can be recreated relatively easy, novel components, such as graph diffusion, are difficult to build in a way that is faithful to the source material  
>
> This lack of experimental evaluation is perhaps the largest challenge that the traffic flow prediction community faces. Addressing this problem will enable practitioners to easily identify the effectiveness of new ideas in improving prediction performance, model efficiency, and the overall applicability of deep neural network models in real-time traffic prediction applications  
>
> 意义：
>
> We believe that the future of the traffic flow prediction field lies on determining a more standardized approach that ensures that the significance of every novel idea can be identified  
>
> 建议做法：开源
>
> to provide more transparency in this research field. Implementation details and publicly accessible codes will be necessary  

基准实验评估需要考虑：新想法的影响、CNN/RNN 类型的影响、应用性和重训练时间、外部数据如天气的作用(消融实验)

> A benchmark experimental evaluation needs to take into account the following insights:  
>
> - The impact of each model’s novel ideas to the prediction power, particularly for models that use a similar network structure.
> - The impact of using a certain neural network type such as CNN and RNN.
> - The viability in real life applications with respect to the retraining time. That is, online learning using a realistically sized batch of data, e.g. data from one week.
> - The impact of using external information such as weather and accidents data. This can be observed by performing an ablation test on models that utilize these external information  

#### 应用新技术

(T-ZS1) Applying Emerging Techniques   

## 写作技巧

根据阅读归纳：

论文作者人名：一个人就人名(姓)，两个人就 and，三个人就 et al.

中文也名在前，且名两个字只有第一个字大写首字母
