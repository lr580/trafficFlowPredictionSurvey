> 诸如 T-ZS1 的标号参见 Zotero 目录(如无请联系我获取)

## 背景介绍

### 背景

#### 交通系统

意义：

- (T-ZS2) Transportation systems are among the most important infrastructure in modern cities, supporting the daily commuting and traveling of millions of people.  

组成：

- (T-ZS2)  With rapid urbanization and population growth, transportation systems have become more complex. Modern transportation systems encompass road vehicles, rail transport, and various shared travel modes that have emerged in recent years, including online ride-hailing, bike-sharing, and e-scooter sharing.  

#### 交通拥堵

- 面临的主要问题

  (T-ZS1) Traffic congestion is a major problem faced by metropolitan cities -> Most congestion mitigation measures are costly, difficult to implement, or both.   
  
  > (T-ZS2) Expanding cities face many transportation-related problems, including air pollution and traffic congestion
  
- 指示：交通速度
  
  (T-ZS2) Traffic speed is another important indicator of traffic state with potential applications in ITS systems, The speed value on the urban road can reflect the crowdedness level of road traffic.  
  
- 其解决：交通预测
  
  (T-ZS1) Educated traffic decision made through accurate prediction is a far cheaper and easier to implement alternative for reducing road congestion  
  
  > (T-ZS1) Traffic flow prediction is one of the easiest and cheapest measures to address traffic congestion  
  
  > (T-ZS2) Traffic forecasting is important for the success of intelligent transportation systems  
  >
  > (T-ZS2) Early intervention based on traffic forecasting is seen as the key to improving the efficiency of a transportation system and to alleviate transportation-related problems  

#### 应用前景

##### 交通流量

交通流量应用面：拥挤控制、信号灯控制等

(T-ZS2 描述 T-ZS10 说的) An accurate traffic flow prediction is beneficial for a variety of applications, e.g., traffic congestion control, traffic light control, vehicular cloud

> 如，交通灯可以减少车辆停留时间，优化交通流，减少交通拥挤和排放
>
> (T-ZS2) For example, traffic light control can reduce vehicle staying time at the road intersections, optimizing the traffic flow, and reducing traffic congestion and vehicle emission.  

(T-ZS3 图2) 更快出行，道路容量增加，交通管理，智慧城市，减少污染，增加交通效率，道路安全 (虽然我觉得有几点是乱扯)

reduce congestion, faster travel times, increase roads capacity, urban traffic management, planning of smart cities, reduced pollution, enhance traffic efficiency, more safe roads

(T-ZS32 图2) 红绿灯优化、导航、智慧交通、安全应急、城市规划

<img src="img/image-20240809114536522.png" alt="image-20240809114536522" style="zoom:67%;" />

##### 交通速度

交通速度：预测拥堵(Google 为例)，路径规划，到达时间评估

(T-ZS2) For example, Google Maps visualizes this crowdedness level from crowd-sourcing data collected from individual mobile devices and in-vehicle sensors. A better traffic speed prediction is also useful for route navigation and estimation of-arrival applications  

> (T-ZS2) **Travel time prediction** is useful for passengers to plan their commuting time and for drivers to select fast routes, respectively. **Traffic congestion** is one of the most important and urgent transportation problems in cities, which brings significant time loss, air pollution and energy waste. The congestion prediction results can be used to control the road conditions and optimize vehicle flow, e.g., with traffic signal control  

##### 交通需求

(T-ZS2) 服务商资源分配，用户合理选择

Traffic demand prediction is a key component for taxi and ride-hailing services to be successful, which benefits these service providers to allocate limited available transportation resources to those urban areas with a higher demand.

For passengers, traffic demand prediction encourages the consideration of various transportation forms, e.g., taking the public transit service when taxi or ride-hailing services are in short supply

(T-ZS2) 现状例子及其重要性

For example, on an online ride-hailing platform, the ride requests sent by passengers represent the demand, whereas only a subset of these requests may be served depending on the supply of drivers and vehicles, especially during rush hours. Accurate prediction of travel demand is a key element of vehicle scheduling systems (e.g. online ride-hailing or taxi dispatch platforms)

##### 交通异常

交通延迟的主要原因，可以助于决策制定

(T-ZS2) the target is to predict the traffic accident number reported to the police system. Traffic anomaly is the major cause of traffic delay and a timely detection and prediction would help the administrators to identify the situation and turn the traffic situation back to normal as quickly as possible    

##### 交通排放

拥堵会增加排放

(T-ZS2) Urban vehicle emission is a major source of air pollutants and its amount is affected by different traffic states, e.g., the excess emission would be created in traffic congestion situations.  

#### 真实数据

- 交通拥挤的代价

  (T-ZS1) In 2015, it is estimated that the avoidable cost of traffic congestion for Australian capital cities is approximately \$16.5 billion, up from the 2010 estimate of \$12.8 billion. Furthermore, this value is estimated to increase to about $30 billion by 2030

  > [参考 Cosgove D. Traffic and congestion cost trends for Australian capital cities[J]. Canberra: Department of Infrastructure and Regional Development, Bureau of Infrastructure, Transport and Regional Economics, 2015.](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Cosgove%2C+Traffic+and+congestion+cost+trends+for+Australian+capital+cities&btnG=#d=gs_cit&t=1721488944765&u=%2Fscholar%3Fq%3Dinfo%3ACPeX2qr_RW8J%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Dzh-CN)

- 交通监管政策

  (T-ZS1) Singapore implemented regulations on the number of vehicles on roads -> which is infeasible for countries with poor public transportation systems

  > [参考 “Singapore to freeze car numbers,” https://www.bbc.
  > com/news/business-41730778, accessed: 20 November
  > 2018](https://www.bbc.
  > com/news/business-41730778)

- 修路成本

  (T-ZS1) the estimated per mile cost of a standard one lane road in New Jersey, USA is $220,490 -> Constructing new roads to ease congestion is also difficult due to the extremely high cost  
  
  > [参考 J. Carnegie and A. M. Voorhees, “The cost of roadway
  > construction, operations and maintenance in new jersey,” pp. 557–566, 2016.  ](https://trid.trb.org/View/1408290)
  
- 城市人口预测

  (T-ZS32) the majority of people resides in urban areas and a percentage that is predicted to rise by 13% by 2050.
  
- 拥堵率

  (T-ZS35) 60% 中国主要城市高峰时段拥堵增加

#### 前置条件

##### 数据获取

- 传感器的普及 -> 大数据获取

  (T-ZS1) With the advancements and widespread adoption of traffic sensors, access to large traffic databases is now available.  -> This has led to the development of traffic prediction as a research field. 
  
  > With the widespread installation of traffic loop detectors, traffic data will continuously grow 
  
  数据源
  
  (T-ZS2) In the development and operation of smart cities and intelligent transportation systems (ITSs), traffic states are detected by sensors (e.g. loop detectors) installed on roads, subway and bus system transaction records, traffic surveillance videos, and even smartphone GPS (Global Positioning System) data collected in a crowd-sourced fashion.  
  
  大数据的介绍：(说引用自另外的文献)
  
  (T-ZS30) the five characteristics of big data, referred to as 5 V features, including large volume, large velocity, large variety, veracity, and value. The 5 V features highlight the notable increase in data volume. Specifically, traffic data is a sort of big data  

##### 库

- 库 

  (T-ZS1) Due to the availability of deep neural network libraries such as Keras, PyTorch , and TensorFlow, development of complex neural network models has become much easier  

  > The introduction of deep neural network libraries such as Keras, PyTorch and TensorFlow has simplified the implementation of complex hybrid deep neural network models. As we have observed, this has resulted in numerous unique hybrid structures, each focusing on specific ideas to improve prediction performance  

  (T-ZS2) Several open source frameworks for implementing general deep learning models, most of which are built with the Python programming language, can be accessed online, e.g. TensorFlow, Keras, PyTorch, MXNet, Additional Python libraries designed for implementing GNNs are available. These include DGL, pytorch\_geometric, and Graph Nets.

  分别是：

  > 17 https://www.tensorflow.org/
  > 18 https://keras.io/
  > 19 https://pytorch.org/
  > 20 https://mxnet.apache.org/
  > 21 https://www.dgl.ai/
  > 22 https://pytorch-geometric.readthedocs.io/
  > 23 https://github.com/deepmind/graph_nets  

  最常用：TensorFlow 和 PyTorch

  (T-ZS2) TensorFlow and PyTorch are the two frameworks that are used most frequently  

### 问题定义

> #### 交通预测

#### 概念

##### 描述

描述：

(T-ZS1)  Future traffic prediction involves creating a prediction model from historical traffic data to predict the short-term future traffic state ranging from 5 to 60 minutes into the future

> (T-ZS2) 相关数据类型：Traffic forecasting is typically based on consideration of historical traffic state data, together with the external factors which affect traffic states, e.g. weather and holidays  

##### 特点

特点：

> 交通预测与其他时序分析的不同在于：
>
> - 一个地点可能影响另一个地点
> - 空间依赖
> - 存在全局外部因素如天气、节假日、交通事故等
> - 数据高维

(T-ZS1)  Traffic prediction is different from conventional time-series analysis in that traffic prediction is subject to **spatial** as well as many **other** external factors.  the prediction of traffic at one site depends on the traffic at other sites and all of the sites are affected by external factors such as weather and holidays.  

> (T-ZS2) The traffic forecasting problem is more challenging than other time series forecasting problems because it involves **large  data** volumes with high dimensionality, as well as **multiple** dynamics including emergency situations, e.g. traffic accidents 
>
> (T-ZS2) The traffic state in a specific location has both **spatial** dependency, which may not be affected only by nearby areas, and **temporal** dependency, which may be seasonal.  
>
> (T-ZS2) Generally speaking, traffic forecasting problems are challenging, not only for the complex **temporal** dependency, but only for the complex **spatial** dependency.  

(T-40 图1)

![image-20240817003909585](img/image-20240817003909585.png)

Figure 1: Spatial correlation is dominated by road network structure. (1) Traffic speed in road 1 are similar to road 2 as they locate in the same highway. (2) Road 1 and road 3 locate in the opposite directions of the highway. Though close to each other in the Euclidean space, their road network distance is large, and their traffic speeds differ significantly.

来回的不同：上班、下班的方向不一样 T-250

![image-20240912135200319](img/image-20240912135200319.png)

##### 时空特点

相互影响

(T-ZS2 说 [T-81](https://ojs.aaai.org/index.php/AAAI/article/view/3881) 说的) As for the traffic problems, the spatial and temporal dependencies are closely intertwined in reality. For example, it is argued that the historical observations in different locations at different times have varying impacts on central region in the future  

(T-64 图1) 空间影响的直观图示

<img src="img/image-20240817220918943.png" alt="image-20240817220918943" style="zoom:67%;" />

##### 动态性

也可以参考 GNN 里的动态图静态图

> T-129 说的时间动态：
>
> A limitation of current casual-embedded traffic prediction models is the assumption of stationary temporal dependencies. However, in reality, the dependencies of traffic data in different places do change over time

##### 严格定义

定义：使用可学习的函数，使用历史交通数据输入，预测未来交通

(T-ZS1) Traffic prediction concerns the usage of a learnable function that takes as input the historical traffic data from several previous time-steps in order to predict the traffic in the future.  

> 近义句 Traffic prediction is a task of training an arbitrary function to predict future traffic given past traffic data  

> 还有其他，参考下文

$$
\hat y_{t+T'}=f([X_{t-T+1},X_{t-T},\cdots,X_t])
$$

目标：找到模型参数，最小化误差：

The objective is to find the model parameters which minimize the error between the predicted traffic and the observed traffic:  
$$
\theta^*=\arg\min_{\theta^*}L(y_{t+T'},\hat y_{t+T'};\theta^*)
$$

> 其中 $y_t$ 是时间 $t$ 的观察值，$\hat y_t$ 是预测值，$T$ 是输入序列长度，$T'$ 是预测范围，$L$ 是损失函数，$f$ 是任意函数，$\theta^*$ 是最优参数。
>
> - The observed traffic at time $t$
> - The predicted traffic at time $t$
> - Input sequence length, i.e., how many time steps of past traffic data are used as the input 
> - Prediction horizon, i.e., how many time steps in the future the prediction is for 
> - An arbitrary function that calculates the traffic prediction based on the input data  
> - Loss function, which is the function that calculates the quality of the prediction
> - The optimal set of parameters for the function $f$

(T-ZS30, T-ZS38, T-ZS29) 有单步和多步的定义

(T-40, T-136, T-ZS27) 有多步定义 (T-136 我觉得不错, T-ZS29 比较简要)

> T-ZS29 

(T-28) 有基于条件概率的多步定义

#### 目标类型

##### 综述

(T-ZS1)

- 交通流量 某地某段时间车辆总数

  (T-ZS1) Traffic flow is denoted as the total number of vehicles detected in a target detection site during a certain time period. 

  (T-ZS2) Traffic flow is defined as the number of vehicles passing through a spatial unit, such as a road segment or traffic sensor point, in a given time period  

- 交通速度 某地某段时间各车辆平均速度

  (T-ZS1) Traffic speed is denoted as the average traveling speed of vehicles detected in a target detection site during a certain time period
  
  (T-ZS2) is defined as the average speed of vehicles passing through a spatial unit in a given time period  

其他类别：

- 交通状况 
  
  (T-ZS1) T-4 traffic condition, which consists of four categories: fluency, slow, congestion and extreme congestion  
  
- 人流量 
  - (T-ZS1) T-51 [T-30](https://www.researchgate.net/profile/Leye-Wang/publication/322886199_Crowd_Flow_Prediction_by_Deep_Spatio-Temporal_Transfer_Learning/links/5aa9bd6b0f7e9b88266f6529/Crowd-Flow-Prediction-by-Deep-Spatio-Temporal-Transfer-Learning.pdf) crowd flow instead of traffic flow: Crowd flow measurements are the same as traffic flow, but they are designed for general human mobility instead of automobile mobility  
  - (T-ZS1) [T-31](https://dl.acm.org/doi/abs/10.1145/3292500.3330646) 细粒度而不是历史数据的  a fine-grained prediction is performed using a coarser data (e.g., predicting crowd flow of different school buildings given crowd flow of the entire university area) instead of using historical data
  
- 红绿灯：影响时空依赖

  (T-ZS2) The traffic light is another source of challenges for various traffic prediction tasks.  

  Short-term traffic flow fluctuation and the spatial relation change between two road segments can be caused by the traffic light. The way of controlling the traffic light may be different in different time periods, causing an inconsistent traffic flow pattern.  
  
- (T-ZS2) 交通需求：如打车服务需求量 (前景应用见上文)

- (T-ZS2) 交通事故，交通异常 Traffic accident and Traffic anomaly  

  定义：A traffic accident is usually an accident in road traffic involving different vehicles, which may cause significant loss of life and property.  

  The traffic anomaly has a broader definition that deviates from the normal traffic state, e.g., the traffic jam caused by a traffic accident or a public procession  

- (T-ZS2) 车位空余

  Parking availability: the target is to predict the availability of vacant parking space for cars in the streets or in a car parking lot

- (T-ZS2 描述 [T-65](https://ieeexplore.ieee.org/abstract/document/9151256)) 车辆排放

  Urban vehicle emission refers to the emission produced by motor vehicles, e.g., those use internal combustion engines.   

- (T-ZS2 描述 [T-66](https://ieeexplore.ieee.org/abstract/document/9294742)) 交通延迟

  Railway delay: the delay time of specific routes in the railway system

- (T-ZS2 描述 [T-67](https://ieeexplore.ieee.org/abstract/document/8917174)) 车道占用

  Lane occupancy: With simulated traffic data, lane occupancy has been measured and predicted  

T-ZS29  可以同时解决多个问题：如流量+速度

For univariate time series problems, only one traffic variable is considered, such as traffic flow or traffic speed. For multivariate time series problems, multiple traffic variables are considered simultaneously

##### 交通流量

可以分为无向流、双向流、入流、出流。

(T-ZS2) Road-level traffic flow problems are further divided into cases of unidirectional and bidirectional traffic flow, whereas region-level and station-level traffic flow problems are further divided into the cases of inflow and outflow, based on different problem formulations.  

(T-110 图)

![image-20240819010513289](img/image-20240819010513289.png)

T-ZS29 交通流量和速度仍然是最受欢迎的问题的原因

- The first reason is that for the road traffic forecasting problem, open datasets and baseline models are more accessible with well-processed steps and instructions, which saves the workload of data collection and preprocessing. 
- The second reason is that building graphs for road-network-related problems is more intuitive, making it more natural to use GNNs to solve road traffic flow and speed prediction problems, and thus more common in the scope of our investigation.

##### 人流量

T-ZS44 一般是在网格里，统计 inflow / outflow，定义为：
$$
x_t^{in,i,j}=\sum_{T_r\in\mathbb P}|\{k>1|g_{k-1}\not\in(i,j)\wedge g_k\in(i,j)\}\\
x_t^{out,i,j}=\sum_{T_r\in\mathbb P}|\{k\ge1|g_k\not\in(i,j)\wedge g_{k+1}\in(i,j)\}
$$
其中 $T_r:g_1\to g_2\to\cdots\to g_{|T_r|}$ 是轨迹路径，$g$ 是坐标。所有网格的 $x$ 的出入流组成 $(2,I,J)$ 的张量 $X$。预测任务是给定历史 $X_t(t\le n-1)$，求 $X_n$



##### 交通需求

定义：

(T-ZS2) Traffic demand refers to the potential demand for travel, which may or may not be fulfilled completely. 

数据：使用用户数据推断，可能低估真实数据

(T-ZS2) However, in some cases, it is difficult to collect the potential travel demand from passengers and a compromise method using transaction records as an indication of the traffic demand is used. In such cases the real demand may be underestimated.  

分类：

(T-ZS2) Based on transport mode, the traffic demand problems considered include ride-hailing demand, taxi demand, shared vehicle demand, and bike demand.  

如 [T-198](https://www.mdpi.com/1099-4300/24/9/1193)

T-ZS26: 利用格兰杰因果关系与基于熵理论的 MIC 方法相互验证， 得到有助于预测共享单车需求的解释变量相互验证，并使 用 TCN 和 GRU 实现了共享单车短期需求预测 (伦敦 london)

##### 交通拥挤

如 [T-191](https://ieeexplore.ieee.org/abstract/document/9082667)

T-ZS26: 使用CNN将交通图像映射到低维空间，通过LSTM学习时序特征，然后使用反卷积（TransposeCNN）对特征提取后的数据进行网络重建以生成预测图像，预测结果优于Conv-LSTM模型

##### 交通占用

traffic occupancy prediction problem T-ZS29 有一整段话描述其不适用 GNN 等的原因

#### 道路类型

##### 综述

(T-ZS2) 分类原因：表征空间依赖的模型要求不一样

Different problem types have different modelling requirements for representing spatial dependency

(T-ZS2) 分类为：道路、区域、站点等级

These include road-level, region-level, and station-level categories.  

- 道路：探测器 -> 路段 / GPS 轨迹(映射为路网)，路网连接+空间近似性

  For the road-level problems, the traffic data are usually collected from sensors, which are associated with specific road segments, or GPS trajectory data, which are also mapped into the road network with map
  matching techniques. In this case, the road network topology can be seen as the graph to use, which may contain hundreds or thousands of road segments potentially. The spatial dependency may be described by the road network connectivity or spatial proximity  

- 站点：地铁/车站拓扑图，数十数百个点，地铁公交线路图为空间依赖

  For the station-level problems, the metro or bus station topology can be taken as the graph to use, which may contain tens or hundreds of stations potentially. The spatial dependency may be described by the metro lines or bus routes  

- 区域：规则或不规则区域为节点，依赖：土地使用目的，POI 等获取

  For the region-level problem, the regular or irregular regions are used as the nodes in a graph. The spatial dependency between different regions can be extracted from the land use purposes, e.g., from the points-of-interest data  

##### 细分

(T-ZS2) 交通流按道路类型细分：

- 道路级：交通流、OD 流、路口吞吐量

  Road-level flow problems are concerned with traffic volumes on a road and include road traffic flow, road origin-destination (OD) Flow, and intersection traffic throughput.

  - 某个传感器位置

    In road traffic flow problems, the prediction target is the traffic volume that passes a road sensor or a specific location along the road within a certain time period (e.g. five minutes)

  - 某个起止点

    In the road OD flow problem, the target is the volume between one location (the origin) and another (the destination) at a single point in time. 

  - 某个交叉路

    The intersection traffic throughput problem considers the volume of traffic moving through an intersection

- 区域级：规则或不规则区域

  Region-level flow problems consider traffic volume in a region. A city may be
  divided into regular regions (where the partitioning is grid-based) or irregular regions (e.g. road-based or zip-code-based partitions). 

  These problems are classified by transport mode into regional taxi flow, regional bike flow, regional ride-hailing flow, regional dockless e-scooter flow, regional OD taxi flow, regional OD bike flow, and regional OD ride-hailing flow problems  

- 站点级：

  Station-level flow problems relate to the traffic volume measured at a physical station, for example, a subway or bus station. These problems are divided by station type into station-level subway passenger flow, station-level bus passenger flow, station-level shared vehicle flow, station-level bike flow, and station-level railway passenger flow problems  

(T-ZS2) 交通速度划分：道路速度、区域级速度、旅行时间、拥堵预测

- 交通拥挤和道路交通速度细分

  (T-ZS2) In several studies, traffic congestion is judged by a threshold-based speed inference. 

  The specific road-level speed problem categories considered are road traffic speed, road travel time, traffic congestion, and time of arrival problems; 

  while the region-level speed problem considered is regional OD taxi speed  

- 高速公路的速度预测相对简单：没有红绿灯、上下坡

  Freeways have a few traffic signals or on/off-ramps, making the prediction easier than the urban case.  

  挑战来自于时间依赖

  And the challenge mainly comes from the complex temporal dependency  

- 城市区域：突发变化、复杂连接、限速、空间依赖

  More complex traffic networks exist in urban roads with more complicated connection patterns and abrupt changes. For example, different road segments may have different speed limit values and the allowed vehicle types. Besides the complex temporal dependency, modeling the spatial dependency becomes a bigger challenge for urban traffic speed forecasting.  

(T-ZS2) 感觉分的太细了：

> - Road Traffic Flow
> - Road OD Flow [Origin-Destination] 仅 2 篇
> - Intersection Traffic Throughput (吞吐量) 仅 1 篇
> - Regional Taxi Flow 几篇
> - Regional Bike Flow 3 篇
> - Regional Ride-hailing Flow (打车) 仅 1 篇
> - Regional Dockless E-Scooter Flow (无桩电摩) 仅 1 篇
> - Regional OD Taxi Flow 仅 2 篇
> - Regional OD Bike Flow 仅 1 篇
> - Regional OD Ride hailing Flow 3 篇
> - Station-level Subway Passenger Flow  近 10 篇
> - Station-level Bus Passenger Flow  3 篇
> - Station-level Shared Vehicle Flow 仅 1 篇
> - Station-level Bike Flow 仅 2 篇
> - Station-level Railway Passenger Flow  仅 1 篇
> - Road Traffic Speed 最多
> - Road Travel Time 几篇
> - Traffic Congestion 几篇
> - Time of Arrival 仅 1 篇
> - Regional OD Taxi Speed 仅 1 篇
> - Ride-hailing Demand 几篇
> - Taxi Demand 十几篇
> - Shared Vehicle Demand 仅 1 篇
> - Bike Demand 十几篇
> - Traffic Accident 3 篇
> - Traffic Anomaly 仅 1 篇
> - Parking Availability 3 篇
> - Transportation Resilience (弹性) 仅 1 篇
> - Urban Vehicle Emission 仅 1 篇
> - Railway Delay 仅 1 篇
> - Lane Occupancy 仅 1 篇

#### 评价指标

##### 准确率

###### 定义

> (T-ZS2) Some commonly used evaluation metrics, namely, RMSE, MAE and MAPE, are defined as follows:  (下文公式符号与论文有所差异)
>
> (T-ZS2) root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE)  
>
> (T-ZS28) 中文分别为平均绝对误差、根均方误差、平均绝对百分比误差

设 $y$ 是实际值，$\hat y$ 是预测值，$n$ 是样本数
$$
\begin{cases}
RMSE=\sqrt{\dfrac1n\sum_{i=1}^n(y_i-\hat y_i)^2}\\
MAE=\dfrac1n\sum_{i=1}^n|y_i-\hat y_i|\\
MAPE=\dfrac{1}n\sum_{i=1}^n\left|\dfrac{y_i-\hat y_i}{y_i}\right|
\end{cases}
$$

> where y denotes the true values, ^y denotes the predicted values, and n is the number of values to predict.   

(T-ZS2) 含义：RMSE/MAE 越低，表现越好

> A lower RMSE or MAE value indicates a better prediction performance  



T-ZS29 指标的不同会影响模型对比

Due to the different evaluation metrics and forecast horizons, it is nearly impossible to fairly compare all surveyed studies and quantify the difficulty of the available datasets.

###### 其他不常用准确率指标

> (T-ZS35) 还有 MSE，就是没有根号

T-166 

> The R2 score or the coefficient of determination expresses the distribution of the variance of actual labels that the independent variables in the model have interpreted. The best R2 score is 1, and it measures the model’s capability to predict new data correctly

$$
R^2=1-\dfrac{\sum_{t=1}(y_t-\hat y_t)^2}{\sum_{t=1}(y_t-\overline y_t)^2}
$$

> Explained variation measures the proportion of model variation influenced by actual factors in the data rather than the error variance

$$
VAR=1-\dfrac{Var(y_t-\hat y_t)}{Var(y)}
$$

> Accuracy: Accuracy describes how close the model prediction is to the actual values, whereby a perfect accuracy would result in a score of 1

$$
Accuracy=1-\dfrac{||y-\hat y||_F}{||y||_F}
$$





> ##### 评价
>
> (T-ZS2 说 T-ZS1 说的) 因为用不同的数据集，所以难以衡量 SOTA
>
> It is known that different works use different datasets and it is very hard to assess the relative performance of different state-of-the-art models  
>
> 同一数据也可能不同子集

##### 性能

训练时间，预测时间衡量模型是否足够轻量化之类的

根据阅读具体论文，许多论文虽然准确率只提升一些，但是速度可以快一倍这样，这也是一种提升，如 T-135

可以用参数量如 T-110

## 现有综述

### 列表

##### 完整读过的

- T-ZS1

  CNN, RNN, FNN 2014-2019

- T-ZS2

  GNN 综述，2018-2020 (212论文)
  
- [T-ZS29](https://www.mdpi.com/2220-9964/12/3/100)

  T-ZS2 的正统续作，研究了 2022 的其他论文，列举了到 2023-2 为止的论文

##### 较完整读过的

- [T-ZS25](https://kns.cnki.net/kcms2/article/abstract?v=zLXkCTFmbAE0kiBiuRwo43mnAPv-R_ASfI6CgqtMR3zj_43SjyOTlvGD1iOASGiFU80MD6K4pd5Ormzx1MgcxP_9iprx62eGFql9DNVEPGfAf7_gd8TfHMvnla9tV6KS1Cfa87s8HL7ZAV7uj2RS7_c5zffroQJ59bwB5YRmZMPZgZs5yGzo_XerdqFM7tbGGNbogxDcESA=&uniplatform=NZKPT&language=CHS)

  中文国内综述，2023 发的，但引用的都是 2020 或以前为主，其相关技术介绍部分可以读，已经把 RNN 和 GNN 部分具体论文整理了

- [T-ZS26](https://kns.cnki.net/kcms2/article/abstract?v=zLXkCTFmbAHQsgkv3Z5hR3gzXma6lYxfCt6KHiMGCj6XF9KOgBA5h7Ba9G_a-N49FAW1pI0ZF9Jbau4sJDZZklmHyMEvb0Bno58PXXshhRTHYFPplpjPh5Gjw0eanMFbjgHUi7ubbN1uQW_YHvDKvaHkKpkZWdlbxTAChnY0-ZERhM_Updl-ny5s550R9g-0Qaadz6lq_1k=&uniplatform=NZKPT&language=CHS)

  中文，给出了公开数据集的下载链接列表和部分介绍

  虽然引用了一些近几年(2019-2022,也有一部分2023)的论文，但是没有做系统的介绍和对比；已经整理了部分引用较高的论文，丢弃了久远冷门的

- [T-ZS27](https://kns.cnki.net/kcms2/article/abstract?v=zLXkCTFmbAEVIf30YEPWb5SUyGnQEDWOxW148qzMF8BbjFczUk4xY6mmbLBOPFd4_--SluXrQNbMqJ5ooZiKn_ec2fVsDu1sN4OfqFbD7tWBcynHZughZYhAZCbfJ1fN7CsNTOm-5mcA5HBMNG1ibHA4-cO4YxkGe-y3KrgUftfnl67WiNW2HvMaexqIVfqs3yTF07-xlcySi-x1wx5GuA==&uniplatform=NZKPT&language=CHS)

  中文，给了一个按技术场景和数据库主题分类的列表文章汇总，年份大约到 2022 年，不新，但是不知道对比结果；论文的介绍很简略，参考价值不大

- [T-ZS28](https://kns.cnki.net/kcms2/article/abstract?v=zLXkCTFmbAGbEBcbq4eDAo3k2DEo3Fsplf6RYMh_a0JPj_N2Uk7TSuSi33CoCnLOGUfG4jFGPG63P0GDtIJEZciu9OaN8MEA2a3F-2U8pLMT2v-M-Eva6MBbAE0TtTEcK1H2o4CrNkOCv8zDb-UVkl9YUUqE9OM_uRwSq7Em7Kgj4PX_AS0Gewc3JxQJlHnecBWt1q2x5vY=&uniplatform=NZKPT&language=CHS)

  中文，讲 GNN 的，有一个 GNN 的模型论文的分类归纳总结表格，实验结果，数据表(没给出处) ，2021 年左右多

- [T-ZS37](https://kns.cnki.net/kcms2/article/abstract?v=yQB21MkjwM8r7VSCFl4R_R0TQjr59IRayu-seXUC7-xY2JRr5EWzAgVQOAbaWuS4KDJp9FwiDgOuCWhNuntH2Ek0XZX987H1yEUwOYOmRb96IYGbqCdgbkUTsoYxZXLQDWXqAbWfaS8qae-4ibLsizj3lfNvicEQviou9qr3GwSewc2n5J5NKi1Z-6Tl2J3ANIYBQktwP8f8CMEfX0IdMldKD_CAcsOHWtO2unjtcaUj3vYCulDsStnMgDQCBe7NKbW88x7R17IbSKndD4ROwePZAFcPEElFKplxgobsDwo9Ys92bM1as7MgfxCxpAF7n89dKdlr5CJn-H0w4DeKKf5b2by0A2tp6AJrDQiESjaQJx526QkViV9a3YumQQc8usgc3dgyg3rBSnzg49melcAlA8LzDIYmzVju2tUBvc0w9Cq6yxeoAFAASPmxD1aiNyl4WE90M03S8hlu3q5mmICURHwNJ7uO6SwJtaq7jMDXcbws5A11mXslGJioesrzariMosF4O_Y7YZjwZwf2ysqPofK4rZ9-HcY7INTOz0IIYs_xi1k1w2PKec5sN6nPq5Ztrk0HddQ=&uniplatform=NZKPT&language=CHS)

  中文，论文和对比结果不多，有新的，有 GNN + 各种东西的详细介绍

##### 粗略读过 / 浏览的

- T-ZS3

  ML 综述，2023 发的，质量不行，主要总结 2019-2020 的引用低的论文

- T-ZS24

  GNN 综述，2023 发的，但是叫 urban computing，对 GNN 技术介绍比较多，对交通的应用只给了一小部分例子论文之类的，感觉作用不大
  
- [T-ZS30](https://link.springer.com/article/10.1007/s41019-024-00246-x)

  2024 写的，描述的论文不多，但比较新，也有可参考之处
  
- [T-ZS32](https://ieeexplore.ieee.org/abstract/document/10522180)

  2023 的论文收录较多，感觉有参考价值
  
- [T-ZS33](https://ieeexplore.ieee.org/abstract/document/10401928)

  可以参考这里对交通速度和流量关系的描述，其他讲智能交通和多任务学习的感觉关系不大

- [T-ZS34](https://ieeexplore.ieee.org/abstract/document/10411651)

  GNN 的，年份大约主要是 2022 的，但是感觉描述不详细，分别对时空要点进行了总结

- [T-ZS35](https://ieeexplore.ieee.org/abstract/document/10562041)

  LSTM 的，年份有到 2023 的近年较多 LSTM+XXX 论文，挑战部分也可以参考一下
  
- [T-ZS38](https://ieeexplore.ieee.org/abstract/document/10535113)

  论文不是很新，时空分类和技术细分可以看一下
  
- [T-ZS44](https://www.mdpi.com/2071-1050/16/5/1818) CI-0

  讲 urban flow 即 crowd + traffic，看了一些问题定义和数据集统计

##### 没读过的

- [T-ZS23](https://www.sciencedirect.com/science/article/pii/S0968090X14000096)

  statistical, neural network, hybrid model 2006-2013

  time series, function approximation 浏览了一下，深度学习较少

  提出了十个挑战，为 T-ZS1 所继承

- [T-ZS4](https://www.sciencedirect.com/science/article/pii/S1574119217306521)

  浏览了一下，对深度学习介绍很少，传统方法介绍篇幅很多

- [T-ZS5](https://ieeexplore.ieee.org/abstract/document/8344848/)

  浏览了一下，主要讲大数据技术，感觉相关性不大

- [T-ZS6](https://www.sciencedirect.com/science/article/pii/S0968090X10001610)

  读摘要，对比统计方法和 NN

- [T-ZS7](https://dl.acm.org/doi/abs/10.1145/3231541.3231544)

  没搞到 pdf，只读了摘要，NN 相关 2018

- T-ZS8

  年份太久远了 2004

- [T-ZS9](https://www.sciencedirect.com/science/article/pii/S1389128620311567)

  浏览摘要，分成统计和摘要方法，2020

- [T-ZS10](https://www.sciencedirect.com/science/article/pii/S1389128620311877)

  浏览摘要都在说 ML，2020

- [T-ZS11](https://link.springer.com/article/10.1007/s11277-020-07612-8)

  浏览摘要有 ML/DL，2020

- [T-ZS12](https://link.springer.com/article/10.1007/s42421-020-00020-1)

  浏览摘要有 DL，2020

- [T-ZS13](https://ieeexplore.ieee.org/abstract/document/9395529)

  浏览摘要有 DL，2021

- [T-ZS14](https://iris.cnr.it/bitstream/20.500.14243/380062/1/prod_438502-doc_157210.pdf)

  浏览摘要有数据源、DL、挑战，2020

- [T-ZS15](https://ieeexplore.ieee.org/abstract/document/9447807)

  浏览摘要有 DL 和实验，2021

- [T-ZS16](https://link.springer.com/article/10.1186/s12544-019-0345-9)

  摘要说特征选择和提取方法，1984-2018.3

- [T-ZS17](https://arxiv.org/abs/1808.06865)

  摘要说是时空序列预测，2018

- [T-ZS18](https://link.springer.com/article/10.1007/s42421-020-00030-z)

  摘要说研究影响 DL 精度的因素，评价指标等，2020

- [T-ZS19](https://www.sciencedirect.com/science/article/pii/S1566253519303094)

  摘要说影响因素，数据预处理，分类为统计、ML、DL、迁移、强化，2020，引用 260

- [T-ZS20](https://ieeexplore.ieee.org/abstract/document/9310691/)

  摘要说 GNN 综述，2020

- [T-ZS21](https://ieeexplore.ieee.org/abstract/document/9352246)

  摘要说有数据集，比较实验，挑战，2020

- [T-ZS22](https://link.springer.com/article/10.1007/s42486-020-00039-x)

  摘要说是 ITS, DL，2020
  
- [T-ZS31](https://dl.acm.org/doi/abs/10.1145/3459637.3482000)

  (T-ZS30) 说是三种分类：网格、图、多变量时序
  
- [T-ZS36](https://shodhganga.inflibnet.ac.in/handle/10603/522607?mode=full)

  只看了参考文献，看年份大部分很旧，感觉没必要读
  
- [T-ZS39](https://www.sciencedirect.com/science/article/pii/S2667305323000935)

  浏览了表格，感觉引用的论文比较旧

- [T-ZS40](https://arxiv.org/abs/2403.07444)

  讲联邦学习，论文还是比较新的

- [T-ZS41](https://ieeexplore.ieee.org/abstract/document/10444919)

  讲智能交通的，相关论文太少了，感觉没必要读

##### 无关综述

自己搜的：

- Forecasting Network Traffic: A Survey and Tutorial With Open-Source Comparative Evaluation

  研究网络的(如 wifi, TCP, 5g)

- Graph-based Time-series Forecasting in Deep Learning

  浏览了目录，感觉关系不大，不必要读

### 评价

#### 论文互评

评价/内容概述

- T-ZS1 只关心 DL，encoder-decoder LSTM+GNN SOTA；介绍了数据类型、DL 结构、挑战

  (T-ZS2 评价) only focus on the progress of deep learning-based methods

  The authors conclude that encoder-decoder long short term-memory (LSTM) combined with graph-based methods is the state-of-the-art prediction technique

  A detailed explanation of various data types and popular deep neural network architectures is also provided, along with challenges and future directions for traffic prediction  

- T-ZS23

  (T-ZS1 评价) 分类老旧、深度学习少

  do not include the now ubiquitous deep neural network models

  their work categorized the models based on several criteria such as the type of model (e.g. statistical, neural network, hybrid model) and the problem (e.g. time series, function approximation). This taxonomy is outdated because modern traffic prediction models are mainly based on deep neural network, which under their taxonomy will all fall under the neural network category of model and function approximation category of problem  

- T-ZS4

  (T-ZS1 评价) 分类比较少、没讨论挑战

  their model taxonomy only has a few points of comparison, which are: whether or not the model integrates environmental data, contains spatial property, handles nonlinearity and handles nonstationarity  

  Additionally, their work does not have a future challenges section that discusses how the field can be advanced  

- T-ZS5

  (T-ZS1 评价) 与机器学习关联不大

  their work focuses on big data analytics without much focus on the actual models  
  
- T-ZS10

  (T-ZS2 评价) 分类了 ML：回归、基于例子的(kNN)、基于核的(SVM, RBF)、NN、混合模型

  Machine learning models for traffic prediction are further categorized, which include the regression model, examplebased models (e.g., k-nearest neighbors), kernel-based models (e.g. support vector machine and radial basis function), neural network models, and hybrid models  
  
- T-ZS11, T-ZS19

  (T-ZS2 评价) 分类了五种预测方法：统计、ML、DL、强化、迁移

  Roughly speaking, five different types of traffic prediction methods are identified and categorized in previous surveys, namely, statistics-based methods, traditional machine learning methods, deep learning-based methods, reinforcement learning-based methods, and transfer learning based methods.  
  
- T-ZS12

  (T-ZS2 评价) GNN 只在交通特征预测任务提及

  GNNs are only mentioned in the task of traffic characteristics prediction 
  
- T-ZS13

  (T-ZS2 评价) 把 DL 分成了五类；GNN 仍然是 SOTA

  Deep learning models are further categorized into five different generations, in which GCNs are classified as the fourth generation and other advanced techniques that have been considered but are not yet widely applied are merged into the fifth generation. These include transfer learning, meta learning, reinforcement learning, and the attention mechanism.  
  
  Before these advanced techniques become mature in traffic prediction tasks, GNNs remain the state-of-the-art technique  
  
- T-ZS15, T-ZS21

  (T-ZS2 评价) 比较了 DL 和基于统计的方法/ML

  compare them with the statistics-based and machine learning methods
  
- T-ZS15

  (T-ZS2 评价) DL 不总是最优的，线性模型/ML 可能更好

  Conversely, it is found that deep learning is not always the best modeling technique in practical applications, where linear models and machine learning techniques with less computational complexity can sometimes be preferable
  
- T-ZS16

  (T-ZS2 评价) 特征选择和预处理方法的综述

  spatiotemporal feature selection and extraction pre-processing methods, which may also be embedded as internal model processes, are reviewed
  
- T-ZS18

  (T-ZS2 评价) 准确率的元分析，不同 DL 方法，样本大小，预测视野

  A meta-analysis of prediction accuracy when applying deep learning methods to transport studies  
  
  In this study, apart from the models themselves, additional factors including sample size and prediction time horizon are shown to have a significant influence on prediction accuracy  
  
- T-ZS20

  (T-ZS2 评价) 对交通堵塞、旅行需求、交通安全等的 GNN 综述；讨论了 GNN 和 DL 的优缺点

  Graph-based deep learning architectures are reviewed for a series of traffic applications, namely, traffic congestion, travel demand, transportation safety, traffic surveillance, and autonomous driving.  
  
  Specific and practical guidance for constructing graphs in these applications is provided  
  
  The advantages and disadvantages of both GNNs and other deep learning models ,e.g. recurrent neural network (RNN), temporal convolutional network (TCN), Seq2Seq, and generative adversarial network (GAN), are examined  
  
  While the focus is not limited to traffic prediction problems, the graph construction process is universal in the traffic domain when GNNs are involved  
  
- T-ZS22

  (T-ZS2 评价) 2019 后 SOTA 都是基于 GNN 的

  Among the major milestones of deep-learning driven traffic prediction (summarized in Figure 2), the state-of-the-art models after 2019 are all based on GNNs, indicating that GNNs are indeed the frontier of deep learning-based traffic prediction research  
  
- [T-ZS42](https://www.tandfonline.com/doi/full/10.1080/23311916.2021.2010510)

  T-ZS26 评价 定义了交通流量和交通速度变化率来表示交通事故灰色信息，通过融合交通流时空特征与事故特征提出G-CNN的灰色卷积神经网络，并将其应用于交通事故环境下预测交通流量

#### 关系

T-ZS1 介绍了 T-ZS23, T-ZS4，好像也有 T-ZS5, T-ZS6, T-ZS7

T-ZS2 提到了 T-ZS8，列举了综述 T-ZS1，T-ZS9 到 T-ZS21

- 其补充是 T-ZS29

#### 个人总结

##### T-ZS3

该论文提及，传统技术还包括：Random Forest (RF) Algorithm, Bayesian Algorithm (BA) approach, K-Nearest Neighbor (KNN), Principal Component Analysis (PCA), and Support Vector Algorithms

神经网络：BackPropagation Neural Network (BPNN)、CNN、RNN、LSTM、Restricted Boltzmann Machines (RBM), Deep Belief Networks (DBN) , and Stacked Auto-Encoder (SAE)  

> 提供了 AI, ML, DL 的概念， ML 领域的分类图，感觉还是可以参考有用的
>
> 以及十页这样描述了 ML 的常用算法，如 KNN 等
>
> 介绍了强化学习的概念和常用方法

> 给了 DL 和 ML 的技术发展时间线

技术介绍部分，感觉没提到 GNN，综述的内容年份也不是很新，整体来说除非要学习 ML/DL 的基本概念不然感觉意义不大

其前 20 页介绍具体技术的时候，没有和交通流量结合起来，只是单纯介绍技术本身

具体论文部分，每一个论文单独写了一句话表述这个论文，并给了表格，表 3 是 DL，包含引用里的 134-159 论文，但表格只是简单描述论文方法，数据集，结论，不加任何统计和对比分类 (~~写的这么烂难怪 CCF NONE)~~

其大部分论文在 2019-2020 年份，最新有一点 2021/2022 的，随便抽查了五六篇，都是引用的具体论文的参考量才几十，感觉都是犄角旮旯的水文总结的水综述，而且感觉都是 CCF NONE，~~鉴定为：水论文，没有参考价值~~

> 挑战章节部分一笔带过

##### T-ZS25

> 还有部分笔记融合到了别的部分不在这里赘述

有 CNN, GNN 的详细介绍，GNN 的发展历史图

提供了点数据和轨迹数据的常用公开数据集列表，但没给出处下载链接，引用的工作没有做按年份和表格的整理，而且感觉也不是很新

> 说可以分为 5-15min 为短时预测，15-45 为中时，45+ 长时
>
> 提到的传统 ML 有 kNN, SVM, 贝叶斯网络等

按照时间特征技术和空间特征技术分类，值得参考

- 时间：ML、RNN、混合(+ARIMA)
- 空间：CNN、GNN、融合

> 其相关技术论述可以阅读，应该能查漏补缺地学习

相关论文：(有时间轴线) (引用量都挺多的)

RNN

- 2015 T-25 [论文笔记](https://blog.csdn.net/qq_39805362/article/details/105509203) LSTM 在交通的开山
- 2016 [T-117](https://ieeexplore.ieee.org/abstract/document/7804912) (使用了 LSTM, GRU 两种 RNN)
- 2017 T-46 (二维 LSTM 变体)
- 2017 [T-118](https://ieeexplore.ieee.org/abstract/document/8215650) Prediction for Time Series at Uber (2层编码器预训练等的 LSTM 变体)
- 2018 [T-119](https://www.sciencedirect.com/science/article/pii/S0925231218310294) (考虑缺失数据的 LSTM-M)
- 2019 T-43 (Meta-RNN)
- 2019 [T-120](Traffic flow prediction using LSTM with feature enhancement) (注意力+LSTM)
- 2020 [T-121](https://ieeexplore.ieee.org/abstract/document/9315723/) (SAE+LSTM)

CNN

- 2017 T-72 (将交通视为图像，横轴为时间、纵轴为空间)
- 2017 [T-122](https://ieeexplore.ieee.org/abstract/document/8240913/) (CNN+GRU)
- 2019 [T-123](https://ieeexplore.ieee.org/abstract/document/8684259) (三维 CNN 结合经纬+时间信息)
- 2019 [T-124](https://ojs.aaai.org/index.php/AAAI/article/view/4511) (局部CNN+LSTM处理动态时空依赖 STDN)
- 2016 T-3 (一维CNN+2层LSTM)
- 还有若干 CNN 网络框架(十几篇，没具体介绍)

> GNN 略

> 还做了实验，对陕西数据跑了 10 个不同领域经典模型
>
> 提出了一种收费流转交通流的路子 [T-125](https://ieeexplore.ieee.org/abstract/document/8600736)

##### T-ZS26

分类把注意力机制、transformer 分为一类，其他类别：混合神经网络、RNN、GNN、CNN、多层感知机

##### T-ZS30

列表总结了一些综述，有单步和多步预测的定义 (T-ZS38 也有定义)

对预测的结构：数据分析（收集、格式、特征）、建模、应用总结

有几种建模图的分类及其严格定义

空间建模：CNN、GNN、注意力、多图融合，有按时间的总结图(到2023)

时间建模：RNN、TCN (一种卷积)、自注意力

时空建模：元学习、ODE 网络、自监督、持续学习

> GPT：自监督学习是一种机器学习方法，它介于监督学习和无监督学习之间。在监督学习中，模型依赖于大量标注的数据进行训练，而无监督学习则完全依赖未标注的数据，自监督学习试图通过构造内部监督信号来解决缺乏标注数据的问题。

有对交通流量预测等的列表描述，表示了时间空间分别怎么处理，新倒是有挺新的，表格里论文数量不多，文字描述篇幅倒是还比较详细

有数据集的列表和描述，按问题领域分类

##### T-ZS32

收录的论文基本都是 2023 的，有引用量，感觉比较新，列表有一定数量论文，可以参考。

##### T-ZS33

摘要说交通速度和交通流量高度关联

讲多任务学习，其中一个应用领域是交通流量预测，还有需求预测等

多任务学习一种模式为硬参数：共享一部分层，参见论文图 2 所示，最常用；另一种是软参数硬更减少过拟合，降低开销

看了一眼第三章相关部分论文的年份，感觉不新。第四页有二者关系的简单论述，提供了表 1 表示相关的几篇论文的内容

##### T-ZS35

有近几年到 2023(不是很多)的 LSTM + X 的论文的表格汇总，包含其数据集，主要技术等

有数据集的表格汇总，分类：速度/流/轨迹，时间，地点，更新时间，链接等，但没有找到详细的介绍

在 PeMS 04/08 上对比了 10 个经典模型的结果

未来挑战部分的观点也可以参考一下

##### T-ZS38

有单步、多步的定义

列表总结了 RNN, LSTM, GRU, CNN, TCN 的梯度消失、长距离信息、时间开销内容、参数异同，分别介绍了它们，还介绍了 Seq2seq 和 Transformer，按时空也分类了一个表格和描述，论文不是很新，没有对论文的列表总结

## 具体技术

### 概述

#### 描述

(T-ZS1) The earliest class of models used is the classical statistical models. Afterwards, machine learning models improve upon the performance of classical statistical models. Then, the deep neural network class of models dominates the field due to its capability in capturing the complex and nonlinear patterns in traffic data.  

#### 分类

(T-ZS28 的树形分类图 1)

![image-20240808152704281](img/image-20240808152704281.png)



### 统计模型

##### ARIMA

(T-ZS1) classical statistical models, of which the Autoregressive Integrated Moving Average (ARIMA) family of models is the most popular. 

局限：(T-ZS1) 线性模型，假设数据规律不变；只能预测小时间段，参数手调

- T-3 T-5 [T-ZS6](https://www.sciencedirect.com/science/article/pii/S0968090X10001610) simple linear models which assume that the traffic is stationary  ->  frequently fail when handling the complex, nonlinear traffic data 
- [T-12](https://arxiv.org/abs/1801.02143) were proposed at a time where traffic data were simpler and much smaller in size  -> a condition that no longer holds true in the present day where the ubiquity of traffic sensors has caused an explosion in traffic flow data   
- [O-1](https://www.tandfonline.com/doi/abs/10.1080/00031305.1996.10473554) the function parameters are manually defined a priori  

> T-ZS29 推断能力不足
>
> However, their predictive performance is inferior to that of machine learning and deep learning models, which are better at capturing nonlinear relationships

评价：(T-ZS2) Traditional linear time series models, e.g. auto-regressive and integrated moving average (ARIMA) models, cannot handle such spatiotemporal forecasting problems  

(stated by T-ZS1)

- [T-6](https://trid.trb.org/View/148123) [1979] first researchers to apply ARIMA to traffic prediction 
- [T-7](https://trid.trb.org/View/167550) [1980] found that the ARIMA(0,1,1) model is the most statistically significant
- [T-8](https://journals.sagepub.com/doi/abs/10.3141/1678-22) [1999] applied subset ARIMA and found that it provides stable and accurate results
- [T-9](https://journals.sagepub.com/doi/abs/10.3141/1776-25) [2001] discovered the impact of upstream traffic sensors to downstream ones and applied ARIMAX model for traffic flow prediction
- [T-10](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-947X(2003)129:6(664)) [2003] applied Seasonal ARIMA to the United States and the United Kingdom traffic data 
- [T-11](https://journals.sagepub.com/doi/abs/10.3141/1857-09) [2003] discussed and compared the Vector Autoregressive Moving Average and Single space-time ARIMA model

(T-ZS26) NN+ARIMA [T-180](https://www.sciencedirect.com/science/article/pii/S0968090X19303821)

- 使用ARIMA模型对MLP的残差进行后处理，提出了一种NN-ARIMA模型，利用MLP捕捉交通路网中所有交通流的协同运动模型，并使用ARIMA模型提取剩余时间序列中的位置交通特征，显著提升了MLP的预测精确度

优点是解释性比 ML 好

(T-ZS2 论述说 T-ZS9 指出)：statistics-based models have better model interpretability, whereas ML-based models are more flexible 

##### SARIMA

T-ZS29

seasonal autoregressive integrated moving average (SARIMA). SARIMA outperforms ARIMA because it captures seasonal patterns. In the transportation domain, both daily and weekly patterns are observed and useful for forecasting

SARIMA was further improved using the Kalman filter in [19], and the improved model outperformed other time series models

##### 多元时间序列模型

> ARIMA 是一元的 (GPT4o)

介绍：如向量自回归模型(VAR, vector autoregression)

(T-ZS2) Before the usage of graph theories and GNNs, the spatial information is usually extracted by multivariate time series models or CNNs. Within a multivariate time series model, e.g., vector autoregression, the traffic states collected in different locations or regions are combined together as multivariate time series.  

缺点：线性

(T-ZS2) However, the multivariate time series models can only extract the linear relationship among different states, which is not enough for modeling the complex and nonlinear spatial dependency  

##### 其他

(T-ZS2) autoregression 

- 如 T-78

(T-ZS2) Markov process (马尔科夫链)

- 如 T-79

(T-233) Ising 物理模型(不一定是统计方法)

### 机器学习

#### 简介

##### 历史

(T-ZS1) machine learning models during the 2000s utilize shallow and simple structures, limiting their prediction power  

(stated by T-ZS1)

- [T-13](https://research.aber.ac.uk/en/publications/the-use-of-neural-networks-to-recognise-and-predict-traffic-conge) [1993] One of the first neural network applications in traffic flow prediction  
- [T-14](https://www.sciencedirect.com/science/article/pii/S0968090X05000276) [2005] proposed a genetic algorithm approach to optimally tune the network
- [T-15](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-947X(2006)132:2(114)) [2006] used multiple neural network predictors which are combined using the theory of conditional probability and the Bayes rule  
- [T-16](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0887-3801(2005)19:1(94)) [2005] neural network model was applied to traffic prediction  
- [T-17](https://ieeexplore.ieee.org/abstract/document/6088012) [2012] imbued a neural network model with the hybrid exponential smoothing method to preprocess training data and the Levenberg-Marquardt algorithm to train the network weights

非 NN：

(stated by T-ZS1)

- k-Nearest Neighbor [T-18](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-947X(1991)117:2(178)) [T-19](https://www.sciencedirect.com/science/article/pii/S1877042813022027) [T-20](https://www.sciencedirect.com/science/article/pii/S0968090X15003812)
- support vector regression (SVR) [T-21](https://www.sciencedirect.com/science/article/abs/pii/S0957417408004740) [T-22](https://ieeexplore.ieee.org/abstract/document/4344269) [T-23](https://link.springer.com/chapter/10.1007/978-3-540-72393-6_121)

(T-ZS2) 其他模型，如 Kalman filters (滤波器) 如 T-80

(T-ZS3 给出的，说引用自另一篇综述 [O-29](https://ui.adsabs.harvard.edu/abs/2021arXiv211215538M/abstract))

![image-20240806225417369](img/image-20240806225417369.png)



##### 概述

T-ZS29  decision-tree-based models are still powerful for making binary decisions, e.g., XGBoost and LightGBM

##### 分类

(T-ZS3 给出的，说引用自另一篇综述 O-29)

![image-20240806224808082](img/image-20240806224808082.png)

##### 优缺点

- 局限性：数据密集

  (T-ZS1) The main weakness is that machine learning models are data intensive 

- 局限性：

  (T-ZS1) powerful but very hard to train efficiently  

- 局限性：手动提取特征

  (T-ZS1) many other machine learning models’ feature extraction phase, which helps extract useful patterns and information from the data to help the prediction, is done manually (i.e., using manually tuned kernels)  

- 优点：

  (T-ZS1) Machine learning models are flexible as they can learn from the data. That is, the parameters of the prediction function are adjusted automatically as the model traverses through the dataset  

(T-ZS25) 评价

基于传统机器学习方法虽然可以处理流量预测中的非线性和不规则性，但在特征提取层面依然执行的是浅层学习，并且需要对交通数据做简单变换。随着城市交通网络的数据量和数据维度呈爆炸式增长，上述技术无法完成需要精细特征表示的复杂交通流预测任务  
基于传统机器学习方法的低效训练策略和浅层结构无法应对海量数据，往往会忽略其他影响因素，多源数据融合预测的优势更得不到体现且优化困难  

#### 混合模型

##### 概念

集各家之长

(T-ZS1) As complex deep neural networks are becoming viable to train, most authors have utilized the hybrid neural network setting, which combines different neural network structures into a larger entity, to maximize the prediction performance  

The popularity of hybrid neural network structure is contributed by its power and flexibility of utilizing the different strengths of its individual components.   

> While complex models are expensive to train, their performance improvements have proven that the investment is worthwhile  

现状：占主要

(T-ZS1) we can see that the simpler “deep neural network” category consists of papers from the earlier years of traffic prediction research while “hybrid deep neural network” and “hybrid deep neural network and graph theory” mostly contain more recent papers. Hybrid deep neural networks combine different types of simple deep neural network structures in order to combine the strengths of each  

##### 对比简单的例子

(T-ZS1) 对比简单模型的例子：

- T-40 encoder-decoder 图扩散比 FNN, LSTM 好，消融证明扩散卷积更好

  have demonstrated that their encoder-decoder model with graph diffusion managed to outperform simple FNN and LSTM. Not only that, they also performed an ablation test to demonstrate that their novel diffusion convolution module manages to outperform simpler variations  

- T-44 与 FNN, LSTM, GRU 对比

  have compared their method against simple FNN, LSTM and GRU, showing similar trends  

结论：复杂的比简单的好，新的技术更好

While we provide only two examples due to space constraints, we can attest that many complex hybrid deep neural network models have managed to outperform simpler deep neural network models and that many novel modules designed to capture spatial and temporal correlations (e.g., spatial and temporal attention) have resulted in further performance improvement  

#### SAE / DBN

##### 概念

(T-ZS1) 评价：不能明确获取时空信息

The main contributing factor of this rarity is that SAEs and DBNs do not explicitly capture the spatial or the temporal aspect of the data and thus tend to perform worse than the neural networks that capture such aspects. 

(T-ZS1) 早期出现的原因：计算快，现在已被淘汰

- 不显示获取时空信息，表现不优，在早期可能多见
- 逐层贪心训练方法预训练权重，加速训练

> SAE 基于多层神经网络的无监督学习算法。它由多个自动编码器（Autoencoder）堆叠而成
>
> Deep Belief Network (深度信念网络) 是一种由多层 Restricted Boltzmann Machines (RBMs) 组成的概率生成模型，通常用于特征学习和无监督预训练
>
> RBM 是一种受限玻尔兹曼机，用于学习数据的概率分布

In fact, SAEs and DBNs receive attention mostly at the earlier years of deep neural network for traffic flow prediction. We speculate that this is because early researchers are concerned with the computation time optimization of the training methodology. SAEs and DBNs use the greedy layer-wise training method ([O-4](https://proceedings.neurips.cc/paper/2006/hash/5da713a690c067105aeb2fae32403405-Abstract.html)) to pre-train their network weights, which accelerates the training in the long run. However, as more and more complex techniques were introduced and as hardware and software optimization reduce the computational time of these methods, the middling performance of SAEs and DBNs resulted in the two being phased out  

##### 具体论文

This has been demonstrated through several experiments:

- T-1 T-4 [T-56](https://arxiv.org/abs/1802.02147)

Stacked Autoencoder (SAE)  

(T-ZS1)

- [T-54](https://ieeexplore.ieee.org/abstract/document/6894591) 

- [T-55](https://ieeexplore.ieee.org/abstract/document/7727607) 使用 Dempster-Shafer theory 结合交通流数据

  > Dempster-Shafer理论是一种用于处理不确定性和推理的数学理论。它由Peter Dempster和Arthur Shafer在20世纪70年代提出，是一种用于描述和处理不确定性信息的方法，特别适用于决策支持系统和人工智能领域。
  >
  > 这个理论的核心是使用概率分布函数（称为Belief函数），来描述每一个可能事件发生的可能性。这种方法与传统的贝叶斯概率理论不同，因为它允许对不同假设之间的关联性进行建模，而不是简单地单独考虑每个假设的概率。
  >
  > Dempster-Shafer理论的应用包括数据融合、模式识别、专家系统、风险评估等领域，它在处理非完整和不确定信息时显示出了一定的优势

Deep Belief Network (DBN)

(T-ZS1)

- T2 T-26 T-27 

(T-ZS25) T-121

#### 贝叶斯网络

Bayesian Network  

(T-ZS2) 

贝叶斯网络：一种概率图模型，使用贝叶斯推断

To tackle this gap, the Bayesian network, which is a type of probabilistic graphical model using Bayesian inference for probability computations, is a promising solution  

(T-ZS25) 贝叶斯方法在小样本交通数据集和突发事故场景中有着极高的应用潜力，然而，贝叶斯方法学习过程中需要求解积分，在面对大数据场景时，难以避免较高的计算复杂度  

- 多数论文是确定性模型和平均预测

  Most of the existing studies aim for deterministic models that make mean predictions 

  > 一些交通应用需要不确定性，特别是极端交通状况
  >
  > However, some traffic applications rely on uncertainty estimates for the future situations  
  >
  > The combination of GNNs with Bayesian networks is proposed for the challenge of GNN model interpretation. With probabilistic predictions, uncertainty estimates are generated for the future situations, especially the chance of extreme traffic states.  

- 应用例子：分位数回归 Quantile Regression

  A similar alternative is Quantile Regression, which estimates the quantile function of a distribution at chosen points, combined with Graph WaveNet for uncertainty estimates [T-116](https://arxiv.org/abs/2012.05207)
  
- (T-ZS25) [T-170](https://ieeexplore.ieee.org/abstract/document/1603558) 可以实现突发事故情况下的交通流预测  

T-ZS29

> The fifth research opportunity is the Bayesian learning approach for uncertainty quantification. Uncertainty in traffic forecasting may not be as critical as uncertainty in other domains, e.g., wireless communication problems. However, it is still important to account for uncertainty in the transportation domain when noisy or missing data could impair predictive capabilities and lead to unusual forecasts. Bayesian neural networks have been shown to be effective in dealing with data uncertainty caused by noisy or missing data in road traffic flow forecasting [66]. Another similar idea is to incorporate the physical mechanism of traffic flow dynamics as constraints, such as neural controlled differential equations [188] and Poisson processes [84], to avoid unreasonable predicted values [196] and help to improve the model interpretability.

#### KNN

(T-ZS25) kNN [T-168](https://ieeexplore.ieee.org/abstract/document/1041310)

kNN 方法由于其无需参数估计和预先训练的特点，在简单场景下有着较好的预测效果，然而 1 值（最近邻居的数量）的选取并不固定，不能应对差异度较大的交通场景，并且 kNN 方法的预测结果受观测值的影响较大，当观测数据库中出现噪声数据和训练样本划分不当时预测效果较差。在实际应用中，由于 kNN 方法的非稀疏性，需要对所有样本进行计算，有着较大的内存消耗和计算复杂度，并不适用于基于大数据的实时交通场景  

#### SVM

(T-ZS30) [T-127](https://ieeexplore.ieee.org/abstract/document/8963628) SVR

(T-41) T-23

(T-ZS25) [T-159](https://ieeexplore.ieee.org/abstract/document/9512877) 粒子群优化方法应用于 SVW 的参数优化

SVM 方法有着坚实的理论基础，并且由于 SVW 的最终决策函数只由少数决策向量决定，可以有效避免“维度灾难”，在解决小样本场景和高维特征问题上有着独到优势，
但 SVW 方法需要预先进行训练，在大规模数据集上计算复杂度较高，除此以外，参数设定也直接影响到训练结果  

#### ODE

(T-145) ODE 常微分方程

- T-155
- T-156

DE Differential Equation

- T-256 +物理模型

### 神经网络

#### 概念

深度神经网络

(T-ZS1) Amongst all the available traffic prediction methods, deep neural network is the most prominent.  

- 概念：

  (T-ZS1) Deep neural networks consist of complex neural network models with a large number of layers. 

- 条件：

  (T-ZS1) increasing computational power, as well as theoretical and software improvements in recent times had made increasingly complex neural network models feasible to train. Thus, in the middle of the 2010s, researchers started to apply deep neural network models for traffic prediction  

  > As technology advanced on both the hardware and the software front, complex deep neural network models are becoming easier to train. This has prompted researchers to combine the capabilities of multiple deep neural networks, and even add some novel components of their own creation  

- 理由：

  (T-ZS1) This is due to its sheer predictive power that can model the complex and nonlinear traffic patterns

  > 参考几个具体应用论文：[T-1](https://www.mdpi.com/1424-8220/17/7/1501)、[T-2](https://www.mdpi.com/1424-8220/17/7/1501)、[T-3](https://arxiv.org/abs/1612.01022)、[T-4](https://ieeexplore.ieee.org/abstract/document/8489600)、[T-5](https://arxiv.org/abs/1707.03213)，引用都不错

#### 优缺

- 适用理由：CNN/RNN抓时空+层数

  (T-ZS1) Some of the deep neural network models can explicitly capture different aspects of traffic data, which made them even more attractive. For instance, CNN can explicitly capture the spatial aspect of traffic data while RNN can explicitly capture the temporal aspect of traffic data. Additionally, the increased number of layers improves the models’ prediction capability. This factor allows them to model traffic fluctuations more accurately  

- 优点：自动学习特征

  (T-ZS1) (The reason behind its prominence is that) neural networks perform automatic feature extraction as well as the actual prediction in one model 

  > 相较于传统机器学习而言 (T-ZS1: O-1)
  >
  > Neural network’s prominence in traffic flow prediction can be attributed to the model’s flexibility. This is because the functional form of neural network models is approximated via learning, as opposed to classical statistical models which assume the functional form a priori  

- 局限性：当前状态和未来方向不明

  (T-ZS1) The increasing popularity of deep neural network models for traffic prediction has led to numerous publications, but issues such as the wide variety of hybrid deep neural network structures have made it difficult to assess the current state and future directions of this research field. This problem is compounded by the fact that survey works focusing specifically on deep neural network models are rare

- 缺点：

  (T-ZS1) 需要大数据，训练代价高，难以理解(如参数含义)

  - Deep neural network models require a large amount of data that covers all traffic conditions. 

    If the amount of data is too small or if the data is not diverse enough, the model’s generalization capability is compromised.

  - Deep neural network models still take a long time to train. 

    As deep neural network models are complex and have a large number of layers, the training time can be very long. This problem is compounded on hybrid deep neural network models. As classical statistical and older machine learning models are not as complex, their training time is much shorter.

  - Deep neural network models are difficult to interpret. 

    This is because of two reasons: the number of internal parameters is very large, and the parameters are learned from training, not set manually. Thus, while they can predict well, it is hard to understand their parameters. Understanding the parameters may reveal important information such as the spatiotemporal dynamics in the road network 
    
    > Consequently, neural network models’ internal parameters are rarely explored because they are hard to interpret as their focus is mostly on raw prediction performance rather than interpretability.  
    
    该缺点可以 更多参见下文未来趋势一节
  
- T-ZS37

  在深度神经网络中，网络的性能并非始终与网络深度呈正相关关系．换句话说，如果只是简单地增加网络的深度，当网络深度超过某个阈值后，预测模型在训练集和测试集上的性能均有一定下降．这明显不同于过拟合时预测模型在训练集上性能有所提升，但在测试集上的性能下降

#### 分类

类别：

(T-ZS1) The three most common deep neural network models used for traffic prediction are Convolutional Neural Networks, Recurrent Neural Networks, and Feedforward Neural Networks

> (T-ZS2) Deep learning models, including convolution neural networks and recurrent neural networks, have been extensively applied in traffic forecasting problems to model spatial and temporal dependencies  

(T-ZS1) RNN, CNN, FNN

- RNN is commonly used to capture the temporal trends of traffic data–the dynamics of how past traffic can influence future traffic. CNN is commonly used to capture the spatial trends of the data–how traffic propagates through the road network. FNN can aggregate the output from different subnetworks and also can process external data such as weather information  

#### 发展

(T-ZS25)

- 1993 [T-171](https://www.safetylit.org/citations/index.php?fuseaction=citations.viewdetails&citationIds[]=citjournalarticle_241813_38) 首次提出用系统识别和人工神经网络进行城市道路网络交通状态的预测 
- 1994 [T-172](https://onlinepubs.trb.org/Onlinepubs/trr/1994/1453/1453-009.pdf) 评价了神经网络在智能交通领域的应用潜力，提出神经网络是智能交通系统最需要的工具，在实时交通流预测中，神经网络要比其他方法优越  



(T-ZS30 图 6)

![image-20240808225705488](img/image-20240808225705488.png)



### FNN

#### 概念

概念：

- (T-ZS1) 名称 A Feedforward Neural Network (FNN), which is also commonly referred to as Fully Connected Neural Network (FC or FCNN), is one of the earliest and simplest neural network models  

  组成 It consists of several layers of fully connected computational nodes organized in many layers  

  计算方式 The value of every node in the hidden or output layers is computed by taking the weighted sum of all of the previous layer’s nodes and then passing the value to a nonlinear function such as sigmoid, tanh and relu  

缺点：

- 参数多、训练久

  (T-ZS1) The FNN’s fully connected structure enables each of its layers to process the combination of all the previous layer’s features. However, this also serves as a weakness because its full connection results in a large amount of parameters  

  Consequently, the training process of FNNs can be quite time consuming. In addition  

- 没有明确获取时空信息

  (T-ZS1) do not have the capability of explicitly capturing spatial or temporal data. Because of this, FNNs are rarely used as the main predictor in deep neural network literatures.  

作用：工具组件：聚合输出、维度转换、引入数据

- (T-ZS1) For traffic flow prediction, FNNs usually serve a utility role in a hybrid deep network, whose main purpose is to perform tasks such as aggregating outputs from different components within the network, dimensionality transformation and incorporating external data such as weather.  

  - 维度转换：This is because the size of input layer or output layer can be set manually, which gives FNN the capability to transform inputs of an arbitrary dimensionality to an output of an arbitrary dimensionality  
  
  - 聚合输出：When used to integrate external data, the input depends on the type of external data. Numerical values can be provided as it is while categorical values need to be transformed first (e.g., using one-hot encoding)  
  
    > FNNs are commonly used to aggregate the output of one or more subnetwork components in a deep neural network 
    >
    > a natural component for CNNs and RNNs, since FNNs can take the output from these networks and output a smaller representation
  
  - 引入数据：For aggregating outputs and dimensionality transformation, the inputs depend entirely on the model  
  
    > FNNs are also commonly used to incorporate external data to the network, because it can take inputs of an arbitrary dimensionality and perform a transformation to ensure that the dimensionality of the external data and that of the other components within the network match  
  
  - 子模块：as a submodule component. FNNs are often used as a component in a model’s submodule, such as attention network modules  

#### 具体论文

(T-ZS1)

1. FNN as Output Aggregator

   - T-3 合并 CNN+2LSTM 的输出

     combine the outputs from one CNN component and two LSTM components  

   - T-1 T-33 T-48 T-50 T-37 合并 CNN 的输出

   - T-41 T-53(结合天气+消融) T-36 合并 RNN 的输出

2. FNNs for Incorporating External data

   - T-51 T-37 T-3

3. FNNs as a submodule component

   - T-43 学习哪条路网重要

     used an FNN to learn features from a road network, which enables the network to learn which nodes in a road network are important  

   - T-42 与上面一样，但没用图结构

     used an FNN for the same purpose, although they do not use the graph structure  

### CNN

#### 基本

##### 概念

组成：卷积层、池化层

(T-ZS1) 

A CNN consists of several “convolution” and “pooling” layers. 

- Convolution’s purpose is to extract features from the input, 

  > Mathematically, convolution layers extract features by computing the dot product between a matrix of some preset values (referred to as filter) and a subset of cells from the original grid, which produces a matrix that is called feature map  

  > The example in Figure 1 shows, (i) the top-left 3 × 3 subset of cells produces the value 470, and (ii) the bottom-right 3 × 3 subset of cells produces the value 170 in the feature map. This can be interpreted as the top-left subset having a much higher number of vehicles in that region than the bottom-right subset  

  <img src="img/image-20240722103753648.png" alt="image-20240722103753648" style="zoom: 67%;" />

- whereas pooling’s purpose is to reduce the dimensionality of each feature map but preserve the most important information.  

功能概述：

(T-ZS1) A Convolutional Neural Network (CNN) has the capability to learn inherent features progressively, starting from low level features and then building up to more abstract concepts through a series of convolutional layers. 

> 功能：建模局部空间信息，划分为规则二维网格图像格式
>
> (T-ZS2) CNNs take a step further by modeling the local spatial information, e.g., the whole spatial range is divided into regular grids as the two-dimensional image format and the convolution operation is performed in the neighbor grids.

T-ZS29 分类

To capture temporal dependencies, there are some classic models, e.g., temporal convolutional network (TCN), long short-term memory (LSTM), and gated recurrent unit (GRU). (+attention)

##### 应用

能用的理由：交通流读入可以建模为图像，每个像素点对应一个交通密集的地区，因此可以用图像识别技术，即把区域网格化，像素值是如车辆数目，不同时间即像素值不一样

> (T-ZS1) A CNN is the optimal choice for capturing the spatial aspect of the data. CNN is able to capture the correlation between different regions in the road network. By utilizing this strength, a CNN can learn the spatial dynamics of traffic in order to improve the prediction accuracy.  

(T-ZS1) 

- Although this strength contributes to its popularity in image recognition, CNNs have been regularly applied to traffic flow prediction. The intuition is, traffic flow readings can be modeled as an image, where each pixel corresponds to the traffic intensity at a certain block of area. Thus, similar techniques developed for image recognition can be easily applied 
- Given a road network, the input of a CNN is preprocessed by partitioning the network as a grid, which is essentially a set of cells with each cell representing an area in the data space and the value associated with the cell representing the number of vehicles detected in that cell at a certain point in a time period (e.g., 5×5 cells in Figure 1). The traffic flow reading for each time period will be represented with the same grid but different number of vehicles. Thus, the entire traffic data modeled this way can be seen as several images with the same size but different pixel values   

具体应用：混合网络、空间特征 (如晚高峰商业区和居住区间流量强关联)

- (T-ZS1)  In the application of traffic prediction, CNN is often used as a component in a hybrid deep neural network, whose task is to capture the spatial aspect of traffic data.
  This is because different roads in different locations may be correlated and these correlated roads share similar traffic trend. Therefore, the traffic of the correlated roads may rise or fall, depending on their historical data 

  For instance, during the evening, there is a strong correlation between the road traffic of commercial and residential districts because employees are heading off from work  

##### 优缺

优点：不全连接，参数少

- (T-ZS1) Unlike most neural networks, CNN’s layers are not fully connected. Consequently, the number of parameters and training time are significantly reduced 

  不全连接的另一个优点在于可以学习空间的局部相关性

  (T-ZS1) Since CNN’s layers are not fully connected, one layer of CNN does not learn from all of the previous layer’s features. However, this actually proves to be an advantage in many applications as CNN can learn how the different aspects of the input relate to each other spatially  

优点：权重共享

- (T-ZS1) Additionally, CNN uses a weight sharing mechanism, which further reduces the number of required parameters  

优点：结构简单、并行计算、稳定的梯度

- (T-ZS2) CNNs demonstrate their superiority in terms of simple structure, parallel computing and stable gradients.  

缺点：路网数据不行 (非欧拓扑不行)

- (T-ZS2) the CNN-based approach is not optimal for traffic foresting problems that have a graph-based form, e.g. road networks

  (T-ZS2) However, the CNN-based approach is bounded to the case of Euclidean structure data, which cannot model the topological structure of the subway network or the road network  
  
  (T-ZS28) 然而,交通网络的连接关系不是二维网格,其节点离散且非规则排列,具有非对称性特点,节点间的相互关系易受距离影响,因此,CNN不能准确地捕获交通网络的空间特征

#### 具体论文

(T-ZS1) 根据数据分类，理由：

Deep neural network models, hybrid or otherwise, that are applicable for one data type are incompatible for the other without major modifications. Consequently, we categorize works related to CNN based on the type of the main datasets  

##### point data

(T-ZS1) CNN 获取空间信息的能力取决于数据类型，一般用点数据。

可以：

- 使用 1D CNN(一维)

  use a 1D CNN as it is compatible with point data which are commonly organized in a line

  如 T-3 T-35

  (T-ZS25) T-3 (一维CNN+2层LSTM)

- 在 2D CNN 矩阵同时使用时空数据(一维时间、一维空间)

  capture both the spatial and the temporal aspects of the data in a 2D matrix to be fed into a CNN. That is, one axis of the matrix captures the different traffic detection sites and the other is used to capture the different time step  

  如：T-33 [T-48](https://ieeexplore.ieee.org/abstract/document/8547068) [T-49](https://ieeexplore.ieee.org/abstract/document/7837874) [T-50](https://dl.acm.org/doi/abs/10.1145/3282834.3282836)

  两者都用，如：T-38

(T-ZS2)

- [T-63](https://ieeexplore.ieee.org/abstract/document/8526506) CNN NYCtaxi 数据

##### trajectory data

(T-ZS1)  可以获取时间数据(如维度：空间、时间点、天)，或对时间做一维卷积。

(T-ZS1) 例子：

- T-1 映射为2D网格

  mapped a road link to a 2D grid and assigned to each grid the average traffic speed of the associated road link.  

- [T-51](https://ojs.aaai.org/index.php/AAAI/article/view/10735) T-31 2D矩形空间，再划分为多个网格

  defined a 2D rectangular space that encompasses all the trajectory points. This space is then divided into grids. Finally, for each grid, the traffic flow for a certain period of time is calculated as the number of trajectory points that are recorded within the grid during that period. Using this modeling, the entire space can be seen as a city and the grids represent small regions within the city. 

  结合天气 

- T-37 在上述方法基础上，增加了起点终点数据

  used a similar method as the previous, but they also modeled the traffic volume using CNN by using data of a trajectory’s start and end  
  
- T-2

- T-30

##### other

(T-ZS1) 时间信息捕获

Some authors have also attempted to use CNNs to capture the temporal aspect of the data  

(T-ZS1) 例子：

- [T-52](https://www.mdpi.com/1424-8220/17/4/818) 行：空间、列：时间、深：天数 -> 比 RNN 更短的输入序列

  included both the spatial and the temporal dimensions by modeling the traffic data as a tensor, where the rows represent the spatial aspect, the columns represent the temporal aspect and the depth represents the different days  

  They argued that using RNNs requires long input sequences which can impact training time greatly and instead applied CNN to capture both the spatial and the temporal aspects of the data  

  车祸考虑 + 模拟实验

- T-51 多个 CNN 分别获取小时、天、周粒度数据

  captured the temporal aspect using CNNs which are fed data from different time granularities (e.g. weekly, daily, hourly)   

-  1D CNN 获取时间

  used a one dimensional convolution on the time axis in order to capture the temporal aspect  

### RNN

> [参考他人笔记(一般般)](https://zhuanlan.zhihu.com/p/41980966) [很一般笔记](https://blog.csdn.net/qq_28247201/article/details/136024142)

#### 基本

##### 概念

定义：

- (T-ZS1) An RNN consists of a single node with a recurrent connection, but is often visualized as a chain of nodes, with each node representing the network state at a particular recurrence/time step  

  <img src="img/image-20240722110704917.png" alt="image-20240722110704917" style="zoom:67%;" />

  节点状态 $s_t$ 处理 $t$ 时刻的输入数据 $x_t$，和截止 $t-1$ 为止的全部信息($s_{t-1}$)一起传入到该节点

  The node state $s_t$ processes the input data $x_t$ at time $t$, as well as a ‘summary’ of all the information obtained up to time $t - 1$. This summary is stored in $s_{t-1}$, and it memorizes which parts of the sequence are important. Node $s_t$ then has the summary up to time $t$ and this information is passed to the next node state
  $s_{t+1}$. Thus, the node state $s_t$ stores the state of nodes for all the previous time steps until the beginning of the input (i.e., $s_{t-1}$, $s_{t-2}$, . . . ). The output $o_t$ is then compared with the ground truth $y_t$ in order to calculate the loss, which is used to fine-tune the model parameters.  

##### 建模

具体输入：

- (T-ZS1) In traffic prediction applications, the input to an RNN consists of past traffic readings. A continuous time period is divided into discrete time blocks and the traffic flow reading from each block is fed into the RNN.  

  > In the field of traffic prediction, LSTM as well as other RNN-based methods are commonly used as a component in hybrid deep neural network models. Its task is to capture the temporal patterns of traffic data; learning how traffic evolves over time  

> 应用：命名实体识别、声音识别、音乐识别、图像字幕生成等
>
> (T-ZS1) RNN-based methods in general possess the major advantage in the form of its memorization capability. The ability of learning important parts of the sequence and knowing when to memorize or forget them had led RNN to be the prime choice for sequence data. Due to this, RNN based models have been applied in many fields such as named entity recognition [40](https://link.springer.com/chapter/10.1007/978-3-319-55699-4_33), voice recognition [41](https://dl.acm.org/doi/abs/10.1145/3132847.3132893), music composition [42](https://people.idsia.ch/~juergen/blues/IDSIA-07-02.pdf), and image caption generation [43](https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Vinyals_Show_and_Tell_2015_CVPR_paper.html)
>
> 这些论文大部分引用不多或比较古老，除了 43 感觉都很一般

##### 发展

(T-ZS25 图5)

![image-20240806234935217](img/image-20240806234935217.png)

##### 优缺

优点：长短的时间依赖都可以记忆，而且比其他记得更长

- (T-ZS1) Recurrent Neural Networks (RNN) are commonly applied to sequence data because of their memorization capability, which can learn both long and short term dependencies between parts of the sequence. Additionally, RNN is able to scale to longer sequences compared to other network architectures. Its unique capability makes it one of the most popular deep neural networks.  

> 适用：(T-ZS2) many solutions have been proposed for dealing with the time dependency, e.g., recurrent neural networks and temporal convolutional networks  

缺点：梯度消失

- (T-ZS1) By its nature of being able to take in possibly very long sequences, RNN suffers from the vanishing gradient problem, which hinders the network’s ability to memorize information for a long time  
- T-ZS37 ＲＮＮ 在计算过程中存在大量的连乘操作，这会导致严重的梯度消失和梯度爆炸问题

缺点：训练时间长

- (T-ZS1) RNN’s recurrent structure leads to significantly longer training time compared to other deep neural network models  

> (T-ZS2) Among different approaches for temporal modeling, RNNs suffer from timeconsuming iterations and gradient vanishing or explosion problem with long sequences  

(T-ZS25) 虽然隐藏状态使 M99 能够在过去的时间步长中记忆输入信息，但也在序列上引入了矩阵乘法。矩阵乘法中的较小值使梯度在每个时间步长都减小，导致最终消失的现象；相反，较大值会导致梯度爆炸问题。消失或爆炸的梯度阻碍了 RNN 学习数据中长期序列依赖关系的能力  

T-ZS37 ＲＮＮ及其变体虽然能有效地捕获时间序列中的时间特征，但由于在ＲＮＮ中下一时刻的输出完全依赖于上一时刻的输入，导致难以进行并行化训练

#### LSTM

开山(1997) [O-2](https://ieeexplore.ieee.org/abstract/document/6795963) ；改进(2000) [O-3](https://ieeexplore.ieee.org/abstract/document/6789445)

概念：

- (T-ZS1) maintains the RNN’s recurrent structure, but introduces the three gates to control the cell value.  

  > also contains multiple layers, each possessing a cell with the memorization capability. In addition, it contains three gates, which control how information propagates throughout the network.  

  These gates are: 种门控制信息的传播($i,o$，分别控制遗忘多少之前信息、当前与下一层的相关性)

  - the input gate $i$, which controls the importance of the inputs $x_t$ and $h_{t-1}$,

  - forget gate $f$ which controls how much of the previous information $C_{t-1}$ is to be forgotten, 

  - and the output gate $o$, which controls how relevant is the current information $C_t$ for the next step.  


<img src="img/image-20240722113840626.png" alt="image-20240722113840626" style="zoom: 67%;" />

T-ZS37 优点：不同于ＲＮＮ，ＬＳＴＭ缓解了梯度消失和梯度爆炸问题．另外，ＬＳＴＭ中的门控机制可以有选择性地将关键信息保存至记忆细胞中，大幅提高了建模长期时间依赖性的能力

适用的原因：交通数据是时序的

(T-ZS1) We speculate that this is because traffic data constitutes a temporal sequence, which fits LSTM’s purpose. Additionally, most available traffic flow data is compatible with LSTM, as these traffic flow data can easily be modeled as a sequence of traffic flow readings  

> For instance, the traffic flow between 11:00 and 12:00 can be captured as the aggregated traffic reading for four periods, including 11:00-11:15, 11:15-11:30, 11:30-11:45, and 11:45-12:00. This data can be fed into an RNN, resulting in an RNN with four recurrences  

#### GRU

(T-ZS25) 在避免梯度消失或爆炸方面表现出色，但其结构复杂导致了更多的内存需求和更长的训练时间  

其结构更为简单，方法中只有 2 个门：更新门和重置门，更新门是输入门和遗忘门的合并，用于控制前一时刻的状态信息被带入到当前状态中的程度，重置门则控制前一状态有多少信息被写入到当前的候选集上  

#### 具体论文

##### basic

(T-ZS1)

- 首次应用 T-25 [T-32](https://ieeexplore.ieee.org/abstract/document/7463717) the first few applications of basic LSTM  
- 建模为矩阵以融合空间信息 [T-33](https://ieeexplore.ieee.org/abstract/document/7966128) [T-34](https://ieeexplore.ieee.org/abstract/document/8317872) use an LSTM that takes in readings from multiple time slots as well as multiple detectors. The data is modeled in a matrix, which captures both the spatial and temporal aspects of the data  

(T-ZS25) T-117 使用基本 LSTM 和 GRU 预测交通流，结果表明：在交通流预测方面 GRU 性能要优于 LSTM

##### hybrid

(T-ZS1) 三种思路：

> 1. RNN 输出特征融入到融合层(fusion layer)(如 FNN) (最简单)
>
> 2. 输出作为下个组成部分的输入(流水线)(先时再空或反过来或多次时间都行)
>
> 3. 作为主预测器，修改模型内部结构 (最复杂) 
>
>    (如反向传播->RTBL, 融入图卷积等)

(T-ZS1) 即：

1. Outputting features to be fed into a fusion layer.

   the simplest because models that fall into this category usually consist of several simpler subnetworks that only interact at the final fusion layer  

2. Outputting features to be fed into subsequent components within the model.

   treats LSTM as a pipeline that transforms one feature representation to another

   > As observed, in this category of method, some preprocessing steps such as the masking of missing values can be a part of the architecture.  

3. Used as the main predictor, but with modifications
   to the internal structure  

  the most complex one, as it requires modifying the internal LSTM structure

(T-ZS1) 分别：

1. 融合层

   - T-3 CNN+2LSTM (空间，短时间特征，周期时间特征)

     a combination of a CNN and two LSTMs to capture spatial features, the short-term temporal feature, and the periodic temporal feature respectively. The outputs from these three networks are then fed into a FNN to fuse the features  

   - [T-35](https://ieeexplore.ieee.org/abstract/document/8258813) CNN+LSTM

     used a combination of a CNN component and an LSTM component to capture spatial features and temporal features respectively. The outputs from these networks are combined to form the prediction  

   - T-29 SAE + LSTM

     a combination of a Stacked Autoencoder to encode traffic accidents data and an LSTM to capture the temporal aspect of the data  

2. 流水线

   - T-1 CNN -> LSTM

   - first used a CNN to encode the spatial aspect of the data and then fed this processed information to an LSTM to learn the temporal aspect  

   - T-4 CNN -> LSTM

     used an LSTM to process the outputs from a CNN before passing them to a max-pooling layer  

   - T-12 缺失值处理 -> 双向LSTM(特征转换) -> LSTM

     performed masking to fill in missing values in the data before passing it to a bidirectional LSTM for feature transformation and then a regular LSTM for the prediction  

   - [T-36](https://arxiv.org/abs/1811.05320) GCN(空间) + GRU(时间)

     used a Gated Recurrent Unit which takes input from a Graph Convolution Network and outputs the predicted traffic

   - [T-37](https://www.researchgate.net/profile/Huaxiu-Yao/publication/323570926_Modeling_Spatial-Temporal_Dynamics_for_Traffic_Prediction/links/5b1e23ea45851587f29f6a61/Modeling-Spatial-Temporal-Dynamics-for-Traffic-Prediction.pdf) 多个 LSTM

     used multiple LSTMs that represent the daily traffic features

   - [T-38](https://www.sciencedirect.com/science/article/pii/S0968090X18302651) 注意力+GRU+CNN

     used a Gated Recurrent Unit to learn feature representation from an attention model which are then fused with the CNN spatial component  

3. 修改结构

   - [T-39](https://ieeexplore.ieee.org/abstract/document/8917706) LSTM: 图卷积+卷积改为RTBL(查不到，疑似自创)

     modified the LSTM calculation to include a graph convolution process as well as using a novel Real-Time Branching Learning (RTBL) which modifies the backpropagation process  

   - [T-40](https://arxiv.org/abs/1707.01926) GRU: 矩阵乘法改为扩散卷积操作

     replaced the matrix multiplication inside Gated Recurrent Unit with the diffusion convolution operation 

##### encoder-decoder

见下文

##### other

(T-ZS1) 可以同时获取时空信息

Some authors have used RNNs to capture both the temporal and the spatial aspects of the data  

- T-34 多检测器一次输入 LSTM

  captured the temporal aspect by feeding data from multiple traffic loop detectors at once into an LSTM  

- [T-46](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-its.2016.0208)  每个检测器一个 LSTM + ODC矩阵表示之间相关

  used one LSTM for each traffic loop detector and incorporates an Origin Destination Correlation (ODC) matrix, which weighs how much the traffic of one loop detector’s location affects another  

  (T-ZS25) 提出了一种由多个存储单元构成的二维LSTM网络，用于从原始目的地相关矩阵中捕获时域和空域的相关性，该LSTM变体可以更全面地考虑路网时空特性，取得更好的预测结果

- T-30 LSTM 密度核改成卷积来同时捕获时空

  replaced the dense kernels in LSTM with convolutional ones to successfully use an LSTM to capture both the spatial and the temporal aspects of traffic data  

  拼接天气和交通流数据

(T-ZS2) +图卷积

- T-82, T-83, T-84, T-85, T-86

##### 多粒度

(T-ZS1) RNN 输入可能过长，因此只选取多个粒度的代表性数据，分别训练多个粒度的 RNN 组合，如要预测某个时刻的流量，与其输入很长的小时单位，不如输入短的小时，短的天，短的周结合起来，代替可能长达周的小时输入。

In addition, RNN has been used to capture the temporal aspect of the data using different granularities. As discussed in Section 3.2, RNN-based methods are commonly used to learn the temporal patterns of traffic data. However, we also mentioned that RNN-based methods are time-consuming. Consequently, RNN-based methods are not usually fed very long input sequences. Several data modeling-based approaches have been explored to mitigate this problem. The most common method is to use multiple LSTMs with each taking shorter sequences from a specific granularity. 

As an example, if we want to predict the traffic at 09:00 AM at December 25, one RNN can be used to capture the data from 06:00, 07:00, and 08:00 AM at December 25 (hourly granularity), one RNN can be used to capture the data from 09:00 AM at 22, 23 and 24 December (daily granularity) and one RNN can be used to capture the data from 09:00 AM at 4, 11 and 18 December (weekly granularity)  

- 例子如 T-3 T-37 T-38

### GNN

> (T-ZS2) GNN 本身的综述：O-7, [O-8](https://ieeexplore.ieee.org/abstract/document/9039675), [O-9](https://www.sciencedirect.com/science/article/pii/S2666651021000012) (都是 2020 的)

#### 概念

##### 兴起

(T-ZS1) 近年新技术：

One of the most significant breakthroughs of recent work in deep neural network for traffic flow prediction is the graph-based methods  ->  in particular, the graph convolution operation  

> 现状：SOTA：图结构和上下文信息(contextual)
>
> (T-ZS2) [O-6](https://ieeexplore.ieee.org/abstract/document/9046288)(GNN 综述) In recent years, to model the graph structures in transportation systems as well as contextual information, graph neural networks have been introduced and have achieved state-of the-art performance in a series of traffic forecasting problems  

##### 适用理由

适用的理由：

- 路网动态获取

  (T-ZS1)  Due to this ability of capturing the dynamics of road network, graph-based method is a promising future research direction.  

  (T-ZS2) For the dynamic spatial dependency, dynamic graphs can be learned from the data automatically.  

  (T-ZS1) they naturally conform to traffic dynamics

- 非欧结构数据信息

  (T-ZS2) Graph neural networks bring new opportunities for solving traffic forecasting problems, because of their strong learning ability to capture the spatial information hidden in the non-Euclidean structure data, which are frequently seen in the traffic domain
  
  远的空间依赖
  
  (T-ZS2) The spatial dependency, which refers to the complex and nonlinear relationship between the traffic state in one particular location with other locations. This location could be a road intersection, a subway station, or a city region. The spatial dependency may not be local, e.g., the traffic state may not only be affected by nearby areas, but also those which are far away in the spatial range but connected by a fast transportation tool. The graphs are necessary to capture such kind of spatial information  
  
- 层次结构，超图子图

  (T-ZS2) For the case of hierarchical traffic problems, the concepts of super-graphs and sub-graphs can be defined and further used  

##### 建模方式

非欧图结构的空间依赖：建图方式，点是路交点，边是路连接

(T-ZS2) GNNs are ideally suited to traffic forecasting problems because of their ability to capture spatial dependency, which is represented using non -Euclidean graph structures. For example, a road network is naturally a graph, with road intersections as the nodes and road connections as the edges. With graphs as the input, several GNN-based models have demonstrated superior performance to previous approaches on tasks including road traffic flow and speed forecasting problems  

> (T-ZS2) Based on graph theories, both nodes and edges have their own attributes, which can be used further in the convolution or aggregation operations. These attributes describe different traffic states, e.g., volume, speed, lane numbers, road level, etc.  

##### 应用领域

应用面：(T-ZS2) The GNN-based approach has also been extended to other transportation modes, utilizing various graph formulations and models.  

##### 发展

(T-ZS25)

![image-20240806235625831](img/image-20240806235625831.png)

##### 对比

(T-ZS2) 欧氏数据：图像、视频、文本

Previous neural networks, e.g. fully-connected neural networks (FNNs), CNNs, and RNNs, could only be applied to Euclidean data (i.e. images, text, and videos)  

(T-ZS1) 图论领域GNN vs 欧氏几何CNN：

(T-ZS27) 网格化数据 vs 拓扑化数据

(T-ZS28) 欧氏空间 vs 非欧空间

When applied to road networks, graph convolution works on the graph domain while regular convolution works on the Euclidean domain

> road networks do not conform to the Euclidean space as roads and highways that are close to each other may connect different parts of the city and thus have very different traffic characteristics  

讨论二者的优缺：

(T-ZS1) Graph-based methods are more appropriate for traffic data compared to the more conventional methods of dividing an area into spatial grids. The reason is that roads close to each other may connect entirely different parts of a city. It is more accurate to capture spatial correlations in terms of the connectivity of different parts of the area, which graph-based methods provide  

(T-140 图示对比)

![image-20240818224842670](img/image-20240818224842670.png)

##### 优缺

优点：图表示的复杂物体联系的获取能力

(T-ZS2 说 [O-10](https://www.sciencedirect.com/science/article/pii/S0140366421004874) 说的) GNNs have the ability to capture complex relationships between objects and make inferences based on data described by graphs. GNNs have been proven effective in various node-level, edge-level, and graph-level prediction tasks  

缺点：

(T-ZS1) 实现复杂，可能需要手动预处理

> Graph-based models can be complex to implement as it requires additional data as well as data preprocessing  
>
> The road topology data, which captures how different traffic detection sites are connected by roads, is often not readily available and has to be manually curated. 
>
> > While this challenge is significant, it is important to measure and understand how well graph-based methods improve the traffic prediction performance  

数据获取难度

(T-ZS1)  the difficulty lies in the data requirement and the additional preprocessing step  

#### 建模

##### 图定义

图的定义：

(T-ZS2) It is defined as $G=(V,E,A)$ where

- $V$ is the set of vertices or nodes

- $E$ is the set of edges between the nodes  

- $A$ is the adjacency matrix  

  Element $a_{ij}$ of $A$​ epresents the "edge weight" between nodes $i$ and $j$

  > For a binary connection matrix $A$, $a_{ij}=1$ if there is an edge between nodes $i$ and $j$ in $E$, and $a_{ij} = 0$ otherwise. 
  >
  > If $A$ is symmetric, the corresponding graph $G$ is defined as undirected. Otherwise, $G$ is directed, when the edge only exists in one direction between a node pair  

点和边都有含义(权/信息)

(T-ZS2) Both nodes and edges can be associated with different attributes in different GNN problems  

> 交通状态建模到点上：
>
> (T-ZS2) For simplicity, we assume that the traffic state is associated with the nodes. The other case with edges can be derived similarly. In practice, the traffic state is collected or aggregated in discrete time steps, e.g. five minutes or one hour, depending on the specific scenario  

> 时间步 $t$，点的特征矩阵为 $\chi_t\in R^{N\times d}$，$N$ 是点数，$d$ 是特征数。
>
> (T-ZS2) For a single time step t, we denote the node feature matrix as $\chi_t\in R^{N\times d}$, where N is the number of nodes and d is the dimension of the node features, i.e., the number of traffic state variables. Now we are ready to give a formal definition of traffic graph

交通图定义：(Traffic Graph)

(T-ZS2) A traffic graph (with node features) is defined as a specific type of graph G = (V; E; A), where V is the node set, E is the edge set, and A is the adjacency matrix. For a single time step t, the node feature matrix $\chi_t\in R^{N\times d}$  for G contains specific traffic states, where N is the number of nodes and d is the number of traffic state variables

##### 问题定义

基于图的交通预测问题：Graph-based Traffic Forecasting)  

(T-ZS2) A graph-based traffic forecasting (without external factors) is defined as follows: find a function $f$ which generates $y=f(\chi;G)$, where $y$ is the traffic state to be predicted, $\chi=\{\chi_1,\chi_2,\cdots,\chi_T\}$ is the historical traffic state defined on graph $G$, and $T$ is the number of time steps in the historical window size.

带外部状态：$\epsilon$ 为外部因素。  

The forecasting problem formulation, extended to incorporate these external factors, takes the form $y=f(\chi,\epsilon, G)$, where $\epsilon$ represents the external factors.  

分为单步预测和多步预测 

> (T-ZS30, T-ZS38 有定义, T-28 有基于条件概率的定义)

(T-ZS2) In single step forecasting, the traffic state in the next time step only is predicted, whereas in multiple step forecasting the traffic state several time steps later is the prediction target  

> T-ZS2 有图示(figure1) (图源 T-ZS20，进行了修改)
>
> ![image-20240801205059347](img/image-20240801205059347.png)

##### 图的分类

(T-ZS2) 静态动态的角度分类：

- 静态图 pre-defined static graphs  

  - 自然图：真实世界路网

    Natural graphs are based on a real-world transportation system, e.g. the road network or subway system  

  - 相似图：点之间相似性

    whereas similarity graphs are based solely on the similarity between different node attributes where nodes may be virtual stations or regions  

- 动态图：从数据学习 dynamic graphs continuously learned from the data  

(T-ZS2) 道路类型的角度分类：(其 P20 提供了一个表展示了各论文的建图类型，点边类型)

- 道路级：探测器图、基于路网的图(路段图、路口图、车道图) (论文图2表示例子)

  Road-level graphs. These include sensor graphs, road segment graphs, road intersection graphs, and road lane graphs.  

  - Sensor graphs are based on traffic sensor data (e.g. the PeMS dataset) where each sensor is a node, and the edges are road connections
  - The other three graphs are based on road networks with the nodes formed by road segments, road intersections, and road lanes, respectively.   

  适用：当应用车辆只在建图范围内移动时

  In some cases, road-level graphs are the most suitable format, e.g., when vehicles can move only through pre-defined roads  

  其中探测器和路段是全部数据里最常用的：现成数据集多

  Sensor graphs and road segment graphs are most frequently used because they are compatible with the available public datasets  

  (图源 T-ZS20，进行了重绘)

  ![image-20240801212136966](img/image-20240801212136966.png)

- 区域级：不规则、规则、OD

  Region-level graphs. These include irregular region graphs, regular region graphs, and OD graphs  

  - 规则：适合 CNN

    Regular region graphs, which have grid-based partitioning, are listed separately because of their natural connection to previous widely used grid-based forecasting using CNNs, in which the grids may be seen as image pixels.  

  - 不规则 (具体 zip code 地图图片实例：[here](https://maps-manhattan.com/manhattan-zip-code-map))

    irregular region graphs include all other partitioning approaches, e.g. road based, or zip code based (如 [T-68](https://www.sciencedirect.com/science/article/pii/S0968090X20307580))

  - OD：节点是起点终点对

    In the OD graph, thenodes are origin region - destination region pairs

  边是邻居或其他相似性(如 PoI 数据的功能相似)

  In these graphs, the edges are usually defined with a spatial neighborhood or other similarities, e.g., functional similarity derived from point-of-interests (PoI) data  

- 站点级：地铁、车站、单车站、铁路、共享汽车站、停车场、停车块

  Station-level graphs. These include subway station graphs, bus station graphs, bike station graphs, railway station graphs, car-sharing station graphs, parking lot graphs, and parking block graphs. Usually, there are natural links between stations that are used to define the edges, e.g. subway or railway lines, or the road network  

  例子如 [北京地铁线路图](https://www.travelchinaguide.com/cityguides/beijing/transportation/subway.htm)

- 可以混合使用，如：[T-69](https://ieeexplore.ieee.org/abstract/document/9098104)、[T-70](https://www.worldscientific.com/doi/abs/10.1142/S0218194019400187)

##### 邻接矩阵构造

Adjacency Matrix Construction

> 重要性：(T-ZS2 说 T-ZS20 说的) Adjacency matrices are seen as the key to capturing spatial dependency in traffic forecasting

灵活性较大：

(T-ZS2) While nodes may be fixed by physical constraints, the user typically has control over the design of the adjacency matrix, which can even be dynamically trained from continuously evolving data

分类：

(T-ZS2 基于 T-ZS20 改进) 基于：道路、距离、相似性、动态矩阵 (论文有表 3)

divide them into four types, namely, road-based, distance-based, similarity-based, and dynamic matrices  

连接和距离最常用：定义简单 

The connection and distance matrices are the most frequently used types, because of their simple definition and representation of spatial dependency.  

- 道路 Road-based Matrix：连接矩阵、交通连接性矩阵、方向矩阵

  This type of adjacency matrix relates to the road network and includes connection matrices, transportation connectivity matrices, and direction matrice  

  - 连接矩阵：最常用，01 矩阵

    A connection matrix is a common way of representing the connectivity between nodes. It has a binary format, with an element value of 1 if connected and 0 otherwise  

  - 交通连接性：很远但可达也连接；可以用几分钟内可达都连一条边

    The transportation connectivity matrix is used where two regions are geographically distant but conveniently reachable by motorway, highway, or subway (T-ZS2 说 T-ZS20 说的)

    It also includes cases where the connection is measured by travel time between different nodes, e.g. if a vehicle can travel between two intersections in less than 5 minutes then there is an edge between the two intersections (用时间内可达做例子的，T-ZS2 说 [T-71](https://ieeexplore.ieee.org/abstract/document/8612556))

- 距离矩阵：邻居和距离

  This widely used matrix-type represents the spatial closeness between nodes. It contains two sub-types, namely, neighbor and distance matrices

  - 邻居：有相邻边界就连边

    In neighbor matrices, the element values are determined by whether the two regions share a common boundary (if connected the value is set to 1, generally, or 1/4 for grids, and 0 otherwise)  

  - 距离：驾驶距离、最短路或近似方位(RWR求出)

    In distance-based matrices, the element values are a function of geometrical distance between nodes. This distance may be calculated in various ways, e.g. the driving distance between two sensors, the shortest path length along the road (最短路如 [T-72](https://ieeexplore.ieee.org/abstract/document/8917213)、[T-73](https://www.sciencedirect.com/science/article/pii/S0968090X21004538)) or the proximity between locations calculated by the random walk
    with restart (RWR) algorithm (如 T-62)

    常见缺陷：不考虑长距离相似性，静态

    One flaw of distance-based matrices is that the fail to take into account the similarity of traffic states between long-distance nodes, and the constructed adjacency matrix is static in most cases  

- 相似性：交通模式、功能相似

  This type of matrix is divided into two sub-types, namely, traffic pattern and functional similarity matrices

  - 交通模式：状态联系，如流量模式、互依赖、交通需求关联

    Traffic pattern similarity matrices represent the correlations between traffic states, e.g. similarities of flow patterns, mutual dependencies between different locations, and traffic demand correlation in different regions  

  - 功能：不同类型 PoI 的分布

    Functional similarity matrices represent, for example, the distribution of different types of PoIs in different regions  

- 动态矩阵：不预定义静态的，有优势

  This type of matrix is used when no pre-defined static matrices are used. Many studies have demonstrated the advantages of using dynamic matrices, instead of a pre-defined adjacency matrix, for various traffic forecasting problems 

##### 动态静态对比

(T-64) 静态图可能不能反应真实依赖

However, the explicit graph structure (relation) does not necessarily reflect the true dependency and genuine relation may be missing due to the incomplete connections in the data.

> (T-64) 静态的局限性的例子
>
> To give each circumstance an example, let us consider a recommendation system. In the first case, two users are connected, but they may have distinct preferences over products. In the second case, two users may share a similar preference

T-ZS29 静态动态各有优缺点，给出了动态的定义

In the early research stages, static graphs were widely used because of their convenience. However, researchers realized that static graphs were insufficient to capture changes in network topology and traffic patterns. For example, traffic flow measurements and their correlations on road segments change dynamically in space and time, which is beyond the modeling capabilities of static graphs. Then, dynamic graphs were introduced. 

As the name implies, a dynamic graph is a graph that can evolve as new nodes or edges are added or removed. However, static graphs are still very useful when the traffic infrastructure remains unchanged for the time period considered. Therefore, some researchers use both dynamic and static graphs. The static graph is used to model the static road network, and the dynamic graph is used to consider the impact of dynamic traffic events and weather information.

#### 基础

> 公式暂略，具体看论文

##### 分类

> 分类：基于 RNN, CNN, FNN, 注意力
>

> (T-ZS2 说 O-7 说的) 循环 GNN，卷积 GNN，GAE(图自编码器)，时空 GNN
>
> GNNs can be roughly divided into four types, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatiotemporal GNNs  
>
> (T-ZS2) 按照这个定义，全都是时空 GNN，但可以根据时间用啥再分：RNN 和 CNN 可以处理时间信息 （RNN 论文数比 CNN 多一倍左右）
>
> Spatiotemporal GNNs can be further categorized based on the approach used to capture the temporal dependency in particular. Most of the relevant studies in the literature can be split into two types, namely, RNN-based and CNN-based spatiotemporal GNNs  
>
> (T-ZS2) 此外还有基于注意力的，基于 FNN 的，一共四种分类。
>
> With the recent expansion of relevant studies, we add two sub-types of spatiotemporal GNNs in this survey, namely, attention-based and FNN-based
>
> (T-ZS2) 其中 Transformer 有 T-74, T-75, T-76, T-77，注意力机制和 FNN 的论文数量差不多，感觉都没 CNN 和 RNN 多
>
> 其他技术：
>
> - autoregression [T-78](https://arxiv.org/abs/1905.10709)
> - Markov processes [T-79](https://www.sciencedirect.com/science/article/pii/S0968090X20305866)
> - Kalman filters [T-80](https://journals.sagepub.com/doi/abs/10.1177/0361198120919399) T-99

> 同时处理时空：图卷积融入 RNN
>
> (T-ZS2) Some efforts are put to jointly modeling the potential interaction between spatial and temporal features and one promising direction is the incorporate of the graph convolution operations into RNNs to capture spatial-temporal correlations  
>
> - 如 [T-82](Gated residual recurrent graph neural networks for traffic prediction), [T-83](Optimized graph convolution recurrent neural network for traffic prediction), [T-84](https://ieeexplore.ieee.org/abstract/document/9269513), [T-85](https://arxiv.org/abs/1903.05631). [T-86](https://arxiv.org/abs/1906.00560)
>
> (T-ZS2) 例如邻接矩阵+局部时空图的 GCN [T-87](https://ojs.aaai.org/index.php/AAAI/article/view/5438)
>
> For example, the localized spatio-temporal correlation information is extracted simultaneously with the adjacency matrix of localized spatio-temporal graph, in which a localized spatio-temporal graph that includes both temporal and spatial attributes is constructed first and a spatial-based GCN method is applied then  

> 卷积 GNN 最常用，循环 GNN ([O-19](https://ieeexplore.ieee.org/abstract/document/4700287)) 和 GAE ([O-20](https://arxiv.org/abs/1611.07308)) 更少用
>
> (T-ZS2) Of the additional GNN components adopted in the surveyed studies, convolutional GNNs are the most popular, while recurrent GNN and Graph Auto-Encoder (GAE) are used less frequently  

##### 讨论

T-ZS29 说 GCN, GAT 最常用

For the model component part, the graph convolutional network (GCN) O-14 and graph attention network (GAT) O-18

> T-ZS28
>
> ![image-20240908210521268](img/image-20240908210521268.png)

- 卷积CNN

  - 空域

    优：灵活性强、可扩展性强

    缺：缺少理论支撑

  - 频域

    优：理论基础扎实

    缺：结构固定，不适用于有向图

- 图注意网络

  优：自适应地关注重要邻居

  缺：只关注节点的局部结构

- 图自编码器

  优：重塑图保留动态随机特性

  缺：为学习到有效数据分布，需要对损失函数进行处理

- 图时空网络

  - 基于RNN

    优：应用广泛，性能良好

    缺：迭代耗时，门控机制复杂

  - 基于CNN

    优：并行计算，稳定梯度

    缺：缺乏对长序列的记忆

##### 卷积GNN介绍

###### 概述

(T-ZS25)

目前，主流研究方向包括基于谱域（频域）和空域的图卷积。其中谱域方法是通过谱分析考虑卷积的局部性，从而将ＣＮＮ模拟构建到谱域，如谱图卷积（Ｓｐｅｃｔｒａｌ　Ｇｒａｐｈ　Ｃｏｎｖｏｌｕｔｉｏｎ，ＳＧＣ），该方法主要集中于对谱图理论核心公式的不断推导和改善，从优化参数的角度降低方法的运算量。空域方法直接在图的节点及其邻域上执行卷积滤波器，如扩散图卷积（Ｄｉｆｆｕｓｉｏｎ　Ｇｒａｐｈ　Ｃｏｎｖｏｌｕｔｉｏｎ，ＤＧＣ）

T-ZS29 

优缺点分析 (O-14 的或一般 GCN 的，GPT 说是一般的)

A GCN is a pioneer in transferring the concept of convolution operations from Euclidean image data to non-Euclidean image data and has achieved great success in the past few years. The basic idea of a GCN is to aggregate the features from neighbors and then apply a linear transformation on the aggregated features. GCN layers can be stacked k times to capture k-hop neighbor information. However, a GCN requires the entire graph structure for training, which consumes a considerable amount of computer memory.

###### 谱域

T-ZS37 利用卷积定理将卷积转换至谱域进行计算，即频域图卷积

T-ZS25 由于图平移不变性的缺失给在节点域定义卷积神经网络带来困难，谱域方法利用卷积定理从谱域定义图卷积。谱域图卷积网络基于图信号处理，将图神经网络的卷积层定义为一个滤波器，即通过滤波器去除噪声信号从而得到输入信号。谱域图卷积的处理过程可以简单理解为：空域的图信号变换到谱域，在谱域进行卷积操作，最后将卷积后的信息再变换回空域，这样就可以实现在非欧式结构的路网中进行空间特征提取

T-ZS37 在谱图分析中，图结构的数据一般用其相应的拉普拉斯矩阵表示．通过分析拉普拉斯矩阵及其特征值，可以得到对应图结构的性质

- O-13

  T-ZS25 基于切比雪夫多项式的切比雪夫网络（ＣｈｅｂｙｓｈｅｖＮｅｔｗｏｒｋ，ＣｈｅｂＮｅｔ），通过限制卷积核的大小实现局部信息的提取和计算复杂度的降低，将计算复杂度由 $O(n^2)$ 降为 $O(n)$，将图卷积从理论推广到实际应用

- O-14

  T-ZS25 为了使ＣｈｅｂＮｅｔ有更好的局部连接特性，使用一阶切比雪夫多项式并通过限制参数来简化谱图卷积

  T-ZS37 当图的维度较大时，直接对拉普拉斯矩阵进行特征值分解复杂度较大．因此，采用切比雪夫多项式进行近似达到高效运算的目的

- [O-30](https://www.sciencedirect.com/science/article/pii/S1063520310000552)

  T-ZS25 图小波神经网络（Ｇｒａｐｈ　Ｗａｖｅｌｅｔ　Ｎｅｕｒａｌ　Ｎｅｔｗｏｒｋ，ＧＷＮＮ），使用小波变换替代谱域图卷积中的傅里叶变换，分别计算特征变换和卷积，有效降低了计算的复杂度，并且利用小波变换的特点实现局部特征的提取
  
- O-12

  图卷积利用在傅里叶域内对角化的线性算子来代替经典的卷积算子
  
- [O-41](https://www.mdpi.com/2077-1312/9/3/330)

  用图拉普拉斯的一阶近似叠加多个局域图卷积层可以定义分层线性公式

T-ZS28 也有介绍，这里没有赘述了，先后提到了 O-13，O-14

###### 空间域

T-ZS37 将图中的顶点按照某种规则重新排列成特定的网格形式，使其可以直接在空间域上进行卷积运算，即空域图卷积

空域图卷积的通用框架主要有两种：一种是 MPNN，一种是 MoNet

- O-16 

  T-ZS28 消息传递神经网络(Message Passing Neural Network,MPNN)概述了基于空域的ConvGNN的一般框架,它将图卷积视为一种消息传递过程,其中消息可以直接从一个节点沿边传递到另一个节点。通过运行T步消息传递使消息得到充分远的传播

  T-ZS37 空域图卷积的通用框架主要有两种：一种是消息传递神经网络，它的出发点是节点之间的信息聚合，其核心是聚合函数

  对空域图卷积聚合函数的一般架构进行了定义，利用聚合函数对各个节点的自身信息和周围信息进行聚合和更新．空域卷积过程被分解为消息传递与状态更新两个过程

  虽然基于ＭＰＮＮ框架可以直接在空域进行卷积，但面对庞大的图数据时，基于ＭＰＮＮ框架的空域卷积方法需要占用庞大的计算资源．另外，平移不变性的缺失还会给图卷积网络的定义带来困难

- [O-36](https://openaccess.thecvf.com/content_cvpr_2017/html/Monti_Geometric_Deep_Learning_CVPR_2017_paper.html)

  T-ZS25 混合模型网络（Ｍｉｘｔｕｒｅ　Ｍｏｄｅｌ　Ｎｅｔｗｏｒｋ，ＭｏＮｅｔ），通过定义多个核函数衡量目标节点与其他节点的相似度，并且将核函数的权重作为卷积核的参数，该方法也作为空域图卷积的经典方法而广泛应用

  T-ZS37 它立足于图的平移不变性，通过合适的映射函数将拓扑上每个节点的局部结构映射为相同大小的向量以便进一步学习共享卷积核

  ＭｏＮｅｔ利用图上定义的伪坐标系，将节点ｙ映射为伪坐标系下的ｄ维向量

- [O-35](https://proceedings.mlr.press/v48/niepert16)

  T-ZS25 空间域图卷积神经网络是从图中的节点出发，设计聚集邻居节点特征的聚合函数，采用消息传播机制，思考怎样准确高效地利用中心节点的邻居节点特征来更新表示中心节点特征。ＣＮＮ的本质是加权求和，空间域的图卷积神经网络正是从ＣＮＮ的基本构造过程出发，从求和的角度来完成图神经网络（Ｇｒａｐｈ　Ｎｅｕｒａｌ　Ｎｅｔｗｏｒｋ，ＧＮＮ）聚合邻居节点的目的

  由于图中的节点无序且邻居节点个数不确定，所以空间域的图卷积神经网络的工作步骤是：①固定邻居节点个数；②给邻居节点排序。如果完成了上述２个工作，非欧氏结构数据就变成了普通的欧氏结构数据，传统的方法也就可以完全迁移到图上来。其中，步骤①也是便于将ＧＮＮ应用于节点数量巨大的图上。但是该方法需要整张图所有节点均参与训练，运算复杂度高，实时性较差，并且只适用于固定图结构

- O-17

  T-ZS25 信息聚合的角度出发提出了图采样与聚合（Ｇｒａｐｈ　Ｓａｍｐｌｅ　ａｎｄＡｇｇｒｅｇａｔｅｄ，ＧｒａｐｈＳＡＧＥ）方法，其核心思想是通过聚合相邻节点的信息以更新中心节点。每个聚合函数可以学习单个节点的不同搜索深度或跳数的信息聚合，通过训练好的聚合函数来对新增节点进行特征提取

  T-ZS28 考虑到权值计算依赖于整个网络结构形式和节点的特征表达,对于大规模图需要占用大量计算资源,图采样聚合(GraphSampleandAggregate,GraphSAGE)网络,有效缓解了这个问题,通过对近邻节点随机采样,每个节点选取固定数量的不同阶邻居作为相关节点,将聚合函数作用在相关节点的特征表达上,来更新目标节点的特征,从而完成相应的预测任务

- [O-37](https://arxiv.org/abs/2007.16002)

  T-ZS25 深度层次图卷积网络（Ｈｉｅｒａｒｃｈｉｃａｌ　Ｇｒａｐｈ　Ｃｏｎｖｏｌｕｔｉｏｎａｌ　Ｎｅｔｗｏｒｋ，ＨＧＣＮ）引入图池机制，将结构上相似的节点聚合为超节点，将粗化的图细化为原始图，从而增大感受野，有效地捕获全局信息
  
- T-ZS28 从邻居聚合的信息不同,邻居信息与自身信息的组合方式不同,或者节点的读出方式不同,都会导致最终获得的结果不同。由此可见,基于空域的图卷积方法的关键在于如何有效地聚合局部特征,聚合函数定义形式是构建模型的核心问题。对偶图(DualGraph)网络考虑了交通网络中节点和边的交互,用消息传递来模拟节点和边之间的递归交互,实现了同时预测节点和边的交通特征 (引用量才12，2019，CCF-C，感觉useless)

- T-ZS28 图采样聚合网络给出了3种聚合函数形式,分别是均值聚合、LSTM聚合和池化聚合。通过随机采样的方式,只需要加载随机采样的局部网络结构和相关节点的特征表达,这为搭建大规模图卷积模型提供了思路。同时引入邻居采样,将节点局部结构唯一表示转变为对应的多种局部结构归纳表示,可增强泛化能力

- O-15 

  T-ZS28 扩散卷积神经网络(Diffusion-ConvolutionalNeuralNetwork,DCNN)将图卷积视为一种扩散过程,它假设信息是以一定的转移概率从一个节点传递到邻域的节点之一,通过多轮传递后收敛于一个平稳分布。由于将交通流的转移过程看作随机游走的扩散过程是形象的,因此,用DCNN对交通网络进行建模是合理的。此外,采用双向扩散操作能够捕获有向图上的空间相关性,能够更灵活地模拟上下游交通的影响

###### 动态

T-ZS37

在早期基于图卷积网络的交通流预测方法中，描述路网中不同节点之间空间关联关系的结构图在训练过程中始终保持不变．但事实上，实际路网中不同节点之间空间关系是随时间变化的，静态的空间结构图不能很好地描述这种变化的空间拓扑结构

- T-134 DGCNN
- [T-228](https://ieeexplore.ieee.org/abstract/document/9729487) DSTAGCN 

- [T-230](https://ieeexplore.ieee.org/abstract/document/9534054) MASTGCN (CCF-C CI-13 DT-2021)

  动态图卷积是基于注意力机制实现的，然而传统注意力机制计算的注意力得分可能存在较大误差．因此，Ｈｕ等提出一种基于多注意力机制时空图卷积网络（ＭＡＳＴＧＣＮ）的交通流预测模型，用以实现对时空特征的动态调整．此外，随着Ｔｒａｎｓｆｏｒｍｅｒ在交通流预测领域的广泛应用，基于传统注意力机制的动态图也面临着巨大的挑战．相比于传统的注意力机制，Ｔｒａｎｓｆｏｒｍｅｒ中的自注意力机制计算的注意力得分更加准确．因此，一些研究者开始使用自注意力机制来代替传统的注意力机制构建动态图卷积网络

- [T-231](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4142192) (CCF-NONE CI-3 DT-2022)

  提出一种基于多头自注意力机制时空信息图卷积网络（ＭＳＡＳＴＩＧＣＮ）的交通流预测方法．在该方法中，将传统的注意力机制替换为多头自注意力机制，使模型能够更准确地捕获路网空间关系的动态变化，在一定程度上提高了模型的预测性能

###### 多图

T-ZS37

在大多数基于单图的图卷积网络中，相邻节点之间的空间相关性是根据它们之间的距离定义的．但事实上，节点之间的距离并不能完全地代表它们之间的空间关联关系．例如，距离较近的两个节点之间可能并无直接的连接关系，距离较远的两个节点之间的流量也可能存在某种相似性．单一的图结构难以充分地描述这些隐含的空间关联关系．因此，一些研究人员使用多图融合的思想，从不同的角度来更加全面地描述节点之间的空间关联关系

- T-69 T-MGCN

- [O-42](https://proceedings.neurips.cc/paper/2020/hash/ea3502c3594588f0e9d5142f99c66627-Abstract.html?ref=https://githubhelp.com) FactorGCN

  为了提高ＧＣＮ捕获节点间空间关联关系的能力，Ｙａｎｇ等设计了一种可分解图卷积结构（ＦａｃｔｏｒＧＣＮ）．在ＧＣＮ中，图被广泛用于表示实体之间的关联关系．多数情况下，这种异构的关系是交织在一起的．可分解图卷积结构ＦａｃｔｏｒＧＣＮ则明确地解开了编码在图中的这种关系．该文先将一个原始的图分解为多个子图，每个子图表示节点之间潜在的、分解的空间关联关系．然后，在每个分解的潜在空间中分别聚合节点的特征以产生分离的特征，从而进一步提高下游预测任务的性能

- T-232 MTMGNN

  提出一种基于多时间⁃多图神经网络（ＭＴＭＧＮＮ）的地铁客流预测模型．该模型采用了６种图来表示不同模式下地铁站不同站点间的空间连接．另外，针对复杂但有规律的地铁客流波动特征，该文同时利用近期客流数据和长期客流数据，并从长期客流数据中挖掘与人们出行习惯密切相关的惯性特征

- T-83 DDP-GCN

  从路网中节点间的距离、方向、位置关系３个维度分别构建空间关联关系图，并在此基础上提出了一种基于多图卷积网络的交通流预测模型．仿真测试结果表明，该模型在解决复杂的城市路网长期交通流预测问题上具有一定优势

- T-234 ST-MGC

  将不同区域间的非欧几里得相关性编码为多个图，然后使用多图卷积对这些相关性进行建模，并在此基础上提出了一种基于时空多图卷积网络（ＳＴ⁃ＭＧＣＮ）的网约车需求预测模型．该模型可以更加充分地挖掘相邻区域和非相邻区域的空间相关性，提高了网约车需求预测的准确性

- [T-235](https://www.sciencedirect.com/science/article/pii/S0950705122004804) TFGAN

  提出一种带有多图卷积网络的生成对抗网络（ＴＦＧＡＮ）模型．该文从空间相似性、相关性、空间距离３个不同的视角创建邻接矩阵描述路网的空间关联关系，并利用多个ＧＣＮ、ＧＲＵ、自注意力机制来学习路网中节点历史流量序列的局部相关性

###### 自适应

T-ZS37

结果表明，使用自适应图的模型比依赖单一静态图结构的模型具有更加优秀的性能．然而，一般的自适应图仅能在训练阶段发挥作用，无法在测试阶段利用测试数据自适应地更新图结构．由于交通数据经常受到时间序列中的异常变化的影响，上述缺点可能会导致某些情况下预测的性能明显下降

- T-64 Graph WaveNet

  通过构造一个自适应邻接矩阵，保留了隐藏的空间依赖性．同时能够从数据中发掘不可见的图结构，而无需任何先验知识的指导

- T-110 AGCRN

  设计了一个ＤＡＧＧ模块，可以从数据中自适应地推断隐藏的空间依赖关系．ＤＡＧＧ模块首先为所有节点随机初始化一个可学习的节点嵌入

- T-236 PGCN

  提出一种渐进式图卷积模型（ＰＧＣＮ）．该模型通过学习图节点之间的趋势相似性，实现了构造渐进式邻接矩阵对路网拓扑进行渐进式学习．为了捕获动态空间相关性

- T-237 TVGCN

  提出一种时变图卷积模型（ＴＶＧＣＮ）．他们设计了一个时变空间卷积模块，可以在不需要任何先验知识的情况下对复杂的路网拓扑结构进行提取．ＴＶＧＣＮ中构建了静态、动态两种自适应图．一个图以数据驱动的方式学习来捕获交通节点之间的静态空间相关性，而另一个图用于自适应地建模不同时间的动态空间相关性．在图卷积网络（ＧＣＮ）的框架下，他们将这两个图分层组合在一起同时捕获交通图的静态和动态空间相关性

###### 残差

T-ZS37

残差网络可以使上一个残差块的信息传递到下一个残差块，提高信息的传递效率，并且避免了随着网络深度的增加出现的梯度消失问题和退化问题

- T-174

  将残差引入ＬＳＴＭ提出残差图卷积长短时记忆（ＲＧＣ⁃ＬＳＴＭ）模型用于交通预测．该模型具有参数少、计算量小、收敛速度快的优势

- T-240

  在图卷积层中加入残差网络（ＲｅｓＧＣＮ），以解决深度卷积网络的退化问题，其结构示意如图４所示，在ＲｅｓＧＣＮ中还使用双向门控递归单元（ＢｉＧＲＵ）对交通时间序列数据进行前向和后向建模．

##### 图注意力

###### 对比 GCN

T-ZS29

GAT, based on the attention mechanism, was introduced as an alternative to GCN. The main difference between GAT and GCN is the introduction of importance scores for different neighbors based on the masked self-attention mechanism

Designing more effective GCN or GAT variants is still a major research direction.

###### 注意力

- O-18

  T-ZS28 上述模型(GCN)在进行聚合过程中对邻居节点共享权值,无法根据节点的特征属性来调整邻居权重,这一点限制了模型对空间相关性的捕捉能力,而交通网络具有复杂的连接关系,各节点对目标节点的重要度不同,例如换乘站点和普通站点对目标站点影响力具有差异性。GAT利用注意力机制来自适应学习节点间的连接关系,实现对邻居的加权聚合,由此增强了对噪声邻居的鲁棒性 

  T-ZS25 通过引入注意力机制，根据每个节点在其邻域节点的注意力程度对该节点进行更新，提出了图注意力网络（ＧｒａｐｈＡｔｔｅｎｔｉｏｎ　Ｎｅｔｗｏｒｋ，ＧＡＴ）方法。由于每个节点的权重不同，ＧＡＴ有着更好的表达能力，相较于ＧｒａｐｈＳＡＧＥ，ＧＡＴ可以访问所有邻居节点，并且无需对其进行排序，运行更加高效

- T-ZS28 GAT还建议合并一种多头注意机制,通过并行运行多个注意力层,使模型在不同表示的子空间里学习到相关信息,从而提取多重语义相关性,以增强模型的表达能力

- T-ZS28 门注意网络(Gated Attention Network,GaAN)T-88引入了自注意力机制,不同于传统多头注意机制均衡所有的注意头,使用一个卷积子网络来控制每个注意头的重要性,在不同的投影空间中捕捉不同的交互信息,并以GaAN为模块构建了图门控递归单元(Graph Gated Recurrent Unit,GGRU),以解决交通速度预测问题

- T-81 T-ZS37

  一种基于时空注意力的图卷积网络（ＡＳＴＧＣＮ）模型用于解决交通流预测问题．提供公式

- [T-242](https://ieeexplore.ieee.org/abstract/document/9721541) 感觉很水这篇 CCF-NONE T-ZS37

  在其提出的基于多头注意力机制的时空图卷积网络中；局部自注意力块

- [T-243](https://ieeexplore.ieee.org/abstract/document/9766337/) 感觉很水这篇 CCF-NONE T-ZS37

  提出一种具有时间关注的多步耦合图卷积神经网络（ＭＣＧＣＮ）来捕获路网中不同层级的时空关联关系．他们设计了一个多步耦合图卷积模块（ＭＣＧＣ），通过耦合学习关系矩阵来建模交通网络的空间特征，以获取交通路网的不同层次信息．然后，将ＭＣＧＣ提取的交通网络信息反馈到多步耦合图门控递归单元（ＭＣＧＲＵ）模块中，实现时空特征的融合．最后，利用多步耦合图注意机制（ＭＣＧＣＡｔｔ）提取历史交通流量中包含的时间信息，从而进一步提升模型的预测性能

###### Transformer

T-ZS37

- T-59 STTN

  通过联合利用动态的有向空间依赖关系和长程时间依赖关系，提出一种新的时空Ｔｒａｎｓｆｏｒｍｅｒ（ＳＴＴＮ）模型来提高长期交通流量预测的准确性．他们设计了一个包含空间Ｔｒａｎｓｆｏｒｍｅｒ和时间Ｔｒａｎｓｆｏｒｍｅｒ的时空模块．其中，空间Ｔｒａｎｓｆｏｒｍｅｒ利用空间多头注意力机制建模不同模式（连通性、相似性等）的动态空间依赖性，时间Ｔｒａｎｓｆｏｒｍｅｒ则被用于建模多个时间步长下的长程时间依赖性．仿真实验结果表明，与现有其他模型相比，ＳＴＴＮ模型在处理长程时空依赖关系时更高效且可扩展．随着研究的深入，研究人员发现Ｔｒａｎｓｆｏｒｍｅｒ模型对近距离时间相关性不够敏感．因此，为综合利用ＲＮＮ擅长建模近距离时间相关性和Ｔｒａｎｓｆｏｒｍｅｒ模型擅长建模长程时间相关性的优势，许多研究人员将ＲＮＮ与Ｔｒａｎｓｆｏｒｍｅｒ模型或是将ＴＣＮ与Ｔｒａｎｓｆｏｒｍｅｒ模型进行融合，以同时捕获数据中的近距离和远距离时间相关性

- T-173 STGNN

  提出一种新的具有位置级注意机制（ｐｏｓｉｔｉｏｎ⁃ｗｉｓｅａｔ⁃ｔｅｎｔｉｏｎｍｅｃｈａｎｉｓｍ）的图神经网络，能动态地聚合来自相邻道路的历史交通流信息．为了更好地提取时间特征，他们同时使用ＲＮＮ和Ｔｒａｎｓｆｏｒｍｅｒ模型来捕获局部和全局的时间相关性．为了进一步提高Ｔｒａｎｓ⁃ｆｏｒｍｅｒ模型在处理交通流预测任务时的有效性，一些研究者对Ｔｒａｎｓｆｏｒｍｅｒ的结构进行了改进

- T-202 Traffic Transformer

  譬如，针对Ｔｒａｎｓｆｏｒｍｅｒ模型适合处理的数据与典型时间序列数据之间存在较大差异、Ｓｅｑ２Ｓｅｑ和Ｔｒａｎｓｆｏｒｍｅｒ模型的结构易导致累计误差、Ｔｒａｎｓｆｏｒｍｅｒ模型不能兼容邻接矩阵等问题，Ｙａｎ等提出一种ＴｒａｆｆｉｃＴｒａｎｓｆｏｒｍｅｒ模型，他们设计了一种特殊的编码和特征嵌入来解决Ｔｒａｎｓｆｏｒｍｅｒ与交通流数据结构不兼容的问题，并将Ｔｒａｎｓｆｏｒｍｅｒ模型的原始编码器和解码器结构改进为全局编码器和全局⁃局部解码器两个组成部分，将多个全局编码器和全局⁃局部解码器块堆叠起来，形成一个具有层次特征的深度预测网络

- [T-246](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9346058) ASTGNN

  提出一种基于时空注意力机制的图神经网络（ＡＳＴＧＮＮ）模型．为了缓解Ｔｒａｎｓｆｏｒｍｅｒ模型中自注意力机制对局部时间特征不敏感的问题，该文设计了一种基于ＣＮＮ实现的自注意力模块提升局部时间特征感知能力，并构建了一个带有自注意力的动态图卷积模块捕获动态空间相关性

##### 图自编码器

T-ZS28

- 图表示学习旨在将节点特征和连接关系的高维复杂网络信息嵌入到低维空间中,使图数据获得高效的表示方式,同时蕴含丰富的语义信息,从而提高下游任务的效率和性能。

- GAE和变分图自编码器(Variational Graph Auto-Encoders,VGAE)是一种图表示学习的深度神经网络结构,其将自编码器的思想引入图结构数据表示中,具有特征提取和节点嵌入的功能 [O-40](https://arxiv.org/abs/1611.07308) 

  具体来说,输入图的特征信息和邻接矩阵,通过学习每个节点的邻域特征信息,进而编码到潜在空间中,再通过解码器重塑图。GAE和VGAE均采用2层GCN结构,解码器采用内积形式,其区别在于GAE中一旦2层GCN的可学习参数确定,得到的潜在表示是确定的,而VGAE通过GCN确定一个潜在表示的近似后验分布,再从分布中采样得到潜在表示。两者训练时目标均为重构图和原始图尽可能相似。除此之外,VGAE目标还包括计算出的分布与标准高斯分布尽可能相似,因此,损失函数由交叉熵和KL散度两部分构成

- [T-226](https://www.tandfonline.com/doi/full/10.1080/21680566.2021.1951885) 提出了基于站点嵌入的混合神经网络,通过具有正则化编码和解码重塑功能的站点嵌入模块,组合每个时隙不同的连接关系构成的图和站点特征信息,获得了每个站点的时变嵌入表示

- [T-227](https://ieeexplore.ieee.org/abstract/document/9140389) 提出的变分图递归注意神经网络中设计了一个用于学习节点静态拓扑相关性和交通状态时间动态性的变分定向GNN模块,该模块能够学习节点潜在表示的近似后验分布,由平均高斯场分布近似,同时学习和传播节点表示的不确定性

- 图自编码器通过对动态图建模,能够捕获动态图中的拓扑和节点属性变化,同时潜在表示可以更好地捕获节点的不确定性。对于交通预测这一时空预测问题,图自编码器不仅能够生成具有动态随机特性的图数据,还能捕获预测结果的不确定性,这对于提升预测性能和模型可解释性具有重要意义

T-ZS37

- [O-41](https://proceedings.neurips.cc/paper/2015/hash/7137debd45ae4d0ab9aa953017286b20-Abstract.html) 自编码器在预测任务上具有更加稳定的表现且泛化效果好

- T-70

  提出一种带有注意力机制的多图卷积Ｓｅｑ２Ｓｅｑ模型（ＡＭＧＣ⁃Ｓｅｑ２Ｓｅｑ）用于共享汽车流量预测．在ＡＭＧＣ⁃Ｓｅｑ２Ｓｅｑ模型中的编码器部分，他们利用ＬＳＴＭ网络提取时间特征，再用多图卷积网络（Ｍ⁃ＧＣＮ）提取空间关联关系．然后，再使用一个ＬＳＴＭ网络对提取的时空特征进行融合，以实现对空间和时间关系的同时编码．在解码器中，一个单独的ＬＳＴＭ被用于解码由编码器传递来的上下文向量，以获得多步预测输出

- T-40

  将交通流量建模为在有向图上进行的扩散过程，提出一种基于扩散卷积循环神经网络（ＤＣＲＮＮ）的交通流预测方法．ＤＣＲＮＮ在利用扩张卷积和ＧＲＵ提取时空依赖的同时，加入自编码器结构来提升模型性能．在模型的训练阶段，历史交通序列被输入到编码器中，并得到隐藏状态．解码器利用隐藏状态和真实观测值生成预测结果．在测试阶段，首先使用训练阶段获得的最终状态初始化解码器．与训练阶段不同的是，解码器的输入由真实的观测值替换为预测值来实现多步预测．另外，为了解决训练和测试两个阶段中数据分布之间存在差异性的问题，ＤＣＲＮＮ模型利用计划采样的方法对输入数据进行采样处理

- [T-241](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-its.2020.0284) 感觉很水这篇 CCF-C

  提出一种用于速度预测的嵌入式图卷积长短时记忆网络（ＥＧＣ⁃ＬＳＴＭ），将ＧＣＮ和ＬＳＴＭ进行融合提取时空特征，并引入注意机制计算特征权重来提高模型在时间维度上的可解释性．为了进一步提高预测准确性，他们在模型中引入了自编码器结构，并将辅助特征进行ｏｎｅ⁃ｈｏｔ编码后输入到解码器部分．特征权重可以反映特征的重要性，间接实现了特征选择；将特征权重传递到ＧＣＮ⁃ＬＳＴＭ中，提高了模型的预测性能

##### 图时空网络

T-ZS28

- 交通网络在时空尺度均具有动态性,同时捕获时空特征的关键在于如何对动态交通网络进行建模。图时空网络一方面能够对节点的动态输入进行建模,另一方面可有效捕获节点间的依赖关系,因此,图时空网络在捕获时空相关性方面占据重要地位,主要可以分为2类:基于RNN的方法和基于CNN的方法

- 为了解决传统RNN导致的梯度弥散和爆炸等问题,研究者大多将图卷积和RNN变体进行结合

  T-36 时间图卷积网络(Temporal Graph Convolutional Network,T-GCN)将GCN和GRU进行了结合,并用于交通速度预测

  T-40 将DCNN和GRU进行结合,利用双向随机游走建模道路网络空间相关性,GRU捕获时间相关性,进一步集成了编码器-解码器架构和定时采样技术,提高了长期预测性能

- T-173? 提 出 的 时 空 图 神 经 网 络 (SpatialTemporalGraph NeuralNetwork,STGNN)结 合 GRU 和变换器层 来 捕 获 局 部 和 全 局 时 间 相 关 性 并 融合了一种学习节点位置潜在表示的空间图神经网 络 (Spatial-Graph NeuralNetwork,S-GNN)层 ,以 更好地聚合邻近道路信息

- T-28 首次应用纯卷积架构,从基于交通图时间序列中同时提取时空特征,通过真实数据集的验证,表明该架构比基于RNN的图时空网络的训练速度快10倍以上,而且训练的参数更少。然而,在处理时间序列问题的实践中,CNN模型不如RNN模型常见,因为CNN模型缺乏对长时间序列的记忆

  T-ZS37

  由于同时包含有图卷积和门控时间卷积，ＳＴＧＣＮ模型可以在提取空间特征的同时，有效地捕获时间特征．由于ＳＴＧＣＮ模型完全由ＣＮＮ组成，因此其训练速度明显优于基于ＲＮＮ的时空图卷积模型

- T-81 基于注意力的时空图卷积网络设计了3个组件来提取时空特征,沿时间轴截取周周期、日周期和最近期3种不同类型的片段,同时将时空注意机制与时空卷积(包括空间维度的图卷积和时间维度的一维卷积)相结合,同时捕获交通网络的动态时空特征,有效提高了预测精度

T-ZS37

- T-39 有公式摘要

- T-238

  提出一种用于城市人流预测的动态深度时空神经网络（ＧＣＮ⁃ＤＨＳＴＮｅｔ）模型．该模型采用ＬＳＴＭ分别提取每小时的流量特征、每天的流量特征和每周的流量特征，利用ＧＣＮ提取空间关联关系来完成预测任务

- T-174

  在ＬＳＴＭ中引入残差连接并与图卷积组合，提出一种基于残差图卷积长短时记忆网络（ＲＧＣ⁃ＬＳＴＭ）的短时流量预测模型

- T-109

  使用动态拉普拉斯矩阵估计器对原有的时空图卷积网络ＳＴＧＣＮ模型进行了改进，提出一种动态图卷积神经网络（ＤＧＣＮＮ）模型．如图２所示，在改进的ＤＧＣＮＮ模型中，拉普拉斯矩阵可以有效感知空间关联性的动态变化

- T-64

  图卷积与扩展因果卷积相结合，提出一种新的图形神经网络体系结构ＧＷＮ（ＧｒａｐｈＷａｖｅＮｅｔ）．图神经网络模型ＧＷＮ具有一个堆叠的扩展１Ｄ卷积组件，其感受野随着层数的增加呈指数增长，因此能够处理长时间序列

##### 图GAN

T-ZS37

- T-244 PL-WGAN

  提出一种用于短时交通速度预测的ＰＬ⁃ＷＧＡＮ模型，其特点是采用一种如图６所示的平行学习框架，构建了一个融合时空注意力机制、ＧＣＮ和ＧＲＵ的混合模型捕获交叉口和路网的时空特征信息．该方法将Ｗａｓｓｅｒｓｔｅｉｎ生成对抗网（ＷＧＡＮ）应用于数据驱动交通建模，并通过在杭州的一个大规模区域网络中的实测验证了其有效性和可扩展性

- [T-245](https://www.tandfonline.com/doi/abs/10.1080/03081079.2023.2203922) CCF-NONE CI-14 DT-2023

  提出一种基于深度学习的时空图生成对抗网络（ＳＴＧ⁃ＧＡＮ）预测模型．该模型构建了一个由门控时间卷积网络（ＴＣＮ）和图卷积网络（ＧＣＮ）构成的生成网络，以捕获交通路网结构的时空依赖性并生成预测数据．同时，也构建了一个包含空间判别器和时间判别器的判别网络，以增强预测模型建模空间和时间约束的能力

##### 图模式分解

T-ZS37

[O-45](https://royalsocietypublishing.org/doi/abs/10.1098/rspa.1998.0193) 经验模态分解（ＥｍｐｉｒｉｃａｌＭｏｄｅＤｅｃｏｍｐｏｓｉｔｉｏｎ，ＥＭＤ）提出的一种信号处理方法，它可以自适应地将原始时间序列分解为几种不同的内在模态函数（ＩＭＦｓ）和残差．得到的ＩＭＦｓ和残差序列具有特定的物理意义，代表原始时间序列的不同时间尺度特征．为了降低预测数据的维度以便更好地对时空相关性进行建模，主成分分析（ＰｒｉｎｃｉｐａｌＣｏｍ⁃ｐｏｎｅｎｔＡｎａｌｙｓｉｓ，ＰＣＡ）方法通过对数据进行归一化等操作将ｍ维原始数据降为ｋ维，然后对归一化得到的数据计算协方差矩阵、特征值和特征向量，将特征值降序排列，并选择最大的ｋ个特征值及其对应的特征向量．最后，使用这些特征向量构造新的特征空间，并在新的特征空间上完成流量预测

- [T-247](https://www.sciencedirect.com/science/article/pii/S0957417422004298) CCF-C 感觉可能水

  借鉴ＥＭＤ和ＰＣＡ等方法通过对时间序列进行分解得到不同时间尺度特征的思路，Ｃｈｅｎ等提出一种基于ＥＭＤ的多元时间图卷积神经网络预测模型．该文先采用ＥＭＤ方法对原始时间序列进行分解，将得到不同尺度下的时间特征作为节点的初始特征生成图模型．然后使用多头注意机制来学习节点之间的隐藏依赖关系，并使用ＧＣＮ网络提取节点空间特征．最后使用一个ＴＣＮ网络为节点嵌入建立时间关系，以执行多变量时间序列预测

- [T-248](https://ieeexplore.ieee.org/abstract/document/9546773) CCF-NONE 感觉水

  设计了一个基于主成分分析（ＰＣＡ）、图卷积网络（ＧＣＮ）和长短期记忆网络（ＬＳＴＭ）的主时空图卷积网络（ＰＳＴ⁃ＧＣＮ）模型．具体来说，ＰＣＡ首先对原始输入数据进行降维，然后构建ＧＣＮ网络学习城市路网的拓扑结构，以获得路网中不同路段和节点间的空间相关性．另外，他们在ＰＳＴ⁃ＧＣＮ模型中构建了一个ＬＳＴＭ网络用来捕获路网中的时间相关性

##### 卷积GNN

> GCN(图卷积网络,Graph Convolutional Network)

给定图 $G=(V,E,A)$，点 $v_i$ 的邻居 $\mathcal N(v_i)$，$\mathbf D$ 是度矩阵，即 $\mathbf D_{ii}=||\mathcal N(v_i)||$，$\mathbf L=\mathbf D-\mathbf A$ 是无向图拉普拉斯矩阵，且 $\tilde{\mathbf L}=\mathbf I_N-\mathbf D^{-\frac12}\mathbf A\mathbf D^{-\frac12}$ 是标准化的该矩阵，其中 $\mathbf I_N$ 是 $N$ 阶单位矩阵；不考虑时间步，则节点信息矩阵是 $\mathbf X\in R^{N\times d}$，$d$ 是信息的维度，$N$ 是节点数

> (T-ZS2) Give a graph G = (V; E; A), N (vi) is defined as the neighbor node set of a single node vi. D is defined as the degree matrix, of which each element is $\mathbf D_{ii}=||\mathcal N(v_i)||$，$\mathbf L=\mathbf D-\mathbf A$ is defined as the Laplacian matrix of an undirected graph and $\tilde{\mathbf L}=\mathbf I_N-\mathbf D^{-\frac12}\mathbf A\mathbf D^{-\frac12}$ is defined as the normalized Laplacian matrix, where  $\mathbf I_N$ is the identity matrix with size N. Without considering the time step index, the node feature matrix of a graph is simplified as $\mathbf X\in R^{N\times d}$ , where N is the node number and d is the dimension of the node feature vector as before.  

欧氏数据卷积扩展到非欧时，将学习一个关于节点及其邻居的数据映射

> (T-ZS2) When extending the convolution operation from Euclidean data to nonEuclidean data, the basic idea of GNNs is to learn a function mapping for a node to aggregate its own features and the features of its neighbors to generate a new representation  

GCN 是基于频谱的卷积 CNN，图卷积：先傅里叶，做操作，再逆傅里叶回去

(T-ZS2) GCNs are spectral-based convolutional GNNs, in which the graph convolutions are defined by introducing filters from graph signal processing in the spectral domain, e.g., the Fourier domain. The graph Fourier transform is firstly used to transform the graph signal to the spectral domain and the inverse graph Fourier transform is further used to transform the result after the convolution operation back

> (T-ZS2) 背景：
>
> - 核是可学习参数，多通道
>
>   [O-11](https://arxiv.org/abs/1312.6203) Spectral convoluted neural networking assumes that the filter is a set of learnable parameters and considers graph signals with multiple channels 
>
> - 平滑，空间局部性
>
>   [O-12](https://arxiv.org/abs/1506.05163) GNN introduces a parameterization with smooth coefficients and makes the spectral filters spatially localized
>
> - 切比雪夫多项式扩展来近似对角矩阵
>
>   [O-13](https://proceedings.neurips.cc/paper_files/paper/2016/hash/04df4d434d481c5bb723be1b6df1ee65-Abstract.html) Chebyshev’s spectral CNN (ChebNet)  leverages a truncated expansion in terms of Chebyshev polynomials up to Kth order to approximate the diagonal matrix  

GCN ([O-14](https://arxiv.org/abs/1609.02907)) 是 ChebNet 的近似，且 $K=1$ 避免过拟合，使用对角矩阵特征值的切比雪夫多项式来近似卷积核，定义卷积操作如下：

(T-ZS2) is a first-order approximation of ChebNet, which approximates the filter using the Chebyshev polynomials of the diagonal matrix of eigenvalues. To avoid overfitting, K = 1 is used in GCN. Formally, the graph convolution operation ∗G in GCN is defined as follows:
$$
\mathbf X_{*G}=\mathbf W(\mathbf I_N+\mathbf D^{-\frac12}\mathbf A\mathbf D^{-\frac12})\mathbf X
$$
$\mathbf W$ 是模型参数，为了降低梯度爆炸，修改为：

> (T-ZS2) where W is a learnable weight matrix, i.e., the model parameters. While in practice, the graph convolution operation is further developed in order to alleviate the potential gradient explosion problem as follows  

$$
\mathbf X_{*G}=\mathbf W(\mathbf{\tilde D}^{-\frac12}\mathbf{\tilde A}\mathbf{\tilde D}^{-\frac12})\mathbf X
$$

其中 $\mathbf{\tilde A}=\mathbf A+\mathbf I_N$ 且 $\mathbf{\tilde D}_{ii}=\sum_j \mathbf{\tilde A}_{ij}$ 

替代方法：基于空间的卷积 GNN：图卷积定义为信息传播。如 DCG, MPNN, GraphSAGE, GAT。

(T-ZS2) The alternative approach is spatial-based convolutional GNNs, in which the graph convolutions are defined by information propagation.  

- DGC [O-15](https://proceedings.neurips.cc/paper_files/paper/2016/hash/390e982518a50e280d8e2b535462ec1f-Abstract.html) Diffusion graph convolution  

  图卷积建模为扩散过程，从一个节点到相邻节点的转移概率被考虑在内，最终达到平衡

  The graph convolution is modeled as a diffusion process with a transition probability from one node to a neighboring node in DGC. An equilibrium is expected to be obtained after several rounds of information transition  

- MPNN [O-16](https://proceedings.mlr.press/v70/gilmer17a) message passing neural network  

  图卷积为从一个点到其他连通点直接传递信息的过程

  The general framework followed is a message passing network, which models the graph convolutions as an information-passing process from one node to another connected node directly  

  用信息传播函数来统一不同空间变量，操作两阶段：信息传递、读出。

  > MPNN uses message passing functions to unify different spatial-based variants. MPNN operates in two stages, namely, a message passing phase and a readout phase. The message passing phase is defined as follows:  

  信息传递阶段：
  $$
  \mathbf m^{(t)}_{v_i}=\sum_{v_j\in\mathcal N(v_i)}\mathcal M^{(t)}(\mathbf X_i^{(t-1)},\mathbf X_j^{(t-1)},\mathbf e_{ij})
  $$
  $\mathbf m^{(t)}_{v_i}$ 是从 $v_i$ 的邻居聚合而来的信息，$\mathcal M^{(t)}(\cdot)$ 是第 $t$ 次迭代的聚合函数，$\mathbf X_i^{(t)}$ 是该次迭代 $v_i$ 节点的隐藏状态，$\mathbf e_{ij}$ 是 $v_i,v_j$ 之间的边特征向量

  > where m( vti) is the message aggregated from the neighbors of node vi, M(t)(·) is the aggregation function in the t-th iteration, X(it) is the hidden state of node vi in the t-th iteration, and eij is the edge feature vector between node vi and node vj.  

  读出阶段：
  $$
  \mathbf X_i^{(t)}=\mathcal U^{(t)}(\mathbf X_i^{(t-1)},\mathbf m^{(t)}_{v_i})
  $$
  其中 $\mathcal U^{(t)}(\cdot)$ 是读出函数。

  > The readout phase is defined as follows, where U(t)(·) is the readout function in the t-th iteration  

- GraphSAGE [O-17](https://proceedings.neurips.cc/paper/2017/hash/5dd9db5e033da9c6fb5ba83c7a7ebea9-Abstract.html)

  只采样固定数量的邻居避免计算问题

  To alleviate the computation problems caused by a large number of neighbors, sampling is used to obtain a fixed number of neighbors  

- GAT [O-18](https://arxiv.org/abs/1710.10903) graph attention network  

  用注意力机制(O-5 开山)学习两个连通点之间的相对权重

  without using a predetermined adjacency matrix, the attention mechanism is used to learn the relative weights between two connected nodes  

  使用了多头注意力机制：稳定学习过程

  the attention mechanism is incorporated into the propagation step and the multi-head attention mechanism is further utilized with the aim of stabilizing the learning process 

  > The specific operation is defined as follows:

  $$
  \mathbf X_i^{(t)}=||_k\sigma(\sum_{j\in\mathcal N(v_i)}\alpha^k(\mathbf X_i^{(t-1)},\mathbf X_j^{(t-1)})\mathbf W^{(t-1)}\mathbf X_j^{(t-1)})
  $$

  其中 $\sigma$ 是激活函数，$\alpha^k(\cdot)$ 是第 $k$ 次的注意力机制，$||$ 是连接操作

  > where k is the concatenation operation, σ is the activation method, αk(·) is the k-th attention mechanism  

> 如图，分别是：两层 GCN 和时空 GNN 典型结构 (1D CNN + GCN 为例)，论文图 5
>
> 上图只有空间依赖被捕获了，下图中：
>
> - GCN 捕获空间依赖，CNN 捕获时间依赖，可以替换
>
>   GCN is used to capture the spatial dependency and 1D-CNN is used to capture the temporal dependency. Both GCN and 1D-CNN components can be replaced with other structures for other spatiotemporal GNNs  
>
> - MLP 转换输出
>
>   A multilayer perceptron (MLP) component is used to generate the desired output  
>
> ![image-20240802212217655](img/image-20240802212217655.png)
>
> ![image-20240802212207043](img/image-20240802212207043.png)

(T-ZS2) 把卷积 GNN 分为：

> We further categorize convolutional GNNs into the following five types:  

1. GCN O-14
2. DGC O-15
3. MPNN O-16
4. GraphSAGE O-17
5. GAT O-18

发展过程如论文图 6 所示：

> These relevant graph neural networks are listed chronologically in Figure 6 

![image-20240803113331085](img/image-20240803113331085.png)

T-ZS2 表格5 给出了使用上述不同模块的论文的列表

##### 设计过程

(T-ZS2 说 O-9 说的) 建议的设计流水线：

> a general design pipeline is proposed and suggested for future studies as follows:

1. 找图结构

   > Find graph structure. As discussed in Section IV, different traffic graphs
   > are available  

2. 找图的类型和规模：如是否有向?同质?静态? 一般规模不大

   > Specify graph type and scale. The graphs can be further classified into different types if needed, e.g., directed/undirected graphs, homogeneous/heterogeneous graphs, static/dynamic graphs. For most cases in traffic forecasting, the graphs of the same type are used in a single study. As for the graph scale, the graphs in the traffic domain are not as large as those for the social networks or academic networks with millions of nodes and edges  

3. 设计损失函数：通常有监督学习，预测任务一般是节点的回归问题，可以用 RMSE, MAE, MAPE

   > Design loss function. The training setting usually follows the supervised approach, which means the GNN-based models are firstly trained on a training set with labels and then evaluated on a test set. The forecasting task is usually designed as the node-level regression problem. Based on these considerations, the proper loss function and evaluation metrics can be chosen, e.g., root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE)  
   >
   > 设 $y$ 是实际值，$\hat y$ 是预测值，$n$ 是样本数，查阅资料：
   > $$
   > \begin{cases}
   > RMSE=\sqrt{\dfrac1n\sum_{i=1}^n(y_i-\hat y_i)^2}\\
   > MAE=\dfrac1n\sum_{i=1}^n|y_i-\hat y_i|\\
   > MAPE=\dfrac{100\%}n\sum_{i=1}^n\left|\dfrac{y_i-\hat y_i}{y_i}\right|
   > \end{cases}
   > $$

4. 用模块构建模型，这些模块如 GCN(最常用), GAT(越来越多) 等

   > The GNNs discussed in this section are exactly those which have already been used as computational modules to build forecasting models in the surveyed studies  
   >
   > Currently, the most widely used GNN is the GCN. However, we also notice a growing trend in the use of GAT in traffic forecasting.  

##### 经典GNN

> (T-ZS2) During the process of customizing GNNs for traffic forecasting,  someclassical models stand out in the literature  

###### DCRNN

最出名的一个是 DCRNN (T-40)

> (T-ZS2) The most famous one is diffusion convolutional recurrent neural network (DCRNN)  

- 图卷积网络和 RNN 学习时空

  > which uses diffusion graph convolutional networks and RNN to learn the representations of spatial dependencies and temporal relations  

- 最初用于交通速度预测，现在成为了基准模型

  > DCRNN was originally proposed for traffic speed forecasting and is now widely used as a baseline.  

- 建图方式：距离矩阵

  > To create the traffic graph, the adjacency matrix is defined as the thresholded pairwise road network distances.  

- 支持有向图，引入扩散卷积(DC)

  > Compared with other graph convolutional models that can only operate on undirected graphs, e.g., ChebNet, DCRNN introduces the diffusion convolution (DC) operation for directed graph and is more suitable for transportation scenarios, which is defined as follows:   

  $$
  \mathbf X_{*DC}=\sum_{k=0}^{K-1}(\theta_{k,1}(D_O^{-1}A)^k+\theta_{k,2}(D_I^{-1}A^T))\mathbf X
  $$

  其中 $\mathbf X\in R^{N\times d}$ 是节点特征矩阵，$A$ 是邻接矩阵，$D_O,D_I$ 是对角矩阵：出度和入度，$\theta$ 是两个模型参数，$K$ 是扩散步数。

  区分入度和出度实现了有向图 

  > where X 2 RN×d is the node feature matrix, A is the adjacency matrix, DO and DI are diagonal out-degree and in-degree matrices, θk;1 and θk;2 are model parameters, K is the number of diffusion steps. By defining and using out-degree and in-degree matrices, DCRNN models the bidirectional diffusion process to capture the influence of both upstream and downstream traffic  

- 对无向图不是很实用

  > While DCRNN is a strong baseline, it is not suitable or desirable for the undirected graph cases  

- 扩展版本 [T-88]()：统一构建 RNN，基于任意图卷积

  Then DCRNN is extended with a stronger learning ability in graph GRU a unified method for constructing an RNN based on an arbitrary graph convolution operator is proposed, instead of the single RNN model used in DCRNN  

###### STGNN

(T-ZS2) Spatio-temporal graph convolutional network (STGCN)  T-28

- 堆叠多个时空卷积块，每个块连接两个时间卷积层和一个图卷积层

  > stacks multiple spatio-temporal convolution blocks and each block concatenate two temporal convolution and one graph convolution layer.  

- 使用 ChebNet 作为图卷积操作，用一阶近似比较

  > ChebNet is chosen as the graph convolution operator in STGCN, after a comparison with its first-order approximation  

- CNN 代替 RNN 获取时间加快了训练时间

  > The usage of temporal convolution layers instead of RNNs for temporal modeling accelerates the training phase of STGCN  

- 变种 ASTGCN 引入两个注意力层分别获取时空动态联系 T-81

  > Attention based Spatio-temporal graph convolutional network (ASTGCN) further introduces two attention layers in STGCN to capture the dynamic correlations in spatial dimension and temporal dimension, respectively  

###### Graph WaveNet

(T-ZS2) T-64 

- 自适应矩阵自动发现隐藏图结构，任意卷积学习时间关联

  > constructs a self-adaptive matrix to uncover unseen graph structures automatically from the data and WaveNet, which is based on causal convolutions, is used to learn temporal relations.  

- 训练后矩阵固定，不能适应动态的数据

  > However, the self-adaptive matrix in Graph WaveNet is fixed after training, which is unable to be adjusted dynamically with the data characteristics  



#### 其他

##### 知识图

包含概念、实体、关系、属性的知识图，未来可以是发展方向。难点是获取这样的信息。

(T-ZS2) While various graphs have been constructed in the surveyed studies as discussed in Section 4.1 and have been proven successful to some extent, most of them are natural graphs based on a real-world transportation system, e.g. the road network or subway system, as the current development status. And most of the graphs used are static, instead of dynamic ones. One specific direction that is not fully considered before is the design of transportation knowledge graph. As an important tool for knowledge integration, knowledge graph is a complex relational network that consists of concepts, entities, entity relations and attributes T-ZS21

The transportation knowledge graph helps to leverage the traffic semantic information to improve the forecasting performance. And the challenge is to extract the hidden transportation domain knowledge from multi-source and heterogeneous traffic data  

#### 具体论文

(T-ZS1) 基于图的方法，图卷积操作(图论领域)。常规卷积是欧氏领域

如：

- 图扩散处理，基于双向图随机游走，结果用于卷积和 RNN

  T-38 (T-ZS1)  performed a graph diffusion process based on a bidirectional graph random walk. Then, the resulting graph diffusion was used in a convolution process which is then incorporated into a Gated Recurrent Unit RNN  

- 图卷积，计算图(几步内)可达

  T-39 (T-ZS1) used a similar idea of graph convolution, but instead of using the diffusion process, they proposed a method which involves calculating whether or not it is possible to reach one node from another under a certain number of time-step when the traffic is on free-flow condition  

- 有向图找上游下游方向融入到卷积层

  T-4 (T-ZS1) used a directed graph which represents how traffic flows between locations. Through this directed graph, it is possible to find the upstream and the downstream locations. This information is incorporated in a convolution layer  

- 空间图卷积层

  T-28 (T-ZS1) modeled the traffic network as a graph and proposed a spatial graph convolutional layer  

- 图注意力网络

  T-43 (T-ZS1) modeled road network as a graph and used a graph attention network to model spatial correlations in the network  

- GN块输出同拓扑不同特征的图

  T-45 (T-ZS1) used a novel component called GN block that takes a road network graph as input and outputs another graph with the same topology but different graph features  

- 用 Deepwalk 把图转向量

  [T-58](https://pubs.aip.org/aip/cha/article-abstract/29/10/103125/282714/Road-traffic-state-prediction-based-on-a-graph?redirectedFrom=fulltext) (T-ZS1) used Deepwalk to transform a graph into a vector representation, which makes it easier to be incorporated into the deep neural network model  

- 扩散卷积 RNN (DCRNN) 

  T-40 (T-ZS1); (T-ZS2) diffusion convolutional recurrent neural network (详见 GNN 经典一节)
  
- Graph WaveNet  

  [T-64](https://arxiv.org/abs/1906.00121) (T-ZS2)

### 注意力

> [感觉很好的笔记](https://zhuanlan.zhihu.com/p/631398525)

#### 概念

(T-ZS1) 动机：替代基于图的方法，比它更容易实现

An alternative to this method is some sort of an attention module that can model the spatial and temporal correlations in the data  

T-ZS26

注意力机制通过模仿人的信号处理策略来实现资源 的不平均分配，为不同元素分配不同的权重以选择更有效 的信息

概述现状 T-ZS29

More recently, an attention-based model, i.e., the Transformer, has proven effective for capturing long-term dependency in time series. Transformer has only been used in a few surveyed studies, and there is still much room for research.  

> #### 基础

开山 O-5

综述：[O-34](https://www.sciencedirect.com/science/article/pii/S092523122100477X)

#### 具体论文

(T-ZS1)

- T-42

- T-44 (T-ZS26)

  提出一种基于深度学习，具有空间和时间注意力的交通流预测器，通过构建空间注意力矩阵表示交通网络中路段之间关系的注意力权重，然后使用注意力机制利用交通中的时间和空间相关性

可以参考图注意力

#### Transformer

##### 概述

(T-ZS1) Transformer $\approx$ encoder-decoder RNN + 注意力 (可并行)

> Transformers are similar to encoder-decoder RNNs in that
> they take sequences as inputs and outputs sequences. The difference is that Transformers are designed with attention mechanisms in mind and can be parallelized  

开山鼻祖 (机器翻译) [O-5](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)

T-ZS26

Transformer彻底抛弃了传统CNN和RNN结构，以注意力机制为模型基础，由self-Attention和FeedForwardNeuralNetwork组成，解决了RNN按序计算的限制，使序列中任意两个位置的距离在同一级别，解决了RNN长期依赖问题

T-ZS37

２０１７年，Ｇｏｏｇｌｅ的机器翻译团队提出一种与循环神经网络（ＲＮＮ）完全不同的Ｔｒａｎｓｆｏｒｍｅｒ模型，用于自然语言处理（ＮＬＰ）任务．由于具有很强的建模上下文信息的能力，Ｔｒａｎｓｆｏｒｍｅｒ模型在ＮＬＰ任务中得到了广泛的应用，并逐步扩展至其他时序预测相关的任务之中．Ｔｒａｎｓｆｏｒｍｅｒ模型的核心是多头注意力机制．在交通流领域中，传统的注意力机制主要用来计算不同特征间的权重，对路网的空间结构图（如拓扑图、距离图）进行动态调整来实现动态图卷积，以及对输入流量数据进行动态加权来得到研究中更为广泛的门控机制．而多头注意力机制可以使用多组注意力同时学习得到不同特征的最优注意力权重．相较于传统的ＲＮＮ，Ｔｒａｎｓｆｏｒｍｅｒ模型通过考虑不同历史时间步长的不同尺度的依赖关系，提升了模型对远距离时间特征建模的能力

> [O-44](https://proceedings.mlr.press/v161/bachlechner21a.html) 一种Ｒｅｚｅｒｏ⁃Ｔｒａｎｓｆｏｒｍｅｒ模型．该文对Ｔｒａｎｓｆｏｒｍｅｒ的归一化和残差连接部分进行了改进

##### 具体论文

(T-ZS1) 第一个应用 [T-59](https://arxiv.org/abs/2001.02908)

(T-ZS2)

- [T-74]() Transformer
- [T-75](https://arxiv.org/abs/2007.15189) 看标题是交通需求分析的 +GNN
- [T-76](https://ebooks.iospress.nl/volumearticle/55026) 看摘要是打车需求的 +GNN
- [T-77](https://link.springer.com/chapter/10.1007/978-3-030-59410-7_49) +GNN
- T-59
- T-202

可以参考图 Transformer/图注意力

### encoder-decoder

> [笔记](https://www.cnblogs.com/ghj1976/p/encoderdecoder-mo-xing-kuang-jia.html)

#### 传统

##### 概念

> 根据问人，一个普通 CNN 也可以认为是一个 encoder-decoder，把输入 encode 为隐藏层，再把隐藏层 decode 成答案。

(T-ZS1) 概念介绍：

In addition to these methods, the encoder-decoder RNNs are also used in many recent studies. Encoder-decoder RNNs are partly inspired by autoencoders. 

Autoencoders are deep neural network structures that consist of two parts: 

- the encoder that takes an input and produces a vector representation of it (usually with a smaller dimension), 
- and the decoder that takes the vector representation and produces an approximation of the original input. 

(T-ZS41) Autoencoders 又名 AES

> GPT：是 encoder-decoder

In encoder-decoder RNNs, both input and output are sequences, and instead of approximating the original input, the target output is a ground-truth sequence (e.g., prediction for 5, 10, 15, 20, 25, and 30 minutes into the future)  

> 效果最好，而且可以输出序列而不是答案，所以可以在任意环节输入向量，或提前拿出答案

(T-ZS1) 特点：输出为序列，可以继续做输入等

can output sequences instead of a single result. This means that Encoder-Decoder RNNs can take input data from multiple steps and also output predictions multiple steps ahead  

encoder-decoder RNN (编码器-解码器模型)

- Autoencoder 是深层神经网络，两部分组成：

  编码器把输入转成向量表示(通常更低维度)

  解码器把向量还原为近似成输入

- 对 encoder-decoder RNN

  解码器从近似输入改成近似真实答案 目前的 SOTA

(T-ZS1) 主要使用基于图的方法

To imbue Encoder-Decoder RNN with the capability to capture spatial data, most of these works also utilize graph-based methods  

> (T-ZS1) 评价：与 GNN 一同 SOTA
>
> Despite the complexity of Encoder-Decoder RNNs and graph-based methods, we have observed that this combination has shown to be very proficient at predicting future traffic and is one of the more important recent developments of traffic prediction

(T-ZS38) 是 Seq2seq

> Seq2Seq is a typical architecture under the Encoder-Decoder structure

(T-ZS26) NLP领域的序列到序列（SequencetoSequence，Seq2Seq）模型同样被借鉴到交通流预测领域中，得益于其独特的编码解码结构克服了其他方法难以进行多步预测的问题，能进一步捕捉交通模式的时间异质性

##### 评价

(T-ZS1) While state-of-the-art models that commonly use encoder-decoder LSTM combined with graph-based methods, have achieved excellent performance, these promising new techniques may be able to further improve the performance of traffic flow prediction  

##### 具体论文

(T-ZS1) 论文例子：

- T-40
- [T-41](https://dl.acm.org/doi/abs/10.1145/3219819.3219895) 200+引用 2018
- [T-42](https://ieeexplore.ieee.org/abstract/document/8580534) STANN (+注意力+RNN) 60引用 2019
- [T-43](https://dl.acm.org/doi/abs/10.1145/3292500.3330884) 500+引用 2019
- [T-44](https://www.sciencedirect.com/science/article/pii/S0968090X19301330) 250引用 2019
- [T-45](https://ieeexplore.ieee.org/abstract/document/8708297/) (STANN+注意力) 60+引用 2019

可以参考图编码器

### GAN

#### 概念

##### 定义

GPT 说是深度学习

(T-ZS2) Generative Adversarial Network (GAN)   

需要达到纳什均衡

(T-ZS1) Generative Adversarial Networks consist of two neural networks that are trained to compete with each other. The two networks are generative networks, designed to capture the data distribution, and discriminative network, which judges whether a given sample came from the true data or from the distribution generated by the generative network  [开山 O-6](https://proceedings.neurips.cc/paper_files/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html)

> (T-ZS2) GAN is a machine learning framework that has two components, namely, a generator, which learns to generate plausible data, and a discriminator, which learns to distinguish the generator’s fake data from real data 
> After training to a state of Nash equilibrium, the generator may generate undistinguished data, which helps to expand the training data size for many problems, including GNN-based traffic forecasting.  

T-ZS37

受博弈论中的零和博弈启发，Ｇｏｏｄｆｅｌｌｏｗ等［５７］将生成问题视为生成器和判别器这两个网络的对抗和博弈，并提出一种生成对抗网络（ＧｅｎｅｒａｔｉｖｅＡｄ⁃ｖｅｒｓａｒｉａｌＮｅｔｗｏｒｋ，ＧＡＮ）．生成对抗网络（ＧＡＮ）由一个生成器和一个判别器组成，生成器通过在潜在空间中随机采样生成网络输入，并通过不断训练使生成器的输出逼近训练集中的真实样本．判别器的输入包括真实样本和生成器的输出，其目的是将生成器的输出从真实样本中区分出来．生成对抗网络擅长无监督学习，且在多种生成模型中能够生成最逼真的结果，是交通流预测研究常用的神经网络之一

##### 作用

(T-ZS2) 可以生成数据来模拟真实数据

GAN is proposed for the challenges caused by the small data amount used in previous studies or the changes in the transportation networks and infrastructure when not enough historical traffic data are available  



##### 评价

> SOTA 可能是这个
>
> (T-ZS1) While state-of-the-art models that commonly use encoder-decoder LSTM combined with graph-based methods, have achieved excellent performance, these promising new techniques may be able to further improve the performance of traffic flow prediction  

优点是可把序列任意部分访问，无视距离

(T-ZS2) As a special case, Transformer is built entirely upon attention mechanisms, which makes it possible to access any part of a sequence regardless of its distance to the target  

#### 具体应用

(T-ZS1)

- [T-60](https://journals.sagepub.com/doi/abs/10.1177/0361198118798737) LSTM 生成和对抗

  use LSTMs for both the generative and discriminative network  

- [T-61](https://ieeexplore.ieee.org/abstract/document/8438991) 增强边界健壮性

  where a GAN is used to enable traffic flow prediction that is more robust to outliers  

- [T-62]() +图CNN 使用句子到句子的 autoencoder

  combine GAN with graph CNN, and use sequence-to-sequence autoencoder for the generative network  

(T-ZS2)

- [T-74](https://onlinelibrary.wiley.com/doi/abs/10.1111/tgis.12644)

- [T-114](https://www.sciencedirect.com/science/article/pii/S0968090X19312409) 

  the road network is used directly as the graph, in which the nodes are road state detectors and the edges are built based on their adjacent links. DeepWalk is used to embed the graph and the road traffic state sensor information is transferred into a low-dimensional space  

- [O-28](https://arxiv.org/abs/1701.07875) WassersteinGAN (WGAN)   

  used to train the traffic state data distribution and generate predicted results. Both public traffic flow (i.e., Caltrans PeMSD7) and traffic speed (i.e., METR-LA) datasets are used for evaluation, and the results demonstrate the effectiveness of the GAN-based solution when used in graph-based modeling.  

可以参考图 GAN

### 其他技术

#### 数据增强

广泛应用于图像分类、时序预测任务。为解决小数据量的预测偏差。

GNN 图结构复杂，增强困难。数据增强有效性未知。

(T-ZS2) Data Augmentation. Data augmentation has been proven effective for boosting the performance of deep learning models, e.g. in image classification tasks and time series prediction tasks. Data augmentation is proposed for the challenge of the possible forecasting bias introduced by the small amount of available data. However, due to the complex structure of graphs, it is more challenging to apply data augmentation techniques to GNNs. Recently, data augmentation for GNNs has proven helpful in semi-supervised node classification tasks [O-25](https://ojs.aaai.org/index.php/AAAI/article/view/17315). However, it remains a question whether data augmentation may be effective in traffic forecasting GNN applications.  

#### 迁移学习

> 如在图像分类，预训练通常源自 ImageNet, MS COCO
>
> (T-ZS2) Transfer learning utilizes knowledge or models trained for one task to solve related tasks, especially those with limited data. In the image classification field, pre-trained deep learning models from the ImageNet or MS COCO datasets are widely used in other problems.  
>
> T-ZS29 Transfer learning has been proven effective for transferring cross-city knowledge, which will help address the cold-start problem in new cities

该领域数据缺失频繁，所以具有应用价值，把一个地点迁移到另个地点

(T-ZS2) In traffic prediction problems, where a lack of historical data is a frequent problem, transfer learning is a possible solution. For GNNs, transfer learning can be used from a graph with more historical traffic data for the model training process to another graph with less available data. Transfer learning can also be used for the challenge caused by the changes in the transportation networks and infrastructure, when new stations or regions have not accumulated enough historical traffic data to train a GNN model
A novel transfer learning approach for DCRNN is proposed in [T-112](https://ieeexplore.ieee.org/abstract/document/9413270), so that a model trained on data-rich regions of highway network can be used to predict traffic on unseen regions of the highway network. The authors demonstrated the efficacy of model transferability between the San Francisco and Los Angeles regions using different parts of the California road network from the PeMS  

隐私

T-ZS29 Privacy-preserving schemes are further proposed to be combined with transfer learning, protecting the sensitive information from the source domain

#### 元学习

(T-ZS2) Meta-learning. Meta-learning, or learning how to learn, has recently become a potential learning paradigm that can absorb information from a task and effectively generalize it to an unseen task. Meta-learning is proposed for the challenge of GNN-based multi-task prediction, especially those involving mutiple graphs. There are different types of meta learning methods and some of them are combined with graph structures for describing relationships between tasks or data samples [O-26](https://ieeexplore.ieee.org/abstract/document/9413270), [O-27](https://arxiv.org/abs/1711.04043). Based on a deep meta learning method called network weight generation, ST-MetaNet+ is proposed in [T-113](https://ieeexplore.ieee.org/abstract/document/9096591), which leverages the meta knowledge extracted from geo-graph attributes and dynamic traffic context learned from traffic states to generate the parameter weights in graph attention networks and RNNs, so that the inherent relationships between diverse types of spatiotemporal correlations and geo-graph attributes can be captured

T-ZS29 Furthermore, meta learning has been shown to be useful for building new graph structures through efficient structure-aware learning during cross-city knowledge transfer.

#### 联邦学习

(T-ZS40 是联邦学习在该问题的综述)

(GPT) 联邦学习（Federated Learning）是一种分布式机器学习的方法，它允许多个参与方在本地训练模型，并仅共享模型的更新而不是原始数据。这样可以保护数据隐私并减少数据传输的需求。

在联邦学习中，每个参与方（比如个人设备或组织）都有自己的数据和模型。每个参与方在本地训练模型，并将模型参数（如权重和梯度）发送到一个中央服务器。中央服务器将这些更新汇总并生成一个全局模型，然后将更新后的全局模型返回给参与方，参与方继续在本地进行训练。这种过程重复进行，直到模型收敛。

联邦学习的主要优点包括：

1. 数据隐私保护：数据不会离开本地设备，只共享模型更新，因此用户的敏感信息更好地被保护。
2. 减少数据传输：只需要传输模型参数而不是原始数据，减少了带宽消耗。
3. 适应分布式环境：适用于数据分布广泛且分散的情况，如移动设备或多个机构的数据。

这种方法特别适用于需要保护隐私和数据安全的场景，如移动设备上的个性化推荐系统或医疗健康数据分析。

T-ZS29 Federated learning is another effective learning approach for maintaining data privacy while training effective deep learning models

分布式学习：更考虑速度而不是精度

T-ZS29

- The fourth research opportunity is a distributed learning approach for training largescale graph neural networks for traffic forecasting
- When the application of GNNs for traffic prediction scales to larger graphs, a distributed training of graph neural networks is necessary. In those cases, improvements in training and runtime efficiency is even more beneficial and important.
- Another similar idea is to leverage cloud computing for model training and edge computing for runtime inference to accelerate the distributed training and inference process.

> 云计算 T-ZS29
>
> The last but not the least research opportunity is the deployment of GNNs based on cloud computing and B5G/6G communication techniques. Cloud computing can provide the required computing and storage resources. GNN models can be trained, deployed, and updated in the cloud with a scalable infrastructure. The B5G/6G communication technique is designed to have the ability to support massive machine-type communication scenarios and can be used for reliable and massive traffic data collection and transmission.

#### 自监督学习

T-162 提到

> poe
>
> 自监督学习(Self-Supervised Learning, SSL)是机器学习的一种重要范式,它利用数据本身的特性来自动生成学习目标或标注,而不需要依赖于人工标注的标签。与监督学习和无监督学习相比,自监督学习可以从大量的未标注数据中学习有价值的特征和表示,从而提高模型在下游任务上的性能。
>
> 自监督学习的主要思想包括:
>
> 1. 利用原始数据的结构和特性来设计学习目标,比如预测图像中遮挡部分的内容、预测文本中被遮蔽的词语等。
> 2. 通过辅助任务(pretext task)来学习数据的有用表示,这些辅助任务是由数据本身自动生成的,不需要人工标注。
> 3. 学习到的通用表示可以迁移到下游的目标任务(main task),提高模型在这些任务上的性能。
>
> 自监督学习在计算机视觉、自然语言处理等领域取得了广泛成功,可以有效利用大量未标注数据,降低标注成本,从而实现性能提升。它是机器学习发展的一大前沿方向,值得关注和研究。
>
> 以计算机视觉领域的图像自监督学习为例:
>
> 假设我们有一个大规模的未标注图像数据集,其中包含了各种不同的图片,如动物、风景、建筑等。在这种情况下,我们可以设计一个自监督学习的任务,让模型去预测图像中某些部分被遮挡后的内容。
>
> 具体来说,我们可以随机遮挡图像的一部分区域,然后让模型去预测被遮住的部分应该是什么样子。这个预测任务就是一个辅助任务(pretext task)。
>
> 通过尝试预测被遮挡的图像部分,模型会学习到图像的整体结构和语义特征,从而学习到有价值的视觉表示。这些学习到的特征可以被迁移到其他计算机视觉任务中,如图像分类、目标检测等,提高模型在这些下游任务上的性能。
>
> 这种自监督学习的方法不需要人工标注图像,而是利用数据本身的结构来自动生成学习目标。这种方法大大降低了标注成本,同时也提高了模型的性能。
>
> 类似的自监督学习方法也被广泛应用在自然语言处理、语音识别等其他机器学习领域。总之,自监督学习是一种非常有价值和前景的机器学习范式。

#### 持续学习

T-331

Continual learning, also referred to as incremental learning and life-long learning 持续学习/增量学习/终身学习

We can summarize works into three categories: (i) regularization-based methods; (ii) parameterisolation based methods; (iii) replay-based methods

These methods aim to acquire knowledge from new tasks while retaining previous information. However, the majority of research on incremental learning has been focused on image classification and reinforcement learning tasks.

> A few works have successfully applied continual learning into graph learning tasks. For example, ContinualGNN ……

#### 强化学习

强化学习（Reinforcement Learning, RL），又称再励学习、评价学习或增强学习，是机器学习的范式和方法论之一，用于描述和解决智能体（agent）在与环境的交互过程中通过学习策略以达成回报最大化或实现特定目标的问题 (百度百科)

Q学习（Q-Learning）是一种强化学习算法，它属于无模型预测算法，用于解决马尔可夫决策过程（MDP）问题。Q学习算法的核心思想是通过学习一个动作价值函数（Q函数），来评估在给定状态下采取某个动作的期望效用 [src](https://baijiahao.baidu.com/s?id=1799742813167573754&wfr=spider&for=pc)

T-ZS29

> he sixth research opportunity is the combination of graph neural networks and reinforcement learning, which is rarely considered in the surveyed studies, with only one exception [90]. The ensemble of these two models can sometimes produce brilliant sparks. For example, some relevant studies leverage reinforcement learning techniques for a more efficient graph neural network structure search [231]. On the other hand, reinforcement learning itself is useful for making optimal decisions in the traffic domain with properly designed rewards, e.g., traffic light control and autonomous driving. There is still a large research gap in applying reinforcement learning to graph data structures

#### AutoML

自动化机器学习 Automated Machine Learning (AutoML).  

ML 里特征获取、模型选择、参数调整都是手动的，AutoML 学习这些步骤，对特征、模型、优化、评估自动化，有助于提高模型

(T-ZS2) The application of machine learning requires considerable manual intervention in various aspects of the process, including feature extraction, model selection, and parameter adjustment. AutoML automatically learns the important steps related to features, models, optimization, and evaluation, so that machine learning models can be applied without manual intervention. AutoML would help to improve the implementation of machine learning models, including GNNs. 

对超参数的选择可能更好

(T-ZS2) AutoML is proposed for the challenge for computational requirements in graph-based modeling, in which case the hyper parameter tuning for GNNs can be more efficient with state-ofthe-art AutoML techniques. 
An early attempt to combine AutoML with GNNs for traffic prediction problems is an Auto-STGCN algorithm, proposed in [T-115](https://arxiv.org/abs/2010.07474). This algorithm searches the parameter space for STGCN models quickly based on reinforcement learning and generates optimal models automatically for specific scenarios.  

#### 分解

T-ZS29

Empirical mode decomposition (EMD) is often used together with time series models, where the time series is first decomposed into different components and each component is then modeled with a time series model. This combination has been shown to be effective for traffic forecasting

## 相关数据



#### 分类

##### 主数据

参考 T-ZS1 的分类标准，主要数据集可以分为两类：

- 固定式采集数据集(point data)：安装在固定地方的探测器所采集的数据

  > (T-ZS1) 标准数据集为 PeMS

- 移动式交通数据(trajectory data)：GPS 等收集的车辆轨迹信息

  > (T-ZS1) 无标准 do not have a standard dataset  
  >
  > Different works use different datasets with different properties, including the origin country (mostly America or China), method of transportation (cars, taxis or bicycles) and time range
  >
  > trajectory data from Beijing is relatively more popular    

> (T-ZS1) road link data 是特殊的 point data 的理由：
>
> As we can derive the traffic speed from road link data by averaging the speed of vehicles on each road link, we also regard road link data as a special type of point data.  
>
> (T-ZS1) 非主流——使用了 point + 道路连接的论文： 
>
> - use road link data in addition to point data as the main datasets  
>
>   T-12 T-39

T-ZS30 图，展示网格和图论的数据

![image-20241008171227909](img/image-20241008171227909.png)

T-ZS31

![image-20241008174820228](img/image-20241008174820228.png)

##### 辅助数据

(T-ZS1) 此外，可能还需要一些辅助数据信息：

- 交通网络数据：探测器的分布图(欧氏空间网格或无向加权图等)
- 气候数据、日期(节假日)数据、事件(如车祸)数据等

(T-ZS1) In traffic prediction, commonly used external information include weather, accidents, events, day of the week, time of the day and social media data  

T-ZS29 外部因素影响显著

It is worth mentioning that external factors such as temperature and weather information have a great impact on the forecasting performance

(T-ZS2) 天气：温度、湿度、降水、气压、风力

Weather Data. Traffic states are highly affected by the meteorological factors including temperature, humidity, precipitation, barometer pressure, and wind strength  

T-70 Weather data is collected from [JUHE](https://www.juhe.cn/docs/api/id/277) website

(T-ZS2) 日期：工作日/节假日。

Calendar Data. This includes the information on weekends and holidays. Because traffic patterns vary significantly between weekdays and weekends/holidays, some studies consider these two cases separately. 

> Both weather and calendar data have been proven useful for traffic forecasting in the literature and should not be neglected in graph-based modeling as external factors  



##### 图网数据

(T-ZS2)

参考 T-ZS2 的分类方法：三类数据是图相关、历史交通和外部

> We categorize the data used in the surveyed studies into three major types, namely, graph-related data, historical traffic data, and external data  

- 图相关：交通的图结构

  > graph-related data refer to those data which exhibit a graph structure in the traffic domain, i.e., transportation network data  

  路网数据，从政府部门或在线地图服务获取，可以直接建图，缺点为静态图

  > Transportation Network Data. These data represent the underlying transportation infrastructure, e.g., road, subway, and bus networks. They can be obtained from government transportation departments or extracted from online map services, e.g., OpenStreetMap. Based on their topology structure, these data can be used to build the graphs directly, e.g., the road segments or the stations are nodes and the road intersections or subway links are the edges. While this modeling approach is straightforward, the disadvantage is that only static graphs can be built from transportation network data.  

- > 历史交通：过去的交通状态，在不同的时空
  >
  > Historical traffic data refer to those data which record the historical traffic states, usually in different locations and time points.  

- > 外部数据：影响交通的其他因素如天气、日历，可能需要预处理
  >
  > External data refer to the factors that would affect the traffic states, i.e., weather data and calendar data. Some of these data can be used in the graph-based modeling directly, while the others may require some pre-processing steps before being Incorporated into GNN-based models  

T-70 [高德](https://lbs.amap.com/)

#### point data

可用性，兼容性好，无序数据转换

(T-ZS1) Point data consists of traffic readings from road-installed sensors. This data is popular due to its availability and compatibility with deep neural network models; usually, point data does not require major data transformation step and can be used as is  

使用/表征方式：向量、矩阵、张量

(T-ZS1) For point data, spatial aspect is typically captured by collating data from multiple detection points into vectors. Sometimes, matrices can be used when capturing both the spatial and the temporal aspects. In addition, tensors can also be used when there are multiple matrices to be used all at once, such as when we are inputting the spatiotemporal traffic data from multiple days at once. These vectors/matrices/tensors are then fed as input into the network where a CNN resides  

优点为：

- 公开数据集可用
- 简单的数据转换
- 可以与图论方法一起用

The advantages of using point data are:

- (T-ZS1) Common public data are available. 

  For instance, the Caltrans data is very commonly used in the literature. Although each work uses different subsets, the availability of one unified data source makes it easier to establish a benchmark data.

  来源权威，覆盖面广

  Point data generally comes from traffic detectors installed by the transportation bureau. Consequently, the system is well-established, resulting in better temporal coverage  

- (T-ZS1) Data transformation is simpler.

  To obtain an input data that contains both the temporal and the spatial trends, the common procedure is just collating the data into vectors/matrices/tensors.

- (T-ZS1) Works better for methods that are based on the graph space. 

  Point data often constitutes traffic detectors installed on roads, which can be easily converted to graphs; each detector site can be treated as a vertex and every two adjacent detectors define an edge.   

限制：

- 成本高昂，几乎没有 arterial/highways 数据

- 与欧氏空间方法不兼容(如 2D CNN 即普通的 CNN)

  因为很多真实空间连成线

- 数据缺失和数据噪音问题

- 获取困难：隐私、存储空间有限

(T-ZS1) Although point data has multiple advantages as detailed above, it also has some limitations as listed below:

- (T-ZS1) Almost exclusive highways data.

  Since traffic loop detectors are difficult and expensive to install, they are not commonly available for arterial roads.

  > However, as traffic detectors are costly to install, they are mostly limited to highways  

  (T-ZS2) While traffic sensors have been successfully used, data collection for traffic flow information is still a challenge when considering the high costs in deployment and maintenance of traffic sensors.  

- (T-ZS1) Not compatible with methods that conform to the Euclidean space (e.g. 2D CNN). 

  This is because most point-based data are highways data where the traffic detectors are spatially organized in a line.  

> (T-ZS2) 探测器数据，广泛使用，优点是节点属性可直接用原始数据，但可能存在数据出错(缺失/噪音)，且区域范围小
>
> Traffic Sensor Data. Traffic sensors, e.g. loop detectors, are installed on roads to collect traffic information, e.g., traffic volume or speed. This type of data is widely used for traffic prediction, especially road traffic flow and speed prediction problems. For graph-based modeling, each sensor can be used as a node, with road connections as the edges. One advantage of using traffic sensor data for graph-based modeling is that the captured traffic information can be **used directly** as the node attributes, with little pre-processing overhead. One exception is that the sensors are prone to hardware **faults**, which causes the missing data or data noise problems and requires corresponding pre-processing techniques, e.g., data imputation and denoising methods. Another disadvantage of using traffic sensor data for graph-based modeling is that the traffic sensors can only be installed in a **limited** number of **locations** for a series of reasons, e.g., installation cost. With this constraint, only the part of the road networks with traffic sensors can be incorporated into a graph, while the uncovered areas are neglected
>
> (T-ZS2) While present road network and weather data can be easily found on the Internet, it is much more difficult to source historical traffic data, both due to data **privacy** concerns and the transmission and **storage** requirements of large data volumes  

#### trajectory data

如果使用轨迹数据，每条轨迹映射到 2D 平面网格，优点：

- GPS 数据，覆盖了 arterial roads(干道) 和 highways(公路)
- 对欧氏空间方法更好
- 结果可视化/可解释简单

The advantages of trajectory data are:

- (T-ZS1) Not exclusive to highways data. 

  Trajectory data are usually GPS data, which cover both arterial roads and highways.

  > has a more general spatial coverage as drivers pass through arterial, urban and highway roads alike  

- (T-ZS1) Works better for methods that are based on the euclidean space.

  After the data processing, the spatial correlation is inherently captured within the resulting 2D plane. Additionally, the resulting data transformation output is a matrix, which naturally fits 2D CNN. Finally, trajectory data usually cover city regions, which usually conform to the 2D shape.

- (T-ZS1) Results are easily interpretable. 

  By visualizing the values assigned to each grid in the 2D map, the region’s traffic flow prediction can be observed directly. 

缺点：

- 数据转换到 2D 平面复杂 (故文献少)
- 不能建图用图论方法
- 时间覆盖没这么广
- 数据质量
- 预处理难度大

(T-ZS1) For trajectory data, utilizing the Euclidean space is common. Each trajectory needs to be mapped onto a 2D plane which represents the region (e.g. city, country) where the data resides. This region is divided into grids where each grid represents a subregion. Processing the data this way yields a matrix that represents the traffic state of a region, which can be fed into a CNN to capture the spatial aspect.

The disadvantages of trajectory data are:

- (T-ZS1) Complex data transformation. 

  The process of mapping each trajectory point to the 2D plane is complex and time consuming.

- (T-ZS1) Not compatible with methods that model their data using graph-based methods. 

  Points in the road network can be transformed into vertices and the connections between them can be mapped to edges. This is not possible for trajectory data.  

- (T-ZS1) the temporal coverage is limited, ranging from a month (T-36 T-37) to several months (T-1 T-37 T-51) and up to one year (T-49 T-30), compared to the Caltrans data, for instance, which contains more than five years’ worth of data for its detectors  

(T-ZS2) Another potential approach is using the pervasive mobile and IoT devices, which have a lower cost generally, e.g., GPS sensors. However, challenges still exist when considering the data quality problems frequently seen in GPS data, e.g., missing data caused by unstable communication links  

(T-ZS2) 2-60 区间间隔记录，匹配到路网里，计算出交通速度/流，低成本高覆盖，数据质量可能存在问题，预处理难

> GPS Trajectory Data. Different types of vehicles (e.g. taxis, buses, online ride-hailing vehicles, and shared bikes) can be equipped with GPS receivers, which record GPS coordinates in 2-60 second intervals. The trajectory data calculated from these GPS coordinate samples can be matched to road networks and further used to derive traffic flow or speed. The advantage of using GPS trajectory data for graph-based modeling is both the **low expense** to collect GPS data with smartphones and the **wider coverage** with the massive number of vehicles, compared with traffic sensor data. However, GPS trajectory data contain no direct traffic information, which can be derived with corresponding definitions though. The data **quality** problems also remain with GPS trajectory data and more **pre-processing** steps are required, e.g., map matching  

(T-ZS2) 有来源更广的数据，但质量更差。

> Location-based Service Data. GPS function is also embedded in smartphones, which can be used to collect various types of location-related data, e.g., check-in data, point-of-interest data, and route navigation application data. The pros and cons of using location-based service data are similar with GPS trajectory data. And the difference is that location-based service data are often collected in a crowd-sourced approach, with more data providers but potentially a lower data quality  

(T-ZS1) 更推荐轨迹数据

The installation of traffic detectors is expensive, and point data’s spatial limitation is difficult to address. Therefore, we recommend focusing on trajectory data. Floating car data collected from GPS is the most widespread and efficient source of trajectory data. However, researchers must take into account the required preprocessing to use trajectory data for traffic prediction

#### 其他来源数据

旅行记录、交通报告、多媒体数据、模拟数据

(T-ZS2) 旅行记录，推导出速度和需求；建模方便，容易收集

Trip Record Data. These include departure and arrival dates/times, departure and arrival locations, and other trip information. Traffic speed and demand can derived from trip record data from various sources, e.g., taxis, ride-hailing services, buses, bikes, or even dock-less e-scooters ([T-89](https://dl.acm.org/doi/abs/10.1145/3366423.3380101))
These data can be collected in public transportation systems with mature methods, for example, by AFC (Automatic Fare Collection) in the subway and bus systems. Trip record data have the advantage of being capable of constructing multiple graph-based problems, e.g., station-level traffic flow and demand problems. They are also easier to collect in existing public transportation systems 

> T-333 用到 AFC
>
> The passenger flow data used in our paper is from the AFC (Automatic Fare Collection), an automatic ticket sale system. The AFC data contains the inbound and outbound information of the passengers, including inbound station name ID, inbound line ID, inbound date, inbound time, outbound station name ID, outbound line ID, outbound date, and outbound time.

(T-ZS2) 交通报告：异常案例，但时空跨度上都很少见故很少用

Traffic Report Data. This type of data is often used for abnormal cases, e.g., anomaly report data used in [T-90](https://ebooks.iospress.nl/volumearticle/55105?ref=https://githubhelp.com), and traffic accident report data used in [T-91](https://ieeexplore.ieee.org/abstract/document/9158447), [T-92](https://ojs.aaai.org/index.php/AAAI/article/view/5480), [T-93](https://ieeexplore.ieee.org/abstract/document/9242313). Traffic report data are less used in graph-based modeling because of their sparsity in both spatial and temporal dimensions, compared with trip record data.  

(T-ZS2) 多媒体数据：街景图预测拥挤、卫星图等。数据收集、存储高要求，信息获取困难

Multimedia Data. This type of data can be used as an additional input to deep learning models or for verifying the traffic status indicated by other data sources. Multimedia data used in the surveyed studies include the Baidu street-view images used in [T-94](https://onlinelibrary.wiley.com/doi/abs/10.1111/tgis.12641), for traffic congestion, as well as satellite imagery data T-91, and video surveillance data. Multimedia data are also less seen in graph-based modeling because of their higher requirement for data collection, transmission and storage, compared with traffic sensor data with similar functionalities. It is also more difficult to extract precise traffic information, e.g., vehicle counts, from images or videos through image processing and object detection techniques  

(T-ZS2) 模拟交通数据，真实数据很多所以少用，但可以模拟罕见情景

Simulated Traffic Data. In addition to observed real-world datasets, microscopic traffic simulators are also used to build virtual training and testing datasets for deep learning models. Examples in the surveyed studies include the MATES Simulator used in [T-95](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-its.2019.0778), and INTEGRATION software used in [T-96](https://ieeexplore.ieee.org/abstract/document/9149233). With many real-world datasets available, simulated traffic data are rarely used in GNN-based and more broader ML-based traffic forecasting studies. Traffic simulations have the potential of modeling unseen graphs though, e.g., evaluating a planned road topology.  

#### 交通流量数据

##### 概述

特指 traffic flow 而不是 crowd flow，列表名字如下，具体描述参见下文数据集列表。(其中 crowd flow 是 urban flow 的一部分)

T-ZS19：urban flow contain crowd flow, traffic flow and public transit flow

- 其 4.3.1、 4.3.2 分别介绍 crowd flow, traffic flow
- 有表格表示 crwod flow, traffic flow 的细分任务和数据集 table2

> 根据 GPT 结果：
>
> The terms **traffic flow** and **urban flow** both relate to the movement of vehicles and people within transportation networks, but they focus on different aspects of mobility and spatial dynamics.
>
> 1. **Traffic Flow** specifically refers to the movement of vehicles on a road network. It focuses on parameters like vehicle speed, density, and flow rates (vehicles per hour) and often deals with highways, arterial roads, and intersections. Models of traffic flow usually aim to optimize road usage, reduce congestion, and improve traffic signal coordination. It can be analyzed at a microscopic level (individual vehicle behavior) or a macroscopic level (aggregated flow, speed, and density)([SpringerLink](https://link.springer.com/article/10.1007/s40747-023-01099-z) T-365)([Engineering LibreTexts](https://eng.libretexts.org/Bookshelves/Civil_Engineering/Fundamentals_of_Transportation/05%3A_Traffic/5.02%3A_Traffic_Flow)).
> 2. **Urban Flow**, on the other hand, is a broader concept that includes not just vehicle movement but also the overall dynamics of people, goods, and services within a city. It encompasses pedestrian movement, public transit, cycling, and even logistic flows. Urban flow examines how these elements interact with infrastructure, geography, and city planning, providing a more comprehensive understanding of urban mobility. It's also influenced by non-transport factors like land use, zoning, and socio-economic factors([MDPI](https://www.mdpi.com/2071-1050/16/5/1818) T-366).
>
> In summary, while **traffic flow** focuses on vehicle movement on roads, **urban flow** encompasses the larger, more complex system of movement within cities, including multiple modes of transportation and human activities.

crowd flow 定义见

##### 探讨

研究下面的数据集是否属于 crowd flow：

taxiBJ bikeNYC

- 已知：在标题上，T-51 为 crowd flow，T-162 为 traffic flow



> T-ZS44 里的表 2 提到的数据集：(但这个综述引用 0)
>
> - crowd flow
>   - Beijing taxi (GPS)
>   - NYC taxi (trajectory)
>   - TaxiBJ
>   - BikeNYC
>   - MobileBJ
>   - Bike data of New York City and Chicago
> - traffic flow
>   - PEMS
>   - NYC taxi (taxi trip)
>   - UK traffic flow
> - public transit flow
>   - bike
>   - metro (/metro AFC)

##### 列表





### 评价

#### 概述

T-ZS29 现状：大部分公开

Most of the collected datasets used in the surveyed studies are open datasets with only a few exceptions.

T-ZS29 用热门数据集的优缺点

- some have made great contributions to support relevant studies, which can fairly evaluate and compare different models
- However, it also poses problems when existing datasets are overutilized and overfitted to GNN-based deep learning models and produce unreliable models for other traffic scenarios and datasets.

#### 日期

> 日期容易结合：
>
> (T-ZS1) Conversely, time-of-day and day-of-week data are much easier to incorporate
>
> 日期少于一年的缺点：
>
> (T-ZS1) 26 out of 37 literatures use less than one year’s worth of data. This deficiency will have an adverse impact on sub-tropical regions, as seasonal changes may affect temperature and weather, which in turn can affect traffic. By using data from only one or several months, the model cannot generalize to different seasons. This can be mitigated by incorporating weather data, but as mentioned before, this is a difficult and time-consuming task.  
>
> 时间不完整一天/周的缺点：
>
> (T-ZS1) e-consuming task. Some authors also use data from only a certain range of hours or use data from weekdays only. This will also cause problems as the model cannot generalize well to situations outside the boundaries of the provided data. For instance, using traffic data from 07.00 AM to 11.00 PM only may reduce the model’s performance on the excluded hours, and using only weekdays data may adversely impact the model’s performance when predicting weekend traffic  



#### 真实性

> 数据要趋于真实的理由：
>
> (T-ZS1) using vastly different datasets may result in an entirely different model. Thereby, for a model to be applicable to real application scenarios, it is important to use a dataset that closely resembles those scenarios.  



#### 时间粒度

> 时间粒度：大部分 5min (默认)，推荐 15min
>
> (T-ZS1) using vastly different datasets may result in an entirely different model. Thereby, for a model to be applicable to real application scenarios, it is important to use a dataset that closely resembles those scenarios.  
>
> (T-ZS1) 指出[文献](https://onlinepubs.trb.org/Onlinepubs/trnews/rpo/rpo.trn129.pdf)推荐 15min 粒度
>
> 数据粒度的辩证讨论：对结果和训练/输入的影响
>
> Depending on the dataset, the data granularity is a potentially important hyperparameter. Using a data granularity that is too small may cause a lot of zero values, especially during conditions where traffic is very sparse. For example, it is highly likely for a traffic loop detector to not detect any cars in 2 or 5 minute periods during off-peak hours (e.g. 02:00 04:00 AM) while this becomes less likely if the granularity is increased to 15 minutes or more. On the other hand, using a granularity that is too high might result in the smoothness of the traffic flow reading where important trends are lost. For instance, if the traffic experiences periodic shifts during 12:30PM, this trend might not be detected if the data granularity is one hour.
>
> Data granularity also impacts the number of possible data points as well as the size of the input sequence. Using a smaller granularity will increase the length of the required data sequence. For instance, one hour’s worth of data can be captured with only a sequence of length 4 when the granularity is 15 minutes, but when the granularity is 5 minutes, the sequence length is 12. This can impact training time, especially for RNN-based models.  
>
> Due to the aforementioned reasons, choosing the correct data granularity becomes a decision based on trade-offs and should be considered carefully depending on the data, the model, as well as the application scenarios  

#### 输入输出长度

> (T-ZS1) 多个长度都试一下，一般输入输出正相关，未得到充分研究：超参搜索耗时。多数是人为设置的，因为搜索超参太慢。可以用小数据集做超参搜索来缓解该问题。
>
> many authors perform experiments with different prediction horizons and use different input sequence lengths for each of the selected prediction horizons  
>
> Intuitively, as we increase the prediction horizon, the input sequence length also needs to be increased. This is because the increase in prediction horizon means predicting the traffic of further time frame in the future and thus, increasing the task complexity. Increasing the size of the data points by extending the input sequence may help in tackling the complex problem.  
>
> Unfortunately, the relationship between the input sequence length and the prediction horizon is rarely explored by the literature. Most of the input sequence lengths were chosen arbitrarily without iterating through different possible values. This is because hybrid deep neural network structures take a long time to train, which makes iterating through different settings unwieldy. Despite this issue, hyperparameter search remains an important facet of deep neural network development that cannot be omitted. One possible remedy of this problem is to first use a smaller data, chosen randomly from the main dataset, to find the optimal parameter setting.  

T-ZS229 输出长度：不同会影响模型对比

orecast horizons also differ per study, such as 5, 10, 30, or 60 min, and it was found that the larger the horizon, the harder the forecasting problem, and the greater the error observed with larger horizons.

Due to the different evaluation metrics and forecast horizons, it is nearly impossible to fairly compare all surveyed studies and quantify the difficulty of the available datasets.

### 数据集列表

> #### 数据集
>

列出部分常用的数据集：

##### PeMS

[PeMS](http://pems.dot.ca.gov/) (Caltrans Performance Measurement System)

> T-87 说数据集论文是 [O-31](https://journals.sagepub.com/doi/abs/10.3141/1748-12)

研究最广泛的数据集，由加利福尼亚州主要公路的上万探测器收集，2001-2009，每半分钟采集一次，包含容量、速度、交通流量等多种数据

> 优点 (T-ZS1) public availability, ease of download, simple structure and long historical data  
>
> 提供的数据、粒度 (T-ZS1) provides information regarding date, time stamp, traffic flow per lane, and aggregated traffic flow. Traffic flow is the most commonly used field, but occupancy and speed information is also available. The data granularity can be set to 5 minutes, hourly, daily, weekly and monthly depending on user requirements  
>
> (T-ZS2) This dataset contains raw detector data from over 18,000 vehicle detector stations on the freeway system spanning all major metropolitan areas of California from 2001 to 2019, collected with various sensors including inductive loops, side-fire radar, and magnetometers. The samples are captured every 30 seconds and aggregated in 5-minute intervals. Each data sample contains a timestamp, station ID, district, freeway ID, direction of travel, total flow, and average speed  
>
> (T-ZS26) 说 4w 多个单独检测器
>
> (T-69) There are totally 39,000 sensors deployed on the freeway system across all major metropolitan areas of the state of California

官网有图片提供(直接打开官网即可看到)

有多个子集广泛用于论文中，包括 PeMS-BAY、PeMSD3、PeMSD4、PeMSD7、PeMSD8 等，可以参考(有的论文会说 D 是 0，但是根据我论文阅读观察其实是同一个数据集)

数据收集和解读 [src](https://blog.csdn.net/qq_40206371/article/details/134527077)，有详细表格



> (T-ZS2) Different subsets of PeMS data have been used in previous studies, for example:  

- [PeMS-BAY](https://github.com/liyaguang/DCRNN)

  This subset contains data from 325 sensors in the Bay Area from January 1st to June 30th, 2017 (2017/1/1 - 2017/5/31)

  (T-64) 2369条边，52116个时间步 (T-133) 2691 条边，5min 粒度

  (T-40) 16937179个数据点，看图表觉得是速度 mile/h (T-159) 速度

- PeMSD3

  This subset uses 358 sensors in the North Central Area. The frequently referenced time period for this dataset is September 1st to November 30th, 2018  

  (T-135) 26208 个时间区间

  (T-158) 缺失率为0.672%

- PeMSD4

  This subset uses 307 sensors in the San Francisco Bay Area. The frequently referenced time period for this dataset is January 1st to February 28th, 2018  

  (T-135) 16992 个时间区间  (T-137, T-138) 说是 flow，680条边

  (T-158) 缺失率为3.182%

  T-344 用了 04, 08 但是说是 speed

- PeMSD7

  This subset uses 883 sensors in the Los Angeles Area. The frequently referenced time period for this dataset is May to June, 2012.  

  (T-28 图4) 有一个U形和双U形数据 ，具体数据看 T-28 具体论文笔记描述

  每天的记录次数乘以天数是行，道路数是列，内容是速度记录，节点数是 228 和 1026，行数是 12672(我算出来44天)，值是 60 多和 70 多的占大头

  (T-145) 228 和 1026 分别是 M 和 L 子数据集，边数分别是 1132, 10150，点数是 12672；但是不含 M/L 的是 883 个点，866 条边，28224

  (T-135) 28224 个时间区间 

  (T-158) 缺失率为0.452% 2017 5-8

- PeMSD8

  This subset uses 170 sensors in the San Bernardino Area. The frequently referenced time period for this dataset is July to August, 2016
  
  (T-135) 17856 个时间区间 (T-138) 说是 flow，548条
  
  (T-158) 缺失率为0.696%

(T-135) 都是 5min 时间步；其论文源码有数据，推荐了 [BasicTS](https://github.com/GestaltCogTeam/BasicTS/tree/master)，其说出处 T-81

(T-138) 速度单位 Traffic speed data records the average vehicles speed (miles per hour)

流量单位：The flow data should be an integer, up to hundreds

其他：

- PeMSD7M (T-28提出)

  (T-141) 228点 5分钟 12672个时间

  (T-128) 12612 个数据点 (T-155) 05/2012 - 06/2012

  (T-153) 说是 speed PEMSD7(M) 228 12672 05/2012 - 06/2012 5min

  (T-160) are all at weekdays

- PEMSD7L

  (T-153) speed PEMSD7(L) 1026 12672 05/2012 - 06/2012 5min

  (T-160) are all at weekdays

- PeMS-S (找不到来源)

  (T-140) The time range of PeMS-S is the weekdays of May and Jun of 2012, the interval is 5 minute and 228 sensors (nodes) are selected
  
- PEMS3-Stream

  T-310 鼻祖 PEMS3-Stream contains traffic flow data in North Central Area from 2011 to 2017. We select data from July 10th to August 9th every year.
  
  T-331 includes traffic flow data from July 10th to August 9th from 2011 to 2017.
  
- BayArea

  (T-151 自建) flow data
  
  is also collected from PeMS of CalTrans. It is collected from 4096 sensors installed in the Bay Area with observations of 12 months of data ranging from January 1 to December 30, 2019. Then we discard the data of nodes with a missing rate greater than 0.1%, leaving only 699 nodes
  
- PEMSD10 T-69 speed

  We randomly select 608 sensors among District 10 of California as data sources. The time period of PEMSD10 is from 1st January, 2018 to 31st March, 2018. The dataset is also aggregated into 15 minutes interval and traffic speed is taken as the traffic condition to be predicted. Finally, PEMSD10 contains 8640 records for each sensor. The POIs in California were collected based on [Google Map API](https://www.google.com/maps).

  There are two things needed to be noted. First, the sensors and roads are not corresponding one to one in PEMSD10 (e.g., there may be multiple sensors deployed in the same road), so we ignore the topological graph and build the weighted topological graph by using a thresholded Gaussian kernel (具体权值公式见论文)

  Second, PEMSD10 also collects incident reports from [Traffic Incident Information Page](http://cad.chp.ca.gov/). An incident report contains information about the date, time, location, and textual description of the incidents.
  
- [T-174](https://www.tandfonline.com/doi/abs/10.1080/13658816.2019.1697879)

  This dataset contains 5-min traffic flow provided by PeMS, collected from January 1, 2015 to May 31, 2015 by 1681 loop detectors at the mainline of the freeways in Los Angeles (District 7), California, USA

- [T-181](https://ieeexplore.ieee.org/abstract/document/8171119) flow

  The freeway traffic data we use is collected at Freeway SR99-S District 10 and the urban traffic flow data we use is collected at Street I980-E District 4 in Oakland City. (2017/9/4-2017/9/8)

- T-109 speed

  This traffic dataset contains real-time speed data from freeways in California. We select 50/142/228 detectors and collect 6 months of data range from April 1st2017 to September 30th2017
  
- [T-222](https://ieeexplore.ieee.org/abstract/document/7848593) flow

  The collected data are then aggregated into a 5-min or 1-hour interval for each vehicle detection station (VDS) and stored in the online database. The particular VDS we look at in this paper has ID 1201100, and locates at lane 2 of I-405 mainline at Irvine Center Drive. One-month data (from August 1st to Agust 31th 2014) are selected in our experiments
  
- T-348 PEMS97 PEMS140 flow

> (T-143) 对 PEMS-BAY 的图：
>
> ![image-20240819013320675](img/image-20240819013320675.png)
>
> T-174 图6：
>
> ![image-20240901111245633](img/image-20240901111245633.png)

##### METR-LA

[METR-LA](https://github.com/liyaguang/DCRNN) (Metro Traffic Los Angeles)

洛杉矶公路网，207 个探测器，5 分钟间隔收集数据，一般用 2012 3.1 - 6-30

(T-ZS2) This dataset contains traffic speed and volume collected from the highway of the Los Angeles County road network, with 207 loop detectors. The samples are aggregated in 5-minute intervals. The most frequently referenced time period for this dataset is from March 1st to June 30th, 2012.  

(T-64) 1515 条边，34272 个时间步  (T-138) 说1722条边

(T-40) 说 6519002 个数据点 (T-128) 说 每个点35000个数据

(T-159) speed 数据

##### Seattle Loop

[Seattle Loop](https://github.com/zhiyongc/Seattle-Loop-Data)

西雅图 4 条路数据，323 个探测器，5 分钟间隔收集数据，2015 年 1 月数据 speed

(T-ZS2) This dataset was collected by inductive loop detectors deployed on four connected freeways (I-5, I-405, I-90, and SR-520) in the Seattle area, from January 1st to 31st, 2015. It contains the traffic speed data from 323 detectors. The samples are aggregated in 5-minute intervals  

(T-ZS26) I-5、I405、I-90和 SR-520这 4条高速公路的环路数据，T-12 用了

T-208 In this paper, one-year loop data from January 1st, 2016 to December 31st, 2016 for a four-lane freeway corridor in Seattle is used for validation. Seattle is currently a city with top ten busiest traffic in the United States. And this study freeway segment is one of the busiest corridors in Seattle. It starts from milepost-170 to milepost-165 of Interstate-5 (I5) freeway southbound, connecting the University of Washington to Downtown Seattle. There are 40 loop detectors on this corridor. They collect speed, volume, and occupancy traffic data.

T-236 Seattle-Loop is a highway speed dataset collected from 323 loop detectors in the Greater Seattle Area. The dataset contains 5-minute resolution data for the entirety of 2015.

T-39 In this study, two real-world network-scale traffic speed datasets are utilized. The first contains data collected from inductive loop detectors deployed on four connected freeways (I-5, I-405, I-90, and SR-520) in the Greater Seattle Area, shown in Fig. 2 (a). This dataset, which is publicly accessible2, contains traffic state data from 323 sensor stations over the entirety of 2015 at 5-minute intervals. The second contains road link-level traffic speeds aggregated from GPS probe data collected by commercial vehicle fleets and mobile apps provided by the company INRIX. The INRIX traffic network covers the Seattle downtown area, shown in Fig. 2 (b). This dataset describes the traffic state at 5-minute intervals for 1014 road segments and covers the entire year of 2012

![image-20240911152844507](img/image-20240911152844507.png)

##### 出租车数据

> [src](https://github.com/uctb/Urban-Dataset) 提供了部分 urban flow

Taxi Data  

- T-drive [T-97](https://dl.acm.org/doi/abs/10.1145/1869790.1869807) 轨迹数据 3w出租车 北京 2015/2/1 到 6/2

  (T-ZS2) This dataset contains a large number of taxicab trajectories collected by 30,000 taxis in Beijing from February 1st to June 2nd, 2015.

  (T-151) 32x32网格 60min 数据 02/01/2015-06/30/2015

  is a dataset based on taxi GPS trajectories on Beijing, jointly released by Microsoft Asia Research Institute and Peking University. The data used in our paper spans from February 1 to June 30, 2015

  contain inflow and outflow data

- [SHSpeed](https://github.com/xxArbiter/grnn) (Shanghai Traffic Speed) [T-98](https://arxiv.org/abs/1811.00740) 轨迹 上海

  (T-ZS2) This dataset contains 10-minute traffic speed data, derived from raw taxi trajectory data, collected from 1 to 30 April 2015, for 156 urban road segments in the central area of Shanghai, China.  

- TaxiBJ T-51 GPS轨迹 3w数据 背景 32x32 网格 [src](https://github.com/Echo-Ji/ST-SSL_Dataset)

  (T-ZS2) This dataset contains inflow and outflow data derived from GPS data in more than 34,000 taxicabs in Beijing from four time intervals: (1) July 1st to October 30th, 2013; (2) March 1st to June 30th, 2014; (3) March 1st to June 30th, 2015; and (4) November 1st, 2015 to April 10th, 2016. The Beijing city map is divided into 32 × 32 grids and the time interval of the flow data is 30 minutes

  T-ZS2 说 T-51 是出处

  T-314 说有 15072 条信息

  (T-162) collected in Beijing, spans from 03/01/2015 to 06/30/2015 on an hourly basis, taxi GPS trajectories

  (T-177) inflow outflow

  (T-203) 2013/7/1 - 2016/4/10 1h 12336 数据，100 区域

  ([T-205](https://link.springer.com/chapter/10.1007/978-3-030-67658-2_33)) TaxiBJ consists of four different time spans (denoted as P1 to P4 with different number of taxicabs and distribution) flow data between 6 am and 11 pm 128x128 分辨率 30min

  ([T-207](https://ojs.aaai.org/index.php/AAAI/article/view/6819), [T-210](https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Memory_in_Memory_A_Predictive_Neural_Network_for_Learning_Higher-Order_CVPR_2019_paper.html)) 32x32x2 grid

  T-274 (116.36, 116.50) (39.85, 39.99) 2015.11-2016.4(即 (4)) 32x32 grid 30minutes

  T-302 论文有表格 general

- [SZ-Taxi](https://github.com/lehaifeng/T-GCN) T-36 深圳罗湖区 156 条路轨迹数据，15 分钟粒度，2015 年 1 月数据

  (T-ZS2) This dataset is derived from taxi trajectories in Shenzhen from January 1st to 31st, 2015. It contains the traffic speed on 156 major roads of the Luohu District every 15 minutes.

  (T-165) speed trajectory

  ([T-218](https://www.mdpi.com/2220-9964/10/7/485)) 也用了；adjacency matrix is 156 × 156

- [TaxiCD](https://js.dclab.run/v2/cmptDetail.html?id=175) 14亿 GPS轨迹数据 1w5 出租车 2014 8月 成都

  (T-ZS2) This dataset contains 1.4 billion GPS records from 14,864 taxis collected from August 3rd to 30th, 2014 in Chengdu, China. Each GPS record consists of a taxi ID, latitude, longitude, an indicator of whether the taxi is occupied, and a timestamp

- [TaxiNYC](https://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml) 2009 纽约 [src2](https://github.com/Echo-Ji/ST-SSL_Dataset)

  (T-ZS2) The taxi trip records in New York starting from 2009, in both yellow and green taxis. Each trip record contains pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts.
  
  ([T-189](https://dl.acm.org/doi/abs/10.1145/3378889)) TaxiNYC dataset contains 1.19B taxicab trip records in New York from January 2009 to December 2015. On average, there are 170M trip records collected in each year. Each taxi trip record includes fields capturing pickup and dropoff dates/times, pickup and dropoff locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts. We use four-year records from 2009 to 2013 as training data, while the records in 2014 and 2015 are used as validation and test sets, respectively [flow]
  
  (64, 64) 网格 taxi gps trip 1h time interval
  
  (T-ZS38 给了另一个下载地址) ＮＹＣＴａｘｉ数据集包括了２００９—２０２０年纽约黄色和绿色出租车行程记录数据，主要记录了接送日期／时间、接送地点、行程距离、分项票价、费率类型、付款类型和司机报告的乘客数量等信息．该数据集是一个学术界常用的出租车数据集
  
  NYCTaxi
  
  (T-148 说 [T-149](https://ieeexplore.ieee.org/abstract/document/9127874/)) 75(15x5) 30min 01/01/2014-12/31/2014 
  
  (T-151) is a dataset of taxi trips made in New York City. It is provided by the New York City Taxi and Limousine Commission (TLC) The data used in our paper spans from January 1 to December 31, 2014.
  
  网格数据 75个点(15x5) 30分钟区间 contain inflow and outflow data
  
  (T-153 不同的，需求分析) 
  
  NYC-Taxi15 200 2880 01/2015 - 03/2015 30 min (2880是时间步)
  
  T-290 也在用15 10x20grid, 22000000+ 轨迹
  
  NYC-Taxi16 266 4368 04/2016 - 06/2016 30 min
  
  the traffic demand datasets have two dimensions: ’Pick-up’ and ’Drop-off
  
  (T-162) 01/01/2015 to 03/01/2015. (可能是taxi15) Its time interval is half an hour, taxi GPS trajectories
  
  (T-203) 2011/1/1 - 2016/6/30 48192 数据，1h，100 区域
  
  ([T-204](https://ieeexplore.ieee.org/abstract/document/8606218)) 2011-2014 Trip data includes: pick-up and drop-off dates/times, pick-up and drop-off locations
  
  T-274 # of Trips About 120 million Longitude (-74.02, -73.93) Latitude (40.65, 40.79) Time range 2015.1-2015.12 16x16 grid time inteval 1h
  
  T-218 [src](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)
  
  > Specifically, we select the For-Hire Vehicle (FHV) trip records in the Manhattan area (divided into 67 zones by administrative zip codes) from January 2018 to April 2018. This SLD data have similar features as the CDP dataset
  
  T-283 Taxicab NYC 2015 1-6 30min 3x10grid demand
  
  T-284 1h 4392时间区间 6800+车 16x8 2014 4-9 bike rent flow
  
  T-291 2018-1 ~ 2019-12-1 700 天
  
  T-301 This dataset contains 53,901,033 trip records of NYC in 2016 (from 01/01/2016 to 06/30/2016) [src](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) flow
  
  T-306  14 million taxi trips collected from 2013-11-01 to 2013-12-31 from Manhattan, New York City [src](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) speed
  
  T-355 demand 略
  
- NYC Yellow Taxi T-354

- CHI-Taxi

  (T-ZS35) 对 Illinois, USA 的数据集，有链接，轨迹数据
  
  T-301 [src](https://data.cityofchicago.org/Transportation/Taxi-Trips-2016/bk5j-9eu2) This dataset contains 956,972 trip records of CHI in 2016 (from 03/01/2016 to 04/30/2016) flow
  
- Suzhou SIP taxicab 轨迹 苏州

  T-283 2017 1-3 30min 12x5grid demand
  
  T-92 For SIP dataset, it contains traffic flows and speeds. We integrate it with another traffic accident dataset collected from Microblog, Sina
  
  T-362 Suzhou Industrial Park (SIP)
  
- T-292 新加坡 轨迹 singapore flow taxi

- T-297 罗马 Rome Italy

- CD chengdu [src](https://goo.gl/3VsEym) speed (其实就是taxiCD)

  T-306 1.4 billion GPS records from 14,864 taxis collected from 2014-08-03 to 2014-08-30 a total of 3,636,845 trips 
  
- T-314 taxiJN GY 济南 贵阳 jinan guiyang flow 有表格

- T-328 taxi Proto, BOS, CHI, DC, NYC 有表格 volume

- T-343 Xi'an Beijing Porto taxi 西安 北京 flow

> T-174 SHSpeed 图6
>
> ![image-20240901111157623](img/image-20240901111157623.png)

##### 打车数据

Ride-hailing Data

(T-ZS2)

- [UberNYC](https://github.com/fivethirtyeight/uber-tlc-foil-response) 百万计的数据 Uber

  This dataset comes from Uber, which is one of the largest online ride-hailing companies in the USA, and is provided by the NYC Taxi & Limousine Commission (TLC). It contains data from over 4.5 million Uber pickups in New York City from April to September 2014, and 14.3 million more Uber pickups from January to June 2015  

- [Digi GAIA Open Data](https://outreach.didichuxing.com/research/opendata/) 滴滴出行

  > (T-ZS37 译为滴滴盖亚开发数据集)：统计了网约车在成都、西安、海口等城市行驶中的所有传感器数据．该数据集包括的数据有：车辆平均速度 OD 信息、轨迹信息、驾驶场景、POI 检索数据等  

  This open data plan is supported by Didi Chuxing, which is one of the largest online ride-hailing companies in China  
  
  - DiDiChengdu: This dataset contains the trajectories of DiDi Express and DiDi Premier drivers within Chengdu, China. The data contains trips from October to November 2016  
  
    > (T-177) 所用：GPS 1.1billion 数据 11-2016
    >
    > The traffic data in Chengdu is the GPS records provided by Didi Chuxing, which is one of the largest online car-hailing platforms in the world
    >
    > We collect 1.10 billion GPS records between November 1st and 30th, 2016. Each record includes the vehicle ID, recorded time, location information (i.e., longitude and latitude), etc
  
    T-297 2016-12 14.4K 
  
    T-355 demand 5749755个orders
  
  - DiDiTTIChengdu: This dataset represents the DiDi Travel Time Index Data in Chengdu, China in the year of 2018, which contains the average speed of major roads every 10 minutes  
  
    \+ T-327 2016-11 demand 成都
  
  - DiDiXi’an: This dataset contains the trajectories of DiDi Express and DiDi Premier drivers within Xi’an, China. The data contains trips from October to November 2016  
  
  - DiDiHaikou: The dataset contains DiDi Express and DiDi Premier orders from May 1st to October 31st, 2017 in the city of Haikou, China, including the coordinates of origins and destinations, pickup and drop-off timestamps, as well as other information  
  
    > T-225 demand 10x10 grids
    
    T-270 flow
    
    T-357
    
  - DiDiNanjing
  
    T-270 flow
  
  - Didi-shenzhen
  
    T-279 flow
    
  - Didi-beijing / shanghai
  
    T-296 The first dataset is collected in Beijing within 6th Ring Road. The second dataset covers the urban area of Shanghai. Both datasets are collected from Jun. to Sep. in 2019 demand
    
    T-306 Nov. 8th 2018 to Dec. 30th 2018
    
  - Didi beijing / suzhou / shenyang
  
    T-316 ETA (预计到达时间)
  
    T-318 shenyang 沈阳

##### 单车数据

(T-ZS2) The open bike data used in the surveyed studies are listed as follows. 

- [BikeNYC](https://www.citibikenyc.com/system-data)

  T-ZS2 This dataset is from the NYC Bike System, which contains 416 stations. The frequently referenced time period for this dataset is from 1st July, 2013 to 31th December, 2016 

  (T-203) 1h 时间步 30720 个数据，416 个区域

  (T-153) 需求数据 (点数，时间步数)

  NYC-Bike14 128 4392 04/2014 - 09/2014 1 hour (T-178, T-209 也用)

  > bike14 T-177  NYC Bike system in 2014, from Apr. 1st to Sept. 30th
  >
  > includes: trip duration, starting and ending station IDs, and start and end times. Among the data, the last 10 days are chosen as testing data, and the others as training data.
  >
  > ([T-215](https://www.mdpi.com/2076-3417/10/21/7778)) 60min 16x8grid 6800+bikes 4292行
  >
  > T-352 也; FLOW

  NYC-Bike15 200 2880 01/2015 - 03/2015 30 min

  NYC-Bike16 250 4368 04/2016 - 06/2016 30 min

  the traffic demand datasets have two dimensions: ’Pick-up’ and ’Drop-off

  (T-162) all measured every 30 minutes, bike rental records

  > T-287 bike order 91 days). Following information is contained: bike pickup station, bike drop-off station, bike pick-up time, bike drop-off time, trip duration 
  >
  > This dataset consists of 35 million taxicab trip records in New York from April 1st, 2016 to June 30th, 2016. Following information is contained: pick-up time, drop-off time, pick-up longitude, pick-up latitude, drop-off longitude, drop-off latitude, trip distance [src2](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)

  NYCBike1 04/01/2014 to 09/30/2014 [src](https://github.com/Echo-Ji/ST-SSL_Dataset)

  NYCBike2 07/01/2016 to 08/29/2016 [src](https://github.com/Echo-Ji/ST-SSL_Dataset)

  (T-189) CitiBikeNYC dataset contains more than 28M bike trips in NewYork from July 2013 to June 2016. In total, CitiBike has established over 600 stations and 10K bikes in New York. Each bike trip contains the trip duration, start/end station IDs, start/end timestamps, station Lat/Long, and bike ID. We use the data from 2013 to 2015 as training and validation data and the data in 2016 as testing data

  T-354

  T-323 N =502 stations and 7,628,418 trips in 2015Q3Q4 and 2016Q1Q2 flow

  bike rent trip 28M 数据 网格 (16, 16)  time interval 1h [flow]

  [T-238](https://www.sciencedirect.com/science/article/pii/S0893608021004123) FLOW

  T-274 与 NYCTaxi 的描述一样，除了 # of trips 是 10M 之外

  T-290 2018-1 ~2019-12-1 700天

  T-291

  T-301 contains 5,675,719 trip records of NYC in 2016 (from 01/01/2016 to 06/30/2016) [src](https://s3.amazonaws.com/tripdata/index.html) flow

- [BikeDC](https://www.capitalbikeshare.com/system-data) 

  This dataset is from the Washington D.C. Bike System, which contains 472 stations. Each record contains trip duration, start and end station IDs, and start and end times.

- [BikeChicago](https://www.divvybikes.com/system-data)

  This dataset is from the Divvy System Data in Chicago, from 2015 to 2020. 
  
  T-267  was collected from 571 bike stations in the city of Chicago, over nine months from April 1st, 2018 to December 31st, 2018 demand
  
- CHI-Bike

  (T-ZS35) Illinois, USA 的轨迹数据
  
  T-274 About 3 million long. (-87.73, -87.55) lat. (41.76, 42.01) time 2015.1-2015.12 # of regions 16 × 16 time inteval 1 hour
  
  T-301 contains 336,075 trip records of CHI in 2016 (from 03/01/2016 to 04/30/2016). [src](https://data.cityofchicago.org/Transportation/Divvy-Trips/fg6s-gzvg) flow
  
- T-323 Divvy, Chicago: which consists of a total of N =607 stations and 3,214,965 trips in 2018Q2-Q4. 

- CHBike

  (T-148 说 [O-32](https://dl.acm.org/doi/abs/10.1145/3474717.3483923))CHBike 270(15x18) 30min 07/01/2020-09/30/2020 
  
- [BikeDC](https://www.capitalbikeshare.com/system-data)

  [T-203](https://ieeexplore.ieee.org/abstract/document/9139357) The data is taken from the Washington D.C. Bike System. Trip data includes: trip duration, start and end station IDs, start and end times. There are 472 stations in otal. For each station, we get two types of flows, where the inflow is the number of checked-in bikes, and the outflow is the number of checked-out bikes. Since many stations have no data or very few records 2011/1/1 - 2016/12/31 1h 区间，52608 时间步，120
  
- bike LA [src](https://bikeshare.metro.net/about/data/)

  T-267 Los Angeles. The Los Angeles (LA) dataset was collected from 83 bike stations in the city of Los Angeles over 15 months from October 1st, 2017 to December 31st, 2018. demand
  
- bike shanghai

  mobike T-270 flow

##### 地铁数据

(T-ZS2) The subway data referenced in the surveyed studies are listed as follows.  

- [SHMetro](https://github.com/ivechan/PVCGN) T-84 上海 8kw 数据 2016 近300个站千条边

  This dataset is derived from 811.8 million transaction records of the Shanghai metro system collected from July 1st to September 30th, 2016. It contains 288 metro stations and 958 physical edges. The inflow and outflow of each station are provided in 15 minute intervals.  

- [T-224](https://www.mdpi.com/2220-9964/10/4/222?ref=https%3A%2F%2Fgithubhelp.com)

  The metro passenger flow data used in this study were collected from Smart Card Data (SCD) of the metro system of Shanghai, China The time span of the data is between April 1st and April 30th in 2015. During this period, there were about nine million card records per day, covering 289 metro stations.

- [HZMetro](https://github.com/ivechan/PVCGN) T-84 杭州 2019 80个站 [src2](https://tianchi.aliyun.com/competition/entrance/231708/information) flow

  This dataset is similar to SHMetro, from the metro system in Hangzhou, China, in January 2019. It contains 80 metro stations and 248 physical edges, and the aggregation time length is also 15 minutes.  
  
  > (T-SZ26 也提及 [T-126](https://www.mdpi.com/1424-8220/20/16/4574)) 为阿里天池数据大赛的公开数据集，记录了杭州市 2019 年 1 月 1 日—2019 年 1 月 15 日约 7 000 万条地 铁刷卡数据，采样时间间隔为 10 min
  >
  > (T-151) The datasets of the metro crowd flow type are collected from the Hangzhou metro system
  >
  > including inflow and outflow datasets. The HZME datasets contain 80 nodes and 168 edges (undirected network) with a sparse spatial structural relationship
  
  [T-232](https://link.springer.com/article/10.1007/s10707-022-00466-1) The HZMF2019 dataset contains approximately 70 million data from 81 metro stations on three lines in the city of Hangzhou, China from January 1st to January 25th, 2019 [src](https://tianchi.aliyun.com/competition/entrance/231708/information)
  
- NYC Subway

  (T-ZS35) 纽约地铁数据有链接，乘客流
  
- Beijing Subway Dataset

  [T-209](https://ieeexplore.ieee.org/abstract/document/8560205) Beijing subway data comes from the people’s departure records of their Beijing metro-card. The data spans from July 1 to October 30, 2016. There are 18 lines in the Beijing Subway. The recording interval is 30 minutes. For this work, we obtained two types of crowd flow and a matrix representation of 2 × 18 channels
  
- shenzhen metro

  OD T-271
  
- hongkong metro

  T-303 Hong Kong metro stations. Each business day is defined as 5:00 AM to 1:00 AM of the next day, and we downsample it by grouping every 5 minutes, with 247 data points each day. For data split, we use data from 5:00AM, 01-Jan2017 to 01:00AM, 19-Feb-2017 as observed data 香港

  inflow passenger flow
  
- Metro Bike FLOW

  T-323 LA: which consists of a total of N =135 stations and 447,408 trips in 2017Q3Q4 and 2018Q1-Q4.

##### 北京其他

- [Beijing Traffic](https://github.com/deepkashiwa20/Urban_Concept_Drift)

  北京市 3126 个路段在 2022 年 5-7 月的 5 分钟粒度的数据

  (T-164 提出) Beijing 2022/05/12∼2022/07/25 3126 5 minutes Sudden

- [Q-Traffic](https://github.com/JingqingZ/BaiduTraffic)

  (T-ZS26 说 T-41)北京 2017 年 4-5 月一万多个路段每 15 分钟采样一次的百度地图数据；速度数据
  
  (T-41) we release a large-scale traffic dataset from Baidu Map, the Q-Traffic dataset, which provides various offline and online auxiliary information along with traffic speed data. There are three kinds of auxiliary domains in the Q-Traffic dataset: 1) Offline geographical and social attributes which include public holidays, peak-hour, speed etc; 2) the road intersection information such as local road network and junctions; and 3) online crowd queries which record map search queries from users.
  
  Road segments 15,073 
  
  Total length 738.91 km 
  
  Interval 15 minutes 
  
  Time April 1, 2017 - May 31, 2017 
  
  Total records 265,967,808 
  
  lon/lat bounding box (116.10, 39.69, 116.71, 40.18)
  
  列表对比了其他数据集，可以参考还有什么别的数据集
  
  [T-233](https://ojs.aaai.org/index.php/AAAI/article/view/26121) contains traffic speed per 15-minutes of 15,073 city road segments in Beijing, including 5856 time slices
  
- NE-BJ (T-133 说 [T-134](https://dl.acm.org/doi/full/10.1145/3532611))

  2023 论文提的新数据
  This dataset is a collection of public transport speed data taken from the navigation data of Tencent Map. It contains 500 segments, with each road segment data contains 6509 5-min time steps.

  (T-134) in weekdays of July 2020. The unit of speed is km/h. The dataset contains 500 road segments selected on the main roads in the northeast area of Beijing where a lot more traffic congestion always happens. The NE-BJ dataset is composed of traffic speed data of corresponding road segments seen as nodes in the graph
  
- T-181 

  At present, Beijing is encircled by four two-way ring roads, that is, the second to fifth ring roads, and has about 10,000 taxis to serve its population of more than 21 million. These taxis are equipped with GPS devices that upload data approximately every minute. The uploaded data contain information, including car positions, recording time, moving directions, vehicle travel speeds, etc. The data were collected from 1 May 2015 to 6 June 2015 (37 days). These data are well-qualified probe data because the missing data accounts for less than 2.9%, and are properly remedied using spatiotemporal adjacent records

  two sub-transportation networks, i.e., the second ring (labeled as Network 1) and north-east transportation network (labeled as Network 2) of Beijing, are selected. Network 1 consists of 236 road sections for aggregating GPS data, all of which are one-way roads. Network 2 consists of 352 road sections, including two-way and crossroads

- [T-183](https://www.sciencedirect.com/science/article/pii/S0378437122008329) 北京daxing flow

  Daxing District of Beijing to verify the accuracy of the model. There are 88 traffic monitors in Daxing District of Beijing. All traffic monitors sample the traffic information every 5 min

- T-123 TrafficBJ 

  TrafficBJ is a set of citywide traffic condition data on the road network in Beijing, which is scratched from a public website Baidu Maps.3 It is collected from May 14th to December 5th in 2017, with an updating frequency of six minutes. In practice, from 11 p.m. to 6 a.m. when most citizens are sleeping, traffic condition is generally smooth. So in this study, we only focus on the time period from 6 a.m. to 11 p.m. when traffic congestion often occurs and reliable traffic predictions are highly desired for travelers. In TrafficBJ, the road network is located within the Fifth Ring Road in Beijing and consists of 904 road links. The links on the road network are partitioned according to the lengths and intersections. The lengths of the links may be not the same, but are all in around [500,1000] meters. Through necessary preprocessing steps (see Appendix), the traffic conditions of all the 904 road links are calculated and arranged into raster data with size 53×42, according to their actual geographical locations. Here, we term the raster data as traffic condition snapshot
  
  raster size 32x32 时间 6min 可用数据量 36040 fifth ring road 
  
- [T-188](https://ieeexplore.ieee.org/abstract/document/9247476)

  we use a real-world traffic dataset in our experiments: one month Beijing taxi GPS trajectory dataset [O-38](https://dl.acm.org/doi/abs/10.1145/3277868.3277870). This dataset collects trajectory data from 1st May to 29th May of around 6000-8000 taxis in Beijing city. There are in total 129 million data samples, of which 75.36% are sampled within 1 minute.

- [T-190](https://www.sciencedirect.com/science/article/pii/S0968090X18315389)

  The freeway network is selected as the entire 2nd ring road, which is the most congested among the ring roads in Beijing. the 33KM-in-length 2nd ring road into 163 road segments with 200 m in length. Furthermore, we calculate the 5-min average speed for each link using the collected trajectory points of anonymous users

  2016-10-1 ~ 11-27 6:00-22:00 58x192x163=1.8M 数据

- [T-202](https://ieeexplore.ieee.org/abstract/document/9520129) Urban-BJ Ring-BJ speed

  Urban-BJ and Ring-BJ are extracted from the Global Positioning System data in Beijing, which are collected by more than 10,000 taxi vehicles from June 2015 to August 2015. A total of 278 nodes in the downtown area are selected in Urban-BJ, whereas 236 nodes are selected in Ring-BJ

  Ring-BJ only contains the traffic data on urban expressways, and Urban-BJ has the traffic data on different types of urban road segments, such as arterial, local street, and expressway. Given that all segments are mixed in a small area, Urban-BJ is more complex in traffic flow composition than METR-LA and Ring-BJ.
  
- [T-214](https://onlinelibrary.wiley.com/doi/epdf/10.1111/mice.12575) speed 自建吧

- [T-234](https://ojs.aaai.org/index.php/AAAI/article/view/4247) demand 自建

- T-235 travel time 北京 2 条路 自建吧

  collected from two bus lines in Beijing in the period from October 1, 2020, to March 31, 2021. The data contains the GPS records of buses traveling on those routes. We have reshaped the data into time series by aggregating the travel time for each route section between two bus stations every 5 min. In these datasets, each route section represents a node in the graph

  Line1 Line2 # Sections 38 36 Length (km) 17.35 50.3 # Timesteps 37,800 38,232 Time interval 5 min 5 min Time span 10/2020∼3/2021 10/2020∼3/2021

- T-247 SPEED

  The Traffic dataset contains minute-level traffic speed data from six roads in Beijing, collected from April 1 to 30, 2016, and it can be obtained from [src](https://github.com/BuaaPercy/Traffic-DataSet-of-Beijing-Road)
  
- T-256 flow

  collected by the Beijing Municipal Commission of Transport, which contains trajectories of 40,000 taxies in Beijing from April 1st 2015 to July 31st 2015 (totally 4 months). These trajectories mapped to the road networks using the map matching algorithm. We statistic the traffic flow by counting the number of taxis on each road segment during every 5-minute time interval, resulting in 288 data points per day.

  Gong Ti (Workers’ Stadium), which has 221 road segments, the second is the area around Beijing West Railway Station, which has 393 road segments, and the last area is around the biggest business park in Beijing, i.e., Zhongguancun (China Silicon Valley), which has 564 road segments. We denote the three datasets as GT-221, WRS393, and ZGC-564 respectively
  
- T-311 mobileBJ FLOW

  T-324 有表格 T-352

- T-114 CrowdBJ flow 

  9/1/2017-11/30/2017 (32, 32) 2016条

  This dataset, which is extracted from the mobile base station, indicates the crowd flow in Beijing. We first partition Beijing into 32 × 32 grids and then calculate the inflows and outflow in each grid.

- T-319 W3-715 E5-2907 Amap volume

- T-325 北京地铁、公交车、出租车轨迹

- T-327 UCAR 1h demand 

- T-330 QD-F qingdao shandong 青岛 flow 2019-8

- T-347 NYC Chicago openstreetmap anomaly

- T-351 transit networks from Tainan City Government(不公开) and Chicago Transit Authority (CTA) [src](https://www.transitchicago.com/) 乘客流 

- T-359 demand 复杂 

- T-362 time

  3,384,847 trajectories of 10,039 taxis from October 1st to October 31st in 2013

> (T-140 自建) BJF, BRF, BRF-L
>
> - are generated from a real-world GPS trajectory data, in which about 80 million GPS points of 30,000 taxis are recoded per day
> - BJF. Each node in BJF indicates a junction and 190 important junctions in Beijing are selected. The traffic data of each node is recorded in every 15 minutes and the time range is from November 2015 to October 2016. 
> - BRF. BRF has totally 300 nodes and each node indicates a road. The time interval is set to 20 minutes and the time period used of BRF is from November 2015 to May 2016. 
> - BRF-L. Similar to BRF, the traffic flow of each road is recoded in the dataset. BRF-L contains 1586 roads and the time interval is set to 10 minutes. The time period used of BRF-L is from November 2015 to December 2015.



北京：

(T-ZS1) it is unclear as to whether or not all of the Beijing-based datasets come from one unified dataset source  

(T-ZS1 stated:) usually cover the Ring Road area

- 用到的 (2015, 2k引用) [T-25](https://www.sciencedirect.com/science/article/pii/S0968090X15000935)、(2017, 100引用) [T-26](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-its.2016.0257)、(2016, 180引用) [T-27](https://ieeexplore.ieee.org/abstract/document/7795712)、(2018，近4k引用) [T-28 STGCN](https://arxiv.org/abs/1709.04875)
- T-25 contains the traffic volume, occupancy and speed data (2017, 近500引用) [T-29](https://epubs.siam.org/doi/abs/10.1137/1.9781611974973.87) 

> (T-134) NE-BJ 图示
>



##### 其他

- [深圳市政府数据开放平台数据集](https://opendata.sz.gov.cn/)

  (T-ZS26) 深圳市部分地区的各种交通相关数据。例如，停车场数、卡口数据、车流量数据、营运车辆GPS数据、街道实时数据和路段属性数据等

- [上海出租车数据集](http://www.cse.ust.hk/scrg/) (好像挂了)

  (T-ZS26) 速度；由香港科技大学智慧城市研究组提出，包含 2007年 2月 20日在中国上海的 4 000辆出租车全天的 GPS 报告。其中，车辆行驶数据采样时间间隔为 1 min，数据包 含ID、时间、经纬度、速度等信息

- [UVDS](https://link.springer.com/chapter/10.1007/978-3-030-73280-6_6) 4 引用 useless 感觉

  (T-ZS26) 韩国城市地区数据集 UVDS 包含 104 个 VDS 传感 器收集的城市主要道路数据，具有交通流量、车辆类型、交 通速度和占用率等交通特征

- [Highways England](http://tris.highwaysengland.co.uk/detail/trafficflowdata)

  (T-ZS26) 英国高速公路数据集包含英国M、A级高速公路的 数据，采样时间间隔为 15 min，具有时间、流量、速度、占用 率等交通特征

  (T-ZS35) 有表格提及该数据集等

  [T-186](https://www.mdpi.com/1424-8220/22/19/7517) map of expressway observation points in Britain [src](https://webtris.highwaysenglend.co.uk/) The target section is in northern Waterford in southern Ireland. To be exact, it is around the place where longitude is 51.716354 and latitude is −0.385198

  > We select traffic flow data monitored every 15 min of each node in the sections of British place named as M25 j20-j21A, M1 j6-j6A, A405, M25 j21A-j22 and M1 j6A-j8, in which both of M and A is the prefix of the highway and j is the prefix of the mark on the different sections on one road. Data collected is the data of the whole month in July 2021, in which the interval of recording traffic flow is 15min. The selected road sections are represented by numbers in the figure, which are 1, 2, 3, 4 and 5 respectively, in which the value of m is 4 and Section 5 is the target section to be predicted.
  >
  > Local Date Local Time Total Carriageway Flow M25 j20-j21A M1 j6-j6A A405 2021-7-1 0:14:00 63 182 30 2021-7-1 0:29:00 57 138 30 2021-7-1 0:44:00 36 136 22 2021-7-1 0:59:00 43 112 14 2021-7-1 1:14:00 26 128 20

  T-300 2014 1-6 England 17353 314 15 mins 6 months

- [LargeST](https://proceedings.neurips.cc/paper_files/paper/2023/hash/ee57cd73a76bd927ffca3dda1dc3b9d4-Abstract-Datasets_and_Benchmarks.html) [src](https://github.com/liuxu77/LargeST  )

  (T-ZS30) This is a large-scale traffic forecasting dataset with 8,600 sensors, which consist of sensor ID, latitude, longitude, district, country, highway location, lane, type, direction. It’s divided into three subsets, including Greater Los Angeles (GLA), Greater Bay Area (GBA), and San Diego (SD). This dataset provides a vital foundation for large-scale traffic prediction research 交通速度；2024的刊才提出的 CCFA
  
- [韩国 Urban](http://topis.seoul.go.kr/)

  (T-ZS38) 记录了韩国首尔江南区（Ｕｒｂａｎ１）和麻浦区（Ｕｒｂａｎ２）两个区域的真实车流数据．Ｕｒｂａｎ１和Ｕｒｂａｎ２是首尔交通流量最大的两个地区，且均具有高度复杂的城市交通网络．数据集的采样周期为２０１８年４月１日至２０１８年４月３０日．数据集主要是基于ＧＰＳ采集的７万多辆出租车的轨迹数据，采样时间间隔为５ｍｉｎ．采集的交通流数据经过数据预处理得到的是各链路的平均速度
  
  T-73 We conducted experiments on two real-world large-scale datasets of Seoul, South Korea. Urban1 (Gangnam) and Urban2 (Mapo) correspond to the most crowded regions in Seoul, and they have highly complex connectivity patterns where most of the streets have bidirectional links with complicated traffic signals. The traffic data were collected for a month ranging from Apr 1st, 2018 to Apr 30th, 2018. The datasets were collected using GPS of over 70,000 taxis, where the trajectory samples were collected every 5 minutes and the post data processing was applied to calculate the average traffic speed of each link.
  
  Dataset Urban1 Urban2 Time spans 4/1/2018 ∼ 4/30/2018 Time interval 5min Region size (width, height)(m) (7000, 7000) Number of links 480 455 Speed mean(std)(km/h) 26.333(10.638) 25.917(9.784) Length mean(min, max)(m) 592(171, 2622) 561(80, 2629) Links per km2 11.274 10.280
  
- T-332 事故风险预测

  This study uses real-world datasets collected from five metropolitan cities in South Korea for September 2016 and September 2018
  
- Urban-core 速度

  [T-236](https://ieeexplore.ieee.org/abstract/document/10400973) Urban-core is an urban speed dataset containing data collected from DTG (Digital Tacho Graph) on Seoul Taxis. The dataset includes speed data aggregated at the road segment level in a 5-minute resolution for one month. The number of road segments in the dataset is 304.
  
- EXPY-TKY

  (T-136 建立) 2021/10/1 - 12/31, 10min 时间区间，13248 时间步，1843 条道路连接，速度

  contains the traffic speed information and the corresponding traffic incident information in 10-minute interval for 1843 expressway road links in Tokyo over three months (2021/10∼2021/12).

- 厦门 [O-30](https://ieeexplore.ieee.org/abstract/document/8029849)

  (T-143 描述) traffic volume prediction on the Xiamen dataset

  which contains 5 months of data recorded by 95 traffic sensors ranging from August 1st, 2015 to December 31st, 2015 in Xiamen, China
  
  > (T-177 的厦门) 
  >
  > The traffic data in Xiamen is the vehicle license plate recognition (VLPR) records, which are collected from numerous traffic cameras deployed around the city
  >
  > We collect 3.15 billion records generated by 262 VLPR devices from August 1st, 2015 to August 31st, 2016. Each record includes the device ID (associated with location information, i.e., longitude and latitude), vehicle license plate number, recorded time, etc
  
- Traffic Flow Prediction T-152

  感觉是自建 The Traffic Flow Prediction dataset is collected every 15 min at 36 sensor locations along two major highways in the Northern Virginia/Washington, D.C., capital region
  
- Los-Loop 只有一周的数据

  T-165 This dataset collected by loop detectors deployed on the highway of Los Angeles in America. It contains 207 nodes characterized by the <u>speed</u> collected by loop detectors. And adjacency matrix represents the positional connections between loop detectors. These data are collected every 5 minutes, ranging from 3/1/2012 to 3/7/2012

  T-166 recorded every 30 s. The data were then aggregated into 5-min intervals
  
  T-218 speed adjacency matrix is thus 207 × 207
  
- HZJTD 杭州 T-69 speed

  was collected by Hangzhou Integrated [Transportation Research Center](http://www.hzjtydzs.com/index.html). It was sampled from 202 roads in the major urban areas of Hangzhou city by loop detectors. The time period of HZJTD is from 16th October, 2013 to 3rd October, 2014. HZJTD contains traffic conditions including traffic speed and traffic congestion index. Traffic speed is taken as the traffic condition to be predicted. We aggregate traffic speed on the roads every 15 minutes. Finally, HZJTD contains 30353 records for each road. The topological structure of the road network of Hangzhou city was manually constructed (as shown in Fig. 4(a)). Note that a two-way road in the figure is treated as two distinct roads. The POIs in Hangzhou city were collected based on [Baidu Map API](https://lbsyun.baidu.com/).

- T-174 杭州

  road types within the urban road network are considered: expressways, highways, major arterials, and minor arterials. The study road network includes 1,969 links, which can be further divided into 6,300 segments (consisting of 2,162 expressway/highway segments, 2,582 major arterial segments, and 1,556 minor arterial segments). The average segment length for the study road network is 128.6 m (with a minimum segment length of 10 m and a maximum segment length of 298 m). Among these segments, 2,488 of them are not adjacent to intersections, while 1,990 and 1,818 segments are adjacent to one or two intersections, respectively.

  The dataset used in this study includes the vehicle trajectories of 7,259 taxis operating (with a total of 271,117,329 rows of data) over nine days (June 22-30, 2015) in Hangzhou, China. The duration between two consecutive sampling points for most of the trajectories ranges from 5 s to 30 s. Table I lists a sample of the GPS data extracted from taxis, and this is used to derive the vehicle trajectory between any two consecutive sampling timestamps. It can be observed that a typical sample record includes the geolocation of taxi (longitude and latitude), timestamp, taxi ID, operation status (occupied: 1/vacant: 0), instantaneous speed (km/h), and movement direction

- T-334

  The data were collected for seven months (June 11, 2015 to November 11, 2015) using seven long-distance microwave detectors on the elevated Shangtang-Zhonghe roadway section of Hangzhou. Three variables were included: flow, density, and lane occupancy.

- T-109 NYC

  NYC: This traffic dataset contains traffic information collected from traffic speed detectors deployed on road segments of Manhattan district in New York city. We select 50 sensors and collect 2 months of data ranging from December 1st2017 to January 30th2018
  
- [NYCDOT](https://opendata.cityofnewyork.us/)

  [T-196](https://ieeexplore.ieee.org/abstract/document/9945489) New York City Department of Transportation (NYCDOT) 10/1/2018 to 12/31/2018 

  Traffic data include time stamp, GPS location of vehicles and other related information 矩阵：13,248 POI 树：10380 subway lines: 36

  1km 区域 32x32

  POI data includes seven categories: residence, commercial, school, entertainment, culture facility, social service, transportation center

  T-289 2013 147k事故 173,179k taxi orders, 1525 POIs, 8760 weathers, 103k 路段 事故预测

- T-92 NYC opendata 有表格 speed 有事故

- [The City of Chicago’s open data portal](https://data.cityofchicago.org/)

  T-196 (同上 NYCDOT) 不同之处在于 13248 个矩阵，9625 个 POI，8 lines

  T-278 [src](https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips/m6dm-c72p) 

  > the trip records of Transportation Network Providers (ride-sharing companies) in the Chicago area. The city of Chicago is divided into 77 zones and the trip requests with pick-up and drop-off zone are recorded every 15min. We use 4-month observations from September 1st, 2019 to December 30th, 2019. The dataset is divided into various spatial resolutions to facilitate the discussion of model performance. We randomly select 10 × 10 O-D pairs with the same time period as spatially sparse data sample

  T-289 2016 2-9 44K事故 1,744k taxiorders, 无POI，天气hours 5832, 56k路段

- T-190 天津

  choose an area with the size of 10 km2 in Tianjin Nankai district as the case study of urban road network. the topology of the network consisting of 242 links, We calculate the 5-min average speed for each link through trajectory data after filtering the outliers.

  2018 8-1 ~ 9-30 7:00-19:00 61x144x242 = 2.1M 数据

- [T-194](https://ieeexplore.ieee.org/abstract/document/9875268)

  自己用监控数据生成矩阵，流量监测，地点未知

- [T-197](https://onlinelibrary.wiley.com/doi/full/10.1155/2020/6896579)

  自建，商业，不公开，地点未知，速度

- [T-201](https://www.tandfonline.com/doi/full/10.1080/21680566.2021.1916646#d1e243)

  自建，flow，2880 条，中国

- T-44 SCATS

  traffic volume dataset provided by VicRoads. Our studied network is an urban corridor of 30 road segments with 24 intersections along Victoria Street (Melbourne) including both directions

  Victoria Street is one of the busiest streets in Melbourne so the prediction of traffic flows for this street is of high interest. The dataset contains traffic volume and DS of every road segment per minute. One-year data of the year 2016 are used in the experiments; public holidays and the days with missing data are excluded. The data are aggregated into 5-min. intervals and normalized to the range [0, 1] using the min-max normalizing technique. 

  In this study, we focus on evaluating the models’ performance in the morning peak hours (6 am–10 am) on weekdays. The morning peak is one of the periods that has attracted a lot of attention due to its high traffic volume and level of congestion
  
- T-205 HappyValley

  HappyValley is the hourly observations of human flow in a theme park in Beijing from ten months flow data between 6 am and 11 pm

  分辨率 50,100  1h 时间 Staying flow

  T-302 论文有表格

- Traffic4cast [competition series](https://www.iarai.ac.at/traffic4cast/)

  [T-206](https://ieeexplore.ieee.org/abstract/document/9749915) This dataset records the GPS trajectories of consecutive traffic flows in Berlin, Moscow, and Istanbul in the form of video frames in 2019. The size of each frame is 495  436  3. The value of each pixel corresponds to the traffic information in an area of 100m x 100 m in 5 minutes, including mean speed, volume, and major traffic direction
  
- INRIS-SEA [T-79](https://www.sciencedirect.com/science/article/pii/S0968090X20305866) 不公开 speed

  Washington Department of Transportation GPS Jan 1st, 2012 to Dec 31st, 2012 Seattle downtown area 725 roads 5-minutes data points is 76,212,000

- 重庆 [T-220](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-its.2018.5511) flow

  the smart card data of 126 stations from 1 January 2014 to 30 March2015 are provided by Chongqing Transport Planning and Research Institute, with the fields involving card ID, station code, date, and heading (Entrance or Exit). According to the privacy protection ordinance, personal information about cardholders has been masked. To obtain more reliable results, incomplete and invalid records are filtered. The inter-station passenger flow for per hour of the day is denoted by hour_OD. Each pair of stations contains 8772 od records. Hence, a total of 1,3926,4272 (126 × 126 × 8772) records are acquired and stored in the MongoDB database. The hour_OD is an array with the length of 24. Subsequently, the number of passengers per hour from station a to station b on day d (w is the day of the week) can be described

- 香港 [T-221](https://ieeexplore.ieee.org/abstract/document/9129440) speed

  The Transport Department of Hong Kong provides real-time and historical average traffic speed of major roads in Hong Kong every five minutes

  We use all the data available (from 2016/11/25 to 2019/10/25) and the average speed in the Cross-Harbour Tunnel at 19:30 as the true value for predictio

- 河南 [T-223](https://onlinelibrary.wiley.com/doi/full/10.1155/2021/1997212) flow

  The experimental data comes from a real application system, which is the Henan Highway Management System [13]. In the experiment, we used weather and traﬃc ﬂow data on highway toll stations from May 2017 to September 2017. The total amount of data is approximately more than 20000. From September 16, 2017 to September 30,2017 as our testing set and the rest of data as our training set, we choose d = 7, that means we use 7 days of historical traﬃc ﬂows of highway toll stations as the temporal feature

- [New York TLC](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) OD based (bike NYC)

  Manhattan After filtering, the dataset contains a total of 18970027 OD transactions.

  \+ Smart Location Database
  
- 甘肃兰州 需求数据 T-226

  we selected the data of 76 electric carsharing stations of a company in Lanzhou City,Gansu Province, from May to September, 2018,

  The electric carsharing network consists of 76 electric car-sharing stations, mainly located in and around the An’ning District, Xigu District, and Yongdeng County of Lanzhou City. The stations cover these areas in a distinctive way
  
- T-234 需求 北京上海 自建

- T-70 EV-CARD

  EVCARD, which is one of the biggest hourly rental operators in China. The dataset contains the orders from 5/1/2017 to 7/31/2017 in Shanghai, and there are about 15,000 orders per day. The order includes pick-up station, drop-off station, pickup time and drop-off time

  Data Source EVCARD Time from 5/1/17 7/1/17 to 6/30/17 7/31/17 #days 61 31 #stations 1433 1433 #orders 964,531 498,856

- [T-244](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9713756) 杭州 speed 感觉自建 FCD AutoNavi

- [T-255](https://ojs.aaai.org/index.php/AAAI/article/view/20342) JONAS-NYC JONAS-DC demand supply [New York City, Washington DC, Chicago]

- T-265 成都自建 轨迹打车 chengdu

- T-268 成都，西安，深圳，HB speed+flow

- T-322 成都，西安，北京，有表格，时间预测

- T-272 室内人流量

- T-273 parking Melbourne

- T-274 chengdu About 7M 数据 2016.11 32x32 1h (103.80, 104.30) (30.50, 30.80)

- T-286 自建 Chicago IL and Minneapolis MN in US, and Edmonton, Canada. Bird, Lime, trip  flow

- NYC Turnstile Usage of Subway Stations 入口闸数据

  T-290 2018-1 ~2019-12-1 700天

- T-293 成都、西安 openstreetmap [src](https://www.openstreetmap.org)

  T-307 也用了 openstreetmap

- T-294 speed easy bay, los angeles US 

- T-295 数据比较多比较杂 主要是东京 救护车需求

- T-304 NSW Sydney Transport 乘客 flow

  T-363 NSW Sydney Trains network  crowd flow

- T-313 停车问题预测，国内数据

- T-316 baidu map 百度地图 taiyuan, hefei, huizhou 太原，合肥，惠州

- T-326 人GPS数据 感觉日本 Konzatsu-Tokei

- T-333 乘客flow AFC Automatic Fare Collection

  For universality, we choose the passenger flow data of Beijing Subway Line 13 in March, 2014. Take the inbound passenger flow data for instance, we first select the passenger flow data of Line 13 from 5:00:00 to 23:00:00 and calculate the data at the intervals of five minutes. Then, the passenger flow is converted into a two-dimensional matrix
  
- T-346 AFC shenzhen, hangzhou深圳，杭州

- T-341 Austin, TX; Louisville, KY; Minneapolis, MN: US 和人工生成数据 flow

- T-349 Freight Datasets 货运 demand 中国

- T-350 jinan hangzhou volume 济南 杭州 有表格

- T-361 Cologne + 合成 flow

- T-362 beijing + shanghai time

  上海 Shanghai dataset contains 9,727,798 trajectories of 13,622 taxis from April 1st to April 30th in 2015

其他数据集：参见 [paperwithcode 网站：Traffic Prediction Task](https://paperswithcode.com/task/traffic-prediction)、[这篇综述](https://arxiv.org/pdf/2101.11174?trk=public_post_comment-text)、[TKDE2020综述](https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=6998&context=sis_research)、[这篇综述](https://kns.cnki.net/kcms2/article/abstract?v=7sQefmFxFK3uEKBquRla5qDHveK9oCCRpBWf04Zyi-hciTPIaXDHO5AckFT2OGZGmxYUV8QI8BcEApyz73mJ280tQxDTOIZYSnF6llnWzinghcTnd6z1lC2pEY218-lrd9AoSHndDepAUNkp_yiHGfr7Tsk5vANL&uniplatform=NZKPT&language=CHS)。

T-ZS29 有新的数据集列表，未经我的整理

> HZJTD
>
> 论文图4表示路网
>
> ![image-20240831140935250](img/image-20240831140935250.png)

### 论文统计

#### paperwithcode

##### METR-LA

[src](https://paperswithcode.com/sota/traffic-prediction-on-metr-la)

按榜单顺序：

1.  [T-141](https://www.sciencedirect.com/science/article/pii/S0957417423007832)
2.  T-74
3.  [T-140](https://aaai.org/ojs/index.php/AAAI/article/view/5470)
4.  [T-139](https://dl.acm.org/doi/abs/10.1145/3583780.3615160)
5.  [T-138](https://arxiv.org/abs/2206.09112)
6.  [T-137](https://dl.acm.org/doi/abs/10.1145/3534678.3539396)
7.  [T-136](https://ojs.aaai.org/index.php/AAAI/article/view/25976)
8.  [T-135](https://arxiv.org/abs/2312.00516)
9.  [T-133](https://www.sciencedirect.com/science/article/pii/S0893608023007542) 
10.  [T-132](https://arxiv.org/abs/2202.03539)
11.  [T-131](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/itr2.12044)
12.  [T-130](https://arxiv.org/abs/1912.07390) 引用少，名不见，CCF NONE，2019，读着感觉很水，就是对 Graph Wave Net 的一些微调
13.  [T-129](https://ieeexplore.ieee.org/abstract/document/10260564)
14.  [T-128](https://proceedings.mlr.press/v139/yoo21b.html)
15.  T-64
16.  T-85 引用少且 T-ZS2 没有具体提及，认为不重要
17.  T-40
18.  T-28

##### NE-BJ

1.  T-133
2.  T-134
3.  [T-143](https://ojs.aaai.org/index.php/AAAI/article/view/5477)
4.  [T-142](https://dl.acm.org/doi/abs/10.1145/3394486.3403118)
5.  T-64
6.  T-110

##### PEMS-BAY

1. T-135
2. T-137
3. T-138
4. T-141
5. T-133
6. T-136
7. T-131
8. T-128
9. T-139
10. T-143
11. T-64
12. T-140
13. T-40
14. [T-144](https://ieeexplore.ieee.org/abstract/document/9565380) 几乎名不见经传，交通信号预测，时间：动态线性模型、空间：图热扩散，2021

##### PEMSD4

1. T-135
2. [T-158](https://arxiv.org/abs/2401.10155) 
3. T-148
4. T-154
5. T-154
6. T-150
7. T-147
8. [T-157](https://arxiv.org/abs/2209.01967)
9. [T-156](https://dl.acm.org/doi/full/10.1145/3604808)
10. [T-155](https://ojs.aaai.org/index.php/AAAI/article/view/20587)

###### PEMS04

1. T-135

2. T-153

3. T-139

4. T-148

5. T-150

6. > IDCN (paper with code 找不到论文出处)

7. T-110

8. [T-159](https://dl.acm.org/doi/abs/10.1145/3589270)

##### PEMSD3

1. T-135
2. T-150
3. T-147
4. T-156
5. T-155

##### PEMS07

1. T-135
2. T-139
3. [T-154](https://arxiv.org/abs/2408.07100)
4. T-154
5. [T-153](https://arxiv.org/abs/2401.15894)
6. [T-152](https://link.springer.com/article/10.1007/s00521-023-08831-3)
7. [T-151](https://arxiv.org/abs/2401.04148)
8. [T-150](https://www.sciencedirect.com/science/article/pii/S0031320323003710)
9. [T-148](https://ojs.aaai.org/index.php/AAAI/article/view/25556)
10. [T-147](https://ieeexplore.ieee.org/abstract/document/10184591)
11. T-132
12. [T-146](https://ojs.aaai.org/index.php/AAAI/article/view/16542) 
13. [T-145](https://dl.acm.org/doi/abs/10.1145/3447548.3467430)
14. T-87
15. T-28
16. T-81

###### PEMSD7

1. T-135
2. T-139
3. T-154
4. T-154
5. T-150
6. T-148
7. T-156
8. T-155

###### PEMSD7M

1. T-150
2. T-154
3. T-154
4. T-156
5. T-155
6. T-141

###### PEMSD7L

1. T-150
2. T-154
3. T-154
4. T-156
5. T-155

###### PEMS-M

1. T-85
2. [T-160](https://arxiv.org/abs/1903.00919)
3. T-28
4. [O-33](https://proceedings.neurips.cc/paper/2014/hash/a14ac55a4f27472c5d894ec1c3c743d2-Abstract.html)
5. T-85

##### PEMS08

1. T-158
2. T-154
3. T-147
4. T-139
5. T-153
6. T-154
7. T-148
8. T-152
9. T-150
10. T-159

###### PEMSD8

1. T-154
2. T-147
3. T-135
4. T-154
5. T-148
6. T-150
7. T-157
8. T-156
9. T-155

##### NYCTaxi

1. [T-162](https://ojs.aaai.org/index.php/AAAI/article/view/25555)
2. T-110
3. T-87
4. T-146
5. T-151

##### BJTaxi

1. T-162
2. T-110
3. T-87
4. T-146
5. [T-163](https://arxiv.org/abs/2312.03406) 感觉是机器学习，且领域也不是单交通的，且名不见传

##### SZTaxi

1.  [T-165](https://arxiv.org/abs/2103.06126)
2.  [T-166](https://arxiv.org/abs/2010.07498)
3.  [T-167](https://www.mdpi.com/1424-8220/23/8/3836)
4.  T-36
5. T-36

##### NYCBike1/2

1. T-162
2. T-110
3. T-87
4. T-146



##### 其他

[T-161](https://dl.acm.org/doi/abs/10.1145/3511808.3557294) PEMS

T-41 Q-Traffic 鼻祖

T-136 EXPY-TKY 

O-30 LargeST 鼻祖 (讲黑车检测的，二分类问题)

[T-164](https://arxiv.org/abs/2309.14216) Beijing traffic

T-152 HZME

#### 出处统计

[参考](https://github.com/jwwthu/GNN4Traffic) [主要参考](https://github.com/jwwthu/DL4Traffic)

##### 会议

Conferences

> 2022-2023 统计了一些 CCF-B，往下只统计很热门(多引用)的 CCF-B，统计全部 CCF-A，不统计 CCF-C 和 CCF-NONE

###### AAAI

AAAI Conference on Artificial Intelligence CCF-A

2023

- T-233 Ising-Traffic
- T-148 PDFormer

2022

- [T-254](https://ojs.aaai.org/index.php/AAAI/article/view/20320) CATN
- T-255 EAST-Net
- T-155 STG-NCDE
- [T-256](https://ojs.aaai.org/index.php/AAAI/article/view/20322) STDEN

2021

- [T-287](https://ojs.aaai.org/index.php/AAAI/article/view/16591) CCRNN
- [T-288]() FC-GAGA
- [T-289](https://ojs.aaai.org/index.php/AAAI/article/view/16566) GSNet
- T-93
- [T-290](https://ojs.aaai.org/index.php/AAAI/article/view/16603) MOHER
- T-146
- [T-291](https://ojs.aaai.org/index.php/AAAI/article/view/17761) ST-GDN
- [T-292](https://ojs.aaai.org/index.php/AAAI/article/view/16104) TrGNN

2020

- [T-303](https://ojs.aaai.org/index.php/AAAI/article/view/5915) WDGTC
- T-143
- [T-304](https://ojs.aaai.org/index.php/AAAI/article/view/5819) MLC-PPF
- T-239
- T-92 RiskOracle
- [T-305](https://ojs.aaai.org/index.php/AAAI/article/view/5471) SHARE
- T-87
- T-140

2019

- [T-324](https://ojs.aaai.org/index.php/AAAI/article/view/3892)
- T-82
- T-124

###### ICDE

IEEE International Conference on Data Engineering CCF-A

2023

- [T-252](https://ieeexplore.ieee.org/abstract/document/10184658) SSTBAN
- T-147 STWave 改版

2022

- [T-266]() ST-WA
- [T-267](https://ieeexplore.ieee.org/abstract/document/9835338) STGNN-DJD

2021

- [T-293](https://ieeexplore.ieee.org/abstract/document/9458698) DeepTP
- [T-294](https://ieeexplore.ieee.org/abstract/document/9458855) EnhanceNet
- [T-295](https://ieeexplore.ieee.org/abstract/document/9458623) 
- [T-296](https://ieeexplore.ieee.org/abstract/document/9458919) Gallet
- [T-297](https://ieeexplore.ieee.org/abstract/document/9458664) AttConvLSTM
- [T-298](https://ieeexplore.ieee.org/abstract/document/9458616) 做系统的

2022

- [T-306](https://ieeexplore.ieee.org/abstract/document/9101359) MPGCN
- [T-307](https://ieeexplore.ieee.org/abstract/document/9101647/)

###### ICML

International Conference on Machine Learning CCF-A

2022

- T-229 DSTAGNN

###### IJCAI

International Joint Conference on Artificial Intelligence CCF-A

2022

- [T-272](https://par.nsf.gov/servlets/purl/10358115) GINet
- [T-273](https://arxiv.org/abs/2204.11008) 一种模块
- [T-274](https://www.ijcai.org/proceedings/2022/0282.pdf) STAN
- [T-275](https://arxiv.org/abs/2210.06126) RGSL
- [T-276](https://www.academia.edu/download/93010705/0545.pdf) FOGS

2021

- [T-308](https://people.engr.tamu.edu/guni/papers/IJCAI-transportation.pdf) 交通拥挤综述
- [T-309](https://dr.ntu.edu.sg/handle/10356/153498)
- [T-310](https://arxiv.org/abs/2106.06273) TrafficStream

2020

- [T-311](https://vonfeng.github.io/files/IJCAI2020_CSCNet_Extension_NoAck.pdf) CSCNet
- [T-312](https://www.researchgate.net/profile/Chuyin-Huang/publication/342797939_LSGCN_Long_Short-Term_Traffic_Prediction_with_Graph_Convolutional_Networks/links/5f5f33e9a6fdcc116410af5b/LSGCN-Long-Short-Term-Traffic-Prediction-with-Graph-Convolutional-Networks.pdf) LSGCN
- [T-313](https://intellistream.github.io/downloads/papers/predictionIJCAI.pdf) PewLSTM 停车预测

2019

- [T-325](https://www.ijcai.org/Proceedings/2019/0317.pdf) GSTNet

###### NeurIPS

Conference on Neural Information Processing Systems CCF-A

2022

- [T-282](https://proceedings.neurips.cc/paper_files/paper/2022/hash/79081c95482707d2db390542614e29cd-Abstract-Conference.html) 攻击模型

2020

- T-110
- [T-321](https://proceedings.neurips.cc/paper/2020/hash/cdf6581cb7aca4b7e19ef136c6e601a5-Abstract.html) StemGNN



###### SIGKDD

ACM SIGKDD Conference on Knowledge Discovery and Data Mining CCF-A

2022

- [T-277](https://dl.acm.org/doi/abs/10.1145/3534678.3539397) MSDR
- [T-278](https://dl.acm.org/doi/abs/10.1145/3534678.3539093) STZINB-GNN
- T-137
- [T-279](https://dl.acm.org/doi/abs/10.1145/3534678.3539281) ST-GFSL
- [T-280](https://dl.acm.org/doi/abs/10.1145/3534678.3539422) SPGCL

2021

- [T-299](https://dl.acm.org/doi/abs/10.1145/3447548.3467371) CNFGNN
- [T-300](https://dl.acm.org/doi/abs/10.1145/3447548.3467275) DMSTGCN

2020

- [T-314](https://dl.acm.org/doi/abs/10.1145/3394486.3403122) AutoST 一种搜索模型结构方法
- [T-315](https://dl.acm.org/doi/abs/10.1145/3394486.3403376) BusTr 公车到达时间预测
- [T-316](https://dl.acm.org/doi/abs/10.1145/3394486.3403386) CompactETA 到达时间预测
- T-142
- [T-317](https://dl.acm.org/doi/abs/10.1145/3394486.3403320) ConSTGAT 时间预测
- [T-318](https://dl.acm.org/doi/abs/10.1145/3394486.3403294) HetETA 时间预测
- [T-319](https://dl.acm.org/doi/abs/10.1145/3394486.3403358) H-STGCN
- [T-320](https://dl.acm.org/doi/abs/10.1145/3394486.3403046) DSAN

2019

- [T-326](https://dl.acm.org/doi/pdf/10.1145/3292500.3330654) Deepurbanevent
- [T-327](https://dl.acm.org/doi/abs/10.1145/3292500.3330877) GEML
- T-43

###### SIGMOD

2020

- [T-322](https://dl.acm.org/doi/abs/10.1145/3318464.3389771)

###### VLDB

International Conference on Very Large Data Bases CCF-A

2022

- T-138

2021

- [T-301](https://dl.acm.org/doi/abs/10.14778/3457390.3457394) MDTP

###### WWW

International World Wide Web Conference CCF-A

2023

- [T-253](https://dl.acm.org/doi/abs/10.1145/3543507.3583304) AutoST

2022

- [T-285](https://dl.acm.org/doi/abs/10.1145/3485447.3511990) Pyramid
- [T-286](https://dl.acm.org/doi/abs/10.1145/3485447.3512145)

2021

- [T-302](https://dl.acm.org/doi/abs/10.1145/3442381.3449792) STRN

2020

- T-89
- [T-323](https://dl.acm.org/doi/abs/10.1145/3366423.3380097) GBikes
- T-173

2019

- [T-328](https://dl.acm.org/doi/abs/10.1145/3308558.3313577) MetaST

###### DASFAA

International Conference on Database Systems for Advanced Applications CCF-B

2023

- [T-249](https://link.springer.com/chapter/10.1007/978-3-031-30678-5_15) 一种改进辅助，没有特定模型
- [T-250](https://link.springer.com/chapter/10.1007/978-3-031-30678-5_32) RGCN ~~致敬传奇第一个我找到的 0 引用论文~~

###### ICASSP

IEEE International Conference on Acoustics, Speech and Signal Processing CCF-B

2023

- [T-251](https://ieeexplore.ieee.org/abstract/document/10095151)  DSGCN ~~致敬传奇引用1~~

2022

- [T-264](https://ieeexplore.ieee.org/abstract/document/9746497) Ada-STNet CI-6
- [T-265](https://ieeexplore.ieee.org/abstract/document/9747016)  CI-1

###### CIKM

ACM International Conference on Information and Knowledge Management CCF-B

2022

- [T-258](https://dl.acm.org/doi/abs/10.1145/3511808.3557432) 微调
- [T-259](https://dl.acm.org/doi/abs/10.1145/3511808.3557243) AutoSTS
- [T-260](https://dl.acm.org/doi/abs/10.1145/3511808.3557540) ASTTN
- [T-261](https://dl.acm.org/doi/abs/10.1145/3511808.3557705) ST-GAT

2021 略

###### DASFAA

International Conference on Database Systems for Advanced Applications CCF-B

2022

- [T-262](https://link.springer.com/chapter/10.1007/978-3-031-00129-1_26) CSTT 传奇引用0
- [T-263](https://link.springer.com/chapter/10.1007/978-3-031-00123-9_15) 引用4

###### ICDM

IEEE International Conference on Data Mining CCF-B

2022

- [T-268](https://ieeexplore.ieee.org/abstract/document/10027643) 引用4
- [T-269](https://ieeexplore.ieee.org/abstract/document/10027720) CI-4
- [T-270](https://ieeexplore.ieee.org/abstract/document/10027729) CI-1
- [T-271](https://ieeexplore.ieee.org/abstract/document/10027683) CI-4

###### WSDM

ACM International Conference on Web Search and Data Mining CCF-B

2022

- [T-283](https://dl.acm.org/doi/abs/10.1145/3488560.3498394) CMT-Net
- [T-284](https://dl.acm.org/doi/abs/10.1145/3488560.3498444) ST-GSP

> ###### APNOMS

###### 其他

- APNOMS Asia-Pacific Network Operations and Management Symposium CCF-C
- BigCom CCF-NONE
- Big data IEEE International Conference on Big Data CCF-C
- CAC CCF-NONE
- CASE CCF-NONE
- CICTP CCF-NONE
- CIKM ACM International Conference on Information and Knowledge Management CCF-B
- DASFAA International Conference on Database Systems for Advanced Applications CCF-B
- DEXA International Conference on Database and Expert System Applications CCF-C
- DSAA IEEE International Conference on Data Science and Advanced Analytics CCF-C
- ECAI European Conference on Artificial Intelligence CCF-B
- ECML-PKDD European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases CCF-B
- GLOBECOM IEEE Global Communications Conference CCF-C
- ICANN International Conference on Artificial Neural Networks CCF-C
- ICC IEEE International Conference on Communications CCF-C
- ICDCS IEEE International Conference on Distributed Computing Systems CCF-B
- ICDM IEEE International Conference on Data Mining CCF-B
- ICONIP International Conference on Neural Information Processing CCF-C
- ICLR CCF-NONE
- ICPR International Conference on Pattern Recognition CCF-C
- ICTAI IEEE International Conference on Tools with Artificial Intelligence CCF-C
- IJCNN International Joint Conference on Neural Networks CCF-C
- ISCAS IEEE International Symposium on Circuits and Systems CCF-C
- ITSC CCF-NONE
- IROS IEEE\RSJ International Conference on Intelligent Robots and Systems CCF-C
- KSEM International conference on Knowledge Science, Engineering and Management CCF-C
- MASS IEEE International Conference on Mobile Adhoc and Sensor Systems CCF-C
- MDM International Conference on Mobile Data Management CCF-C
- MobiQuitous International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services CCF-C
- PAKDD Pacific-Asia Conference on Knowledge Discovery and Data Mining CCF-C
- PIMRC CCF-NONE
- SDM SIAM International Conference on Data Mining CCF-B
- SECON IEEE International Conference on Sensing, Communication, and Networking CCF-B
- SIGSPATIAL ACM Special Interest Group on Spatial Information CCF-C
- SMC IEEE International Conference on Systems, Man, and Cybernetics CCF-C
- SmartComp CCF-NONE
- SSCI CCF-NONE
- SSTD International Symposium on Spatial and Temporal Databases CCF-C
- UrbComp CCF-NONE
- VTC CCF-NONE
- WCNC IEEE Wireless Communications and Networking Conference CCF-C
- WCSP CCF-NONE
- WISE Web Information Systems Engineering CCF-C



> 2022
>
> - [T-257](https://ieeexplore.ieee.org/abstract/document/9919973) 引用1

##### 期刊

###### TKDE

CCF-A

2023

- [T-337](https://ieeexplore.ieee.org/abstract/document/10145833) CitiTrans
- [T-338](https://ieeexplore.ieee.org/abstract/document/9851916/) ST-ExpertNet

2022

- [T-340](https://ieeexplore.ieee.org/abstract/document/9944937/) DMGAN
- [T-341](https://ieeexplore.ieee.org/abstract/document/9363542) GCScoot
- [T-342](https://ieeexplore.ieee.org/abstract/document/9956738) MixRNN+
- [T-343](https://ieeexplore.ieee.org/abstract/document/9944966) ST-PEF+
- [T-344](https://ieeexplore.ieee.org/abstract/document/9786854) GAMCN
- [T-345](https://ieeexplore.ieee.org/abstract/document/9786834) MBA-STNet
- [T-346](https://ieeexplore.ieee.org/abstract/document/9813413) STP-TrellisNets+
- [T-347](https://ieeexplore.ieee.org/abstract/document/9711930) SNIPER 事故

2021

- T-341
- [T-355](https://ieeexplore.ieee.org/abstract/document/9657493) DAGNN
- [T-356](https://ieeexplore.ieee.org/abstract/document/9540306) DeFlow-Net
- [T-357](https://ieeexplore.ieee.org/abstract/document/9537675) ST-GCSL

2020

- T-93 事故预测
- [T-363](https://ieeexplore.ieee.org/abstract/document/9063494) OLS
- T-203
- T-305
- T-113 ST-MetaNet+
- [T-362](https://ieeexplore.ieee.org/abstract/document/9261122) TTPNet

2019

- T-204 
- [T-364](https://ieeexplore.ieee.org/abstract/document/8873676/)

###### TITS

CCF-B

2023

- [T-330](https://ieeexplore.ieee.org/abstract/document/10143385) DST-GraphSAGE

- [T-331](https://ieeexplore.ieee.org/abstract/document/10101714/) STKEC

- [T-332](https://ieeexplore.ieee.org/abstract/document/10023949) MG-TAR 

- [T-333](https://ieeexplore.ieee.org/abstract/document/10004201) 

- [T-334](https://ieeexplore.ieee.org/abstract/document/9701439) STFSA-CNN-GRU

- [T-335](https://ieeexplore.ieee.org/abstract/document/10054349/) 安全系统感觉关系不大

- [T-ZS43](https://ieeexplore.ieee.org/abstract/document/10077454) GNN ITS 综述

- > …… 太多了不继续搞了，感觉 CCFA 会已经够用了

2022

- 更多了，几十篇

###### TKDD

CCF-B 

2023

- T-134
- [T-336](https://dl.acm.org/doi/abs/10.1145/3586164) DMGF-Net

2022

- T-115
- [T-348](https://dl.acm.org/doi/abs/10.1145/3564753) DSTM-DWT
- [T-349](https://dl.acm.org/doi/full/10.1145/3565578) STHAN

2021

- [T-351](https://dl.acm.org/doi/abs/10.1145/3451393) 引用少 推荐系统
- [T-352](https://dl.acm.org/doi/full/10.1145/3477577) DeepSTN+
- [T-353](https://dl.acm.org/doi/abs/10.1145/3439346) Double-Encoder
- [T-354](https://dl.acm.org/doi/abs/10.1145/3450528) CEST

2020

- [T-358](https://dl.acm.org/doi/abs/10.1145/3385414) MGSTC 引用很高

2019

- [T-359](https://dl.acm.org/doi/abs/10.1145/3355563) 

###### AI

CCF-A

2023

- [T-339](https://www.sciencedirect.com/science/article/pii/S0004370223000450) AutoSTG+

###### TMC

CCF-A

2020

- [T-360](https://ieeexplore.ieee.org/abstract/document/9127090) FlowFlexDP
- [T-361](https://ieeexplore.ieee.org/abstract/document/9132706) MTL-CV

###### 概述

Journals

- AAI CCF-NONE
- ACE CCF-NONE
- **AEI CCF-B** Advanced Engineering Informatics
- **CCF-C** Ad Hoc Networks
- AEJ CCF-NONE
- **AI CCF-A** Artificial Intelligence
- **AI CCF-C** Applied Intelligence
- AJSE CCF-NONE
- AMM CCF-NONE
- ASC CCF-NONE
- Access CCF-NONE
- Algorithms CCF-NONE
- Applied Sciences CCF-NONE
- Artificial Intelligence 前文
- BDR CCF-NONE
- Big Data CCF-NONE
- CACIE CCF-NONE
- **CC** **CCF-C** Computer Communications
- CCPE CCF-NONE
- CEE CCF-NONE
- CEUS CCF-NONE
- **CI CCF-C** Computational Intelligence
- CIAN CCF-NONE
- CIS CCF-NONE
- CSUR CCF-NONE
- Cogent CCF-NONE
- **CCF-B** The Computer Journal
- **CCF-C** Connection Science
- CMC CCF-NONE
- Chaos CCF-NONE
- **Cluster CCF-B** IEEE International Conference on Cluster Computing
- **Complexity CCF-C** Journal of Complexity
- CTR CCF-NONE
- DCN CCF-NONE
- **DMKD CCF-B** Data Mining and Knowledge Discovery
- **DSE CCF-C** Data Science and Engineering
- DSP CCF-NONE
- **EAAI CCF-C** Engineering Applications of Artificial Intelligence
- **ES CCF-C** Expert Systems
- **ESWA CCF-C** Expert Systems with Applications
- ETRR CCF-NONE
- Electronics CCF-NONE
- Entropy CCF-NONE
- Evolving Systems CCF-NONE
- **FGCS CCF-C** Future Generation Computer Systems
- FI CCF-NONE
- FT CCF-NONE
- Forecasting CCF-NONE
- **CCF-B** GeoInformatica
- ICAE CCF-NONE
- IEICE-TIS CCF-ONE
- IEEE Access CCF-NONE
- IEEE-IS CCF-NONE
- IEEE-JAS CCF-NONE
- IEEE-OJITS CCF-NONE
- **IET-ITS** **CCF-C** IET Intelligent Transport Systems
- IET-SC CCF-NONE
- IET-SP CCF-NONE
- IF CCF-NONE
- **IJCIS CCF-C** International Journal of Cooperative Information Systems
- IJDE CCF-NONE
- IJES CCF-NONE
- IJGI CCF-NONE
- **IJGIS CCF-C** International Journal of Geographical Information Science
- **IJIS CCF-C** International Journal of Intelligent Systems
- IJITSR CCF-NONE
- IJMLC CCF-NONE
- IJPR CCF-NONE
- **IJPRAI CCF-C** International Journal of Pattern Recognition and Artificial Intelligence
- **IJSEKE CCF-B** International Journal of Software Engineering and Knowledge Engineering
- IMWUT CCF-NONE
- ISR CCF-NONE
- **ITC CCF-B** International Test Conference
- ITIIS CCF-NNE
- ITS-Magazine CCF-NONE
- **IOT CCF-C** IEEE Internet of Things Journal
- Iscience CCF-NONE
- **CCF-B** Information Sciences
- JACIII CCF-NONE
- JAIHC CCF-NONE
- JAT CCF-NONE
- JBD CCF-NONE
- JBDAT CCF-NONE
- JCSC CCF-NONE
- JCSE CCF-NONE
- JF CCF-NONE
- JIFS CCF-NONE
- **JISA CCF-C** Journal of Information Security and Applications
- JITS CCF-NONE
- JKSU-CIS CCF-NONE
- JS CCF-NONE
- **JSA CCF-B** Journal of Systems Architecture: Embedded Software Design
- **JSCT CCF-B** Journal of Computer Science and Technology
- JSEN CCF-NONE
- JSSSE CCF-NONE
- JTE-PartA CCF-NONE
- **KBS CCF-C** Knowledge-Based Systems
- KIS CCF-NONE
- MNA CCF-NONE
- MIS CCF-NONE
- MPE CCF-NONE
- MPLB CCF-NONE
- MTAA CCF-NONE
- Mathematics CCF-NONE
- Measurement-Sensors CCF-NONE
- **NC CCF-C** Natural Computing
- **NCA CCF-C** Neural Computing and Applications 
- **NN CCF-B** Neural Networks
- **NPL CCF-C** Neural Processing Letters
- **CCF-C** Neurocomputing
- **PR CCF-B** Pattern Recognition
- **PRL CCF-C** Pattern Recognition Letters
- PeerJ-CS CCF-NONE
- PhysicaA CCF-NONE
- Plos-One CCF-NONE
- Promet CCF-NONE
- RAL CCF-NONE
- RFID CCF-NONE
- RS CCCF-NONE
- **SC CCF-A International Conference for High Performance Computing, Networking, Storage, and Analysis**
- **SCIS CCF-A Science China Information Sciences**
- SCIS CCF-NONE Sustainable Cities and Society
- **SCN CCF-C** Security and Communication Networks
- SCS CCF-NONE
- SNAS CCF-NONE
- Sensors CCF-NONE
- **CCF-C** The Journal of Supercomputing
- **SPL CCF-C** IEEE Signal Processing Letters
- Sustainability CCF-NONE
- Symmetry CCF-NONE
- TAI CCF-NONE
- **TBD CCF-C** IEEE Transactions on Big Data
- **TCSS CCF-C** IEEE Transactions on Computational Social Systems
- **TCYB CCF-C** IEEE Transactions on Cybernetics
- **TFS CCF-B** IEEE Transactions on Fuzzy Systems
- TGIS CCF-NONE
- **TII CCF-C** IEEE Transactions on Industrial Informatics
- **TITS CCF-B IEEE Transactions on Intelligent Transportation Systems** 
- TIST CCF-NONE
- **TJSC CCF-C** The Journal of Supercomputing
- **TKDD CCF-B ACM Transactions on Knowledge Discovery from Data**
- **TKDE CCF-A IEEE Transactions on Knowledge and Data Engineering**
- TL CCF-NONE
- **TMC CCF-A IEEE Transactions on Mobile Computing**
- TMIS CCF-NONE
- **TNNLS CCF-B** IEEE Transactions on Neural Networks and learning systems
- TNSE CCF-NONE
- **TNSM CCF-C** IEEE Transactions on Network and Service Management
- **TOIT CCF-B** ACM Transactions on Internet Technology
- **TOSN CCF-B** ACM Transactions on Sensor Networks
- TPT CCF-NONE
- **TR CCF-B** IEEE Transactions on Robotics
- TRA CCF-NONE
- TRB CCF-NONE
- TRC CCF-NONE
- TRE CCF-NONE
- TRR CCF-NONE
- TS CCF-NONE
- TSAS CCF-NONE
- TSIPN CCF-NONE
- TVT CCF-NONE
- Technologies CCF-NONE
- TransportmetricaA/B CCF-NONE
- VJCS CCF-NONE
- **WCMC CCF-C** Wireless Communications and Mobile Computing
- WN CCF-NONE
- **WWW CCF-B** World Wide Web

#### 综述统计

(T-ZS2) 表11 对常用的数据集就三种指标 RMSE, MAE, MAPE 下最好的几篇论文 (60min 为预测周期)

(T-ZS2) 经典基线模型 DCRNN T-40, STGCN T-28, Graph WaveNet T-64

> (T-ZS1)  表格的评价尺度：
>
> - 参考([xx])、作者、年份、主要数据类型、主数据集、时间范围、粒度、次要数据集、输入序列长度、预测视野
>
> - 模型分类、预测值、时/空、模型子分类
>
>   > 时空分类的具体定义参见论文，指模型专门用来处理哪一部分，or both
>

> 数据集
>
> - PeMS 14/37
> - 北京点数据和轨迹数据，各 6/37
>
> 辅助数据
>
> - 天气 6/37 ；时间(time of day / day of week) 3/37  ；路网(road network) 3/37
>
> 数据跨度
>
> - 一个月 5/37；数个月 22/37；一年 6/37；超过一年 4/37
>
> 模型：
>
> - LSTM 18/37； 混合模型 21/37； 其他DNN(SAE, DBN) 6/37
>

(T-ZS2) 统计了一整页不同的数据集，和用这些数据集的论文 (表6)，这些数据通常数据清洗/预处理过。

该综述的表7, 8, 9, 10 分别统计了交通流量、交通速度、交通需求和其他问题的，开源代码及其年份、所用的代码框架(如 PyTorch)和开源链接

> #### 旧论文排行
>
> 列举部分 [paperwithcode](https://paperswithcode.com/task/traffic-prediction) 上的 SOTA 论文，概述如下：
>
> - METR-LA 数据集：
>
>   - [STGM](https://www.sciencedirect.com/science/article/pii/S0957417423007832) 注意力捕获时空依赖+GNN(空间处理)+改进CNN(时间处理) 2023 (SOTA)
>
>   - [Traffic Transformer](https://onlinelibrary.wiley.com/doi/abs/10.1111/tgis.12644) (Transformer) 2020
>
>   - [SLCNN](https://aaai.org/ojs/index.php/AAAI/article/view/5470/5326) (CNN+图) 2020
>
>   - [STAEformer](https://arxiv.org/pdf/2308.10425v5) (Transformer) 2023 (也是 PeMSD7 的 SOTA)
>
>   - [D2STGNN](https://arxiv.org/pdf/2206.09112v4)、[STEP](https://arxiv.org/pdf/2206.09113v2)、[MegaCRN](https://arxiv.org/pdf/2211.14701v4) (GNN) 2022
>
>     [DCGCN](https://arxiv.org/pdf/2306.07019v2) (GNN) 2023； [DCRNN](https://arxiv.org/pdf/1707.01926v3) (有向图扩散+CRNN) 2018
>
> - PeMSD8 数据集：
>
>   - [STWave](https://ieeexplore.ieee.org/abstract/document/10184591/) (图+注意力) 2023 (SOTA)
>
>   - [STD-MAE](https://arxiv.org/pdf/2312.00516v3) (两个 autoencoder 分别处理时空) 2023
>
>     PeMS-BAY、PeMS07、PeMSD04、PeMS04 四个数据集的 SOTA
>
>   - [PDFormrer](https://paperswithcode.com/paper/pdformer-propagation-delay-aware-dynamic-long) (Transformer) 2023
>
>   - [DDGCRN](https://paperswithcode.com/paper/a-decomposition-dynamic-graph-convolutional) GNN 2023
>
> - 其他数据集：
>
>   - SOTA PeMS08 [HTVGNN](https://arxiv.org/pdf/2401.10155v4) (注意力(时间)+改进GNN(空间)) 2024
>   - SOTA NE-BJ [RGDAN](https://www.sciencedirect.com/science/article/pii/S0893608023007542) (图扩散+注意力) 2024
>   - ……

## 未来挑战

> (T-ZS2) 一种开头表述方法 While GNNs achieve a better forecasting performance, they are not the panacea. Some existing challenges from the border topic of traffic forecasting remain unsolved in current graph-based studies. Based on these challenges, we discuss possible future directions as well as early attempts in these directions.  
>
> T-ZS29 一个参考概括
>
> Several challenges can be observed from the surveyed studies, which can be categorized into data, model, and system perspectives. From a data perspective, challenges include data quality and cold-start issues. From a model perspective, challenges include complex graph structure and model robustness concerns. From a system perspective, the real-world deployment of GNNs in transportation systems is a challenge that cannot be ignored

> ### 现存挑战

#### 应用问题

##### 异常数据健壮性

T-ZS29

The fourth challenge is the robustness of GNN models. Deep learning models have long been criticized for their black-box nature with little or no interpretation paired with predicted outcomes. This black-box problem exists for graph neural networks as well, and there are few systematic methods for interpreting GNNs in traffic forecasting settings. Many anomalies or outliers in the data are removed during processing steps or do not appear in the training dataset. When these anomalies are encountered during the testing or deployment phase, the performance of the trained GNN model degrades, leading to large deviations in model predictions. Given such risks, it is important to enhance the robustness and interpretability of GNN models to increase user confidence in the models.

##### 落地

(T-ZS2) Applications in Real-World ITS Systems  

如，红绿灯控制、地图导航、打车服务

> Last but not the least, most of the surveyed GNN-based studies are only based on the simulations with historical traffic data, without being validated or deployed in real-world ITS systems. However, there are a number of potential applications, especially for GNN-based models with the better forecasting performance  
>
> - To name a few potential cases, the GNN-based forecasting model can be used for traffic light control in signalized intersections, when each intersection is modeled as a node in the graph and the corresponding traffic flow forecasting result can be used to design the traffic light control strategy  
> - Another example is the application in map service and navigation applications, in which each road segment is modeled as a node in the graph and the corresponding traffic speed and travel time forecasting result can be used to calculate the estimated time of arrival  
> - A third example is the application in online ride-hailing service providers, e.g., Uber and Lyft, in which each region is modeled as a node and the corresponding ride-hailing demand forecasting can be used to design a more profitable vehicle dispatching and scheduling system  
>
> Inspired by these potential application scenarios, there are a lot of potential research opportunities for researchers from both the academia and the industry.  

T-ZS29 计算资源开销，服务器集群(?)，存储资源，预测精度和计算开销的平衡

The fifth challenge is the real-world deployment of GNNs in transportation systems. The real-world implementation of the surveyed GNN solutions requires substantial computing, communication, and storage resources. However, most of the surveyed studies only consider empirical evaluations based on offline datasets without testing their models on real-world transportation systems. Several obstacles arise in the real-world deployment of GNNs. To effectively utilize graph-based structures, a centralized deployment mode is required to collect global information and compute predictions in a single server.

When the considered graph becomes larger, the communication overhead also increases. To achieve more efficient and safe transportation systems, complex GNN architectures may not be necessary for traffic-related tasks if their marginal performance improvement fails to cover the increased computational, communication, and storage costs

##### 响应式方案

(类似：数据结合问题)

(T-ZS1) 响应式方案：如交通事故，天气变化融入到模型

Developing responsive algorithms and prediction schemes. 

Several of the recent works have attempted to address the problem of algorithm responsiveness in the face of unexpected traffic incidents such as accidents and weather changes. This is mainly done by using weather and accidents data as additional inputs to the traffic flow prediction models

- 如 T-55 使用 Dempster-Shafer theory 结合天气与交通流数据(参见上文)

  combined weather and traffic flow data using the Dempster-Shafer theory  

- 如 T-30 单纯结合天气 

  simply concatenated weather and traffic flow data  

- 如 T-51 简单相加

  performed simple addition  

评价：缺乏消融实验

lack ablation tests which can reveal the effectiveness of utilizing weather data  

有实验的：

- T-53 嵌入天气 + 消融实验

  incorporated weather data by embedding them into the traffic flow data in their test and performed a simple ablation test, which proved that the inclusion of weather data does improve prediction performance  

- T-52 事故+模拟实验

  performed a network stimulation test to understand the
  effect of sudden traffic accidents  

评价：探索不足，融合数据困难

As we can see, several authors have tested the impacts of weather and accidents in traffic flow prediction. Although several experiments have proven that the addition of these data can increase the prediction power of the models and increase their responsiveness to unexpected changes in traffic, this facet of traffic prediction has not been explored in great depth. This is due to the difficulty of incorporating these external data. Overcoming the challenge of data incorporation is the first step in utilizing weather and non-recurring incidents data in general to improve model responsiveness.  

#### 模型解释能力

(T-ZS1) Explanatory power, associations and causality  解释力、关联、因果关系

(T-ZS2) Model Interpretation

模型参数难以理解，NN 是黑盒模型

> (T-ZS2) The challenge of model interpretation is a point of criticism for all blackbox" machine learning or deep learning models, and traffic forecasting tasks are no exception [T-111](https://ieeexplore.ieee.org/abstract/document/8916985), T-38

参考上文具体技术，神经网络节的优缺点

如：

- T-40 观察图扩散过程和邻节点关联

  observed the traffic diffusion along the road network and the correlation between several adjacent traffic sensors

- T-39 可视化网络权重以预训练不同探测器找到关键路段

  visualized the network weights pertaining to different detector sites to find key road segments in the traffic network

- T-4 可视化注意力权重上下流，观察交通流的移动

  visualized the attention weights of upstream and downstream stations to observe how traffic flow moves across several traffic stations

(T-ZS1) 解读参数的意义

Performing explanatory analyses on neural networks may uncover useful traffic patterns 

黑盒模型，只解释了空间方面的一部分内容

(T-ZS1) While neural networks have proven to be a very effective prediction model, they are infamously known as black-box models; models that are difficult to dissect and explain. Although the aforementioned authors managed to explain the traffic phenomena to some degree, their observations are mostly limited to the spatial aspect; observing how the traffic at one site affects another and how traffic propagates across the road network. To the best of our knowledge, there  is no work that observes other aspects of the prediction, such as the dynamics of abrupt weather changes and accidents.  

对 CNN 的解读可视化有进展，但 GNN 尚未有

(T-ZS2) While there have been remarkable progresses for visualizing and explaining other deep neural network structures, e.g., CNNs, the development of post-processing techniques to explain the predictions made by GNNs is still in an early phase [O-21](https://arxiv.org/abs/1905.13686), [O-22](https://openaccess.thecvf.com/content_CVPR_2019/html/Pope_Explainability_Methods_for_Graph_Convolutional_Neural_Networks_CVPR_2019_paper.html), [O-23](https://proceedings.neurips.cc/paper_files/paper/2019/hash/d80b7040b773199015de6d3b4293c8ff-Abstract.html), and the application of these techniques to the traffic forecasting domain has not yet been addressed  

> 跟其他领域相比，该领域对可解释性的要求更高
>
> (T-ZS2) Compared with other similar forecasting problems in other domains, lack of model interpretation may be a more severe problem in the transportation domain, when complex data types and representations of heterogeneous traffic data make it more challenging to design an interpretable deep learning model, compared with other data formats, e.g., images and text. While some efforts have been made to incorporate the state space model to increase the model interpretation for traffic forecasting [O-24](https://arxiv.org/abs/2102.00397), , this problem has not fully solved, especially for GNN-based models  

> ### 未来挑战

#### 数据问题

##### 缺乏基准数据集

Lack of a benchmark dataset / Centralized Data Repository  

(T-ZS1) 难以对比，且同一数据集也有多个子集/不同与处理方式

- (我个人) 就算用同一个数据集，其预测长度不一样，参数不一样，指标不一样，也会有不一样的结果

(T-ZS1) The availability of a wide range of traffic data supports traffic prediction. However, this availability also poses a challenge to comparative work. Due to the fact that different works use different datasets, it is very hard to assess the relative performance of different state-of-the-art models. The Caltrans data is the closest to a benchmark dataset, as it is used by 14 out of 37 literatures we have covered. However, different works use different subsets of the Caltrans from different periods of time and from different traffic detector sites  

> (T-ZS2 再表述) It is known that different works use different datasets and it is very hard to assess the relative performance of different state-of-the-art models. Even for those studies using the same dataset, different subsets may be used. Different preprocessing techniques, e.g., the missing data imputation method, and different evaluation settings, e.g., the training/validation/test subset split ratio, also cause incomparable results  
>
> (T-ZS2) With more and more GNN-based models being proposed, it becomes even more difficult to compare different models and validate the effectiveness of new traffic forecasting methods without a considerable effort, when a standardized benchmark dataset and consistent experimental settings have not been established yet  
>
> T-ZS29 T-ZS29 输出长度、评价指标、训练变量的不同
>
> - Due to the different evaluation metrics and forecast horizons, it is nearly impossible to fairly compare all surveyed studies and quantify the difficulty of the available datasets
> - their reported performance in different studies could vary when the training variables were different.

但选择大的子集存在训练代价困难，依赖复杂；选择小的子集难以拟合真实数据，在时空上分别讨论

(T-ZS1) Choosing a subset of data within a larger dataset also poses a challenge. As temporal and spatial correlation affects traffic greatly, the period of the data and the traffic detector locations become important considerations. For instance, when using data that covers a period of less than a year, there is a risk of not capturing the seasonal effects on traffic, and when using only weekdays data, the models cannot learn weekend traffic well. For the spatial aspect, the choice of roads or highways can greatly affect the traffic flow as metropolitan roads have significantly busier traffic compared to rural areas, and long interstate highways tend to cover both rural and metropolitan areas. Models that are trained on a certain traffic condition may not perform well when used to predict traffic on significantly different traffic

> 统一数据集的意义：
>
> (T-ZS2) A centralized data repository for GNN-based traffic forecasting resources would facilitate objective comparison of the performance of different models and be an invaluable contribution to the field  

理想的基准数据集：城乡结合、工作日周末结合、一天各时段、至少一年

(T-ZS1) For deep neural network models to perform well on real applications, the dataset needs to mimic real data. Therefore, it is important for benchmark datasets to cover enough time frame and locations so that the models can generalize well to any traffic situations. To overcome this challenge, the following criteria are important:

- The data covers both urban and rural areas.
- The data covers both weekdays and weekends.
- The data covers all hours of the day.
- The temporal range is at least one year

> 理想数据：时空覆盖广、增加时间、增加天气和事故
>
> (T-ZS1) A benchmark data that covers a specific area within a specific period, complete with relevant secondary data will greatly benefit the traffic flow field. We recommend the following sequence of actions:
>
> 1) Establish a benchmark dataset that has sufficient spatial and temporal coverage based on the requirements mentioned in the previous challenge.
> 2) Add day of the week and time of day data by concatenating them with the traffic reading data.
> 3) Add geographical-related data, such as weather and accidents data to every traffic data reading. For instance, one reading at a particular time stamp and location will have both the traffic flow, current weather and accident type, if any accident occurs at the location.  
>
> T-ZS29 理想的困难：花销大，事故少(特殊情况)；数据隐私问题，只有探测器数据多
>
> - On the one hand, high-quality datasets are expensive to build, as the data collection process can be time-consuming and costly. As extreme or urgent traffic events such as traffic jams and accidents are rare, collecting comprehensive datasets is more difficult
> - On the other hand, data privacy is also non-negligible if we want to create more comprehensive datasets, since most existing traffic datasets are collected from public transportation modes (e.g., taxis and shared bikes) or road sensors, rather than from private vehicles
>
> 解决数据质量问题，增加图数据：
>
> (T-ZS2) This future direction is proposed for the challenge of heterogeneous data as well as the data quality problem. Another unique feature of this repository could be the inclusion of graph-related data, which have not be provided directly in previous traffic forecasting studies.  
>
> 一些要求：统一数据格式、版本管理、开源代码、排名结果、长于一年。
>
> (T-ZS2) Some criteria for building such data repositories, e.g. a unified data format, tracking of dataset versions, public code and ranked results, and sufficient record lengths (longer than a year ideally) T-ZS15
>
> 在 GNN 里，因为图被编码的格式多样化，所以具有难度
>
> (T-ZS2) Compiling a centralized and standardized data repository is particularly challenging for GNN-based models where natural graphs are collected and stored in a variety of data formats (e.g. Esri Shapefile and OSM XML used by Openstreetmap are used for digital maps in the GIS community) and various different similarity graphs can be constructed from the same traffic data in different models  

在 paperwithcode 有基准对多个任务，有竞赛系列(打不开了)

> (T-ZS2) Some previous attempts in this direction have been made in the machine learning community, e.g. setting benchmarks for several traffic prediction tasks in [Papers With Code](https://paperswithcode.com/task/traffic-prediction), and in data science competitions, e.g., the Traffic4cast [competition series](https://www.iarai.ac.at/traffic4cast/). However, the realization of a centralized data repository remains an open challenge.  

目前最接近的是 PeMS，但只包含道路级数据

> (T-ZS2) The most close one is the PeMS dataset, but it covers the road-level case only and more efforts are still needed, especially for the remaining cases  

##### 数据结合难

(类似：响应方案)

(T-ZS1) Difficulty of incorporating external information with traffic data

(T-ZS2) / Heterogeneous Data

> 结合数据的困难：难以包含外部信息：天气、车祸、事件、星期、时刻、媒体信息
>
> (T-ZS1) one model that uses the Caltrans data covering a long highway will need to match the time stamp, the latitude, and the longitude of each reading in order to find the appropriate weather and accidents data  
>
> (T-ZS2) Traffic prediction problems involve both spatiotemporal data and external factors, e.g., weather and calendar information.  
>
> - 时间容易其他难：理由是需要和具体时空对应
>
>   (T-ZS1) While the inclusion of day of the week and time of the day is relatively simple, data that are bound to a specific geographical coordinate or a geographical area is difficult to incorporate with traffic data. This is because the process requires the coordinates of detection points (in the case of point data) or trajectory points (in the case of trajectory data) to be mapped to the secondary data
>
> 成本变大：
>
> (T-ZS1) added time complexity of aggregating the different data together , which is undesirable, especially in an already time-consuming hybrid deep neural network structure  



##### 不同路段的预测

(T-ZS1) Freeway, arterial and network traffic predictions. 

The authors mentioned several related sub-challenges: the complexity of urban arterial traffic prediction, network-level traffic prediction and the incorporation of network dynamics on traffic prediction  

数据的缺乏，采集数据成本过大，只在 highways 有

轨迹数据可以代替网络预测(network-wide prediction)，覆盖 arterial 和 highways

While the prediction of traffic in urban arterial roads and network-level traffic prediction are dissimilar challenges, the cause is the same: the lack of traffic detectors on urban arterial roads. This is because installing traffic detectors is costly and thus, is often done only on highways. However, the increasing amount of trajectory data has resulted in an alternative solution for network-wide prediction, as car trajectories cover both arterial and highways alike.  

使用了轨迹数据的论文：T-29, T-1, T-51, T-30, T-37，具体参见上文

动态网络的预测(路网数据)使用图论方法：

The third challenge, incorporation of network dynamics on traffic prediction, is caused by traffic flow readings not inherently containing road network data. Therefore, this operation has to be done manually through data modeling. The most popular method to capture network data is to use graph-based methods  

使用了图论的论文：T-4 T-28 T-40 T-39

忽略了 T-ZS1 对 CNN, RNN 获取时空依赖这一段的描述，忽略了对 GNN 一段的描述

T-ZS29 非热点地区和时段等

The third challenge is the diverse and complicated graph structures that exist in the real-world traffic infrastructure. Most surveyed studies consider only dense graphs, e.g., in downtown areas or on closely connected highways, when traffic activities are active. However, the complete traffic graph of a city may be sparse, with some nodes having no or few connections to other nodes. This real-world condition has received insufficient attention in the surveyed studies. Another limitation of the surveyed studies is that the graphs considered are relatively small, e.g., less than 1,000 nodes. For example, the most popular PeMS datasets are a collection of subsets from a large dataset collected from more than 40,000 individual detectors spread over a wider geographic area, since the size of the original dataset exceeds the computing abilities for some research groups.

##### 数据过少

时空跨度，样本量少，导致跟真实有偏差：但增加数据成本大，难以采集

(T-ZS2) First, there is significant bias introduced by the small amount of data considered in the existing GNN-based studies which, in most cases, spans less than one year. The proposed solutions are therefore not necessarily applicable to different time periods or different places. If longer traffic data are to be used in GNNs, the corresponding change of the underlying traffic infrastructures should be recorded and updated, which increases both the expense and difficulty of the associated data collection process in practice.  

GNN 计算规模小，难以处理真实世界量级

(T-ZS2) A second challenge is the computation scalability of GNNs. To avoid the huge computation requirements of the large-scale real-world traffic network graphs, only a subset of the nodes and edges are typically considered. For example, most studies only use a subset of the PeMS dataset when considering the road traffic flow or speed problems. Their results can therefore only be applied to the selected subsets  

解决办法：图分块，并行计算，但提升很有限

(T-ZS2) Graph partitioning and parallel computing infrastructures have been proposed for solving this problem. The traffic speed and flow of the entire PeMS dataset with 11,160 traffic sensor locations are predicted simultaneously in [T-108](https://journals.sagepub.com/doi/abs/10.1177/0361198120930010), using a graph-partitioning method that decomposes a large highway network into smaller networks and trains a single DCRNN model on a cluster with graphics processing units (GPUs). However, increased modeling power can only improve the state-of-the-art results with narrow performance margins, compared to statistical and machine learning models with less complex structures and computational requirements  

T-ZS29 数据过少，过拟合

developing new datasets is still beneficial for the following two reasons. The first reason is the risk of overfitting of deep learning models on existing datasets, especially those that are relatively small compared to datasets in other domains, such as large collections of images and natural language corpora.

解决办法：T-ZS29 提到了数据生成，如数据驱动的 GAN 和模型驱动的

> The first research opportunity is the introduction of traffic simulation tools for creating unseen complex situations as training data. Two specific approaches, model-driven and data-driven approaches, can be further investigated. Model-driven approaches are based on macroscopic or microscopic traffic simulators, where macroscopic tools focus on the high-level deterministic relationships of flow, speed, and the density of traffic flows, while microscopic tools focus on individual details. On the other hand, data-driven methods do not rely on traffic domain knowledge but create more data samples from existing methods, e.g., generative adversarial network (GAN)-based studies. Regarding the black-box nature of neural networks, the use of physics-informed neural network approaches is gaining popularity in research. These approaches combine both modeldriven and data-driven methods and have been successfully applied in the transportation domain

##### 数据质量

数据缺失、数据稀疏、数据噪音

(T-ZS2) Data quality concerns present an additional challenge with problems such as missing data, sparse data and noise potentially compromising forecasting results.   

相邻的点不一定是最有影响的

(T-ZS2) geographically close nodes may not be the most influential, both for CNN-based and GNN-based approaches.  

数据可能是过时的或不准确的：真实情况的动态性，故静态图不足够解决

(T-ZS2) the underlying graph information may not be correct or up to date. For example, the road topology data of OpenStreetMap, an online map services, are collected in a crowd-sourced approach, which may be inaccurate or lagged behind the real road network. The spatial dependency relationship extracted by GNNs with these inaccurate data may decrease the forecasting accuracy  

数据过时：偏移

T-ZS29 The second reason is that models trained using datasets collected many years ago may suffer from data drift as traffic facilities change. The data-shift problem means that the traffic patterns in the historical training data could be totally different from those in the newly collected test data, and the performance of trained deep learning models can degrade significantly in unseen cases.

(T-ZS2) A challenge is presented by changes in the transportation networks and infrastructure, which are essential to build the graphs in GNNs. The realworld network graphs change when road segments or bus lines are added or removed. Points-of-interest in a city also change when new facilities are built. Static graph formulations are not enough for handling these situations. 
Some efforts have been made to solve this problem with promising results  

- 动态拉普拉斯矩阵评估器 [T-109](https://ojs.aaai.org/index.php/AAAI/article/view/3877)

  a dynamic Laplacian matrix estimator is proposed to find the change of Laplacian matrix, according to changes in spatial dependencies hidden in the traffic data  

- 数据自适应图生成器 DAGG [T-110](https://proceedings.neurips.cc/paper/2020/hash/ce1aad92b939420fc17005e5461e6f48-Abstract.html?ref=https://githubhelp.com)

  a Data Adaptive Graph Generation (DAGG) module is proposed to infer the inter-dependencies between different traffic series automatically, without using pre-defined graphs based on spatial connections 

> 多数模型只考虑处理过的高质量数据集
>
> (T-ZS2) Most of the surveyed models are only evaluated with processed highquality datasets  
>
> 一些模型考虑了数据质量问题：
>
> (T-ZS2) A few studies do, however, take data quality related problems into consideration, e.g.,   
>
> - [T-99](https://dl.acm.org/doi/abs/10.1145/3397536.3422257) using the Kalman filter to deal with the sensor data bias and noise 
> - [T-100](https://ieeexplore.ieee.org/abstract/document/9005965) infilling missing data with moving average filters  
> - T-99 [T-101](https://ieeexplore.ieee.org/abstract/document/9201971) linear interpolation 
>
> 且 GNN 中可能缺失数据更明显：GCN 可以填充缺失数据间隙，OD 问题
>
> (T-ZS2) Missing data problem could be more common in GNNs, with the potential missing phenomena happening with historical traffic data or underlying graph information, e.g., GCNs are proposed to fill data gaps in missing OD flow problems [T-102](https://ieeexplore.ieee.org/abstract/document/9130943)

交通异常(如拥堵)，影响显著，社会事件和节假日也是，但数据太少难以训练

> (T-ZS2) Traffic anomalies (e.g., congestion) are an important external factor that may affect prediction accuracy and it has been proven that under congested traffic conditions a deep neural network may not perform as well as under normal traffic conditions [T-103](https://ieeexplore.ieee.org/abstract/document/9092975)
> However, it remains a challenge to collect enough anomaly data to train deep learning models (including GNNs) in both normal and anomalous situations. The same concern applies for social events, public holidays, etc  
>
> 还有数据的隐私权利应该得到保证，参见论文
>
> However, it remains a challenge to collect enough anomaly data to train deep learning models (including GNNs) in both normal and anomalous situations. The same concern applies for social events, public holidays, etc  

##### 冷启动

没看懂，感觉是说要开始收集的起步代价大

T-ZS29 The second challenge is the cold-start problem when initializing GNNs for traffic prediction. Deep learning models, including GNNs, usually require a large quantity of training data to efficiently train the model and obtain satisfactory predictions. However, data collection in the traffic field is often time-consuming and labor-intensive, for example, by installing loop detectors for traffic flow and speed information collection. The cold-start problem arises when the developed GNN models are to be used in a new area or station, especially for a growing urban network

解决：T-ZS29 机会2 迁移学习

#### 在线学习

(T-ZS1) Online learning.

在线学习。持续更新应对 concept drift 的存在。现状：没有研究探索在线学习：但训练开销大，模型复杂难以更新。需要考虑更新频率和数据数目、更新所用时间。

> Concept Drift（概念漂移）指的是数据分布或数据生成过程发生变化的现象。训练与真实不一致就会概念漂移

In this setting where new data is incrementally added, traffic trends will shift over time. This is applicable even for the same traffic detector site. This idea is called concept drift and it causes the relationship between the input and output data to change over time, rendering models that are trained on past data to degrade in performance on present and future data  

> One way to mitigate this problem is to incrementally update the prediction model with new data in real-time, in a process often called online learning. However, to the best of our knowledge, there is no work that explores online learning in the traffic prediction domain. This can be attributed to the time complexity of training hybrid deep neural network model and the lack of attention to the concept drift problem. Online learning is a promising subtopic to explore in the field of traffic prediction as this will ensure that complex deep neural network models are always up-to-date. Experiments that seek to identify the viability of online training will need to take into account the following factors:
>
> - The frequency of which the deep neural network models need to be retrained. Practitioners need to ask the question “How often do we need to update our prediction model to ensure that it is always upto-date?”
>
> - The number of data points required for the update, which is affected by the frequency and has to reflect real life scenario. Practitioners need to ask the questions “How much data can we acquire during a certain period?” and “How long will it take to collect and preprocess the data to fit it into the prediction models?”  
>
> - The time required for the model to be re-trained using the specified number of data points and whether or not it is suitable for real life scenario. Practitioners need to ask the question “With the available amount of data, will the training of the model be fast enough such that daily operations are not hindered?”  

T-ZS29

Although deep learning models, including GNNs, can be trained offline, the online inference process still requires considerable computing and storage resources when the considered traffic graph is very large. When the considered graph becomes larger, the communication overhead also increases

#### 其他领域任务

(T-ZS1) Exploring other traffic prediction tasks

其他领域问题。子问题/其他问题可能会启发该问题。如交通拥挤分析。

Currently, the Intelligent Transportation Systems (ITS) field greatly focuses on traffic flow prediction, neglecting the other traffic prediction tasks. Exploring these subproblems may bring new insights that are able to help the main traffic prediction task. As we mentioned before, deep neural network models are black-box models. Models that are trained on the traffic flow prediction may not be able to explain the intricacies of traffic patterns. Additionally, each of the subproblems is interesting by itself as its results can be directly used by drivers and traffic management bureau alike to make educated decisions. One example of these prediction tasks is traffic congestion analysis. Knowing how traffic congestion moves throughout the network can assist in the traffic prediction task  

> #### 多任务
>
> 流量和速度可以一定程度一起用，但其他领域不太行
>
> (T-ZS2) or the public service operation of ITSs, a multi-task framework is necessary to incorporate all the traffic information and predict the demand of multiple transportation modes simultaneously. For example, knowledge adaption is proposed to adapt the relevant knowledge from an information-intensive source to information-sparse sources for demand prediction [T-104](https://dl.acm.org/doi/abs/10.1145/3340531.3411965) 
> Related challenges lie in data format incompatibilities as well as the inherent differences in spatial or temporal patterns. While some of the surveyed models can be used for multiple tasks, e.g., traffic flow and traffic speed prediction on the same road segment, most can only be trained for a single task at one time  
>
> 有几个多任务完成了的论文例子
>
> (T-ZS2) Multi-task forecasting is a bigger challenge in graph-based modeling because different tasks may use different graph structures, e.g., road-level and stationlevel problems use different graphs and thus are difficult to be solved with a single GNN model. Some efforts that have been made in GNN-based models for multi-task prediction include taxi departure flow and arrival flow [T-105](https://www.mdpi.com/1424-8220/20/13/3776), region-flow and transition-flow [T-106](https://link.springer.com/chapter/10.1007/978-3-030-59410-7_30), crowd flows, and OD of the flows [T-107](https://dl.acm.org/doi/abs/10.1145/3340531.3412054). However, most of the existing attempts are based on the same graph with multiple outputs generated by feed forward layers. Nonetheless, GNN-based multi-task prediction for different types of traffic forecasting problems is a research direction requiring significant further development, especially those requiring multiple graph structures  

#### 缺乏最新试验评估

(T-ZS1) Lack of up-to-date experimental evaluation  

> there is a lack of up-to-date and comprehensive experimental evaluation, making it difficult to assess how promising these specific ideas are  

缺乏最新试验评估 (最大的问题)。库简化了实现，每个论文实现了不同的想法，但没有综合的整理。缺乏基准数据集，代码有效性(可复现性)。



> T-ZS1 Experimental evaluation in traffic flow prediction is complex due to two factors. The first is the lack of benchmark dataset, a problem that we have discussed above. The second is the lack of code availability. One might attempt to recreate the model from the author’s description. However, while the deep neural network aspect can be recreated relatively easy, novel components, such as graph diffusion, are difficult to build in a way that is faithful to the source material  
>
> This lack of experimental evaluation is perhaps the largest challenge that the traffic flow prediction community faces. Addressing this problem will enable practitioners to easily identify the effectiveness of new ideas in improving prediction performance, model efficiency, and the overall applicability of deep neural network models in real-time traffic prediction applications  
>
> 意义：
>
> We believe that the future of the traffic flow prediction field lies on determining a more standardized approach that ensures that the significance of every novel idea can be identified  
>
> 建议做法：开源
>
> to provide more transparency in this research field. Implementation details and publicly accessible codes will be necessary  

T-ZS1 基准实验评估需要考虑：新想法的影响、CNN/RNN 类型的影响、应用性和重训练时间、外部数据如天气的作用(消融实验)

> A benchmark experimental evaluation needs to take into account the following insights:  
>
> - The impact of each model’s novel ideas to the prediction power, particularly for models that use a similar network structure.
> - The impact of using a certain neural network type such as CNN and RNN.
> - The viability in real life applications with respect to the retraining time. That is, online learning using a realistically sized batch of data, e.g. data from one week.
> - The impact of using external information such as weather and accidents data. This can be observed by performing an ablation test on models that utilize these external information  

#### 其他技术

T-ZS2 ; 参考具体技术，包含迁移学习、元学习、数据增强、GAN、Auto ML、贝叶斯网络。

T-ZS29

- he second research opportunity is to introduce new learning schemes to traffic forecasting problems, e.g., transfer learning, meta learning, and federated learning.

#### 应用新技术

(T-ZS1) Applying Emerging Techniques   

## 写作技巧

### 组织结构

#### T-ZS1

1. INTRODUCTION

   一段交通拥挤现状

   一段交通预测的应用、定义、特点

   一长段技术简述和论文目的

   一无序列表表示论文要点

   一段论文行文结构

   三段比较其他综述（一段一篇综述）

   一段描述实现框架（PyTorch 等）

2. BACKGROUND  

   一段概括本章内容

   三段交通预测定义（公式隔开了段落）

   三段介绍 ARIMA（初始，变式，优缺）

   一段介绍 ML 及其与统计模型相比的优缺

   一段介绍 NN 及其与 ML 相比的优缺

   一段介绍 NN, ML 在交通的应用

   三段介绍 DNN（兴起条件，分类简述，优缺）

   一段总结

3. DEEP NEURAL NETWORK  

   一段概括本章内容

   1. Convolutional Neural Network

      一段简述

      一段组成定义，含图

      一段介绍应用建模思路

      一段介绍优点特点

      一段介绍应用方法

   2. Recurrent Neural Network and Long Short-Term Memory

      一段 RNN 简述

      一段 RNN 组成定义，含图

      一段缺点和 LSTM 引入

      一段 LSTM 组成定义，含图

      一段 RNN 优缺和其他领域应用

      一段应用

   3. Feedforward Neural Network

      一段定义

      一段优缺

      一段应用

   一段总结本章内容

4. DEEP NEURAL NETWORK FOR TRAFFIC FLOW PREDICTION

   一段研究范围和本章介绍 

   1. Traffic Flow Prediction – Data

      两个小表格分别列表表示主数据、辅助数据集的占比、典例、类型

      两个大表格按数据分类了论文，表头有：引用、作者、年份、主数据类型、主数据集、时间范围、数据粒度、辅数据集、输入序列长度、预测视野

      (表格里的论文我抽查了几篇，发现都在正文有出现过)

      一段介绍这两大表格及其举例和特例介绍

      一段介绍主数据集及其代表（表项一）

      一段介绍北京数据集（表项二）

      一段介绍轨迹数据集（表项三）和对小表格一介绍

      一段介绍辅助数据集和对小表格二介绍

      一段介绍辅助的低使用率

      一段介绍时间辅助数据

      两段介绍数据时间范围及其两个大表格例子

      一段介绍数据集多样性的意义

      四段介绍数据粒度

      四段介绍输入序列长度和预测视野

   2. Traffic Flow Prediction – Model

      三段介绍大表格及其举例

      大表格：按模型类型表头再分类，其他表头为引用、年份、问题类型、是否使用时/空、主数据类型、模型子类

      1. RNN

         两段总结 LSTM 常见性及其原因和举例

         一段介绍基础 RNN 的几篇论文，按历史顺序一篇一句话

         一段介绍混合模型的使用简介和原因

         一无序列表表示三种使用方法

         三段分别介绍三种方法的论文，每篇论文一句话，疑似时间顺序

         一段介绍 encoder-decoder RNN，定义和一句话列举所用论文及其效果(SOTA)

         一段介绍其他 RNN 用法，一句话一篇论文

         一段介绍 RNN 与多粒度方法及一句话列举多个论文

      2. CNN

         一段简述

         一段介绍 CNN 与两种数据类型及其例外论文

         两段介绍点数据如何用到 CNN，两个无序列表介绍优缺点

         一段介绍两种点数据应用方法，分别介绍和列举相关论文

         一段介绍轨迹数据应用，两个无序列表介绍优缺点

         一段介绍相关论文并总结

         一段介绍其他用法如获取空间数据及其论文例子

      3. Feedforward Neural Networks  

         一段介绍三种用法

         三段分别介绍三种用法，前两段先介绍后枚举，第三段后一句话介绍

      4. Other Deep Neural Networks  

         一段介绍 SAE, DBN 并枚举论文和占比

         一段介绍兴起时间和原因推断和衰落原因

      5. Other Techniques

         一段承上启下

         一段介绍 GNN 及其优势

         一段介绍 GNN 的各论文，一篇论文一两句话

   3. Discussion  

      一段简介

      1. Complex Versus Simple Models

         一段介绍现状

         一段比较优缺并提供论文例子

      2. Benchmark Model Structures

         一段介绍 encoder-decoder RNN 特点

         一段介绍上述+GNN 的结合，枚举论文例子

         一段介绍注意力机制和枚举论文

         一段总结

5. CHALLENGES AND FUTURE DIRECTIONS  

   一段简介和表明继承

   1. Existing Challenges

      第一个挑战一段介绍，两段论文举例介绍，一段总结

      第二个挑战一段介绍，一段举例和枚举论文

      第三个挑战一段介绍和枚举论文

      第四个挑战一段介绍并引用前文

      第五个挑战一段介绍和一段论文例子介绍再接一段介绍

   2. Future Challenges

      一段简介

      第一个挑战三段介绍，现状和论文举例，两段建议和无需列表描述

      第二个挑战一段介绍，一个有序列表建议

      第三个挑战一段介绍，一段建议，两段无序列表具体陈述

      第四个挑战引用前文和一段介绍

      第五个挑战一段介绍

      第六个挑战一段介绍，两段原因，一个无序列表建议

      第七个挑战一段总介绍，两段分陈述和论文例子，一段总结

6. CONCLUSION

   一段论文内容总结

   一段建议

   一段展望

ABSTRACT, ACKNOWLEDGMENTS, REFERNCES 略

#### T-ZS2

1. Introduction

   一段交通系统的介绍，交通预测的定义

   一段交通预测的特点和技术历史

   一段 RNN 的介绍

   一段综述枚举，本文内容介绍

   一段本文受众介绍

   一个有序列表描述文章内容

   一段话描述论文章节

2. Related Research Surveys

   一段简介

   四段综述介绍（交通大类、交通预测、DL 相关、其他）

   一段本文优势内容

3. Problems

   一段简介

   一段定义数据粒度分类的介绍

   一段话介绍所研究论文，提供表格按问题细分类别

   一段描述问题的时空特征及其对应模型

   一段描述 CNN 等思路解决空间特征的办法和缺点

   一段描述 GNN 解决空间特征的优势

   1. Traffic Flow

      一段介绍定义和意义

      一段描述按数据粒度的三种分类

      三段分别描述三种分类下的细分类和定义

      一段介绍按有向无向图的分类

      一段描述数据来源和特点

   2. Traffic Speed

      一段介绍定义和意义

      一段介绍按数据粒度的两种分类及其细分

      一段介绍两类的区别

   3. Traffic Demand

      一段意义

      一段定义和细分

   4. Other Problems

      一段引出下文

      一段介绍交通异常

      一小段介绍停车

      三段介绍车辆排放、铁路延迟、道路占用，分别指出论文

4. Graphs and Graph Neural Networks

   一段介绍本章内容和其他更广的参考论文

   1. Traffic Graphs

      1. Graph Construction

         三段介绍图的定义、点权假设、时间

         两段定义段交通图、基于图的交通预测，中间一段过渡

         一段介绍单步多步预测，提供图

         一段按数据真实性分类图

         三段按数据粒度分类图，提供图和指出相关论文

         一段介绍按图的类型、节点和边的意义分类的论文的竖表格

      2. Adjacency Matrix Construction

         一段介绍分类法的出处论文和分类

         四段介绍四种类型的矩阵，子类，两段介绍了相关论文的建模例子

         一段介绍按邻接矩阵的类型、元素定义分类的论文的竖表格

   2. Graph Neural Networks

      一段对比 CNN，分类 GNN 为四类

      一段提供 GCN 相关的数学定义，提供符号表格

      一段介绍基于频谱的 GNNs 的发展和相关论文

      两段介绍 GCN 的相关数学定义，有公式断开

      一段介绍基于空间的的 GNNs 的发展和相关论文

      五段介绍这些经典方法的数学定义和思想，提供图

      一段介绍按时间是 RNN 还是 CNN 的分类大枚举论文代替表格

      一段介绍给予注意力和 FNN 和其他的分类大枚举论文

      一段介绍 RNN, CNN 的对比优缺和时空联系解决的相关论文

      一段对卷积 GNN 进行再分类，有图介绍发展时间

      一个有序列表介绍了设计模型的步骤

      三段分别介绍了三种经典模型的数学定义、相关论文

5. Open Data and Source Codes

   一段介绍本章内容

   1. Open data

      一段介绍分类

      十段分别介绍不同类型的数据，有一些有举例论文

      总结数据的应用，提供表格列举了使用不同数据集的各论文

      1. Traffic Sensor Data

         一段启下

         三段分别介绍不同数据集，其中一段有无序列表

      2. Taxi Data

         一段启下

         六段分别介绍不同数据集

      3. Ride-hailing Data

         一段启下

         两段分别介绍不同数据集，其中一段有无序列表

      4. Bike Data

         一段启下

         三段分别介绍不同数据集

      5. Subway Data

         一段启下

         两段分别介绍不同数据集

   2. Open Source Codes

      一段介绍 python 框架

      一段提供多个表格列举使用这些框架的论文，年份，及其研究问题，按研究问题大类划分不同的表格

   3. State-of-the-art Performance

      一段陈述难以选出最优的理由

      一段给出评价指标的定义，一个表格给出不同数据集的经典和最高论文的不同指标得分

      一段总结

6. Challenges and Future Directions

   一段简介

   1. Challenges

      1. Heterogeneous Data

         四段，提供了相关论文

      2. Multi-task Performance  

         两段，提供了相关论文

      3. Practical Implementation

         四段，提供了相关论文

      4. Model Interpretation

         两段，提供了相关论文

   2. Future Directions

      1. Centralized Data Repository

         四段，提供了相关论文

      2. Traffic Graph Design

         一段，提供了相关论文

      3. Combination with Other Techniques

         一段总述

         六段讲述了六种技术，提供了相关论文

      4. Applications in Real-World ITS Systems

         一段

7. Conclusion

   一段概括了文章内容

Abstract, References 略

#### 建议

论文分类依据：

- 时间特征处理技术
- 空间特征处理技术
- 时空依赖处理技术
- 数据预处理的技术
- 其它补充信息技术
- 缩写年份基本信息
- 是否使用 encoder-decoder

论文数据依据：

- 所用数据集
- 所用额外数据集
- [训练参数 (输入长度等)]

数据表格依据：

- 问题类型 (速度/流量等)
- 时间跨度
- 开山论文
- 地理位置
- 时间间隔
- 节点数量
- 时间数量

每个挑战可以对应一个解决办法，参考 T-ZS29

### LaTeX

#### 概述

根据肉眼观察，在 overleaf template 直接搜索 ieee 能得到期刊和论文的模板，简单替换第一行代码可以直接转换，有简略模板和范文。而 acm 的模板有很多个。暂时以 ieee conference 为模板进行写作。其中 [IEEE Conference Template](https://www.overleaf.com/latex/templates/ieee-conference-template/grfzhhncsfqn) 里的 HOWTO.pdf 提供了详细的使用说明文档。提供了 `IEEEtran.cls` 模板文件。

> 在本机，对 bare conference，使用 xe / pdflatex 都可以编译。

#### 例子

[bare conference](https://www.overleaf.com/latex/templates/ieee-bare-demo-template-for-conferences/ypypvwjmvtdf) 的 GPT 翻译本如下：

大部分的内容：提供了几个包的说明，如 ifpdf, cite, graphicx, amsmath, algorithm, array, multicol, hyperref, filecontents, adjustbox, todonotes, amssymb, inputenc, balance

```tex
%% bare_conf.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% 请参阅：
%% http://www.michaelshell.org/
%% 获取最新的联系信息。
%%
%% 这是一个骨架文件，演示了如何使用 IEEEtran.cls
%% （需要 IEEEtran.cls 版本 1.8b 或更高版本）来撰写 IEEE
%% 会议论文。
%%
%% 支持网站：
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% 和
%% http://www.ieee.org/

%%*************************************************************************
%% 法律声明：
%% 此代码按原样提供，不附带任何明示或暗示的保证；
%% 甚至不包含适销性或
%% 特定用途适用性的暗示保证！
%% 用户承担所有风险。
%% 在任何情况下，IEEE 或任何对本代码的贡献者均不对
%% 由于使用或误用此处包含的任何信息而导致的
%% 任何损害或损失负责，包括但不限于偶发性、
%% 后果性或任何其他损害。
%%
%% 所有评论都是其各自作者的观点，并不一定
%% 得到 IEEE 的认可。
%%
%% 本工作根据 LaTeX 项目公共许可证（LPPL）
%% （http://www.latex-project.org/）版本 1.3 进行分发，
%% 可以自由使用、分发和修改。LPPL 的副本，版本 1.3，
%% 包含在所有发布于
%% 2003/12/01 或之后的 LaTeX 分发的基本 LaTeX 文档中。
%% 保留所有贡献声明和致谢。
%% ** 修改后的文件应明确标识为此类文件，包括  **
%% ** 重命名它们并更改作者支持联系信息。 **
%%*************************************************************************

% *** 作者应验证（并在必要时纠正）其 LaTeX 系统  ***
% *** 在信任其 LaTeX 平台进行生产工作之前，使用 testflow 诊断 ***
% *** IEEE 的字体选择和论文大小可能会触发在使用其他类文件时不出现的错误。 ***
% testflow 支持页面位于：
% http://www.michaelshell.org/tex/testflow/

\documentclass[conference]{IEEEtran}
% 一些计算机协会的会议也要求使用 compsoc 模式选项，
% 但其他会议使用标准会议格式。
%
% 如果 IEEEtran.cls 尚未安装到 LaTeX 系统文件中，
% 请手动指定路径，例如：
% \documentclass[conference]{../sty/IEEEtran}

% 一些非常有用的 LaTeX 包包括：
% （取消注释您想加载的包）

% *** 杂项实用程序包 ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek 的 ifpdf.sty 在需要基于输出是 pdf 还是 dvi 的条件编译时非常有用。
% 用法：
% \ifpdf
%   % pdf 代码
% \else
%   % dvi 代码
% \fi
% ifpdf.sty 的最新版本可以从以下网址获得：
% http://www.ctan.org/pkg/ifpdf
% 此外，请注意 IEEEtran.cls V1.7 及更高版本提供了一个内置的
% \ifCLASSINFOpdf 条件，其工作方式相同。
% 在从 latex 切换到 pdflatex 以及反向切换时，编译器可能
% 需要运行两次以清除警告/错误消息。

% *** 引用包 ***
%
%\usepackage{cite}
% cite.sty 由 Donald Arseneau 编写
% IEEEtran V1.6 及更高版本预定义了 cite.sty 包的格式
% \cite{} 输出以符合 IEEE 格式。加载 cite 包将
% 自动对引用编号进行排序并正确地
% “压缩/范围”。例如， [1], [9], [2], [7], [5], [6] 在不使用
% cite.sty 的情况下将变为 [1], [2], [5]--[7], [9] 使用 cite.sty。cite.sty 的
% \cite 将自动添加前导空格（如果需要）。如果您想关闭此功能，
% 请使用 cite.sty 的 noadjust 选项（cite.sty V3.8 及更高版本）。
% cite.sty 已在大多数 LaTeX 系统上安装。确保使用
% 版本 5.0（2009-03-20）及更高版本，如果使用 hyperref.sty。
% 最新版本可以在以下网址获得：
% http://www.ctan.org/pkg/cite
% 文档包含在 cite.sty 文件中。

% *** 图形相关包 ***
%
\ifCLASSINFOpdf % 判断输出是否为 pdf
  % \usepackage[pdftex]{graphicx}
  % 声明您的图形文件的路径
  % \graphicspath{{../pdf/}{../jpeg/}}
  % 及其扩展名，这样您就不必在每个
  % \includegraphics 的实例中指定这些。
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % 或其他类选项（dvipsone, dvipdf，如果不使用 dvips）。graphicx
  % 将默认为在系统 graphics.cfg 中指定的驱动程序，如果未指定
  % 驱动程序。
  % \usepackage[dvips]{graphicx}
  % 声明您的图形文件的路径
  % \graphicspath{{../eps/}}
  % 及其扩展名，这样您就不必在每个
  % \includegraphics 的实例中指定这些。
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx 由 David Carlisle 和 Sebastian Rahtz 编写。它是
% 如果您想要图形、照片等必需的。graphicx.sty 已在大多数 LaTeX 系统上
% 安装。最新版本和文档可以在以下网址获得：
% http://www.ctan.org/pkg/graphicx
% 另一个好的文档来源是 Keith Reckdahl 的《使用导入的图形在
% LaTeX2e 中》，可以在以下网址找到：
% http://www.ctan.org/pkg/epslatex
%
% latex 和 pdflatex 在 dvi 模式下支持
% 封装的后处理 (.eps) 格式的图形。pdflatex 在 pdf 模式下支持
% .pdf、.jpeg、.png 和 .mps（metapost）格式的图形。用户应确保
% 所有非照片图形使用矢量格式 (.eps, .pdf, .mps)，而不是位图格式 (.jpeg, .png)。IEEE 不鼓励使用位图格式，
% 这可能导致线条和字母的“锯齿状”/模糊渲染，以及文件大小的大幅增加。
%
% 您可以在以下网址找到有关 pdfTeX 应用程序的文档：
% http://www.tug.org/applications/pdftex

% *** 数学包 ***
%
%\usepackage{amsmath}
% 这是美国数学学会提供的一个流行包，提供
% 许多用于处理数学的有用和强大的命令。
%
% 请注意，amsmath 包将 \interdisplaylinepenalty 设置为 10000，
% 从而防止多行方程内发生页面中断。使用：
%\interdisplaylinepenalty=2500
% 在加载 amsmath 之后恢复此类页面中断，因为 IEEEtran.cls 通常
% 这样做。amsmath.sty 已在大多数 LaTeX 系统上安装。最新版本
% 和文档可以在以下网址获得：
% http://www.ctan.org/pkg/amsmath

% *** 专用列表包 ***
%
%\usepackage{algorithmic}
% algorithmic.sty 由 Peter Williams 和 Rogerio Brito 编写。
% 此包提供描述算法的算法环境。
% 您可以在文本中或在图形环境中使用算法环境
% 提供浮动算法。请勿使用 algorithm.sty（由同一作者提供）或
% algorithm2e.sty（由 Christophe Fiorio 提供）所提供的算法浮动环境，
% 因为 IEEE 不使用专用的算法浮动类型，提供这些的包将不会提供
% 正确的 IEEE 样式标题。algorithmic.sty 的最新版本和文档可以在：
% http://www.ctan.org/pkg/algorithms
% 另外可能感兴趣的是 Szasz Janos 的相对较新和更可定制的
% algorithmicx.sty 包：
% http://www.ctan.org/pkg/algorithmicx

% *** 对齐包 ***
%
%\usepackage{array}
% Frank Mittelbach 和 David Carlisle 的 array.sty 修补和改进了
% 标准 LaTeX2e array 和 tabular 环境，以提供更好的
% 外观和额外的用户控制。由于默认的 LaTeX2e 表格生成代码在
% 最终结果的质量方面几乎缺失，因此强烈建议所有用户使用
% 一组增强的表格包。

% *** 多列包 ***
%
%\usepackage{multicol}
% 为了在 LaTeX 中使用多个列的支持。
%
% 将以下两行替换为上面的行，以允许
% 关键字和其他背景文本在多列中正确换行。
% \usepackage{multicol}
% \usepackage{multicol}
% \setlength{\columnsep}{4pt}
% 使用此命令可以为每个列之间的间距设置
% 自定义长度，您可以根据需要选择更大的值。

% *** 超链接包 ***
%
\usepackage{hyperref}
% 如果你要使用 hyperref，你需要在\begin{document}之前加载它。

% *** 提供和引用源文件的标头包 ***
%
%\usepackage{filecontents}
% 由 Donald Arseneau 编写，filecontents.sty 提供了一个简单的
% 方法来在 LaTeX 中嵌入外部文件的内容，以便在处理文档时
% 可以一次性运行 LaTeX 而不需要手动交互。
% 文件的创建将只发生在文档首次编译时。

% *** 自定义参数的包 ***
%
\usepackage{adjustbox}
% 通过使用此包，用户可以在不同的环境中为图像设置自定义边界框大小。

% *** 自定义注释的包 ***
%
%\usepackage{todonotes}
% 提供简单的注释和注释功能。

% *** 自定义符号和缩写的包 ***
%
\usepackage{amssymb}
% 由美国数学学会提供，amssymb.sty 提供了额外的数学符号。

% *** 编码包 ***
%
\usepackage[utf8]{inputenc}
% 使用此命令来处理任何 utf-8 文本。

% *** 页面控制包 ***
%
\usepackage{balance}
% 由 Mike Shell 编写，balance.sty 在双栏文档中用于均匀分配
% 页面上的列。

% 1. 论文的完整标题（应在单独的行中写出）
\title{Sample Conference Paper Title: A Comprehensive Guide}

% 2. 作者名单和所属机构
\author{
\IEEEauthorblockN{Author One}
\IEEEauthorblockA{Department of Computer Science\\
University A\\
City, Country\\
Email: author.one@example.com}
\and
\IEEEauthorblockN{Author Two}
\IEEEauthorblockA{Department of Computer Science\\
University B\\
City, Country\\
Email: author.two@example.com}
}

% 3. 论文开始
\begin{document}

% 4. 制作标题
\maketitle

% 5. 在标题后的段落中放置摘要
\begin{abstract}
This paper provides a concise overview of the conference paper format according to the IEEE guidelines. It discusses the necessary sections, formatting requirements, and submission guidelines, ensuring authors adhere to the best practices for scholarly communication.
\end{abstract}

% 6. 关键词
\begin{IEEEkeywords}
IEEE, conference, paper, guidelines, formatting
\end{IEEEkeywords}

% 7. 主体部分的开始
\section{Introduction}
The introduction is a critical part of any conference paper, providing the context and relevance of the research. This section should introduce the problem area, highlight gaps in existing research, and state the objectives and contributions of the paper.

\section{Related Work}
In this section, authors should summarize relevant literature, outlining previous research findings and identifying how their work fits into the existing body of knowledge.

\section{Methodology}
A clear and detailed explanation of the methods used in the research is crucial. This section should describe the research design, data collection techniques, and analysis procedures.

\section{Results}
Present the findings of the research in this section. Use tables and figures where necessary to illustrate results effectively.

\section{Discussion}
Discuss the implications of the findings, how they contribute to the field, and any limitations of the research. This section may also suggest areas for future research.

\section{Conclusion}
Summarize the main points of the paper and restate the importance of the findings. This section should provide a clear closure to the research presented.

% 8. 引用部分
\begin{thebibliography}{1}
\bibitem{IEEEexample}
IEEE, "IEEE Citation Reference," IEEE, 2017. [Online]. Available: https://ieeeauthorcenter.ieee.org/wp-content/uploads/IEEE-Reference-Guide.pdf
\end{thebibliography}

\end{document}

```



### 通用用语

根据阅读归纳：

论文作者人名：一个人就人名(姓)，两个人就 and，三个人就 et al.

中文也名在前，且名两个字只有第一个字大写首字母

[i.e. e.g. et al. 的读法和全称](https://www.bilibili.com/video/BV14W421d74d/)

续表叫

- continued (T-ZS35)
- Contd. (T-ZS1)
- continued from previous page (T-ZS2)

w/o (消融实验里) with/without

实验数据：Bold values denote the best results

### 通用排版

#### 标题

IEEE Conference 说明：

Titles are generally capitalized except for words such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to and up, which are usually not capitalized unless they are the first or last word of the title. Linebreaks \\\\ can be used within to get better formatting as desired. Do not put math or special symbols in the title.

#### 摘要

IEEE Conference 说明：

As a general rule, do not put math, special symbols or citations in the abstract

#### 图片

IEEE Conference 标准：

Note that \label must occur AFTER (or within) \caption.

For figures, \caption should occur after the \includegraphics.

Note that the IEEE typically puts floats only at the top, even when this results in a large percentage of a column being occupied by floats.

#### 表格

Note that, for IEEE style tables, the \caption command should come BEFORE the table and, given that table captions serve much like titles

### 专用术语

#### 关键词

(T-ZS1) Deep neural network, deep learning, traffic flow prediction, traffic speed prediction, road network  

(T-ZS2) Traffic Forecasting, Graph Neural Networks, Graph Convolution Network, Graph Attention Network, Deep Learning  
