> 诸如 T-ZS1 的标号参见 Zotero 目录(如无请联系我获取)

## 背景介绍

### 背景

#### 交通系统

意义：

- (T-ZS2) Transportation systems are among the most important infrastructure in modern cities, supporting the daily commuting and traveling of millions of people.  

组成：

- (T-ZS2)  With rapid urbanization and population growth, transportation systems have become more complex. Modern transportation systems encompass road vehicles, rail transport, and various shared travel modes that have emerged in recent years, including online ride-hailing, bike-sharing, and e-scooter sharing.  

#### 交通拥堵

- 面临的主要问题

  (T-ZS1) Traffic congestion is a major problem faced by metropolitan cities -> Most congestion mitigation measures are costly, difficult to implement, or both.   
  
  > (T-ZS2) Expanding cities face many transportation-related problems, including air pollution and traffic congestion
  
- 指示：交通速度
  
  (T-ZS2) Traffic speed is another important indicator of traffic state with potential applications in ITS systems, The speed value on the urban road can reflect the crowdedness level of road traffic.  
  
- 其解决：交通预测
  
  (T-ZS1) Educated traffic decision made through accurate prediction is a far cheaper and easier to implement alternative for reducing road congestion  
  
  > (T-ZS1) Traffic flow prediction is one of the easiest and cheapest measures to address traffic congestion  
  
  > (T-ZS2) Traffic forecasting is important for the success of intelligent transportation systems  
  >
  > (T-ZS2) Early intervention based on traffic forecasting is seen as the key to improving the efficiency of a transportation system and to alleviate transportation-related problems  

#### 应用前景

##### 交通流量

交通流量应用面：拥挤控制、信号灯控制等

(T-ZS2 描述 T-ZS10 说的) An accurate traffic flow prediction is beneficial for a variety of applications, e.g., traffic congestion control, traffic light control, vehicular cloud

如，交通灯可以减少车辆停留时间，优化交通流，减少交通拥挤和排放

(T-ZS2) For example, traffic light control can reduce vehicle staying time at the road intersections, optimizing the traffic flow, and reducing traffic congestion and vehicle emission.  

##### 交通速度

交通速度：预测拥堵(Google 为例)，路径规划，到达时间评估

(T-ZS2) For example, Google Maps visualizes this crowdedness level from crowd-sourcing data collected from individual mobile devices and in-vehicle sensors. A better traffic speed prediction is also useful for route navigation and estimation of-arrival applications  

> (T-ZS2) **Travel time prediction** is useful for passengers to plan their commuting time and for drivers to select fast routes, respectively. **Traffic congestion** is one of the most important and urgent transportation problems in cities, which brings significant time loss, air pollution and energy waste. The congestion prediction results can be used to control the road conditions and optimize vehicle flow, e.g., with traffic signal control  

##### 交通需求

(T-ZS2) 服务商资源分配，用户合理选择

Traffic demand prediction is a key component for taxi and ride-hailing services to be successful, which benefits these service providers to allocate limited available transportation resources to those urban areas with a higher demand.

For passengers, traffic demand prediction encourages the consideration of various transportation forms, e.g., taking the public transit service when taxi or ride-hailing services are in short supply

(T-ZS2) 现状例子及其重要性

For example, on an online ride-hailing platform, the ride requests sent by passengers represent the demand, whereas only a subset of these requests may be served depending on the supply of drivers and vehicles, especially during rush hours. Accurate prediction of travel demand is a key element of vehicle scheduling systems (e.g. online ride-hailing or taxi dispatch platforms)

##### 交通异常

交通延迟的主要原因，可以助于决策制定

(T-ZS2) the target is to predict the traffic accident number reported to the police system. Traffic anomaly is the major cause of traffic delay and a timely detection and prediction would help the administrators to identify the situation and turn the traffic situation back to normal as quickly as possible    

##### 交通排放

拥堵会增加排放

(T-ZS2) Urban vehicle emission is a major source of air pollutants and its amount is affected by different traffic states, e.g., the excess emission would be created in traffic congestion situations.  

#### 真实数据

- 交通拥挤的代价

  (T-ZS1) In 2015, it is estimated that the avoidable cost of traffic congestion for Australian capital cities is approximately \$16.5 billion, up from the 2010 estimate of \$12.8 billion. Furthermore, this value is estimated to increase to about $30 billion by 2030

  > [参考 Cosgove D. Traffic and congestion cost trends for Australian capital cities[J]. Canberra: Department of Infrastructure and Regional Development, Bureau of Infrastructure, Transport and Regional Economics, 2015.](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Cosgove%2C+Traffic+and+congestion+cost+trends+for+Australian+capital+cities&btnG=#d=gs_cit&t=1721488944765&u=%2Fscholar%3Fq%3Dinfo%3ACPeX2qr_RW8J%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Dzh-CN)

- 交通监管政策

  (T-ZS1) Singapore implemented regulations on the number of vehicles on roads -> which is infeasible for countries with poor public transportation systems

  > [参考 “Singapore to freeze car numbers,” https://www.bbc.
  > com/news/business-41730778, accessed: 20 November
  > 2018](https://www.bbc.
  > com/news/business-41730778)

- 修路成本

  (T-ZS1) the estimated per mile cost of a standard one lane road in New Jersey, USA is $220,490 -> Constructing new roads to ease congestion is also difficult due to the extremely high cost  
  
  > [参考 J. Carnegie and A. M. Voorhees, “The cost of roadway
  > construction, operations and maintenance in new jersey,” pp. 557–566, 2016.  ](https://trid.trb.org/View/1408290)

#### 前置条件

- 传感器的普及 -> 大数据获取

  (T-ZS1) With the advancements and widespread adoption of traffic sensors, access to large traffic databases is now available.  -> This has led to the development of traffic prediction as a research field. 
  
  > With the widespread installation of traffic loop detectors, traffic data will continuously grow 
  
  数据源
  
  (T-ZS2) In the development and operation of smart cities and intelligent transportation systems (ITSs), traffic states are detected by sensors (e.g. loop detectors) installed on roads, subway and bus system transaction records, traffic surveillance videos, and even smartphone GPS (Global Positioning System) data collected in a crowd-sourced fashion.  
  
- 库 

  (T-ZS1) Due to the availability of deep neural network libraries such as Keras, PyTorch , and TensorFlow, development of complex neural network models has become much easier  
  
  > The introduction of deep neural network libraries such as Keras, PyTorch and TensorFlow has simplified the implementation of complex hybrid deep neural network models. As we have observed, this has resulted in numerous unique hybrid structures, each focusing on specific ideas to improve prediction performance  

### 问题定义

> #### 交通预测

#### 概念

##### 描述

描述：

(T-ZS1)  Future traffic prediction involves creating a prediction model from historical traffic data to predict the short-term future traffic state ranging from 5 to 60 minutes into the future

> (T-ZS2) 相关数据类型：Traffic forecasting is typically based on consideration of historical traffic state data, together with the external factors which affect traffic states, e.g. weather and holidays  

##### 特点

特点：

> 交通预测与其他时序分析的不同在于：
>
> - 一个地点可能影响另一个地点
> - 空间依赖
> - 存在全局外部因素如天气、节假日、交通事故等
> - 数据高维

(T-ZS1)  Traffic prediction is different from conventional time-series analysis in that traffic prediction is subject to **spatial** as well as many **other** external factors.  the prediction of traffic at one site depends on the traffic at other sites and all of the sites are affected by external factors such as weather and holidays.  

> (T-ZS2) The traffic forecasting problem is more challenging than other time series forecasting problems because it involves **large  data** volumes with high dimensionality, as well as **multiple** dynamics including emergency situations, e.g. traffic accidents 
>
> (T-ZS2) The traffic state in a specific location has both **spatial** dependency, which may not be affected only by nearby areas, and **temporal** dependency, which may be seasonal.  
>
> (T-ZS2) Generally speaking, traffic forecasting problems are challenging, not only for the complex **temporal** dependency, but only for the complex **spatial** dependency.  

##### 时空特点

相互影响

(T-ZS2 说 [T-81](https://ojs.aaai.org/index.php/AAAI/article/view/3881) 说的) As for the traffic problems, the spatial and temporal dependencies are closely intertwined in reality. For example, it is argued that the historical observations in different locations at different times have varying impacts on central region in the future  

##### 严格定义

定义：使用可学习的函数，使用历史交通数据输入，预测未来交通

(T-ZS1) Traffic prediction concerns the usage of a learnable function that takes as input the historical traffic data from several previous time-steps in order to predict the traffic in the future.  

> 近义句 Traffic prediction is a task of training an arbitrary function to predict future traffic given past traffic data  

> 还有其他，参考下文

$$
\hat y_{t+T'}=f([X_{t-T+1},X_{t-T},\cdots,X_t])
$$

目标：找到模型参数，最小化误差：

The objective is to find the model parameters which minimize the error between the predicted traffic and the observed traffic:  
$$
\theta^*=\arg\min_{\theta^*}L(y_{t+T'},\hat y_{t+T'};\theta^*)
$$

> 其中 $y_t$ 是时间 $t$ 的观察值，$\hat y_t$ 是预测值，$T$ 是输入序列长度，$T'$ 是预测范围，$L$ 是损失函数，$f$ 是任意函数，$\theta^*$ 是最优参数。
>
> - The observed traffic at time $t$
> - The predicted traffic at time $t$
> - Input sequence length, i.e., how many time steps of past traffic data are used as the input 
> - Prediction horizon, i.e., how many time steps in the future the prediction is for 
> - An arbitrary function that calculates the traffic prediction based on the input data  
> - Loss function, which is the function that calculates the quality of the prediction
> - The optimal set of parameters for the function $f$

#### 目标类型

##### 综述

(T-ZS1)

- 交通流量 某地某段时间车辆总数

  (T-ZS1) Traffic flow is denoted as the total number of vehicles detected in a target detection site during a certain time period. 

  (T-ZS2) Traffic flow is defined as the number of vehicles passing through a spatial unit, such as a road segment or traffic sensor point, in a given time period  

- 交通速度 某地某段时间各车辆平均速度

  (T-ZS1) Traffic speed is denoted as the average traveling speed of vehicles detected in a target detection site during a certain time period
  
  (T-ZS2) is defined as the average speed of vehicles passing through a spatial unit in a given time period  

其他类别：

- 交通状况 
  
  (T-ZS1) T-4 traffic condition, which consists of four categories: fluency, slow, congestion and extreme congestion  
  
- 人流量 
  - (T-ZS1) T-28 [T-30](https://www.researchgate.net/profile/Leye-Wang/publication/322886199_Crowd_Flow_Prediction_by_Deep_Spatio-Temporal_Transfer_Learning/links/5aa9bd6b0f7e9b88266f6529/Crowd-Flow-Prediction-by-Deep-Spatio-Temporal-Transfer-Learning.pdf) crowd flow instead of traffic flow: Crowd flow measurements are the same as traffic flow, but they are designed for general human mobility instead of automobile mobility  
  - (T-ZS1) [T-31](https://dl.acm.org/doi/abs/10.1145/3292500.3330646) 细粒度而不是历史数据的  a fine-grained prediction is performed using a coarser data (e.g., predicting crowd flow of different school buildings given crowd flow of the entire university area) instead of using historical data
  
- 红绿灯：影响时空依赖

  (T-ZS2) The traffic light is another source of challenges for various traffic prediction tasks.  

  Short-term traffic flow fluctuation and the spatial relation change between two road segments can be caused by the traffic light. The way of controlling the traffic light may be different in different time periods, causing an inconsistent traffic flow pattern.  
  
- (T-ZS2) 交通需求：如打车服务需求量 (前景应用见上文)

- (T-ZS2) 交通事故，交通异常 Traffic accident and Traffic anomaly  

  定义：A traffic accident is usually an accident in road traffic involving different vehicles, which may cause significant loss of life and property.  

  The traffic anomaly has a broader definition that deviates from the normal traffic state, e.g., the traffic jam caused by a traffic accident or a public procession  

- (T-ZS2) 车位空余

  Parking availability: the target is to predict the availability of vacant parking space for cars in the streets or in a car parking lot

- (T-ZS2 描述 [T-65](https://ieeexplore.ieee.org/abstract/document/9151256)) 车辆排放

  Urban vehicle emission refers to the emission produced by motor vehicles, e.g., those use internal combustion engines.   

- (T-ZS2 描述 [T-66](https://ieeexplore.ieee.org/abstract/document/9294742)) 交通延迟

  Railway delay: the delay time of specific routes in the railway system

- (T-ZS2 描述 [T-67](https://ieeexplore.ieee.org/abstract/document/8917174)) 车道占用

  Lane occupancy: With simulated traffic data, lane occupancy has been measured and predicted  

##### 交通流量

可以分为无向流、双向流、入流、出流。

(T-ZS2) Road-level traffic flow problems are further divided into cases of unidirectional and bidirectional traffic flow, whereas region-level and station-level traffic flow problems are further divided into the cases of inflow and outflow, based on different problem formulations.  

##### 交通需求

定义：

(T-ZS2) Traffic demand refers to the potential demand for travel, which may or may not be fulfilled completely. 

数据：使用用户数据推断，可能低估真实数据

(T-ZS2) However, in some cases, it is difficult to collect the potential travel demand from passengers and a compromise method using transaction records as an indication of the traffic demand is used. In such cases the real demand may be underestimated.  

分类：

(T-ZS2) Based on transport mode, the traffic demand problems considered include ride-hailing demand, taxi demand, shared vehicle demand, and bike demand.  

#### 道路类型

##### 综述

(T-ZS2) 分类原因：表征空间依赖的模型要求不一样

Different problem types have different modelling requirements for representing spatial dependency

(T-ZS2) 分类为：道路、区域、站点等级

These include road-level, region-level, and station-level categories.  

- 道路：探测器 -> 路段 / GPS 轨迹(映射为路网)，路网连接+空间近似性

  For the road-level problems, the traffic data are usually collected from sensors, which are associated with specific road segments, or GPS trajectory data, which are also mapped into the road network with map
  matching techniques. In this case, the road network topology can be seen as the graph to use, which may contain hundreds or thousands of road segments potentially. The spatial dependency may be described by the road network connectivity or spatial proximity  

- 站点：地铁/车站拓扑图，数十数百个点，地铁公交线路图为空间依赖

  For the station-level problems, the metro or bus station topology can be taken as the graph to use, which may contain tens or hundreds of stations potentially. The spatial dependency may be described by the metro lines or bus routes  

- 区域：规则或不规则区域为节点，依赖：土地使用目的，POI 等获取

  For the region-level problem, the regular or irregular regions are used as the nodes in a graph. The spatial dependency between different regions can be extracted from the land use purposes, e.g., from the points-of-interest data  

##### 细分

(T-ZS2) 交通流按道路类型细分：

- 道路级：交通流、OD 流、路口吞吐量

  Road-level flow problems are concerned with traffic volumes on a road and include road traffic flow, road origin-destination (OD) Flow, and intersection traffic throughput.

  - 某个传感器位置

    In road traffic flow problems, the prediction target is the traffic volume that passes a road sensor or a specific location along the road within a certain time period (e.g. five minutes)

  - 某个起止点

    In the road OD flow problem, the target is the volume between one location (the origin) and another (the destination) at a single point in time. 

  - 某个交叉路

    The intersection traffic throughput problem considers the volume of traffic moving through an intersection

- 区域级：规则或不规则区域

  Region-level flow problems consider traffic volume in a region. A city may be
  divided into regular regions (where the partitioning is grid-based) or irregular regions (e.g. road-based or zip-code-based partitions). 

  These problems are classified by transport mode into regional taxi flow, regional bike flow, regional ride-hailing flow, regional dockless e-scooter flow, regional OD taxi flow, regional OD bike flow, and regional OD ride-hailing flow problems  

- 站点级：

  Station-level flow problems relate to the traffic volume measured at a physical station, for example, a subway or bus station. These problems are divided by station type into station-level subway passenger flow, station-level bus passenger flow, station-level shared vehicle flow, station-level bike flow, and station-level railway passenger flow problems  

(T-ZS2) 交通速度划分：道路速度、区域级速度、旅行时间、拥堵预测

- 交通拥挤和道路交通速度细分

  (T-ZS2) In several studies, traffic congestion is judged by a threshold-based speed inference. 

  The specific road-level speed problem categories considered are road traffic speed, road travel time, traffic congestion, and time of arrival problems; 

  while the region-level speed problem considered is regional OD taxi speed  

- 高速公路的速度预测相对简单：没有红绿灯、上下坡

  Freeways have a few traffic signals or on/off-ramps, making the prediction easier than the urban case.  

  挑战来自于时间依赖

  And the challenge mainly comes from the complex temporal dependency  

- 城市区域：突发变化、复杂连接、限速、空间依赖

  More complex traffic networks exist in urban roads with more complicated connection patterns and abrupt changes. For example, different road segments may have different speed limit values and the allowed vehicle types. Besides the complex temporal dependency, modeling the spatial dependency becomes a bigger challenge for urban traffic speed forecasting.  

(T-ZS2) 感觉分的太细了：

> - Road Traffic Flow
> - Road OD Flow [Origin-Destination] 仅 2 篇
> - Intersection Traffic Throughput (吞吐量) 仅 1 篇
> - Regional Taxi Flow 几篇
> - Regional Bike Flow 3 篇
> - Regional Ride-hailing Flow (打车) 仅 1 篇
> - Regional Dockless E-Scooter Flow (无桩电摩) 仅 1 篇
> - Regional OD Taxi Flow 仅 2 篇
> - Regional OD Bike Flow 仅 1 篇
> - Regional OD Ride hailing Flow 3 篇
> - Station-level Subway Passenger Flow  近 10 篇
> - Station-level Bus Passenger Flow  3 篇
> - Station-level Shared Vehicle Flow 仅 1 篇
> - Station-level Bike Flow 仅 2 篇
> - Station-level Railway Passenger Flow  仅 1 篇
> - Road Traffic Speed 最多
> - Road Travel Time 几篇
> - Traffic Congestion 几篇
> - Time of Arrival 仅 1 篇
> - Regional OD Taxi Speed 仅 1 篇
> - Ride-hailing Demand 几篇
> - Taxi Demand 十几篇
> - Shared Vehicle Demand 仅 1 篇
> - Bike Demand 十几篇
> - Traffic Accident 3 篇
> - Traffic Anomaly 仅 1 篇
> - Parking Availability 3 篇
> - Transportation Resilience (弹性) 仅 1 篇
> - Urban Vehicle Emission 仅 1 篇
> - Railway Delay 仅 1 篇
> - Lane Occupancy 仅 1 篇


## 现有综述

### 列表

年份，模型分类，问题分类，数据集分类

- T-ZS1

  CNN, RNN, FNN 2014-2019

- T-ZS2

  GNN 综述，2018-2020 (212论文)

- [T-ZS3](https://www.sciencedirect.com/science/article/pii/S0968090X14000096)

  statistical, neural network, hybrid model 2006-2013

  time series, function approximation 浏览了一下，深度学习较少
  
  提出了十个挑战，为 T-ZS1 所继承
  
- [T-ZS4](https://www.sciencedirect.com/science/article/pii/S1574119217306521)

  浏览了一下，对深度学习介绍很少，传统方法介绍篇幅很多

- [T-ZS5](https://ieeexplore.ieee.org/abstract/document/8344848/)

  浏览了一下，主要讲大数据技术，感觉相关性不大

- [T-ZS6](https://www.sciencedirect.com/science/article/pii/S0968090X10001610)

  读摘要，对比统计方法和 NN

- [T-ZS7](https://dl.acm.org/doi/abs/10.1145/3231541.3231544)

  没搞到 pdf，只读了摘要，NN 相关 2018
  
- T-ZS8

  年份太久远了 2004

- [T-ZS9](https://www.sciencedirect.com/science/article/pii/S1389128620311567)

  浏览摘要，分成统计和摘要方法，2020

- [T-ZS10](https://www.sciencedirect.com/science/article/pii/S1389128620311877)

  浏览摘要都在说 ML，2020

- [T-ZS11](https://link.springer.com/article/10.1007/s11277-020-07612-8)

  浏览摘要有 ML/DL，2020
  
- [T-ZS12](https://link.springer.com/article/10.1007/s42421-020-00020-1)

  浏览摘要有 DL，2020

- [T-ZS13](https://ieeexplore.ieee.org/abstract/document/9395529)

  浏览摘要有 DL，2021

- [T-ZS14](https://iris.cnr.it/bitstream/20.500.14243/380062/1/prod_438502-doc_157210.pdf)

  浏览摘要有数据源、DL、挑战，2020

- [T-ZS15](https://ieeexplore.ieee.org/abstract/document/9447807)

  浏览摘要有 DL 和实验，2021

- [T-ZS16](https://link.springer.com/article/10.1186/s12544-019-0345-9)

  摘要说特征选择和提取方法，1984-2018.3

- [T-ZS17](https://arxiv.org/abs/1808.06865)

  摘要说是时空序列预测，2018

- [T-ZS18](https://link.springer.com/article/10.1007/s42421-020-00030-z)

  摘要说研究影响 DL 精度的因素，评价指标等，2020

- [T-ZS19](https://www.sciencedirect.com/science/article/pii/S1566253519303094)

  摘要说影响因素，数据预处理，分类为统计、ML、DL、迁移、强化，2020

- [T-ZS20](https://ieeexplore.ieee.org/abstract/document/9310691/)

  摘要说 GNN 综述，2020

- [T-ZS21](https://ieeexplore.ieee.org/abstract/document/9352246)

  摘要说有数据集，比较实验，挑战，2020

- [T-ZS22](https://link.springer.com/article/10.1007/s42486-020-00039-x)

  摘要说是 ITS, DL，2020

### 评价

评价/内容概述

- T-ZS1 只关心 DL，encoder-decoder LSTM+GNN SOTA；介绍了数据类型、DL 结构、挑战

  (T-ZS2 评价) only focus on the progress of deep learning-based methods

  The authors conclude that encoder-decoder long short term-memory (LSTM) combined with graph-based methods is the state-of-the-art prediction technique

  A detailed explanation of various data types and popular deep neural network architectures is also provided, along with challenges and future directions for traffic prediction  

- T-ZS3

  (T-ZS1 评价) 分类老旧、深度学习少

  do not include the now ubiquitous deep neural network models

  their work categorized the models based on several criteria such as the type of model (e.g. statistical, neural network, hybrid model) and the problem (e.g. time series, function approximation). This taxonomy is outdated because modern traffic prediction models are mainly based on deep neural network, which under their taxonomy will all fall under the neural network category of model and function approximation category of problem  

- T-ZS4

  (T-ZS1 评价) 分类比较少、没讨论挑战

  their model taxonomy only has a few points of comparison, which are: whether or not the model integrates environmental data, contains spatial property, handles nonlinearity and handles nonstationarity  

  Additionally, their work does not have a future challenges section that discusses how the field can be advanced  

- T-ZS5

  (T-ZS1 评价) 与机器学习关联不大

  their work focuses on big data analytics without much focus on the actual models  
  
- T-ZS10

  (T-ZS2 评价) 分类了 ML：回归、基于例子的(kNN)、基于核的(SVM, RBF)、NN、混合模型

  Machine learning models for traffic prediction are further categorized, which include the regression model, examplebased models (e.g., k-nearest neighbors), kernel-based models (e.g. support vector machine and radial basis function), neural network models, and hybrid models  
  
- T-ZS11, T-ZS19

  (T-ZS2 评价) 分类了五种预测方法：统计、ML、DL、强化、迁移

  Roughly speaking, five different types of traffic prediction methods are identified and categorized in previous surveys, namely, statistics-based methods, traditional machine learning methods, deep learning-based methods, reinforcement learning-based methods, and transfer learning based methods.  
  
- T-ZS12

  (T-ZS2 评价) GNN 只在交通特征预测任务提及

  GNNs are only mentioned in the task of traffic characteristics prediction 
  
- T-ZS13

  (T-ZS2 评价) 把 DL 分成了五类；GNN 仍然是 SOTA

  Deep learning models are further categorized into five different generations, in which GCNs are classified as the fourth generation and other advanced techniques that have been considered but are not yet widely applied are merged into the fifth generation. These include transfer learning, meta learning, reinforcement learning, and the attention mechanism.  
  
  Before these advanced techniques become mature in traffic prediction tasks, GNNs remain the state-of-the-art technique  
  
- T-ZS15, T-ZS21

  (T-ZS2 评价) 比较了 DL 和基于统计的方法/ML

  compare them with the statistics-based and machine learning methods
  
- T-ZS15

  (T-ZS2 评价) DL 不总是最优的，线性模型/ML 可能更好

  Conversely, it is found that deep learning is not always the best modeling technique in practical applications, where linear models and machine learning techniques with less computational complexity can sometimes be preferable
  
- T-ZS16

  (T-ZS2 评价) 特征选择和预处理方法的综述

  spatiotemporal feature selection and extraction pre-processing methods, which may also be embedded as internal model processes, are reviewed
  
- T-ZS18

  (T-ZS2 评价) 准确率的元分析，不同 DL 方法，样本大小，预测视野

  A meta-analysis of prediction accuracy when applying deep learning methods to transport studies  
  
  In this study, apart from the models themselves, additional factors including sample size and prediction time horizon are shown to have a significant influence on prediction accuracy  
  
- T-ZS20

  (T-ZS2 评价) 对交通堵塞、旅行需求、交通安全等的 GNN 综述；讨论了 GNN 和 DL 的优缺点

  Graph-based deep learning architectures are reviewed for a series of traffic applications, namely, traffic congestion, travel demand, transportation safety, traffic surveillance, and autonomous driving.  
  
  Specific and practical guidance for constructing graphs in these applications is provided  
  
  The advantages and disadvantages of both GNNs and other deep learning models ,e.g. recurrent neural network (RNN), temporal convolutional network (TCN), Seq2Seq, and generative adversarial network (GAN), are examined  
  
  While the focus is not limited to traffic prediction problems, the graph construction process is universal in the traffic domain when GNNs are involved  
  
- T-ZS22

  (T-ZS2 评价) 2019 后 SOTA 都是基于 GNN 的

  Among the major milestones of deep-learning driven traffic prediction (summarized in Figure 2), the state-of-the-art models after 2019 are all based on GNNs, indicating that GNNs are indeed the frontier of deep learning-based traffic prediction research  

### 关系

T-ZS1 介绍了 T-ZS3, T-ZS4，好像也有 T-ZS5, T-ZS6, T-ZS7

T-ZS2 提到了 T-ZS8，列举了综述 T-ZS1，T-ZS9 到 T-ZS21

## 具体技术

### 概述

(T-ZS1) The earliest class of models used is the classical statistical models. Afterwards, machine learning models improve upon the performance of classical statistical models. Then, the deep neural network class of models dominates the field due to its capability in capturing the complex and nonlinear patterns in traffic data.  

### 统计模型

##### ARIMA

(T-ZS1) classical statistical models, of which the Autoregressive Integrated Moving Average (ARIMA) family of models is the most popular. 

局限：(T-ZS1) 线性模型，假设数据规律不变；只能预测小时间段，参数手调

- T-3 T-5 [T-ZS6](https://www.sciencedirect.com/science/article/pii/S0968090X10001610) simple linear models which assume that the traffic is stationary  ->  frequently fail when handling the complex, nonlinear traffic data 
- [T-12](https://arxiv.org/abs/1801.02143) were proposed at a time where traffic data were simpler and much smaller in size  -> a condition that no longer holds true in the present day where the ubiquity of traffic sensors has caused an explosion in traffic flow data   
- [O-1](https://www.tandfonline.com/doi/abs/10.1080/00031305.1996.10473554) the function parameters are manually defined a priori  

评价：(T-ZS2) Traditional linear time series models, e.g. auto-regressive and integrated moving average (ARIMA) models, cannot handle such spatiotemporal forecasting problems  

(stated by T-ZS1)

- [T-6](https://trid.trb.org/View/148123) [1979] first researchers to apply ARIMA to traffic prediction 
- [T-7](https://trid.trb.org/View/167550) [1980] found that the ARIMA(0,1,1) model is the most statistically significant
- [T-8](https://journals.sagepub.com/doi/abs/10.3141/1678-22) [1999] applied subset ARIMA and found that it provides stable and accurate results
- [T-9](https://journals.sagepub.com/doi/abs/10.3141/1776-25) [2001] discovered the impact of upstream traffic sensors to downstream ones and applied ARIMAX model for traffic flow prediction
- [T-10](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-947X(2003)129:6(664)) [2003] applied Seasonal ARIMA to the United States and the United Kingdom traffic data 
- [T-11](https://journals.sagepub.com/doi/abs/10.3141/1857-09) [2003] discussed and compared the Vector Autoregressive Moving Average and Single space-time ARIMA model

优点是解释性比 ML 好

(T-ZS2 论述说 T-ZS9 指出)：statistics-based models have better model interpretability, whereas ML-based models are more flexible 

##### 多元时间序列模型

> ARIMA 是一元的 (GPT4o)

介绍：如向量自回归模型(VAR, vector autoregression)

(T-ZS2) Before the usage of graph theories and GNNs, the spatial information is usually extracted by multivariate time series models or CNNs. Within a multivariate time series model, e.g., vector autoregression, the traffic states collected in different locations or regions are combined together as multivariate time series.  

缺点：线性

(T-ZS2) However, the multivariate time series models can only extract the linear relationship among different states, which is not enough for modeling the complex and nonlinear spatial dependency  

##### 其他

(T-ZS2) autoregression 

- 如 T-78

(T-ZS2) Markov process (马尔科夫链)

- 如 T-79

### 机器学习

#### 历史

(T-ZS1) machine learning models during the 2000s utilize shallow and simple structures, limiting their prediction power  

(stated by T-ZS1)

- [T-13](https://research.aber.ac.uk/en/publications/the-use-of-neural-networks-to-recognise-and-predict-traffic-conge) [1993] One of the first neural network applications in traffic flow prediction  
- [T-14](https://www.sciencedirect.com/science/article/pii/S0968090X05000276) [2005] proposed a genetic algorithm approach to optimally tune the network
- [T-15](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-947X(2006)132:2(114)) [2006] used multiple neural network predictors which are combined using the theory of conditional probability and the Bayes rule  
- [T-16](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0887-3801(2005)19:1(94)) [2005] neural network model was applied to traffic prediction  
- [T-17](https://ieeexplore.ieee.org/abstract/document/6088012) [2012] imbued a neural network model with the hybrid exponential smoothing method to preprocess training data and the Levenberg-Marquardt algorithm to train the network weights

非 NN：

(stated by T-ZS1)

- k-Nearest Neighbor [T-18](https://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-947X(1991)117:2(178)) [T-19](https://www.sciencedirect.com/science/article/pii/S1877042813022027) [T-20](https://www.sciencedirect.com/science/article/pii/S0968090X15003812)
- support vector regression (SVR) [T-21](https://www.sciencedirect.com/science/article/abs/pii/S0957417408004740) [T-22](https://ieeexplore.ieee.org/abstract/document/4344269) [T-23](https://link.springer.com/chapter/10.1007/978-3-540-72393-6_121)

(T-ZS2) 其他模型，如 Kalman filters (滤波器) 如 T-80

#### 概述

- 局限性：数据密集

  (T-ZS1) The main weakness is that machine learning models are data intensive 

- 局限性：

  (T-ZS1) powerful but very hard to train efficiently  

- 局限性：手动提取特征

  (T-ZS1) many other machine learning models’ feature extraction phase, which helps extract useful patterns and information from the data to help the prediction, is done manually (i.e., using manually tuned kernels)  

- 优点：

  (T-ZS1) Machine learning models are flexible as they can learn from the data. That is, the parameters of the prediction function are adjusted automatically as the model traverses through the dataset  

### SAE / DBN

#### 概念

(T-ZS1) 评价：不能明确获取时空信息

The main contributing factor of this rarity is that SAEs and DBNs do not explicitly capture the spatial or the temporal aspect of the data and thus tend to perform worse than the neural networks that capture such aspects. 

(T-ZS1) 早期出现的原因：计算快，现在已被淘汰

- 不显示获取时空信息，表现不优，在早期可能多见
- 逐层贪心训练方法预训练权重，加速训练

> SAE 基于多层神经网络的无监督学习算法。它由多个自动编码器（Autoencoder）堆叠而成
>
> Deep Belief Network 是一种由多层 Restricted Boltzmann Machines (RBMs) 组成的概率生成模型，通常用于特征学习和无监督预训练
>
> RBM 是一种受限玻尔兹曼机，用于学习数据的概率分布

In fact, SAEs and DBNs receive attention mostly at the earlier years of deep neural network for traffic flow prediction. We speculate that this is because early researchers are concerned with the computation time optimization of the training methodology. SAEs and DBNs use the greedy layer-wise training method ([O-4](https://proceedings.neurips.cc/paper/2006/hash/5da713a690c067105aeb2fae32403405-Abstract.html)) to pre-train their network weights, which accelerates the training in the long run. However, as more and more complex techniques were introduced and as hardware and software optimization reduce the computational time of these methods, the middling performance of SAEs and DBNs resulted in the two being phased out  

#### 具体论文

This has been demonstrated through several experiments:

- T-1 T-4 [T-56](https://arxiv.org/abs/1802.02147)

Stacked Autoencoder (SAE)  

(T-ZS1)

- [T-54](https://ieeexplore.ieee.org/abstract/document/6894591) 

- [T-55](https://ieeexplore.ieee.org/abstract/document/7727607) 使用 Dempster-Shafer theory 结合交通流数据

  > Dempster-Shafer理论是一种用于处理不确定性和推理的数学理论。它由Peter Dempster和Arthur Shafer在20世纪70年代提出，是一种用于描述和处理不确定性信息的方法，特别适用于决策支持系统和人工智能领域。
  >
  > 这个理论的核心是使用概率分布函数（称为Belief函数），来描述每一个可能事件发生的可能性。这种方法与传统的贝叶斯概率理论不同，因为它允许对不同假设之间的关联性进行建模，而不是简单地单独考虑每个假设的概率。
  >
  > Dempster-Shafer理论的应用包括数据融合、模式识别、专家系统、风险评估等领域，它在处理非完整和不确定信息时显示出了一定的优势

Deep Belief Network (DBN)

(T-ZS1)

- T2 T-26 T-27 

### 神经网络

#### 概念

深度神经网络

(T-ZS1) Amongst all the available traffic prediction methods, deep neural network is the most prominent.  

- 概念：

  (T-ZS1) Deep neural networks consist of complex neural network models with a large number of layers. 

- 条件：

  (T-ZS1) increasing computational power, as well as theoretical and software improvements in recent times had made increasingly complex neural network models feasible to train. Thus, in the middle of the 2010s, researchers started to apply deep neural network models for traffic prediction  

  > As technology advanced on both the hardware and the software front, complex deep neural network models are becoming easier to train. This has prompted researchers to combine the capabilities of multiple deep neural networks, and even add some novel components of their own creation  

- 理由：

  (T-ZS1) This is due to its sheer predictive power that can model the complex and nonlinear traffic patterns

  > 参考几个具体应用论文：[T-1](https://www.mdpi.com/1424-8220/17/7/1501)、[T-2](https://www.mdpi.com/1424-8220/17/7/1501)、[T-3](https://arxiv.org/abs/1612.01022)、[T-4](https://ieeexplore.ieee.org/abstract/document/8489600)、[T-5](https://arxiv.org/abs/1707.03213)，引用都不错

#### 优缺

- 适用理由：CNN/RNN抓时空+层数

  (T-ZS1) Some of the deep neural network models can explicitly capture different aspects of traffic data, which made them even more attractive. For instance, CNN can explicitly capture the spatial aspect of traffic data while RNN can explicitly capture the temporal aspect of traffic data. Additionally, the increased number of layers improves the models’ prediction capability. This factor allows them to model traffic fluctuations more accurately  

- 优点：自动学习特征

  (T-ZS1) (The reason behind its prominence is that) neural networks perform automatic feature extraction as well as the actual prediction in one model 

  > 相较于传统机器学习而言 (T-ZS1: O-1)
  >
  > Neural network’s prominence in traffic flow prediction can be attributed to the model’s flexibility. This is because the functional form of neural network models is approximated via learning, as opposed to classical statistical models which assume the functional form a priori  

- 局限性：当前状态和未来方向不明

  (T-ZS1) The increasing popularity of deep neural network models for traffic prediction has led to numerous publications, but issues such as the wide variety of hybrid deep neural network structures have made it difficult to assess the current state and future directions of this research field. This problem is compounded by the fact that survey works focusing specifically on deep neural network models are rare

- 缺点：

  (T-ZS1) 需要大数据，训练代价高，难以理解(如参数含义)

  - Deep neural network models require a large amount of data that covers all traffic conditions. 

    If the amount of data is too small or if the data is not diverse enough, the model’s generalization capability is compromised.

  - Deep neural network models still take a long time to train. 

    As deep neural network models are complex and have a large number of layers, the training time can be very long. This problem is compounded on hybrid deep neural network models. As classical statistical and older machine learning models are not as complex, their training time is much shorter.

  - Deep neural network models are difficult to interpret. 

    This is because of two reasons: the number of internal parameters is very large, and the parameters are learned from training, not set manually. Thus, while they can predict well, it is hard to understand their parameters. Understanding the parameters may reveal important information such as the spatiotemporal dynamics in the road network 
    
    > Consequently, neural network models’ internal parameters are rarely explored because they are hard to interpret as their focus is mostly on raw prediction performance rather than interpretability.  
    
    该缺点可以 更多参见下文未来趋势一节

#### 分类

类别：

(T-ZS1) The three most common deep neural network models used for traffic prediction are Convolutional Neural Networks, Recurrent Neural Networks, and Feedforward Neural Networks

> (T-ZS2) Deep learning models, including convolution neural networks and recurrent neural networks, have been extensively applied in traffic forecasting problems to model spatial and temporal dependencies  

(T-ZS1) RNN, CNN, FNN

- RNN is commonly used to capture the temporal trends of traffic data–the dynamics of how past traffic can influence future traffic. CNN is commonly used to capture the spatial trends of the data–how traffic propagates through the road network. FNN can aggregate the output from different subnetworks and also can process external data such as weather information  

### FNN

#### 概念

概念：

- (T-ZS1) 名称 A Feedforward Neural Network (FNN), which is also commonly referred to as Fully Connected Neural Network (FC or FCNN), is one of the earliest and simplest neural network models  

  组成 It consists of several layers of fully connected computational nodes organized in many layers  

  计算方式 The value of every node in the hidden or output layers is computed by taking the weighted sum of all of the previous layer’s nodes and then passing the value to a nonlinear function such as sigmoid, tanh and relu  

缺点：

- 参数多、训练久

  (T-ZS1) The FNN’s fully connected structure enables each of its layers to process the combination of all the previous layer’s features. However, this also serves as a weakness because its full connection results in a large amount of parameters  

  Consequently, the training process of FNNs can be quite time consuming. In addition  

- 没有明确获取时空信息

  (T-ZS1) do not have the capability of explicitly capturing spatial or temporal data. Because of this, FNNs are rarely used as the main predictor in deep neural network literatures.  

作用：工具组件：聚合输出、维度转换、引入数据

- (T-ZS1) For traffic flow prediction, FNNs usually serve a utility role in a hybrid deep network, whose main purpose is to perform tasks such as aggregating outputs from different components within the network, dimensionality transformation and incorporating external data such as weather.  

  - 维度转换：This is because the size of input layer or output layer can be set manually, which gives FNN the capability to transform inputs of an arbitrary dimensionality to an output of an arbitrary dimensionality  
  
  - 聚合输出：When used to integrate external data, the input depends on the type of external data. Numerical values can be provided as it is while categorical values need to be transformed first (e.g., using one-hot encoding)  
  
    > FNNs are commonly used to aggregate the output of one or more subnetwork components in a deep neural network 
    >
    > a natural component for CNNs and RNNs, since FNNs can take the output from these networks and output a smaller representation
  
  - 引入数据：For aggregating outputs and dimensionality transformation, the inputs depend entirely on the model  
  
    > FNNs are also commonly used to incorporate external data to the network, because it can take inputs of an arbitrary dimensionality and perform a transformation to ensure that the dimensionality of the external data and that of the other components within the network match  
  
  - 子模块：as a submodule component. FNNs are often used as a component in a model’s submodule, such as attention network modules  

#### 具体论文

(T-ZS1)

1. FNN as Output Aggregator

   - T-3 合并 CNN+2LSTM 的输出

     combine the outputs from one CNN component and two LSTM components  

   - T-1 T-33 T-48 T-50 T-37 合并 CNN 的输出

   - T-41 T-53(结合天气+消融) T-36 合并 RNN 的输出

2. FNNs for Incorporating External data

   - T-51 T-37 T-3

3. FNNs as a submodule component

   - T-43 学习哪条路网重要

     used an FNN to learn features from a road network, which enables the network to learn which nodes in a road network are important  

   - T-42 与上面一样，但没用图结构

     used an FNN for the same purpose, although they do not use the graph structure  

### CNN

#### 基本

##### 概念

组成：卷积层、池化层

(T-ZS1) 

A CNN consists of several “convolution” and “pooling” layers. 

- Convolution’s purpose is to extract features from the input, 

  > Mathematically, convolution layers extract features by computing the dot product between a matrix of some preset values (referred to as filter) and a subset of cells from the original grid, which produces a matrix that is called feature map  

  > The example in Figure 1 shows, (i) the top-left 3 × 3 subset of cells produces the value 470, and (ii) the bottom-right 3 × 3 subset of cells produces the value 170 in the feature map. This can be interpreted as the top-left subset having a much higher number of vehicles in that region than the bottom-right subset  

  <img src="img/image-20240722103753648.png" alt="image-20240722103753648" style="zoom: 67%;" />

- whereas pooling’s purpose is to reduce the dimensionality of each feature map but preserve the most important information.  

功能概述：

(T-ZS1) A Convolutional Neural Network (CNN) has the capability to learn inherent features progressively, starting from low level features and then building up to more abstract concepts through a series of convolutional layers. 

> 功能：建模局部空间信息，划分为规则二维网格图像格式
>
> (T-ZS2) CNNs take a step further by modeling the local spatial information, e.g., the whole spatial range is divided into regular grids as the two-dimensional image format and the convolution operation is performed in the neighbor grids.  

##### 应用

能用的理由：交通流读入可以建模为图像，每个像素点对应一个交通密集的地区，因此可以用图像识别技术，即把区域网格化，像素值是如车辆数目，不同时间即像素值不一样

> (T-ZS1) A CNN is the optimal choice for capturing the spatial aspect of the data. CNN is able to capture the correlation between different regions in the road network. By utilizing this strength, a CNN can learn the spatial dynamics of traffic in order to improve the prediction accuracy.  

(T-ZS1) 

- Although this strength contributes to its popularity in image recognition, CNNs have been regularly applied to traffic flow prediction. The intuition is, traffic flow readings can be modeled as an image, where each pixel corresponds to the traffic intensity at a certain block of area. Thus, similar techniques developed for image recognition can be easily applied 
- Given a road network, the input of a CNN is preprocessed by partitioning the network as a grid, which is essentially a set of cells with each cell representing an area in the data space and the value associated with the cell representing the number of vehicles detected in that cell at a certain point in a time period (e.g., 5×5 cells in Figure 1). The traffic flow reading for each time period will be represented with the same grid but different number of vehicles. Thus, the entire traffic data modeled this way can be seen as several images with the same size but different pixel values   

具体应用：混合网络、空间特征 (如晚高峰商业区和居住区间流量强关联)

- (T-ZS1)  In the application of traffic prediction, CNN is often used as a component in a hybrid deep neural network, whose task is to capture the spatial aspect of traffic data.
  This is because different roads in different locations may be correlated and these correlated roads share similar traffic trend. Therefore, the traffic of the correlated roads may rise or fall, depending on their historical data 

  For instance, during the evening, there is a strong correlation between the road traffic of commercial and residential districts because employees are heading off from work  

##### 优缺

优点：不全连接，参数少

- (T-ZS1) Unlike most neural networks, CNN’s layers are not fully connected. Consequently, the number of parameters and training time are significantly reduced 

  不全连接的另一个优点在于可以学习空间的局部相关性

  (T-ZS1) Since CNN’s layers are not fully connected, one layer of CNN does not learn from all of the previous layer’s features. However, this actually proves to be an advantage in many applications as CNN can learn how the different aspects of the input relate to each other spatially  

优点：权重共享

- (T-ZS1) Additionally, CNN uses a weight sharing mechanism, which further reduces the number of required parameters  

优点：结构简单、并行计算、稳定的梯度

- (T-ZS2) CNNs demonstrate their superiority in terms of simple structure, parallel computing and stable gradients.  

缺点：路网数据不行 (非欧拓扑不行)

- (T-ZS2) the CNN-based approach is not optimal for traffic foresting problems that have a graph-based form, e.g. road networks

  (T-ZS2) However, the CNN-based approach is bounded to the case of Euclidean structure data, which cannot model the topological structure of the subway network or the road network  

#### 具体论文

(T-ZS1) 根据数据分类，理由：

Deep neural network models, hybrid or otherwise, that are applicable for one data type are incompatible for the other without major modifications. Consequently, we categorize works related to CNN based on the type of the main datasets  

##### point data

(T-ZS1) CNN 获取空间信息的能力取决于数据类型，一般用点数据。

可以：

- 使用 1D CNN(一维)

  use a 1D CNN as it is compatible with point data which are commonly organized in a line

  如 T-3 T-35

- 在 2D CNN 矩阵同时使用时空数据(一维时间、一维空间)

  capture both the spatial and the temporal aspects of the data in a 2D matrix to be fed into a CNN. That is, one axis of the matrix captures the different traffic detection sites and the other is used to capture the different time step  

  如：T-33 [T-48](https://ieeexplore.ieee.org/abstract/document/8547068) [T-49](https://ieeexplore.ieee.org/abstract/document/7837874) [T-50](https://dl.acm.org/doi/abs/10.1145/3282834.3282836)

  两者都用，如：T-38

(T-ZS2)

- [T-63](https://ieeexplore.ieee.org/abstract/document/8526506) CNN NYCtaxi 数据

##### trajectory data

(T-ZS1)  可以获取时间数据(如维度：空间、时间点、天)，或对时间做一维卷积。

(T-ZS1) 例子：

- T-1 映射为2D网格

  mapped a road link to a 2D grid and assigned to each grid the average traffic speed of the associated road link.  

- [T-51](https://ojs.aaai.org/index.php/AAAI/article/view/10735) T-31 2D矩形空间，再划分为多个网格

  defined a 2D rectangular space that encompasses all the trajectory points. This space is then divided into grids. Finally, for each grid, the traffic flow for a certain period of time is calculated as the number of trajectory points that are recorded within the grid during that period. Using this modeling, the entire space can be seen as a city and the grids represent small regions within the city. 

  结合天气 

- T-37 在上述方法基础上，增加了起点终点数据

  used a similar method as the previous, but they also modeled the traffic volume using CNN by using data of a trajectory’s start and end  
  
- T-2

- T-30

##### other

(T-ZS1) 时间信息捕获

Some authors have also attempted to use CNNs to capture the temporal aspect of the data  

(T-ZS1) 例子：

- [T-52](https://www.mdpi.com/1424-8220/17/4/818) 行：空间、列：时间、深：天数 -> 比 RNN 更短的输入序列

  included both the spatial and the temporal dimensions by modeling the traffic data as a tensor, where the rows represent the spatial aspect, the columns represent the temporal aspect and the depth represents the different days  

  They argued that using RNNs requires long input sequences which can impact training time greatly and instead applied CNN to capture both the spatial and the temporal aspects of the data  

  车祸考虑 + 模拟实验

- T-51 多个 CNN 分别获取小时、天、周粒度数据

  captured the temporal aspect using CNNs which are fed data from different time granularities (e.g. weekly, daily, hourly)   

-  1D CNN 获取时间

  used a one dimensional convolution on the time axis in order to capture the temporal aspect  

### RNN

#### 基本

##### 概念

定义：

- (T-ZS1) An RNN consists of a single node with a recurrent connection, but is often visualized as a chain of nodes, with each node representing the network state at a particular recurrence/time step  

  <img src="img/image-20240722110704917.png" alt="image-20240722110704917" style="zoom:67%;" />

  节点状态 $s_t$ 处理 $t$ 时刻的输入数据 $x_t$，和截止 $t-1$ 为止的全部信息($s_{t-1}$)一起传入到该节点

  The node state $s_t$ processes the input data $x_t$ at time $t$, as well as a ‘summary’ of all the information obtained up to time $t - 1$. This summary is stored in $s_{t-1}$, and it memorizes which parts of the sequence are important. Node $s_t$ then has the summary up to time $t$ and this information is passed to the next node state
  $s_{t+1}$. Thus, the node state $s_t$ stores the state of nodes for all the previous time steps until the beginning of the input (i.e., $s_{t-1}$, $s_{t-2}$, . . . ). The output $o_t$ is then compared with the ground truth $y_t$ in order to calculate the loss, which is used to fine-tune the model parameters.  

##### 建模

具体输入：

- (T-ZS1) In traffic prediction applications, the input to an RNN consists of past traffic readings. A continuous time period is divided into discrete time blocks and the traffic flow reading from each block is fed into the RNN.  

  > In the field of traffic prediction, LSTM as well as other RNN-based methods are commonly used as a component in hybrid deep neural network models. Its task is to capture the temporal patterns of traffic data; learning how traffic evolves over time  

> 应用：命名实体识别、声音识别、音乐识别、图像字幕生成等
>
> (T-ZS1) RNN-based methods in general possess the major advantage in the form of its memorization capability. The ability of learning important parts of the sequence and knowing when to memorize or forget them had led RNN to be the prime choice for sequence data. Due to this, RNN based models have been applied in many fields such as named entity recognition [40](https://link.springer.com/chapter/10.1007/978-3-319-55699-4_33), voice recognition [41](https://dl.acm.org/doi/abs/10.1145/3132847.3132893), music composition [42](https://people.idsia.ch/~juergen/blues/IDSIA-07-02.pdf), and image caption generation [43](https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Vinyals_Show_and_Tell_2015_CVPR_paper.html)
>
> 这些论文大部分引用不多或比较古老，除了 43 感觉都很一般

##### 优缺

优点：长短的时间依赖都可以记忆，而且比其他记得更长

- (T-ZS1) Recurrent Neural Networks (RNN) are commonly applied to sequence data because of their memorization capability, which can learn both long and short term dependencies between parts of the sequence. Additionally, RNN is able to scale to longer sequences compared to other network architectures. Its unique capability makes it one of the most popular deep neural networks.  

> 适用：(T-ZS2) many solutions have been proposed for dealing with the time dependency, e.g., recurrent neural networks and temporal convolutional networks  

缺点：梯度消失

- (T-ZS1) By its nature of being able to take in possibly very long sequences, RNN suffers from the vanishing gradient problem, which hinders the network’s ability to memorize information for a long time  

缺点：训练时间长

- (T-ZS1) RNN’s recurrent structure leads to significantly longer training time compared to other deep neural network models  

> (T-ZS2) Among different approaches for temporal modeling, RNNs suffer from timeconsuming iterations and gradient vanishing or explosion problem with long sequences  

#### LSTM

开山(1997) [O-2](https://ieeexplore.ieee.org/abstract/document/6795963) ；改进(2000) [O-3](https://ieeexplore.ieee.org/abstract/document/6789445)

概念：

- (T-ZS1) maintains the RNN’s recurrent structure, but introduces the three gates to control the cell value.  

  > also contains multiple layers, each possessing a cell with the memorization capability. In addition, it contains three gates, which control how information propagates throughout the network.  

  These gates are: 种门控制信息的传播($i,o$，分别控制遗忘多少之前信息、当前与下一层的相关性)

  - the input gate $i$, which controls the importance of the inputs $x_t$ and $h_{t-1}$,

  - forget gate $f$ which controls how much of the previous information $C_{t-1}$ is to be forgotten, 

  - and the output gate $o$, which controls how relevant is the current information $C_t$ for the next step.  


<img src="img/image-20240722113840626.png" alt="image-20240722113840626" style="zoom: 67%;" />

适用的原因：交通数据是时序的

(T-ZS1) We speculate that this is because traffic data constitutes a temporal sequence, which fits LSTM’s purpose. Additionally, most available traffic flow data is compatible with LSTM, as these traffic flow data can easily be modeled as a sequence of traffic flow readings  

> For instance, the traffic flow between 11:00 and 12:00 can be captured as the aggregated traffic reading for four periods, including 11:00-11:15, 11:15-11:30, 11:30-11:45, and 11:45-12:00. This data can be fed into an RNN, resulting in an RNN with four recurrences  

#### 具体论文

##### basic

(T-ZS1)

- 首次应用 T-25 [T-32](https://ieeexplore.ieee.org/abstract/document/7463717) the first few applications of basic LSTM  
- 建模为矩阵以融合空间信息 [T-33](https://ieeexplore.ieee.org/abstract/document/7966128) [T-34](https://ieeexplore.ieee.org/abstract/document/8317872) use an LSTM that takes in readings from multiple time slots as well as multiple detectors. The data is modeled in a matrix, which captures both the spatial and temporal aspects of the data  

##### hybrid

(T-ZS1) 三种思路：

> 1. RNN 输出特征融入到融合层(fusion layer)(如 FNN) (最简单)
>
> 2. 输出作为下个组成部分的输入(流水线)(先时再空或反过来或多次时间都行)
>
> 3. 作为主预测器，修改模型内部结构 (最复杂) 
>
>    (如反向传播->RTBL, 融入图卷积等)

(T-ZS1) 即：

1. Outputting features to be fed into a fusion layer.

   the simplest because models that fall into this category usually consist of several simpler subnetworks that only interact at the final fusion layer  

2. Outputting features to be fed into subsequent components within the model.

   treats LSTM as a pipeline that transforms one feature representation to another

   > As observed, in this category of method, some preprocessing steps such as the masking of missing values can be a part of the architecture.  

3. Used as the main predictor, but with modifications
   to the internal structure  

  the most complex one, as it requires modifying the internal LSTM structure

(T-ZS1) 分别：

1. 融合层

   - T-3 CNN+2LSTM (空间，短时间特征，周期时间特征)

     a combination of a CNN and two LSTMs to capture spatial features, the short-term temporal feature, and the periodic temporal feature respectively. The outputs from these three networks are then fed into a FNN to fuse the features  

   - [T-35](https://ieeexplore.ieee.org/abstract/document/8258813) CNN+LSTM

     used a combination of a CNN component and an LSTM component to capture spatial features and temporal features respectively. The outputs from these networks are combined to form the prediction  

   - T-29 SAE + LSTM

     a combination of a Stacked Autoencoder to encode traffic accidents data and an LSTM to capture the temporal aspect of the data  

2. 流水线

   - T-1 CNN -> LSTM

   - first used a CNN to encode the spatial aspect of the data and then fed this processed information to an LSTM to learn the temporal aspect  

   - T-4 CNN -> LSTM

     used an LSTM to process the outputs from a CNN before passing them to a max-pooling layer  

   - T-12 缺失值处理 -> 双向LSTM(特征转换) -> LSTM

     performed masking to fill in missing values in the data before passing it to a bidirectional LSTM for feature transformation and then a regular LSTM for the prediction  

   - [T-36](https://arxiv.org/abs/1811.05320) GCN(空间) + GRU(时间)

     used a Gated Recurrent Unit which takes input from a Graph Convolution Network and outputs the predicted traffic

   - [T-37](https://www.researchgate.net/profile/Huaxiu-Yao/publication/323570926_Modeling_Spatial-Temporal_Dynamics_for_Traffic_Prediction/links/5b1e23ea45851587f29f6a61/Modeling-Spatial-Temporal-Dynamics-for-Traffic-Prediction.pdf) 多个 LSTM

     used multiple LSTMs that represent the daily traffic features

   - [T-38](https://www.sciencedirect.com/science/article/pii/S0968090X18302651) 注意力+GRU+CNN

     used a Gated Recurrent Unit to learn feature representation from an attention model which are then fused with the CNN spatial component  

3. 修改结构

   - [T-39](https://ieeexplore.ieee.org/abstract/document/8917706) LSTM: 图卷积+卷积改为RTBL(查不到，疑似自创)

     modified the LSTM calculation to include a graph convolution process as well as using a novel Real-Time Branching Learning (RTBL) which modifies the backpropagation process  

   - [T-40](https://arxiv.org/abs/1707.01926) GRU: 矩阵乘法改为扩散卷积操作

     replaced the matrix multiplication inside Gated Recurrent Unit with the diffusion convolution operation 

##### encoder-decoder

见下文

##### other

(T-ZS1) 可以同时获取时空信息

Some authors have used RNNs to capture both the temporal and the spatial aspects of the data  

- T-34 多检测器一次输入 LSTM

  captured the temporal aspect by feeding data from multiple traffic loop detectors at once into an LSTM  

- [T-46](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-its.2016.0208)  每个检测器一个 LSTM + ODC矩阵表示之间相关

  used one LSTM for each traffic loop detector and incorporates an Origin Destination Correlation (ODC) matrix, which weighs how much the traffic of one loop detector’s location affects another  

- T-30 LSTM 密度核改成卷积来同时捕获时空

  replaced the dense kernels in LSTM with convolutional ones to successfully use an LSTM to capture both the spatial and the temporal aspects of traffic data  

  拼接天气和交通流数据

(T-ZS2) +图卷积

- T-82, T-83, T-84, T-85, T-86

##### 多粒度

(T-ZS1) RNN 输入可能过长，因此只选取多个粒度的代表性数据，分别训练多个粒度的 RNN 组合，如要预测某个时刻的流量，与其输入很长的小时单位，不如输入短的小时，短的天，短的周结合起来，代替可能长达周的小时输入。

In addition, RNN has been used to capture the temporal aspect of the data using different granularities. As discussed in Section 3.2, RNN-based methods are commonly used to learn the temporal patterns of traffic data. However, we also mentioned that RNN-based methods are time-consuming. Consequently, RNN-based methods are not usually fed very long input sequences. Several data modeling-based approaches have been explored to mitigate this problem. The most common method is to use multiple LSTMs with each taking shorter sequences from a specific granularity. 

As an example, if we want to predict the traffic at 09:00 AM at December 25, one RNN can be used to capture the data from 06:00, 07:00, and 08:00 AM at December 25 (hourly granularity), one RNN can be used to capture the data from 09:00 AM at 22, 23 and 24 December (daily granularity) and one RNN can be used to capture the data from 09:00 AM at 4, 11 and 18 December (weekly granularity)  

- 例子如 T-3 T-37 T-38

### GNN

> (T-ZS2) GNN 本身的综述：O-7, [O-8](https://ieeexplore.ieee.org/abstract/document/9039675), [O-9](https://www.sciencedirect.com/science/article/pii/S2666651021000012) (都是 2020 的)

#### 概念

##### 兴起

(T-ZS1) 近年新技术：

One of the most significant breakthroughs of recent work in deep neural network for traffic flow prediction is the graph-based methods  ->  in particular, the graph convolution operation  

> 现状：SOTA：图结构和上下文信息(contextual)
>
> (T-ZS2) [O-6](https://ieeexplore.ieee.org/abstract/document/9046288)(GNN 综述) In recent years, to model the graph structures in transportation systems as well as contextual information, graph neural networks have been introduced and have achieved state-of the-art performance in a series of traffic forecasting problems  

##### 适用理由

适用的理由：

- 路网动态获取

  (T-ZS1)  Due to this ability of capturing the dynamics of road network, graph-based method is a promising future research direction.  

  (T-ZS2) For the dynamic spatial dependency, dynamic graphs can be learned from the data automatically.  

  (T-ZS1) they naturally conform to traffic dynamics

- 非欧结构数据信息

  (T-ZS2) Graph neural networks bring new opportunities for solving traffic forecasting problems, because of their strong learning ability to capture the spatial information hidden in the non-Euclidean structure data, which are frequently seen in the traffic domain
  
  远的空间依赖
  
  (T-ZS2) The spatial dependency, which refers to the complex and nonlinear relationship between the traffic state in one particular location with other locations. This location could be a road intersection, a subway station, or a city region. The spatial dependency may not be local, e.g., the traffic state may not only be affected by nearby areas, but also those which are far away in the spatial range but connected by a fast transportation tool. The graphs are necessary to capture such kind of spatial information  
  
- 层次结构，超图子图

  (T-ZS2) For the case of hierarchical traffic problems, the concepts of super-graphs and sub-graphs can be defined and further used  

##### 建模方式

非欧图结构的空间依赖：建图方式，点是路交点，边是路连接

(T-ZS2) GNNs are ideally suited to traffic forecasting problems because of their ability to capture spatial dependency, which is represented using non -Euclidean graph structures. For example, a road network is naturally a graph, with road intersections as the nodes and road connections as the edges. With graphs as the input, several GNN-based models have demonstrated superior performance to previous approaches on tasks including road traffic flow and speed forecasting problems  

> (T-ZS2) Based on graph theories, both nodes and edges have their own attributes, which can be used further in the convolution or aggregation operations. These attributes describe different traffic states, e.g., volume, speed, lane numbers, road level, etc.  

##### 应用领域

应用面：(T-ZS2) The GNN-based approach has also been extended to other transportation modes, utilizing various graph formulations and models.  

##### 对比

(T-ZS2) 欧氏数据：图像、视频、文本

Previous neural networks, e.g. fully-connected neural networks (FNNs), CNNs, and RNNs, could only be applied to Euclidean data (i.e. images, text, and videos)  

(T-ZS1) 图论领域GNN vs 欧氏几何CNN：

When applied to road networks, graph convolution works on the graph domain while regular convolution works on the Euclidean domain

> road networks do not conform to the Euclidean space as roads and highways that are close to each other may connect different parts of the city and thus have very different traffic characteristics  

讨论二者的优缺：

(T-ZS1) Graph-based methods are more appropriate for traffic data compared to the more conventional methods of dividing an area into spatial grids. The reason is that roads close to each other may connect entirely different parts of a city. It is more accurate to capture spatial correlations in terms of the connectivity of different parts of the area, which graph-based methods provide  

##### 优缺

优点：图表示的复杂物体联系的获取能力

(T-ZS2 说 [O-10](https://www.sciencedirect.com/science/article/pii/S0140366421004874) 说的) GNNs have the ability to capture complex relationships between objects and make inferences based on data described by graphs. GNNs have been proven effective in various node-level, edge-level, and graph-level prediction tasks  

缺点：

(T-ZS1) 实现复杂，可能需要手动预处理

> Graph-based models can be complex to implement as it requires additional data as well as data preprocessing  
>
> The road topology data, which captures how different traffic detection sites are connected by roads, is often not readily available and has to be manually curated. 
>
> > While this challenge is significant, it is important to measure and understand how well graph-based methods improve the traffic prediction performance  

数据获取难度

(T-ZS1)  the difficulty lies in the data requirement and the additional preprocessing step  

#### 建模

##### 图定义

图的定义：

(T-ZS2) It is defined as $G=(V,E,A)$ where

- $V$ is the set of vertices or nodes

- $E$ is the set of edges between the nodes  

- $A$ is the adjacency matrix  

  Element $a_{ij}$ of $A$​ epresents the "edge weight" between nodes $i$ and $j$

  > For a binary connection matrix $A$, $a_{ij}=1$ if there is an edge between nodes $i$ and $j$ in $E$, and $a_{ij} = 0$ otherwise. 
  >
  > If $A$ is symmetric, the corresponding graph $G$ is defined as undirected. Otherwise, $G$ is directed, when the edge only exists in one direction between a node pair  

点和边都有含义(权/信息)

(T-ZS2) Both nodes and edges can be associated with different attributes in different GNN problems  

> 交通状态建模到点上：
>
> (T-ZS2) For simplicity, we assume that the traffic state is associated with the nodes. The other case with edges can be derived similarly. In practice, the traffic state is collected or aggregated in discrete time steps, e.g. five minutes or one hour, depending on the specific scenario  

> 时间步 $t$，点的特征矩阵为 $\chi_t\in R^{N\times d}$，$N$ 是点数，$d$ 是特征数。
>
> (T-ZS2) For a single time step t, we denote the node feature matrix as $\chi_t\in R^{N\times d}$, where N is the number of nodes and d is the dimension of the node features, i.e., the number of traffic state variables. Now we are ready to give a formal definition of traffic graph

交通图定义：(Traffic Graph)

(T-ZS2) A traffic graph (with node features) is defined as a specific type of graph G = (V; E; A), where V is the node set, E is the edge set, and A is the adjacency matrix. For a single time step t, the node feature matrix $\chi_t\in R^{N\times d}$  for G contains specific traffic states, where N is the number of nodes and d is the number of traffic state variables

##### 问题定义

基于图的交通预测问题：Graph-based Traffic Forecasting)  

(T-ZS2) A graph-based traffic forecasting (without external factors) is defined as follows: find a function $f$ which generates $y=f(\chi;G)$, where $y$ is the traffic state to be predicted, $\chi=\{\chi_1,\chi_2,\cdots,\chi_T\}$ is the historical traffic state defined on graph $G$, and $T$ is the number of time steps in the historical window size.

带外部状态：$\epsilon$ 为外部因素。  

The forecasting problem formulation, extended to incorporate these external factors, takes the form $y=f(\chi,\epsilon, G)$, where $\epsilon$ represents the external factors.  

分为单步预测和多步预测

(T-ZS2) In single step forecasting, the traffic state in the next time step only is predicted, whereas in multiple step forecasting the traffic state several time steps later is the prediction target  

> T-ZS2 有图示(figure1) (图源 T-ZS20，进行了修改)
>
> ![image-20240801205059347](img/image-20240801205059347.png)

##### 图的分类

(T-ZS2) 静态动态的角度分类：

- 静态图 pre-defined static graphs  

  - 自然图：真实世界路网

    Natural graphs are based on a real-world transportation system, e.g. the road network or subway system  

  - 相似图：点之间相似性

    whereas similarity graphs are based solely on the similarity between different node attributes where nodes may be virtual stations or regions  

- 动态图：从数据学习 dynamic graphs continuously learned from the data  

(T-ZS2) 道路类型的角度分类：(其 P20 提供了一个表展示了各论文的建图类型，点边类型)

- 道路级：探测器图、基于路网的图(路段图、路口图、车道图) (论文图2表示例子)

  Road-level graphs. These include sensor graphs, road segment graphs, road intersection graphs, and road lane graphs.  

  - Sensor graphs are based on traffic sensor data (e.g. the PeMS dataset) where each sensor is a node, and the edges are road connections
  - The other three graphs are based on road networks with the nodes formed by road segments, road intersections, and road lanes, respectively.   

  适用：当应用车辆只在建图范围内移动时

  In some cases, road-level graphs are the most suitable format, e.g., when vehicles can move only through pre-defined roads  

  其中探测器和路段是全部数据里最常用的：现成数据集多

  Sensor graphs and road segment graphs are most frequently used because they are compatible with the available public datasets  

  (图源 T-ZS20，进行了重绘)

  ![image-20240801212136966](img/image-20240801212136966.png)

- 区域级：不规则、规则、OD

  Region-level graphs. These include irregular region graphs, regular region graphs, and OD graphs  

  - 规则：适合 CNN

    Regular region graphs, which have grid-based partitioning, are listed separately because of their natural connection to previous widely used grid-based forecasting using CNNs, in which the grids may be seen as image pixels.  

  - 不规则 (具体 zip code 地图图片实例：[here](https://maps-manhattan.com/manhattan-zip-code-map))

    irregular region graphs include all other partitioning approaches, e.g. road based, or zip code based (如 [T-68](https://www.sciencedirect.com/science/article/pii/S0968090X20307580))

  - OD：节点是起点终点对

    In the OD graph, thenodes are origin region - destination region pairs

  边是邻居或其他相似性(如 PoI 数据的功能相似)

  In these graphs, the edges are usually defined with a spatial neighborhood or other similarities, e.g., functional similarity derived from point-of-interests (PoI) data  

- 站点级：地铁、车站、单车站、铁路、共享汽车站、停车场、停车块

  Station-level graphs. These include subway station graphs, bus station graphs, bike station graphs, railway station graphs, car-sharing station graphs, parking lot graphs, and parking block graphs. Usually, there are natural links between stations that are used to define the edges, e.g. subway or railway lines, or the road network  

  例子如 [北京地铁线路图](https://www.travelchinaguide.com/cityguides/beijing/transportation/subway.htm)

- 可以混合使用，如：[T-69](https://ieeexplore.ieee.org/abstract/document/9098104)、[T-70](https://www.worldscientific.com/doi/abs/10.1142/S0218194019400187)

##### 邻接矩阵构造

Adjacency Matrix Construction

> 重要性：(T-ZS2 说 T-ZS20 说的) Adjacency matrices are seen as the key to capturing spatial dependency in traffic forecasting

灵活性较大：

(T-ZS2) While nodes may be fixed by physical constraints, the user typically has control over the design of the adjacency matrix, which can even be dynamically trained from continuously evolving data

分类：

(T-ZS2 基于 T-ZS20 改进) 基于：道路、距离、相似性、动态矩阵 (论文有表 3)

divide them into four types, namely, road-based, distance-based, similarity-based, and dynamic matrices  

连接和距离最常用：定义简单 

The connection and distance matrices are the most frequently used types, because of their simple definition and representation of spatial dependency.  

- 道路 Road-based Matrix：连接矩阵、交通连接性矩阵、方向矩阵

  This type of adjacency matrix relates to the road network and includes connection matrices, transportation connectivity matrices, and direction matrice  

  - 连接矩阵：最常用，01 矩阵

    A connection matrix is a common way of representing the connectivity between nodes. It has a binary format, with an element value of 1 if connected and 0 otherwise  

  - 交通连接性：很远但可达也连接；可以用几分钟内可达都连一条边

    The transportation connectivity matrix is used where two regions are geographically distant but conveniently reachable by motorway, highway, or subway (T-ZS2 说 T-ZS20 说的)

    It also includes cases where the connection is measured by travel time between different nodes, e.g. if a vehicle can travel between two intersections in less than 5 minutes then there is an edge between the two intersections (用时间内可达做例子的，T-ZS2 说 [T-71](https://ieeexplore.ieee.org/abstract/document/8612556))

- 距离矩阵：邻居和距离

  This widely used matrix-type represents the spatial closeness between nodes. It contains two sub-types, namely, neighbor and distance matrices

  - 邻居：有相邻边界就连边

    In neighbor matrices, the element values are determined by whether the two regions share a common boundary (if connected the value is set to 1, generally, or 1/4 for grids, and 0 otherwise)  

  - 距离：驾驶距离、最短路或近似方位(RWR求出)

    In distance-based matrices, the element values are a function of geometrical distance between nodes. This distance may be calculated in various ways, e.g. the driving distance between two sensors, the shortest path length along the road (最短路如 [T-72](https://ieeexplore.ieee.org/abstract/document/8917213)、[T-73](https://www.sciencedirect.com/science/article/pii/S0968090X21004538)) or the proximity between locations calculated by the random walk
    with restart (RWR) algorithm (如 T-62)

    常见缺陷：不考虑长距离相似性，静态

    One flaw of distance-based matrices is that the fail to take into account the similarity of traffic states between long-distance nodes, and the constructed adjacency matrix is static in most cases  

- 相似性：交通模式、功能相似

  This type of matrix is divided into two sub-types, namely, traffic pattern and functional similarity matrices

  - 交通模式：状态联系，如流量模式、互依赖、交通需求关联

    Traffic pattern similarity matrices represent the correlations between traffic states, e.g. similarities of flow patterns, mutual dependencies between different locations, and traffic demand correlation in different regions  

  - 功能：不同类型 PoI 的分布

    Functional similarity matrices represent, for example, the distribution of different types of PoIs in different regions  

- 动态矩阵：不预定义静态的，有优势

  This type of matrix is used when no pre-defined static matrices are used. Many studies have demonstrated the advantages of using dynamic matrices, instead of a pre-defined adjacency matrix, for various traffic forecasting problems 

#### 基础

##### 分类

分类：基于 RNN, CNN, FNN, 注意力

> (T-ZS2 说 O-7 说的) 循环 GNN，卷积 GNN，GAE(图自编码器)，时空 GNN
>
> GNNs can be roughly divided into four types, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatiotemporal GNNs  
>
> (T-ZS2) 按照这个定义，全都是时空 GNN，但可以根据时间用啥再分：RNN 和 CNN 可以处理时间信息 （RNN 论文数比 CNN 多一倍左右）
>
> Spatiotemporal GNNs can be further categorized based on the approach used to capture the temporal dependency in particular. Most of the relevant studies in the literature can be split into two types, namely, RNN-based and CNN-based spatiotemporal GNNs  
>
> (T-ZS2) 此外还有基于注意力的，基于 FNN 的，一共四种分类。
>
> With the recent expansion of relevant studies, we add two sub-types of spatiotemporal GNNs in this survey, namely, attention-based and FNN-based
>
> (T-ZS2) 其中 Transformer 有 T-74, T-75, T-76, T-77，注意力机制和 FNN 的论文数量差不多，感觉都没 CNN 和 RNN 多
>
> 其他技术：
>
> - autoregression [T-78](https://arxiv.org/abs/1905.10709)
> - Markov processes [T-79](https://www.sciencedirect.com/science/article/pii/S0968090X20305866)
> - Kalman filters [T-80](https://journals.sagepub.com/doi/abs/10.1177/0361198120919399)

> 同时处理时空：图卷积融入 RNN
>
> (T-ZS2) Some efforts are put to jointly modeling the potential interaction between spatial and temporal features and one promising direction is the incorporate of the graph convolution operations into RNNs to capture spatial-temporal correlations  
>
> - 如 [T-82](Gated residual recurrent graph neural networks for traffic prediction), [T-83](Optimized graph convolution recurrent neural network for traffic prediction), [T-84](https://ieeexplore.ieee.org/abstract/document/9269513), [T-85](https://arxiv.org/abs/1903.05631). [T-86](https://arxiv.org/abs/1906.00560)
>
> (T-ZS2) 例如邻接矩阵+局部时空图的 GCN [T-87](https://ojs.aaai.org/index.php/AAAI/article/view/5438)
>
> For example, the localized spatio-temporal correlation information is extracted simultaneously with the adjacency matrix of localized spatio-temporal graph, in which a localized spatio-temporal graph that includes both temporal and spatial attributes is constructed first and a spatial-based GCN method is applied then  

##### 卷积GNN

> GCN(图卷积网络,Graph Convolutional Network)

给定图 $G=(V,E,A)$，点 $v_i$ 的邻居 $\mathcal N(v_i)$，$\mathbf D$ 是度矩阵，即 $\mathbf D_{ii}=||\mathcal N(v_i)||$，$\mathbf L=\mathbf D-\mathbf A$ 是无向图拉普拉斯矩阵，且 $\tilde{\mathbf L}=\mathbf I_N-\mathbf D^{-\frac12}\mathbf A\mathbf D^{-\frac12}$ 是标准化的该矩阵，其中 $\mathbf I_N$ 是 $N$ 阶单位矩阵；不考虑时间步，则节点信息矩阵是 $\mathbf X\in R^{N\times d}$，$d$ 是信息的维度，$N$ 是节点数

> (T-ZS2) Give a graph G = (V; E; A), N (vi) is defined as the neighbor node set of a single node vi. D is defined as the degree matrix, of which each element is $\mathbf D_{ii}=||\mathcal N(v_i)||$，$\mathbf L=\mathbf D-\mathbf A$ is defined as the Laplacian matrix of an undirected graph and $\tilde{\mathbf L}=\mathbf I_N-\mathbf D^{-\frac12}\mathbf A\mathbf D^{-\frac12}$ is defined as the normalized Laplacian matrix, where  $\mathbf I_N$ is the identity matrix with size N. Without considering the time step index, the node feature matrix of a graph is simplified as $\mathbf X\in R^{N\times d}$ , where N is the node number and d is the dimension of the node feature vector as before.  

欧氏数据卷积扩展到非欧时，将学习一个关于节点及其邻居的数据映射

> (T-ZS2) When extending the convolution operation from Euclidean data to nonEuclidean data, the basic idea of GNNs is to learn a function mapping for a node to aggregate its own features and the features of its neighbors to generate a new representation  

GCN 是基于频谱的卷积 CNN，图卷积：先傅里叶，做操作，再逆傅里叶回去

(T-ZS2) GCNs are spectral-based convolutional GNNs, in which the graph convolutions are defined by introducing filters from graph signal processing in the spectral domain, e.g., the Fourier domain. The graph Fourier transform is firstly used to transform the graph signal to the spectral domain and the inverse graph Fourier transform is further used to transform the result after the convolution operation back

> (T-ZS2) 背景：
>
> - 核是可学习参数，多通道
>
>   [O-11](https://arxiv.org/abs/1312.6203) Spectral convoluted neural networking assumes that the filter is a set of learnable parameters and considers graph signals with multiple channels 
>
> - 平滑，空间局部性
>
>   [O-12](https://arxiv.org/abs/1506.05163) GNN introduces a parameterization with smooth coefficients and makes the spectral filters spatially localized
>
> - 切比雪夫多项式扩展来近似对角矩阵
>
>   [O-13](https://proceedings.neurips.cc/paper_files/paper/2016/hash/04df4d434d481c5bb723be1b6df1ee65-Abstract.html) Chebyshev’s spectral CNN (ChebNet)  leverages a truncated expansion in terms of Chebyshev polynomials up to Kth order to approximate the diagonal matrix  

GCN ([O-14](https://arxiv.org/abs/1609.02907)) 是 ChebNet 的近似，且 $K=1$ 避免过拟合，使用对角矩阵特征值的切比雪夫多项式来近似卷积核，定义卷积操作如下：

(T-ZS2) is a first-order approximation of ChebNet, which approximates the filter using the Chebyshev polynomials of the diagonal matrix of eigenvalues. To avoid overfitting, K = 1 is used in GCN. Formally, the graph convolution operation ∗G in GCN is defined as follows:
$$
\mathbf X_{*G}=\mathbf W(\mathbf I_N+\mathbf D^{-\frac12}\mathbf A\mathbf D^{-\frac12})\mathbf X
$$
$\mathbf W$ 是模型参数，为了降低梯度爆炸，修改为：

> (T-ZS2) where W is a learnable weight matrix, i.e., the model parameters. While in practice, the graph convolution operation is further developed in order to alleviate the potential gradient explosion problem as follows  

$$
\mathbf X_{*G}=\mathbf W(\mathbf{\tilde D}^{-\frac12}\mathbf{\tilde A}\mathbf{\tilde D}^{-\frac12})\mathbf X
$$

其中 $\mathbf{\tilde A}=\mathbf A+\mathbf I_N$ 且 $\mathbf{\tilde D}_{ii}=\sum_j \mathbf{\tilde A}_{ij}$ 

替代方法：基于空间的卷积 GNN：图卷积定义为信息传播。如 DCG, MPNN, GraphSAGE, GAT。

(T-ZS2) The alternative approach is spatial-based convolutional GNNs, in which the graph convolutions are defined by information propagation.  

- DCG [O-15](https://proceedings.neurips.cc/paper_files/paper/2016/hash/390e982518a50e280d8e2b535462ec1f-Abstract.html) Diffusion graph convolution  

  图卷积建模为扩散过程，从一个节点到相邻节点的转移概率被考虑在内，最终达到平衡

  The graph convolution is modeled as a diffusion process with a transition probability from one node to a neighboring node in DGC. An equilibrium is expected to be obtained after several rounds of information transition  

- MPNN [O-16](https://proceedings.mlr.press/v70/gilmer17a) message passing neural network  

  图卷积为从一个点到其他连通点直接传递信息的过程

  The general framework followed is a message passing network, which models the graph convolutions as an information-passing process from one node to another connected node directly  

  用信息传播函数来统一不同空间变量，操作两阶段：信息传递、读出。

  > MPNN uses message passing functions to unify different spatial-based variants. MPNN operates in two stages, namely, a message passing phase and a readout phase. The message passing phase is defined as follows:  

  信息传递阶段：
  $$
  \mathbf m^{(t)}_{v_i}=\sum_{v_j\in\mathcal N(v_i)}\mathcal M^{(t)}(\mathbf X_i^{(t-1)},\mathbf X_j^{(t-1)},\mathbf e_{ij})
  $$
  $\mathbf m^{(t)}_{v_i}$ 是从 $v_i$ 的邻居聚合而来的信息，$\mathcal M^{(t)}(\cdot)$ 是第 $t$ 次迭代的聚合函数，$\mathbf X_i^{(t)}$ 是该次迭代 $v_i$ 节点的隐藏状态，$\mathbf e_{ij}$ 是 $v_i,v_j$ 之间的边特征向量

  > where m( vti) is the message aggregated from the neighbors of node vi, M(t)(·) is the aggregation function in the t-th iteration, X(it) is the hidden state of node vi in the t-th iteration, and eij is the edge feature vector between node vi and node vj.  

  读出阶段：
  $$
  \mathbf X_i^{(t)}=\mathcal U^{(t)}(\mathbf X_i^{(t-1)},\mathbf m^{(t)}_{v_i})
  $$
  其中 $\mathcal U^{(t)}(\cdot)$ 是读出函数。

  > The readout phase is defined as follows, where U(t)(·) is the readout function in the t-th iteration  

- GraphSAGE [O-17](https://proceedings.neurips.cc/paper/2017/hash/5dd9db5e033da9c6fb5ba83c7a7ebea9-Abstract.html)

  只采样固定数量的邻居避免计算问题

  To alleviate the computation problems caused by a large number of neighbors, sampling is used to obtain a fixed number of neighbors  

- GAT [O-18](https://arxiv.org/abs/1710.10903) graph attention network  

  用注意力机制(O-5 开山)学习两个连通点之间的相对权重

  without using a predetermined adjacency matrix, the attention mechanism is used to learn the relative weights between two connected nodes  

  使用了多头注意力机制：稳定学习过程

  the attention mechanism is incorporated into the propagation step and the multi-head attention mechanism is further utilized with the aim of stabilizing the learning process 

  > The specific operation is defined as follows:

  $$
  \mathbf X_i^{(t)}=||_k\sigma(\sum_{j\in\mathcal N(v_i)}\alpha^k(\mathbf X_i^{(t-1)},\mathbf X_j^{(t-1)})\mathbf W^{(t-1)}\mathbf X_j^{(t-1)})
  $$

  其中 $\sigma$ 是激活函数，$\alpha^k(\cdot)$ 是第 $k$ 次的注意力机制，$||$ 是连接操作

  > where k is the concatenation operation, σ is the activation method, αk(·) is the k-th attention mechanism  

> 如图，分别是：两层 GCN 和时空 GNN 典型结构 (1D CNN + GCN 为例)，论文图 5
>
> 上图只有空间依赖被捕获了，下图中：
>
> - GCN 捕获空间依赖，CNN 捕获时间依赖，可以替换
>
>   GCN is used to capture the spatial dependency and 1D-CNN is used to capture the temporal dependency. Both GCN and 1D-CNN components can be replaced with other structures for other spatiotemporal GNNs  
>
> - MLP 转换输出
>
>   A multilayer perceptron (MLP) component is used to generate the desired output  
>
> ![image-20240802212217655](img/image-20240802212217655.png)
>
> ![image-20240802212207043](img/image-20240802212207043.png)

#### 具体论文

(T-ZS1) 基于图的方法，图卷积操作(图论领域)。常规卷积是欧氏领域

如：

- 图扩散处理，基于双向图随机游走，结果用于卷积和 RNN

  T-38 (T-ZS1)  performed a graph diffusion process based on a bidirectional graph random walk. Then, the resulting graph diffusion was used in a convolution process which is then incorporated into a Gated Recurrent Unit RNN  

- 图卷积，计算图(几步内)可达

  T-39 (T-ZS1) used a similar idea of graph convolution, but instead of using the diffusion process, they proposed a method which involves calculating whether or not it is possible to reach one node from another under a certain number of time-step when the traffic is on free-flow condition  

- 有向图找上游下游方向融入到卷积层

  T-4 (T-ZS1) used a directed graph which represents how traffic flows between locations. Through this directed graph, it is possible to find the upstream and the downstream locations. This information is incorporated in a convolution layer  

- 空间图卷积层

  T-28 (T-ZS1) modeled the traffic network as a graph and proposed a spatial graph convolutional layer  

- 图注意力网络

  T-43 (T-ZS1) modeled road network as a graph and used a graph attention network to model spatial correlations in the network  

- GN块输出同拓扑不同特征的图

  T-45 (T-ZS1) used a novel component called GN block that takes a road network graph as input and outputs another graph with the same topology but different graph features  

- 用 Deepwalk 把图转向量

  [T-58](https://pubs.aip.org/aip/cha/article-abstract/29/10/103125/282714/Road-traffic-state-prediction-based-on-a-graph?redirectedFrom=fulltext) (T-ZS1) used Deepwalk to transform a graph into a vector representation, which makes it easier to be incorporated into the deep neural network model  

- 扩散卷积 RNN (DCRNN) 

  T-40 (T-ZS1); (T-ZS2) diffusion convolutional recurrent neural network 
  
- Graph WaveNet  

  [T-64](https://arxiv.org/abs/1906.00121) (T-ZS2)

### 注意力

#### 概念

(T-ZS1) 动机：替代基于图的方法，比它更容易实现

An alternative to this method is some sort of an attention module that can model the spatial and temporal correlations in the data  

> #### 基础

开山 O-5



#### 具体论文

(T-ZS1)

- T-42
- T-44

### encoder-decoder

#### 传统

##### 概念

(T-ZS1) 概念介绍：

In addition to these methods, the encoder-decoder RNNs are also used in many recent studies. Encoder-decoder RNNs are partly inspired by autoencoders. 

Autoencoders are deep neural network structures that consist of two parts: 

- the encoder that takes an input and produces a vector representation of it (usually with a smaller dimension), 
- and the decoder that takes the vector representation and produces an approximation of the original input. 

In encoder-decoder RNNs, both input and output are sequences, and instead of approximating the original input, the target output is a ground-truth sequence (e.g., prediction for 5, 10, 15, 20, 25, and 30 minutes into the future)  

> 效果最好，而且可以输出序列而不是答案，所以可以在任意环节输入向量，或提前拿出答案

(T-ZS1) 特点：输出为序列，可以继续做输入等

can output sequences instead of a single result. This means that Encoder-Decoder RNNs can take input data from multiple steps and also output predictions multiple steps ahead  

encoder-decoder RNN (编码器-解码器模型)

- Autoencoder 是深层神经网络，两部分组成：

  编码器把输入转成向量表示(通常更低维度)

  解码器把向量还原为近似成输入

- 对 encoder-decoder RNN

  解码器从近似输入改成近似真实答案 目前的 SOTA

(T-ZS1) 主要使用基于图的方法

To imbue Encoder-Decoder RNN with the capability to capture spatial data, most of these works also utilize graph-based methods  

> (T-ZS1) 评价：与 GNN 一同 SOTA
>
> Despite the complexity of Encoder-Decoder RNNs and graph-based methods, we have observed that this combination has shown to be very proficient at predicting future traffic and is one of the more important recent developments of traffic prediction

##### 评价

(T-ZS1) While state-of-the-art models that commonly use encoder-decoder LSTM combined with graph-based methods, have achieved excellent performance, these promising new techniques may be able to further improve the performance of traffic flow prediction  

##### 具体论文

(T-ZS1) 论文例子：

- T-40
- [T-41](https://dl.acm.org/doi/abs/10.1145/3219819.3219895) 200+引用 2018
- [T-42](https://ieeexplore.ieee.org/abstract/document/8580534) STANN (+注意力+RNN) 60引用 2019
- [T-43](https://dl.acm.org/doi/abs/10.1145/3292500.3330884) 500+引用 2019
- [T-44](https://www.sciencedirect.com/science/article/pii/S0968090X19301330) 250引用 2019
- [T-45](https://ieeexplore.ieee.org/abstract/document/8708297/) (STANN+注意力) 60+引用 2019

#### Transformer

##### 概述

(T-ZS1) Transformer $\approx$ encoder-decoder RNN + 注意力 (可并行)

> Transformers are similar to encoder-decoder RNNs in that
> they take sequences as inputs and outputs sequences. The difference is that Transformers are designed with attention mechanisms in mind and can be parallelized  

开山鼻祖 (机器翻译) [O-5](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)

##### 具体论文

(T-ZS1) 第一个应用 [T-59](https://arxiv.org/abs/2001.02908)

(T-ZS2)

- [T-74]() Transformer
- [T-75](https://arxiv.org/abs/2007.15189) 看标题是交通需求分析的 +GNN
- [T-76](https://ebooks.iospress.nl/volumearticle/55026) 看摘要是打车需求的 +GNN
- [T-77](https://link.springer.com/chapter/10.1007/978-3-030-59410-7_49) +GNN

### GAN

#### 概念

##### 定义

(T-ZS1)  

Generative Adversarial Networks consist of two neural networks that are trained to compete with each other. The two networks are generative networks, designed to capture the data distribution, and discriminative network, which judges whether a given sample came from the true data or from the distribution generated by the generative network  [开山](https://proceedings.neurips.cc/paper_files/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html)

##### 评价

> SOTA 可能是这个
>
> (T-ZS1) While state-of-the-art models that commonly use encoder-decoder LSTM combined with graph-based methods, have achieved excellent performance, these promising new techniques may be able to further improve the performance of traffic flow prediction  

优点是可把序列任意部分访问，无视距离

(T-ZS2) As a special case, Transformer is built entirely upon attention mechanisms, which makes it possible to access any part of a sequence regardless of its distance to the target  

#### 具体应用

(T-ZS1)

- [T-60](https://journals.sagepub.com/doi/abs/10.1177/0361198118798737) LSTM 生成和对抗

  use LSTMs for both the generative and discriminative network  

- [T-61](https://ieeexplore.ieee.org/abstract/document/8438991) 增强边界健壮性

  where a GAN is used to enable traffic flow prediction that is more robust to outliers  

- [T-62]() +图CNN 使用句子到句子的 autoencoder

  combine GAN with graph CNN, and use sequence-to-sequence autoencoder for the generative network  

(T-ZS2)

- [T-74](https://onlinelibrary.wiley.com/doi/abs/10.1111/tgis.12644)

### 混合模型

#### 概念

集各家之长

(T-ZS1) As complex deep neural networks are becoming viable to train, most authors have utilized the hybrid neural network setting, which combines different neural network structures into a larger entity, to maximize the prediction performance  

The popularity of hybrid neural network structure is contributed by its power and flexibility of utilizing the different strengths of its individual components.   

> While complex models are expensive to train, their performance improvements have proven that the investment is worthwhile  

现状：占主要

(T-ZS1) we can see that the simpler “deep neural network” category consists of papers from the earlier years of traffic prediction research while “hybrid deep neural network” and “hybrid deep neural network and graph theory” mostly contain more recent papers. Hybrid deep neural networks combine different types of simple deep neural network structures in order to combine the strengths of each  

#### 对比简单的例子

(T-ZS1) 对比简单模型的例子：

- T-40 encoder-decoder 图扩散比 FNN, LSTM 好，消融证明扩散卷积更好

  have demonstrated that their encoder-decoder model with graph diffusion managed to outperform simple FNN and LSTM. Not only that, they also performed an ablation test to demonstrate that their novel diffusion convolution module manages to outperform simpler variations  

- T-44 与 FNN, LSTM, GRU 对比

  have compared their method against simple FNN, LSTM and GRU, showing similar trends  

结论：复杂的比简单的好，新的技术更好

While we provide only two examples due to space constraints, we can attest that many complex hybrid deep neural network models have managed to outperform simpler deep neural network models and that many novel modules designed to capture spatial and temporal correlations (e.g., spatial and temporal attention) have resulted in further performance improvement  



## 相关数据

### 概述

#### 分类

##### 主数据

参考 T-ZS1 的分类标准，主要数据集可以分为两类：

- 固定式采集数据集(point data)：安装在固定地方的探测器所采集的数据

  > (T-ZS1) 标准数据集为 PeMS

- 移动式交通数据(trajectory data)：GPS 等收集的车辆轨迹信息

  > (T-ZS1) 无标准 do not have a standard dataset  
  >
  > Different works use different datasets with different properties, including the origin country (mostly America or China), method of transportation (cars, taxis or bicycles) and time range
  >
  > trajectory data from Beijing is relatively more popular    

> (T-ZS1) road link data 是特殊的 point data 的理由：
>
> As we can derive the traffic speed from road link data by averaging the speed of vehicles on each road link, we also regard road link data as a special type of point data.  
>
> (T-ZS1) 非主流——使用了 point + 道路连接的论文： 
>
> - use road link data in addition to point data as the main datasets  
>
>   T-12 T-39

##### 辅助数据

此外，可能还需要一些辅助数据信息：

- 交通网络数据：探测器的分布图(欧氏空间网格或无向加权图等)
- 气候数据、日期(节假日)数据、事件(如车祸)数据等

(T-ZS1) In traffic prediction, commonly used external information include weather, accidents, events, day of the week, time of the day and social media data  

### 评价

#### 数据集基准缺乏

参见下文

#### point data

可用性，兼容性好，无序数据转换

(T-ZS1) Point data consists of traffic readings from road-installed sensors. This data is popular due to its availability and compatibility with deep neural network models; usually, point data does not require major data transformation step and can be used as is  

使用/表征方式：向量、矩阵、张量

(T-ZS1) For point data, spatial aspect is typically captured by collating data from multiple detection points into vectors. Sometimes, matrices can be used when capturing both the spatial and the temporal aspects. In addition, tensors can also be used when there are multiple matrices to be used all at once, such as when we are inputting the spatiotemporal traffic data from multiple days at once. These vectors/matrices/tensors are then fed as input into the network where a CNN resides  

优点为：

- 公开数据集可用
- 简单的数据转换
- 可以与图论方法一起用

The advantages of using point data are:

- (T-ZS1) Common public data are available. 

  For instance, the Caltrans data is very commonly used in the literature. Although each work uses different subsets, the availability of one unified data source makes it easier to establish a benchmark data.

  来源权威，覆盖面广

  Point data generally comes from traffic detectors installed by the transportation bureau. Consequently, the system is well-established, resulting in better temporal coverage  

- (T-ZS1) Data transformation is simpler.

  To obtain an input data that contains both the temporal and the spatial trends, the common procedure is just collating the data into vectors/matrices/tensors.

- (T-ZS1) Works better for methods that are based on the graph space. 

  Point data often constitutes traffic detectors installed on roads, which can be easily converted to graphs; each detector site can be treated as a vertex and every two adjacent detectors define an edge.   

限制：

- 成本高昂，几乎没有 arterial/highways 数据

- 与欧氏空间方法不兼容(如 2D CNN 即普通的 CNN)

  因为很多真实空间连成线

(T-ZS1) Although point data has multiple advantages as detailed above, it also has some limitations as listed below:

- (T-ZS1) Almost exclusive highways data.

  Since traffic loop detectors are difficult and expensive to install, they are not commonly available for arterial roads.

  > However, as traffic detectors are costly to install, they are mostly limited to highways  

  (T-ZS2) While traffic sensors have been successfully used, data collection for traffic flow information is still a challenge when considering the high costs in deployment and maintenance of traffic sensors.  

- (T-ZS1) Not compatible with methods that conform to the Euclidean space (e.g. 2D CNN). 

  This is because most point-based data are highways data where the traffic detectors are spatially organized in a line.  

#### trajectory data

如果使用轨迹数据，每条轨迹映射到 2D 平面网格，优点：

- GPS 数据，覆盖了 arterial roads(干道) 和 highways(公路)
- 对欧氏空间方法更好
- 结果可视化/可解释简单

The advantages of trajectory data are:

- (T-ZS1) Not exclusive to highways data. 

  Trajectory data are usually GPS data, which cover both arterial roads and highways.

  > has a more general spatial coverage as drivers pass through arterial, urban and highway roads alike  

- (T-ZS1) Works better for methods that are based on the euclidean space.

  After the data processing, the spatial correlation is inherently captured within the resulting 2D plane. Additionally, the resulting data transformation output is a matrix, which naturally fits 2D CNN. Finally, trajectory data usually cover city regions, which usually conform to the 2D shape.

- (T-ZS1) Results are easily interpretable. 

  By visualizing the values assigned to each grid in the 2D map, the region’s traffic flow prediction can be observed directly. 

缺点：

- 数据转换到 2D 平面复杂 (故文献少)
- 不能建图用图论方法
- 时间覆盖没这么广
- 数据质量

(T-ZS1) For trajectory data, utilizing the Euclidean space is common. Each trajectory needs to be mapped onto a 2D plane which represents the region (e.g. city, country) where the data resides. This region is divided into grids where each grid represents a subregion. Processing the data this way yields a matrix that represents the traffic state of a region, which can be fed into a CNN to capture the spatial aspect.

The disadvantages of trajectory data are:

- (T-ZS1) Complex data transformation. 

  The process of mapping each trajectory point to the 2D plane is complex and time consuming.

- (T-ZS1) Not compatible with methods that model their data using graph-based methods. 

  Points in the road network can be transformed into vertices and the connections between them can be mapped to edges. This is not possible for trajectory data.  
  
- (T-ZS1) the temporal coverage is limited, ranging from a month (T-36 T-37) to several months (T-1 T-37 T-51) and up to one year (T-49 T-30), compared to the Caltrans data, for instance, which contains more than five years’ worth of data for its detectors  

(T-ZS2) Another potential approach is using the pervasive mobile and IoT devices, which have a lower cost generally, e.g., GPS sensors. However, challenges still exist when considering the data quality problems frequently seen in GPS data, e.g., missing data caused by unstable communication links  

(T-ZS1) 更推荐轨迹数据

The installation of traffic detectors is expensive, and point data’s spatial limitation is difficult to address. Therefore, we recommend focusing on trajectory data. Floating car data collected from GPS is the most widespread and efficient source of trajectory data. However, researchers must take into account the required preprocessing to use trajectory data for traffic prediction  

#### 日期

> 日期容易结合：
>
> (T-ZS1) Conversely, time-of-day and day-of-week data are much easier to incorporate
>
> 日期少于一年的缺点：
>
> (T-ZS1) 26 out of 37 literatures use less than one year’s worth of data. This deficiency will have an adverse impact on sub-tropical regions, as seasonal changes may affect temperature and weather, which in turn can affect traffic. By using data from only one or several months, the model cannot generalize to different seasons. This can be mitigated by incorporating weather data, but as mentioned before, this is a difficult and time-consuming task.  
>
> 时间不完整一天/周的缺点：
>
> (T-ZS1) e-consuming task. Some authors also use data from only a certain range of hours or use data from weekdays only. This will also cause problems as the model cannot generalize well to situations outside the boundaries of the provided data. For instance, using traffic data from 07.00 AM to 11.00 PM only may reduce the model’s performance on the excluded hours, and using only weekdays data may adversely impact the model’s performance when predicting weekend traffic  

#### 结合数据

参见下文未来趋势

#### 真实性

> 数据要趋于真实的理由：
>
> (T-ZS1) using vastly different datasets may result in an entirely different model. Thereby, for a model to be applicable to real application scenarios, it is important to use a dataset that closely resembles those scenarios.  

#### 时间粒度

> 时间粒度：大部分 5min (默认)，推荐 15min
>
> (T-ZS1) using vastly different datasets may result in an entirely different model. Thereby, for a model to be applicable to real application scenarios, it is important to use a dataset that closely resembles those scenarios.  
>
> (T-ZS1) 指出[文献](https://onlinepubs.trb.org/Onlinepubs/trnews/rpo/rpo.trn129.pdf)推荐 15min 粒度
>
> 数据粒度的辩证讨论：对结果和训练/输入的影响
>
> Depending on the dataset, the data granularity is a potentially important hyperparameter. Using a data granularity that is too small may cause a lot of zero values, especially during conditions where traffic is very sparse. For example, it is highly likely for a traffic loop detector to not detect any cars in 2 or 5 minute periods during off-peak hours (e.g. 02:00 04:00 AM) while this becomes less likely if the granularity is increased to 15 minutes or more. On the other hand, using a granularity that is too high might result in the smoothness of the traffic flow reading where important trends are lost. For instance, if the traffic experiences periodic shifts during 12:30PM, this trend might not be detected if the data granularity is one hour.
>
> Data granularity also impacts the number of possible data points as well as the size of the input sequence. Using a smaller granularity will increase the length of the required data sequence. For instance, one hour’s worth of data can be captured with only a sequence of length 4 when the granularity is 15 minutes, but when the granularity is 5 minutes, the sequence length is 12. This can impact training time, especially for RNN-based models.  
>
> Due to the aforementioned reasons, choosing the correct data granularity becomes a decision based on trade-offs and should be considered carefully depending on the data, the model, as well as the application scenarios  

#### 输入输出长度

> (T-ZS1) 多个长度都试一下，一般输入输出正相关，未得到充分研究：超参搜索耗时。多数是人为设置的，因为搜索超参太慢。可以用小数据集做超参搜索来缓解该问题。
>
> many authors perform experiments with different prediction horizons and use different input sequence lengths for each of the selected prediction horizons  
>
> Intuitively, as we increase the prediction horizon, the input sequence length also needs to be increased. This is because the increase in prediction horizon means predicting the traffic of further time frame in the future and thus, increasing the task complexity. Increasing the size of the data points by extending the input sequence may help in tackling the complex problem.  
>
> Unfortunately, the relationship between the input sequence length and the prediction horizon is rarely explored by the literature. Most of the input sequence lengths were chosen arbitrarily without iterating through different possible values. This is because hybrid deep neural network structures take a long time to train, which makes iterating through different settings unwieldy. Despite this issue, hyperparameter search remains an important facet of deep neural network development that cannot be omitted. One possible remedy of this problem is to first use a smaller data, chosen randomly from the main dataset, to find the optimal parameter setting.  

### 列表

列出部分常用的数据集：

- [PeMS](http://pems.dot.ca.gov/) (Caltrans Performance Measurement System)

  研究最广泛的数据集，由加利福尼亚州主要公路的上万探测器收集，每半分钟采集一次，包含容量、速度、交通流量等多种数据

  有多个子集广泛用于论文中，包括 PeMS-BAY、PeMSD3、PeMSD4、PeMSD7、PeMSD8 等，可以参考 [这篇综述](https://arxiv.org/pdf/2101.11174?trk=public_post_comment-text)

  > 优点 (T-ZS1) public availability, ease of download, simple structure and long historical data  
  >
  > 提供的数据、粒度 (T-ZS1) provides information regarding date, time stamp, traffic flow per lane, and aggregated traffic flow. Traffic flow is the most commonly used field, but occupancy and speed information is also available. The data granularity can be set to 5 minutes, hourly, daily, weekly and monthly depending on user requirements  

  官网有图片提供(直接打开官网即可看到)

- [METR-LA](https://github.com/liyaguang/DCRNN) (Metro Traffic Los Angeles)

  洛杉矶公路网，207 个探测器，5 分钟间隔收集数据

- [Seattle Loop](https://github.com/zhiyongc/Seattle-Loop-Data)

  西雅图 4 条路数据，323 个探测器，5 分钟间隔收集数据，2015 年 1 月数据

- [SZ-Taxi](https://github.com/lehaifeng/T-GCN)

  深圳罗湖区 156 条路的数据，15 分钟粒度，2015 年 1 月数据

- [Beijing Traffic](https://github.com/deepkashiwa20/Urban_Concept_Drift)

  北京市 3126 个路段在 2022 年 5-7 月的 5 分钟粒度的数据

- [Q-Traffic](https://github.com/JingqingZ/BaiduTraffic)

  北京 2017 年 4-5 月一万多个路段每 15 分钟采样一次的百度地图数据、
  
- [NYC Taxi](https://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml)

  (T-ZS2) The taxi trip records in New York starting from 2009, in both yellow and green taxis. Each trip record contains pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts.

北京：

(T-ZS1) it is unclear as to whether or not all of the Beijing-based datasets come from one unified dataset source  

(T-ZS1 stated:) usually cover the Ring Road area

- 用到的 (2015, 2k引用) [T-25](https://www.sciencedirect.com/science/article/pii/S0968090X15000935)、(2017, 100引用) [T-26](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-its.2016.0257)、(2016, 180引用) [T-27](https://ieeexplore.ieee.org/abstract/document/7795712)、(2018，近4k引用) [T-28 STGCN](https://arxiv.org/abs/1709.04875)
- T-25 contains the traffic volume, occupancy and speed data (2017, 近500引用) [T-29](https://epubs.siam.org/doi/abs/10.1137/1.9781611974973.87)

其他数据集：参见 [paperwithcode 网站：Traffic Prediction Task](https://paperswithcode.com/task/traffic-prediction)、[这篇综述](https://arxiv.org/pdf/2101.11174?trk=public_post_comment-text)、[TKDE2020综述](https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=6998&context=sis_research)、[这篇综述](https://kns.cnki.net/kcms2/article/abstract?v=7sQefmFxFK3uEKBquRla5qDHveK9oCCRpBWf04Zyi-hciTPIaXDHO5AckFT2OGZGmxYUV8QI8BcEApyz73mJ280tQxDTOIZYSnF6llnWzinghcTnd6z1lC2pEY218-lrd9AoSHndDepAUNkp_yiHGfr7Tsk5vANL&uniplatform=NZKPT&language=CHS)。

### 统计

(T-ZS1) 

表格的评价尺度：

- 参考([xx])、作者、年份、主要数据类型、主数据集、时间范围、粒度、次要数据集、输入序列长度、预测视野

- 模型分类、预测值、时/空、模型子分类

  > 时空分类的具体定义参见论文，指模型专门用来处理哪一部分，or both

数据集

- PeMS 14/37
- 北京点数据和轨迹数据，各 6/37

辅助数据

- 天气 6/37 ；时间(time of day / day of week) 3/37  ；路网(road network) 3/37

数据跨度

- 一个月 5/37；数个月 22/37；一年 6/37；超过一年 4/37

模型：

- LSTM 18/37； 混合模型 21/37； 其他DNN(SAE, DBN) 6/37

## 未来挑战

> ### 现存挑战
>

#### 响应式方案

(T-ZS1) 响应式方案：如交通事故，天气变化融入到模型

Developing responsive algorithms and prediction schemes. 

Several of the recent works have attempted to address the problem of algorithm responsiveness in the face of unexpected traffic incidents such as accidents and weather changes. This is mainly done by using weather and accidents data as additional inputs to the traffic flow prediction models

- 如 T-55 使用 Dempster-Shafer theory 结合天气与交通流数据(参见上文)

  combined weather and traffic flow data using the Dempster-Shafer theory  

- 如 T-30 单纯结合天气 

  simply concatenated weather and traffic flow data  

- 如 T-51 简单相加

  performed simple addition  

评价：缺乏消融实验

lack ablation tests which can reveal the effectiveness of utilizing weather data  

有实验的：

- T-53 嵌入天气 + 消融实验

  incorporated weather data by embedding them into the traffic flow data in their test and performed a simple ablation test, which proved that the inclusion of weather data does improve prediction performance  

- T-52 事故+模拟实验

  performed a network stimulation test to understand the
  effect of sudden traffic accidents  

评价：探索不足，融合数据困难

As we can see, several authors have tested the impacts of weather and accidents in traffic flow prediction. Although several experiments have proven that the addition of these data can increase the prediction power of the models and increase their responsiveness to unexpected changes in traffic, this facet of traffic prediction has not been explored in great depth. This is due to the difficulty of incorporating these external data. Overcoming the challenge of data incorporation is the first step in utilizing weather and non-recurring incidents data in general to improve model responsiveness.  

#### 不同路段的预测

(T-ZS1) Freeway, arterial and network traffic predictions. 

The authors mentioned several related sub-challenges: the complexity of urban arterial traffic prediction, network-level traffic prediction and the incorporation of network dynamics on traffic prediction  

数据的缺乏，采集数据成本过大，只在 highways 有

轨迹数据可以代替网络预测(network-wide prediction)，覆盖 arterial 和 highways

While the prediction of traffic in urban arterial roads and network-level traffic prediction are dissimilar challenges, the cause is the same: the lack of traffic detectors on urban arterial roads. This is because installing traffic detectors is costly and thus, is often done only on highways. However, the increasing amount of trajectory data has resulted in an alternative solution for network-wide prediction, as car trajectories cover both arterial and highways alike.  

使用了轨迹数据的论文：T-29, T-1, T-51, T-30, T-37，具体参见上文

动态网络的预测(路网数据)使用图论方法：

The third challenge, incorporation of network dynamics on traffic prediction, is caused by traffic flow readings not inherently containing road network data. Therefore, this operation has to be done manually through data modeling. The most popular method to capture network data is to use graph-based methods  

使用了图论的论文：T-4 T-28 T-40 T-39

忽略了 T-ZS1 对 CNN, RNN 获取时空依赖这一段的描述，忽略了对 GNN 一段的描述

#### 模型解释能力

(T-ZS1) Explanatory power, associations and causality  解释力、关联、因果关系

模型参数难以理解，NN 是黑盒模型

参考上文具体技术，神经网络节的优缺点处

如：

- T-40 观察图扩散过程和邻节点关联

  observed the traffic diffusion along the road network and the correlation between several adjacent traffic sensors

- T-39 可视化网络权重以预训练不同探测器找到关键路段

  visualized the network weights pertaining to different detector sites to find key road segments in the traffic network

- T-4 可视化注意力权重上下流，观察交通流的移动

  visualized the attention weights of upstream and downstream stations to observe how traffic flow moves across several traffic stations

(T-ZS1) 解读参数的意义

Performing explanatory analyses on neural networks may uncover useful traffic patterns 

黑盒模型，只解释了空间方面的一部分内容

While neural networks have proven to be a very effective prediction model, they are infamously known as black-box models; models that are difficult to dissect and explain. Although the aforementioned authors managed to explain the traffic phenomena to some degree, their observations are mostly limited to the spatial aspect; observing how the traffic at one site affects another and how traffic propagates across the road network. To the best of our knowledge, there  is no work that observes other aspects of the prediction, such as the dynamics of abrupt weather changes and accidents.  

> ### 未来挑战

#### 缺乏基准数据集

Lack of a benchmark dataset

(T-ZS1) 难以对比，且同一数据集也有多个子集

The availability of a wide range of traffic data supports traffic prediction. However, this availability also poses a challenge to comparative work. Due to the fact that different works use different datasets, it is very hard to assess the relative performance of different state-of-the-art models. The Caltrans data is the closest to a benchmark dataset, as it is used by 14 out of 37 literatures we have covered. However, different works use different subsets of the Caltrans from different periods of time and from different traffic detector sites  

但选择大的子集存在训练代价困难，依赖复杂；选择小的子集难以拟合真实数据，在时空上分别讨论

Choosing a subset of data within a larger dataset also poses a challenge. As temporal and spatial correlation affects traffic greatly, the period of the data and the traffic detector locations become important considerations. For instance, when using data that covers a period of less than a year, there is a risk of not capturing the seasonal effects on traffic, and when using only weekdays data, the models cannot learn weekend traffic well. For the spatial aspect, the choice of roads or highways can greatly affect the traffic flow as metropolitan roads have significantly busier traffic compared to rural areas, and long interstate highways tend to cover both rural and metropolitan areas. Models that are trained on a certain traffic condition may not perform well when used to predict traffic on significantly different traffic

理想的基准数据集：城乡结合、工作日周末结合、一天各时段、至少一年

For deep neural network models to perform well on real applications, the dataset needs to mimic real data. Therefore, it is important for benchmark datasets to cover enough time frame and locations so that the models can generalize well to any traffic situations. To overcome this challenge, the following criteria are important:

- The data covers both urban and rural areas.
- The data covers both weekdays and weekends.
- The data covers all hours of the day.
- The temporal range is at least one year

#### 数据结合难

(T-ZS1) Difficulty of incorporating external information with traffic data

> 结合数据的困难：难以包含外部信息：天气、车祸、事件、星期、时刻、媒体信息
>
> (T-ZS1) one model that uses the Caltrans data covering a long highway will need to match the time stamp, the latitude, and the longitude of each reading in order to find the appropriate weather and accidents data  
>
> - 时间容易其他难：理由是需要和具体时空对应
>
>   While the inclusion of day of the week and time of the day is relatively simple, data that are bound to a specific geographical coordinate or a geographical area is difficult to incorporate with traffic data. This is because the process requires the coordinates of detection points (in the case of point data) or trajectory points (in the case of trajectory data) to be mapped to the secondary data
>
> 成本变大：
>
> (T-ZS1) added time complexity of aggregating the different data together , which is undesirable, especially in an already time-consuming hybrid deep neural network structure  

理想数据：时空覆盖广、增加时间、增加天气和事故

A benchmark data that covers a specific area within a specific period, complete with relevant secondary data will greatly benefit the traffic flow field. We recommend the following sequence of actions:

1) Establish a benchmark dataset that has sufficient spatial and temporal coverage based on the requirements mentioned in the previous challenge.
2) Add day of the week and time of day data by concatenating them with the traffic reading data.
3) Add geographical-related data, such as weather and accidents data to every traffic data reading. For instance, one reading at a particular time stamp and location will have both the traffic flow, current weather and accident type, if any accident occurs at the location.  

#### 在线学习

(T-ZS1) Online learning.

在线学习。持续更新应对 concept drift 的存在。现状：没有研究探索在线学习：但训练开销大，模型复杂难以更新。需要考虑更新频率和数据数目、更新所用时间。

> Concept Drift（概念漂移）指的是数据分布或数据生成过程发生变化的现象。训练与真实不一致就会概念漂移

In this setting where new data is incrementally added, traffic trends will shift over time. This is applicable even for the same traffic detector site. This idea is called concept drift and it causes the relationship between the input and output data to change over time, rendering models that are trained on past data to degrade in performance on present and future data  

> One way to mitigate this problem is to incrementally update the prediction model with new data in real-time, in a process often called online learning. However, to the best of our knowledge, there is no work that explores online learning in the traffic prediction domain. This can be attributed to the time complexity of training hybrid deep neural network model and the lack of attention to the concept drift problem. Online learning is a promising subtopic to explore in the field of traffic prediction as this will ensure that complex deep neural network models are always up-to-date. Experiments that seek to identify the viability of online training will need to take into account the following factors:
>
> - The frequency of which the deep neural network models need to be retrained. Practitioners need to ask the question “How often do we need to update our prediction model to ensure that it is always upto-date?”
>
> - The number of data points required for the update, which is affected by the frequency and has to reflect real life scenario. Practitioners need to ask the questions “How much data can we acquire during a certain period?” and “How long will it take to collect and preprocess the data to fit it into the prediction models?”  
>
> - The time required for the model to be re-trained using the specified number of data points and whether or not it is suitable for real life scenario. Practitioners need to ask the question “With the available amount of data, will the training of the model be fast enough such that daily operations are not hindered?”  

#### 其他领域任务

(T-ZS1) Exploring other traffic prediction tasks

其他领域问题。子问题/其他问题可能会启发该问题。如交通拥挤分析。

Currently, the Intelligent Transportation Systems (ITS) field greatly focuses on traffic flow prediction, neglecting the other traffic prediction tasks. Exploring these subproblems may bring new insights that are able to help the main traffic prediction task. As we mentioned before, deep neural network models are black-box models. Models that are trained on the traffic flow prediction may not be able to explain the intricacies of traffic patterns. Additionally, each of the subproblems is interesting by itself as its results can be directly used by drivers and traffic management bureau alike to make educated decisions. One example of these prediction tasks is traffic congestion analysis. Knowing how traffic congestion moves throughout the network can assist in the traffic prediction task  

#### 缺乏最新试验评估

(T-ZS1) Lack of up-to-date experimental evaluation  

> there is a lack of up-to-date and comprehensive experimental evaluation, making it difficult to assess how promising these specific ideas are  

缺乏最新试验评估 (最大的问题)。库简化了实现，每个论文实现了不同的想法，但没有综合的整理。缺乏基准数据集，代码有效性(可复现性)。

> Experimental evaluation in traffic flow prediction is complex due to two factors. The first is the lack of benchmark dataset, a problem that we have discussed above. The second is the lack of code availability. One might attempt to recreate the model from the author’s description. However, while the deep neural network aspect can be recreated relatively easy, novel components, such as graph diffusion, are difficult to build in a way that is faithful to the source material  
>
> This lack of experimental evaluation is perhaps the largest challenge that the traffic flow prediction community faces. Addressing this problem will enable practitioners to easily identify the effectiveness of new ideas in improving prediction performance, model efficiency, and the overall applicability of deep neural network models in real-time traffic prediction applications  
>
> 意义：
>
> We believe that the future of the traffic flow prediction field lies on determining a more standardized approach that ensures that the significance of every novel idea can be identified  
>
> 建议做法：开源
>
> to provide more transparency in this research field. Implementation details and publicly accessible codes will be necessary  

基准实验评估需要考虑：新想法的影响、CNN/RNN 类型的影响、应用性和重训练时间、外部数据如天气的作用(消融实验)

> A benchmark experimental evaluation needs to take into account the following insights:  
>
> - The impact of each model’s novel ideas to the prediction power, particularly for models that use a similar network structure.
> - The impact of using a certain neural network type such as CNN and RNN.
> - The viability in real life applications with respect to the retraining time. That is, online learning using a realistically sized batch of data, e.g. data from one week.
> - The impact of using external information such as weather and accidents data. This can be observed by performing an ablation test on models that utilize these external information  

#### 应用新技术

(T-ZS1) Applying Emerging Techniques   

## 写作技巧

根据阅读归纳：

论文作者人名：一个人就人名(姓)，两个人就 and，三个人就 et al.

中文也名在前，且名两个字只有第一个字大写首字母
